{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"NAPT - Not a Pkg Tool","text":"<p>Automated Windows application packaging and deployment to Microsoft Intune using PSAppDeployToolkit</p> <p> </p>"},{"location":"#overview","title":"Overview","text":"<p>NAPT is a Python-based CLI tool that automates the entire workflow for packaging Windows applications and deploying them to Microsoft Intune. It runs on Windows, Linux, and macOS, though packaging (.intunewin creation) requires Windows.</p>"},{"location":"#why-napt","title":"Why NAPT?","text":"<p>Packaging applications for Microsoft Intune with PSAppDeployToolkit (PSADT) typically involves a manual, time-consuming process:</p> <ol> <li> <p>Manually check for new versions - Check vendor sites/APIs for updates. Easy to miss versions or waste time when nothing changed.</p> </li> <li> <p>Create PSADT deployment - Copy template, manually edit <code>Invoke-AppDeployToolkit.ps1</code> with variables, configure install/uninstall logic. Error-prone and repetitive.</p> </li> <li> <p>Create detection script - Write PowerShell detection logic, test thoroughly, maintain version checks. Must update for each new version.</p> </li> <li> <p>Package as .intunewin - Run IntuneWinAppUtil.exe manually, manage paths, handle errors. Tedious and error-prone.</p> </li> <li> <p>Upload to Intune - Upload package via portal, fill metadata, configure app info and requirements manually.</p> </li> <li> <p>Configure deployment - Set up rollout assignments manually for each version.</p> </li> </ol> <p>This manual workflow is repetitive, difficult to automate in CI/CD pipelines, lacks version tracking, and requires re-doing most of the work for every update. NAPT automates this entire workflow with YAML-based recipes and automatic version tracking.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\u2705 Automatic version tracking - Automatic discovery from MSI, EXE, URLs, or APIs with caching to skip unnecessary downloads</li> <li>\u2705 YAML-based recipes - Define app packaging once with layered configuration (Organization \u2192 Vendor \u2192 Recipe)</li> <li>\u2705 Automated PSADT packaging - Generate Intune-ready packages with detection scripts, no manual template editing</li> <li>\u2705 Cross-platform workflow - Run on Windows, Linux, and macOS (packaging requires Windows)</li> <li>\ud83d\udea7 Direct Intune upload - Automatic deployment (planned)</li> </ul>"},{"location":"#cross-platform-support","title":"Cross-Platform Support","text":"Feature Windows Linux/macOS Discovery &amp; Download \u2705 \u2705 PSADT Package Building \u2705 \u2705 Intune Packaging \u2705 \u26ab Windows Only <p>See the Cross-Platform Support section for detailed workflows.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Most users interact with NAPT via CLI - see the Quick Start Guide for installation instructions and your first steps with NAPT.</p>"},{"location":"#creating-recipes","title":"Creating Recipes","text":"<p>Recipes are YAML configuration files that define how to discover, download, and package applications.</p> <p>Example recipes:</p> <ul> <li>chrome.yaml - url_download strategy with MSI version extraction</li> <li>7zip.yaml - web_scrape strategy for vendor download pages</li> </ul> <p>NAPT supports multiple discovery strategies (url_download, web_scrape, api_github, api_json) - see the Discovery Strategies guide for detailed configuration and more examples.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Ideas and feedback are welcome! See Contributing for guidelines.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the Apache License 2.0 - see the LICENSE file for details.</p>"},{"location":"#author","title":"Author","text":"<p>Roger Cibrian</p>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<ul> <li>Draws inspiration from AutoPkg for macOS application packaging automation</li> <li>Uses PSAppDeployToolkit (PSADT) for Windows application packaging</li> <li>Uses IntuneWinAppUtil for creating .intunewin packages</li> </ul>"},{"location":"branching/","title":"Branching Strategy","text":"<p>NAPT uses GitHub Flow - a simple, branch-based workflow that keeps <code>main</code> always deployable.</p>"},{"location":"branching/#core-principles","title":"Core Principles","text":"<ol> <li><code>main</code> branch is always stable - Production-ready code only</li> <li>Feature branches for all work - Every change starts from a branch</li> <li>Pull Requests for review - All changes reviewed before merging</li> <li>Merge frequently - Keep branches short-lived (&lt; 1 week ideal)</li> </ol>"},{"location":"branching/#quick-start","title":"Quick Start","text":"<p>The most common workflow for making changes:</p>"},{"location":"branching/#1-start-new-work","title":"1. Start New Work","text":"<pre><code># Always start from updated main\ngit checkout main\ngit pull origin main\n\n# Create your feature branch\ngit checkout -b feature/your-feature-name\n</code></pre>"},{"location":"branching/#2-during-development","title":"2. During Development","text":"<pre><code># Make changes, commit frequently\ngit add .\ngit commit -m \"feat: add your feature\"\n\n# Push your branch\ngit push origin feature/your-feature-name\n</code></pre>"},{"location":"branching/#3-create-pull-request","title":"3. Create Pull Request","text":"<ol> <li>Push your branch to GitHub</li> <li>Create a Pull Request on GitHub</li> <li>Fill out the description using the PR template</li> <li>Request review from maintainers</li> <li>Address any feedback</li> </ol>"},{"location":"branching/#4-after-merge","title":"4. After Merge","text":"<pre><code># Update your local main\ngit checkout main\ngit pull origin main\n\n# Delete your local feature branch\ngit branch -d feature/your-feature-name\n\n# Remote branch is usually auto-deleted by GitHub\n</code></pre>"},{"location":"branching/#branch-management","title":"Branch Management","text":""},{"location":"branching/#branch-structure","title":"Branch Structure","text":"<pre><code>main (always deployable)\n\u251c\u2500\u2500 feature/add-rpm-support\n\u251c\u2500\u2500 bugfix/fix-version-parsing\n\u251c\u2500\u2500 docs/update-installation-guide\n\u2514\u2500\u2500 refactor/simplify-config-loader\n</code></pre>"},{"location":"branching/#branch-naming-convention","title":"Branch Naming Convention","text":"<p>Use descriptive names with type prefixes:</p> Prefix Purpose Example <code>feature/</code> New features or enhancements <code>feature/add-rpm-support</code> <code>bugfix/</code> Bug fixes <code>bugfix/fix-version-parsing</code> <code>docs/</code> Documentation updates <code>docs/update-installation-guide</code> <code>refactor/</code> Code improvements (no behavior change) <code>refactor/simplify-config-loader</code> <code>test/</code> Test additions/improvements <code>test/add-integration-tests</code> <code>chore/</code> Maintenance tasks <code>chore/update-dependencies</code> <code>hotfix/</code> Urgent production fixes <code>hotfix/security-patch</code>"},{"location":"branching/#naming-rules","title":"Naming Rules","text":"<ul> <li>Use lowercase with hyphens</li> <li>Be descriptive but concise (3-6 words)</li> <li>Avoid generic names like <code>fix-bug</code> or <code>updates</code></li> <li>No issue numbers in branch names (use commit messages instead)</li> </ul> <p>Good Examples: <pre><code>feature/add-exe-version-extraction\nbugfix/fix-download-resume-logic\ndocs/add-cross-platform-examples\nrefactor/simplify-config-loader\n</code></pre></p> <p>Bad Examples: <pre><code>my-branch              # No type prefix\nfeature/stuff          # Not descriptive\nFeature/My_Branch      # Wrong case\nfix-bug                # Too generic\n</code></pre></p>"},{"location":"branching/#commit-guidelines","title":"Commit Guidelines","text":""},{"location":"branching/#commit-message-format","title":"Commit Message Format","text":"<p>Use conventional commit format for clarity:</p> <pre><code>&lt;type&gt;: &lt;description&gt;\n\n[optional body]\n</code></pre>"},{"location":"branching/#commit-types","title":"Commit Types","text":"Type Purpose Example <code>feat</code> New feature <code>feat: add EXE version extraction</code> <code>fix</code> Bug fix <code>fix: correct version comparison logic</code> <code>docs</code> Documentation <code>docs: update installation instructions</code> <code>refactor</code> Code improvement <code>refactor: simplify config loading</code> <code>test</code> Tests <code>test: add tests for MSI extraction</code> <code>chore</code> Maintenance <code>chore: update Poetry dependencies</code> <code>perf</code> Performance <code>perf: optimize version comparison</code>"},{"location":"branching/#commit-guidelines_1","title":"Commit Guidelines","text":"<ul> <li>Use imperative mood: \"add\" not \"added\" or \"adds\"</li> <li>Keep subject line under 50 characters</li> <li>Capitalize subject line</li> <li>No period at end of subject</li> <li>Separate subject from body with blank line</li> </ul> <p>Good Examples: <pre><code>git commit -m \"feat: add RPM version extraction support\"\ngit commit -m \"fix: handle missing ETag headers gracefully\"\ngit commit -m \"docs: add examples for Linux MSI extraction\"\n</code></pre></p> <p>Bad Examples: <pre><code>git commit -m \"added stuff\"           # Not descriptive\ngit commit -m \"Fix bug\"               # No type prefix\ngit commit -m \"WIP\"                   # Too vague\n</code></pre></p>"},{"location":"branching/#pull-request-process","title":"Pull Request Process","text":""},{"location":"branching/#pull-request-description-template","title":"Pull Request Description Template","text":"<pre><code>## Description\nBrief description of what this PR does.\n\n## Motivation\nWhy is this change needed?\n\n## Changes\n- Bullet list of key changes\n- Include any breaking changes\n\n## Testing\nHow was this tested?\n- [ ] Unit tests added/updated\n- [ ] Integration tests added/updated\n- [ ] Manual testing performed\n\n## Checklist\n- [ ] Code follows project conventions\n- [ ] Documentation updated\n- [ ] Tests pass\n- [ ] No linting errors\n</code></pre>"},{"location":"branching/#merge-strategy","title":"Merge Strategy","text":"<p>Default: Squash and Merge</p> <p>NAPT uses squash and merge for most Pull Requests to maintain a clean, readable history in <code>main</code>.</p>"},{"location":"branching/#why-squash-and-merge","title":"Why Squash and Merge?","text":"<ul> <li>\u2705 Clean history: One commit per feature/fix in <code>main</code></li> <li>\u2705 Conventional commits: Each merge becomes a properly formatted commit</li> <li>\u2705 Easy rollback: Revert entire features with one command</li> <li>\u2705 Better changelogs: No noise from \"WIP\" or \"fix typo\" commits</li> <li>\u2705 Simple bisecting: Each commit represents a complete, working change</li> </ul>"},{"location":"branching/#when-to-use-each-strategy","title":"When to Use Each Strategy","text":"<p>Squash and Merge (Default - 95% of PRs)</p> <p>Use for: - Feature additions - Bug fixes - Documentation updates - Refactoring - Chores and maintenance</p> <p>When merging on GitHub: 1. Click \"Squash and merge\" 2. Edit the commit message to follow conventional commit format 3. Summarize all changes in the commit body 4. Reference any issues with <code>Closes #XX</code></p> <p>Example: <pre><code>feat: add RPM version extraction support\n\n- Implement RPM ProductVersion parser using rpm-py-installer\n- Add cross-platform support for RPM files (Linux/macOS)\n- Add comprehensive test coverage with mock RPM files\n- Update documentation with RPM examples\n\nCloses #42\n</code></pre></p> <p>Regular Merge (Exceptional Cases)</p> <p>Use only when: - Multiple authors need attribution for distinct contributions - Release PRs where version bump history should be preserved - Large features with logically separate commits worth keeping</p> <p>Example scenarios: - Version bump PRs (preserve \"bump version\" + \"update changelog\" as separate commits) - Community contributions with multiple meaningful commits - Complex refactors where commit-by-commit history aids debugging</p>"},{"location":"branching/#workflow","title":"Workflow","text":"<ol> <li>Before creating PR: Clean up your branch commits if needed</li> <li>During review: Add commits normally (don't squash yet)</li> <li>When merging: Use GitHub's \"Squash and merge\" button</li> <li>After merge: Branch is auto-deleted, pull latest <code>main</code></li> </ol>"},{"location":"branching/#tips","title":"Tips","text":"<ul> <li>Don't worry about messy commits in your branch - they'll be squashed</li> <li>Focus on clear PR descriptions - they become the squash commit message</li> <li>Use conventional commit prefixes in PR titles for easy squashing</li> <li>If you accidentally use wrong merge method, you can revert and redo</li> </ul>"},{"location":"branching/#troubleshooting-scenarios","title":"Troubleshooting &amp; Scenarios","text":""},{"location":"branching/#multiple-related-changes","title":"Multiple Related Changes","text":"<p>If changes are closely related, keep in one branch: <pre><code>feature/add-exe-support\n  \u251c\u2500\u2500 Add EXE parsing module\n  \u251c\u2500\u2500 Add tests\n  \u2514\u2500\u2500 Update documentation\n</code></pre></p> <p>If changes are independent, use separate branches: <pre><code>feature/add-exe-support\nfeature/add-rpm-support\n</code></pre></p>"},{"location":"branching/#long-running-features","title":"Long-Running Features","text":"<p>For features taking multiple days/weeks: 1. Keep branch updated with <code>main</code> regularly 2. Break into smaller PRs if possible 3. Use draft PRs to show progress 4. Consider feature flags for incomplete features</p>"},{"location":"branching/#urgent-hotfixes","title":"Urgent Hotfixes","text":"<p>For critical production issues: <pre><code># Branch from main\ngit checkout main\ngit pull origin main\ngit checkout -b hotfix/fix-security-vulnerability\n\n# Fix, test, and push\ngit commit -am \"fix: patch security vulnerability\"\ngit push origin hotfix/fix-security-vulnerability\n\n# Create PR with high priority\n# Fast-track review and merge\n</code></pre></p>"},{"location":"branching/#best-practices-quality-checks","title":"Best Practices &amp; Quality Checks","text":""},{"location":"branching/#do","title":"DO \u2705","text":"<ul> <li>Create small, focused branches with single purpose</li> <li>Commit early and often with clear messages</li> <li>Keep branches short-lived (merge within 1 week)</li> <li>Run tests before pushing (<code>pytest tests/</code>)</li> <li>Format code before committing (<code>black notapkgtool/</code>)</li> <li>Update branch with <code>main</code> if it's behind</li> <li>Delete branches after merging</li> </ul>"},{"location":"branching/#dont","title":"DON'T \u274c","text":"<ul> <li>Never commit directly to <code>main</code></li> <li>Don't create long-lived feature branches</li> <li>Don't use generic branch/commit names</li> <li>Don't merge without tests passing</li> <li>Don't force push to shared branches</li> <li>Don't include unrelated changes in one PR</li> </ul> <p>Last Updated: 2025-11-18</p> <p>Strategy: GitHub Flow with Squash and Merge</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to NAPT (Not a Pkg Tool) will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Detection Script Generation - Automatic PowerShell detection script generation for Intune Win32 app deployments during build process. Scripts check Windows uninstall registry keys, support exact or minimum version matching, and include CMTrace-formatted logging</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Discovery Performance Optimization - Version-first strategies (web_scrape, api_github, api_json) now check versions before downloading, enabling ~100-300ms update checks when unchanged instead of full downloads</li> <li>State file now saves actual download URLs for all strategies</li> <li>url_download Strategy Simplification - Removed <code>version.type</code> configuration requirement. MSI files are now auto-detected by file extension (<code>.msi</code>) for version extraction</li> <li>BREAKING: Uniform Strategy Naming - Discovery strategies renamed to follow consistent <code>&lt;source&gt;_&lt;method&gt;</code> pattern for better discoverability and scalability:<ul> <li><code>http_static</code> \u2192 <code>url_download</code> (fixed URL with file extraction)</li> <li><code>url_regex</code> \u2192 <code>web_scrape</code> (web scraping for vendor download pages)</li> <li><code>http_json</code> \u2192 <code>api_json</code> (generic JSON API queries)</li> <li><code>github_release</code> \u2192 <code>api_github</code> (GitHub releases API)</li> </ul> </li> <li>BREAKING: Simplified Version Types - Version type names shortened for clarity:<ul> <li><code>msi_product_version_from_file</code> \u2192 <code>msi</code></li> <li>Removed nested <code>version.type</code> for <code>web_scrape</code> (simplified to <code>source.link_selector</code> and <code>source.version_pattern</code>)</li> </ul> </li> <li>BREAKING: Recipe Format Change - Changed recipe format from <code>apps:</code> array to <code>app:</code> single object. Recipes now define a single application per file instead of an array. This simplifies the schema and matches actual usage (only one app was ever processed per recipe).</li> <li>Documentation Rendering - Fixed module docstrings to follow Google-style format with proper indentation for mkdocstrings</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Fixed ETag preservation bug causing alternating download/cached behavior in url_download strategy</li> <li>Fixed docstring formatting issues across multiple modules (missing blank lines, incorrect Args sections)</li> </ul>"},{"location":"changelog/#020-2025-11-07","title":"0.2.0 - 2025-11-07","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>PSADT Package Generation with <code>napt build</code> command - Creates complete PSADT v4 deployment packages with custom branding support</li> <li>.intunewin Package Creation with <code>napt package</code> command - Generates Intune-ready packages using Microsoft's IntuneWinAppUtil.exe</li> <li>GitHub Release Strategy (<code>api_github</code>) - Discovers versions from GitHub releases with asset pattern filtering</li> <li>HTTP JSON Strategy (<code>api_json</code>) - Extracts versions and download URLs from JSON API endpoints using JSONPath</li> <li>URL Regex Strategy (<code>url_pattern</code>) - Extracts versions directly from URLs using regex patterns</li> <li>Roadmap Management (<code>docs/roadmap.md</code>) - Structured feature tracking with status categories and workspace automation</li> <li>MkDocs Documentation Site - User guide and auto-generated API reference</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>State File Schema v2 - Convention-based file paths, improved metadata tracking, per-app isolation (Breaking: old state files need regeneration)</li> <li>CLI Commands - Renamed <code>check</code> to <code>validate</code> for clarity</li> <li>Recipe Format - PSADT <code>install</code>/<code>uninstall</code> blocks now generate PSAppDeployToolkit v4 scripts</li> <li>Console Output - Replaced Unicode symbols with ASCII for Windows compatibility (<code>\u2713</code> \u2192 <code>[OK]</code>, etc.)</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>PSADT Template Handling - Correctly identifies and copies PSAppDeployToolkit_Template_v4.zip files</li> <li>ETag Preservation - Fixed bug causing alternating download/cached behavior in url_download strategy</li> <li>Branding Application - Fixed Assets/ directory path resolution for custom icons and banners</li> <li>Version Extraction - Corrected regex escape sequences causing SyntaxWarnings</li> </ul>"},{"location":"changelog/#010-2025-10-23","title":"0.1.0 - 2025-10-23","text":"<p>Initial internal release.</p>"},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Recipe Validation with <code>napt check</code> command - Validates recipe syntax and configuration without network calls</li> <li>HTTP Static Discovery - Downloads installers from static URLs with ETag caching for efficiency</li> <li>Three-Layer Configuration - Organization defaults, vendor overrides, and recipe-specific settings with deep merging</li> <li>Version Comparison - Supports semantic versioning, MSI/EXE numeric versions, and Chrome-style multi-part versions</li> <li>MSI Version Extraction - Cross-platform support (Windows via msilib/PowerShell, Linux/macOS via msitools)</li> <li>Robust Downloads - Retry logic, atomic writes, SHA-256 verification, and conditional requests</li> </ul>"},{"location":"common-tasks/","title":"Common Tasks","text":"<p>Step-by-step guides for common NAPT workflows. Each task includes complete, working examples you can copy and adapt.</p> <p>\ud83d\udca1 Tip: Need help with a specific command? Use <code>napt &lt;command&gt; --help</code> to see all options and examples. For instance, <code>napt discover --help</code> shows discovery command details.</p>"},{"location":"common-tasks/#create-a-recipe-for-a-github-release-app","title":"Create a Recipe for a GitHub Release App","text":"<p>Use this when the application is hosted on GitHub with releases.</p> <p>Example: Git for Windows</p> <ol> <li>Create the recipe file:</li> </ol> <pre><code># recipes/Git/git.yaml\napiVersion: v1  # Recipe format version (currently v1)\napp:  # Application configuration\n  name: \"Git for Windows\"  # Display name for the application\n  id: \"napt-git\"  # Unique identifier (used for build directories and package names)\n  source:  # Discovery configuration - how to find and download the installer\n    strategy: api_github  # Discovery strategy: api_github, api_json, url_download, or web_scrape\n    repo: \"git-for-windows/git\"  # GitHub repository (owner/repo format)\n    asset_pattern: \"Git-.*-64-bit\\\\.exe$\"  # Regex pattern to match installer filename in release assets\n    version_pattern: \"v?([0-9.]+)\"  # Regex pattern to extract version from Git tag\n    psadt:  # PSAppDeployToolkit configuration\n      install: |  # PowerShell script executed during installation\n        Start-ADTProcess -Path \"$dirFiles\\Git-*.exe\" -Parameters \"/VERYSILENT /NORESTART\"\n      uninstall: |  # PowerShell script executed during uninstallation\n        Uninstall-ADTApplication -Name \"Git\"\n</code></pre> <ol> <li>Validate the recipe:</li> </ol> <pre><code>napt validate recipes/Git/git.yaml\n</code></pre> <ol> <li>Test discovery:</li> </ol> <pre><code>napt discover recipes/Git/git.yaml --verbose\n</code></pre> <p>What to customize: - <code>repo</code>: GitHub repository (owner/repo format) - <code>asset_pattern</code>: Regex to match the installer filename - <code>version_pattern</code>: Regex to extract version from tag - <code>install</code>/<code>uninstall</code>: PowerShell deployment scripts</p>"},{"location":"common-tasks/#create-a-recipe-for-a-vendor-download-page","title":"Create a Recipe for a Vendor Download Page","text":"<p>Use this when the vendor has a download page listing installers (no API available).</p> <p>Example: 7-Zip</p> <ol> <li>Create the recipe file:</li> </ol> <pre><code># recipes/7-Zip/7zip.yaml\napiVersion: v1  # Recipe format version\napp:\n  name: \"7-Zip\"  # Display name\n  id: \"napt-7zip\"  # Unique identifier\n  source:\n      strategy: web_scrape  # Scrape vendor download page for installer link\n      page_url: \"https://www.7-zip.org/download.html\"  # URL of vendor download page\n      link_selector: 'a[href$=\"-x64.msi\"]'  # CSS selector to find download link\n      version_pattern: \"7z(\\\\d{2})(\\\\d{2})-x64\"  # Regex to extract version from URL (captures year and month)\n      version_format: \"{0}.{1}\"  # Format captured groups as \"25.01\" (year.month)\n    psadt:\n      install: |  # MSI installation script\n        Start-ADTMsiProcess -Action Install -Path \"$dirFiles\\7z*-x64.msi\" -Parameters \"ALLUSERS=1\"\n      uninstall: |  # MSI uninstallation script\n        Uninstall-ADTApplication -Name \"7-Zip\"\n</code></pre> <ol> <li>Validate and test:</li> </ol> <pre><code>napt validate recipes/7-Zip/7zip.yaml\nnapt discover recipes/7-Zip/7zip.yaml --verbose\n</code></pre> <p>What to customize:</p> <ul> <li><code>page_url</code>: Vendor download page URL</li> <li><code>link_selector</code>: CSS selector to find the download link</li> <li><code>version_pattern</code>: Regex to extract version from URL</li> <li><code>version_format</code>: Format string to transform version (optional)</li> </ul>"},{"location":"common-tasks/#create-a-recipe-for-a-json-api-endpoint","title":"Create a Recipe for a JSON API Endpoint","text":"<p>Use this when the vendor provides a JSON API with version and download URL.</p> <p>Example: Generic JSON API</p> <ol> <li>Create the recipe file:</li> </ol> <pre><code># recipes/Vendor/app.yaml\napiVersion: v1  # Recipe format version\napp:\n  name: \"Application Name\"  # Display name\n  id: \"napt-app\"  # Unique identifier\n  source:\n      strategy: api_json  # Query JSON API for version and download URL\n      api_url: \"https://api.vendor.com/latest\"  # JSON API endpoint URL\n      version_path: \"version\"  # JSONPath to version field (e.g., \"version\" or \"data.version\")\n      download_url_path: \"download_url\"  # JSONPath to download URL field\n      headers:  # Optional HTTP headers (e.g., for authentication)\n        Authorization: \"Bearer ${API_TOKEN}\"  # Environment variable substitution supported\n    psadt:\n      install: |  # Installation script\n        Start-ADTProcess -Path \"$dirFiles\\app-installer.exe\" -Parameters \"/S\"\n      uninstall: |  # Uninstallation script\n        Uninstall-ADTApplication -Name \"Application Name\"\n</code></pre> <ol> <li>Set environment variable (if needed):</li> </ol> <pre><code># Windows PowerShell\n$env:API_TOKEN=\"your-token-here\"\n\n# Linux/macOS\nexport API_TOKEN=\"your-token-here\"\n</code></pre> <ol> <li>Validate and test:</li> </ol> <pre><code>napt validate recipes/Vendor/app.yaml\nnapt discover recipes/Vendor/app.yaml --verbose\n</code></pre> <p>What to customize:</p> <ul> <li><code>api_url</code>: JSON API endpoint URL</li> <li><code>version_path</code>: JSONPath to version field (e.g., \"version\" or \"data.version\")</li> <li><code>download_url_path</code>: JSONPath to download URL field</li> <li><code>headers</code>: Optional authentication headers</li> </ul>"},{"location":"common-tasks/#create-a-recipe-for-a-fixed-download-url","title":"Create a Recipe for a Fixed Download URL","text":"<p>Use this when the vendor has a stable download URL (like Chrome enterprise MSI).</p> <p>Example: Google Chrome</p> <ol> <li>Create the recipe file:</li> </ol> <pre><code># recipes/Google/chrome.yaml\napiVersion: v1  # Recipe format version\napp:\n  name: \"Google Chrome\"  # Display name\n  id: \"napt-chrome\"  # Unique identifier\n  source:\n      strategy: url_download  # Direct download from fixed URL\n      url: \"https://dl.google.com/chrome/install/googlechromestandaloneenterprise64.msi\"  # Stable download URL\n      version:  # Version extraction configuration\n        type: msi  # Extract version from MSI ProductVersion property\n    psadt:\n      install: |  # MSI installation script\n        Start-ADTMsiProcess -Action Install -Path \"$dirFiles\\googlechromestandaloneenterprise64.msi\" -Parameters \"ALLUSERS=1\"\n      uninstall: |  # MSI uninstallation script\n        Uninstall-ADTApplication -Name \"Google Chrome\"\n</code></pre> <ol> <li>Validate and test:</li> </ol> <pre><code>napt validate recipes/Google/chrome.yaml\nnapt discover recipes/Google/chrome.yaml --verbose\n</code></pre> <p>What to customize:</p> <ul> <li><code>url</code>: Direct download URL (must be stable, not version-specific)</li> </ul> <p>Note: MSI files (<code>.msi</code> extension) are automatically detected and versions are extracted from the MSI ProductVersion property.</p>"},{"location":"common-tasks/#troubleshoot-discovery-failures","title":"Troubleshoot Discovery Failures","text":"<p>Common issues and solutions when <code>napt discover</code> fails.</p>"},{"location":"common-tasks/#issue-strategy-not-found","title":"Issue: \"Strategy not found\"","text":"<p>Problem: Recipe uses a strategy that doesn't exist or isn't registered.</p> <p>Solution:</p> <ol> <li> <p>Check strategy name spelling (must be: <code>api_github</code>, <code>api_json</code>, <code>url_download</code>, or <code>web_scrape</code>)</p> </li> <li> <p>Validate recipe: <code>napt validate recipes/App/app.yaml</code></p> </li> <li> <p>Check for typos in strategy configuration</p> </li> </ol>"},{"location":"common-tasks/#issue-version-extraction-failed","title":"Issue: \"Version extraction failed\"","text":"<p>Problem: NAPT can't extract version from the downloaded file or API response.</p> <p>Solution:</p> <ol> <li>Use <code>--debug</code> to see what NAPT is trying to parse:</li> </ol> <pre><code>napt discover recipes/App/app.yaml --debug\n</code></pre> <ol> <li> <p>For MSI files, verify the file is a valid MSI</p> </li> <li> <p>For <code>api_json</code>, check that <code>version_path</code> points to the correct JSON field</p> </li> <li> <p>For <code>web_scrape</code>, verify <code>version_pattern</code> regex matches the URL format</p> </li> </ol>"},{"location":"common-tasks/#issue-github-api-rate-limit","title":"Issue: \"GitHub API rate limit\"","text":"<p>Problem: Using <code>api_github</code> without authentication hits rate limits.</p> <p>Solution:</p> <ol> <li>Create a GitHub personal access token</li> <li>Add to recipe:    <pre><code>source:\n  strategy: api_github\n  repo: \"owner/repo\"\n  token: \"${GITHUB_TOKEN}\"\n</code></pre></li> <li>Set environment variable:    <pre><code>$env:GITHUB_TOKEN=\"ghp_your_token_here\"  # Windows\nexport GITHUB_TOKEN=\"ghp_your_token_here\"  # Linux/macOS\n</code></pre></li> </ol>"},{"location":"common-tasks/#issue-download-failed-or-network-error","title":"Issue: \"Download failed\" or \"Network error\"","text":"<p>Problem: Can't download the installer file.</p> <p>Solution:</p> <ol> <li> <p>Check URL is accessible: <code>curl -I &lt;url&gt;</code> or open in browser</p> </li> <li> <p>Verify authentication if required (API tokens, headers)</p> </li> <li> <p>Check network connectivity and firewall rules</p> </li> <li> <p>Use <code>--verbose</code> to see HTTP request/response details</p> </li> </ol>"},{"location":"common-tasks/#issue-state-file-corrupted","title":"Issue: \"State file corrupted\"","text":"<p>Problem: <code>state/versions.json</code> has invalid JSON or is corrupted.</p> <p>Solution:</p> <ol> <li> <p>NAPT automatically creates a backup: <code>state/versions.json.backup</code></p> </li> <li> <p>Delete corrupted state file: <code>rm state/versions.json</code></p> </li> <li> <p>Run discovery again to recreate state file</p> </li> <li> <p>Or use <code>--stateless</code> to bypass state tracking temporarily</p> </li> </ol>"},{"location":"common-tasks/#update-existing-recipes","title":"Update Existing Recipes","text":"<p>When a recipe needs changes (new version format, different download URL, etc.).</p> <ol> <li> <p>Edit the recipe file: <pre><code># Edit the YAML file\ncode recipes/Vendor/app.yaml\n</code></pre></p> </li> <li> <p>Validate changes: <pre><code>napt validate recipes/Vendor/app.yaml\n</code></pre></p> </li> <li> <p>Test discovery: <pre><code>napt discover recipes/Vendor/app.yaml --verbose\n</code></pre></p> </li> <li> <p>If version format changed, clear state: <pre><code># Delete state entry for this app\n# Or delete entire state file to start fresh\nrm state/versions.json\n</code></pre></p> </li> <li> <p>Test full workflow: <pre><code>napt discover recipes/Vendor/app.yaml\nnapt build recipes/Vendor/app.yaml\nnapt package builds/napt-app/*/\n</code></pre></p> </li> </ol>"},{"location":"common-tasks/#handle-authentication-tokens","title":"Handle Authentication Tokens","text":"<p>Many APIs require authentication. Here's how to handle tokens securely.</p>"},{"location":"common-tasks/#environment-variables-recommended","title":"Environment Variables (Recommended)","text":"<ol> <li> <p>Set token in environment: <pre><code># Windows PowerShell\n$env:API_TOKEN=\"your-token-here\"\n\n# Linux/macOS\nexport API_TOKEN=\"your-token-here\"\n</code></pre></p> </li> <li> <p>Reference in recipe: <pre><code>source:\n  strategy: api_json\n  api_url: \"https://api.vendor.com/latest\"\n  headers:\n    Authorization: \"Bearer ${API_TOKEN}\"\n</code></pre></p> </li> <li> <p>In CI/CD, use secrets: <pre><code># GitHub Actions\n- name: Discover version\n  env:\n    API_TOKEN: ${{ secrets.API_TOKEN }}\n  run: napt discover recipes/Vendor/app.yaml\n</code></pre></p> </li> </ol>"},{"location":"common-tasks/#recipe-level-tokens-less-secure","title":"Recipe-Level Tokens (Less Secure)","text":"<p>If you must store tokens in recipes (not recommended for production):</p> <pre><code>source:\n  strategy: api_github\n  repo: \"owner/repo\"\n  token: \"ghp_your_token_here\"  # Not recommended - use env vars instead\n</code></pre> <p>Security best practice: Always use environment variables or CI/CD secrets, never commit tokens to version control.</p>"},{"location":"common-tasks/#test-recipes-before-production","title":"Test Recipes Before Production","text":"<p>Validate and test recipes thoroughly before using in production.</p> <ol> <li> <p>Syntax validation: <pre><code>napt validate recipes/Vendor/app.yaml\n</code></pre></p> </li> <li> <p>Test discovery: <pre><code>napt discover recipes/Vendor/app.yaml --verbose\n</code></pre></p> </li> <li> <p>Verify downloaded file: <pre><code># Check file exists and has content\nls -lh downloads/\n</code></pre></p> </li> <li> <p>Test build: <pre><code>napt build recipes/Vendor/app.yaml --verbose\n</code></pre></p> </li> <li> <p>Verify build structure: <pre><code># Check PSADT files are present\nls builds/napt-app/*/Invoke-AppDeployToolkit.ps1\n</code></pre></p> </li> <li> <p>Test packaging: <pre><code>napt package builds/napt-app/*/ --verbose\n</code></pre></p> </li> <li> <p>Verify .intunewin file: <pre><code># Check file was created\nls -lh packages/napt-app/*.intunewin\n</code></pre></p> </li> </ol>"},{"location":"common-tasks/#whats-next","title":"What's Next?","text":"<ul> <li>User Guide - Deep dive into discovery strategies, state management, and configuration</li> <li>Creating Recipes - Detailed strategy configuration guides</li> <li>Examples - Browse working recipe examples</li> </ul>"},{"location":"contributing/","title":"Contributing to NAPT","text":"<p>Thank you for your interest in contributing to NAPT! We welcome ideas and feedback.</p>"},{"location":"contributing/#how-to-contribute","title":"How to Contribute","text":""},{"location":"contributing/#feature-ideas","title":"Feature Ideas","text":"<p>Have an idea for NAPT? We'd love to hear it!</p> <ol> <li>Check the roadmap - See Roadmap to see what's planned</li> <li>Open a GitHub Discussion - Share your idea and get feedback</li> <li>Or open a GitHub Issue - For more structured feature requests</li> </ol> <p>When suggesting features, please include:</p> <ul> <li>What problem it solves</li> <li>How you envision it working</li> <li>Any examples or use cases</li> </ul>"},{"location":"contributing/#feedback","title":"Feedback","text":"<p>Have feedback, questions, or encountered issues? We'd love to hear from you!</p> <ul> <li>Questions about using NAPT - Open a GitHub Discussion</li> <li>Feature ideas or suggestions - See the Feature Ideas section above</li> <li>Issues or problems - Open a GitHub Issue (note: NAPT is pre-release, so issues are expected)</li> </ul>"},{"location":"contributing/#questions","title":"Questions","text":"<p>Have questions about using NAPT? Open a GitHub Discussion - we're happy to help!</p>"},{"location":"contributing/#code-contributions","title":"Code Contributions","text":"<p>We're currently not accepting code contributions. NAPT is still in active development and has not been officially released yet. The project is evolving rapidly with frequent changes to APIs, schemas, configuration formats, and internal structure.</p> <p>This means:</p> <ul> <li>APIs and function signatures may change without notice</li> <li>Recipe schema and configuration formats are still being refined</li> <li>Breaking changes are common and backward compatibility is not maintained</li> <li>Code contributions would likely require significant maintenance as the codebase evolves</li> </ul> <p>Once NAPT is officially released, we'll be open to code contributions and will establish contribution guidelines. Until then, your ideas and feedback are incredibly valuable and help shape the direction of the project.</p> <p>If you're interested in contributing code in the future, please reach out via GitHub Discussion first to discuss the current state and future plans.</p>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing ideas or feedback, you agree that your contributions will be licensed under the Apache License 2.0.</p>"},{"location":"quick-start/","title":"Quick Start Guide","text":""},{"location":"quick-start/#installation","title":"Installation","text":""},{"location":"quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Git</li> </ul>"},{"location":"quick-start/#choose-your-installation-method","title":"Choose Your Installation Method","text":""},{"location":"quick-start/#option-1-pip-for-using-napt","title":"Option 1: pip (For Using NAPT)","text":"<p>Best for users who just want to use the tool without extra tooling.</p> <pre><code># Clone repository\ngit clone https://github.com/RogerCibrian/notapkgtool.git\ncd notapkgtool\n\n# Create and activate virtual environment (recommended)\npython -m venv .venv\n.venv\\Scripts\\Activate.ps1  # On Linux/macOS: source .venv/bin/activate\n\n# Install\npip install -e .\n\n# Verify installation\nnapt --version\n</code></pre>"},{"location":"quick-start/#option-2-poetry-for-development","title":"Option 2: Poetry (For Development)","text":"<p>Best for developers who want reproducible builds and dependency management.</p> <p>Prerequisites: Poetry must be installed. See Poetry Installation Guide</p> <pre><code># Clone repository\ngit clone https://github.com/RogerCibrian/notapkgtool.git\ncd notapkgtool\n\n# Install (Poetry creates .venv automatically)\npoetry install\n\n# Activate virtual environment\npoetry shell\n\n# Verify installation\nnapt --version\n</code></pre>"},{"location":"quick-start/#platform-requirements","title":"Platform Requirements","text":"<p>Discovery and building: Work on Windows, Linux, and macOS.</p> <p>Packaging (.intunewin creation): Requires Windows (uses IntuneWinAppUtil.exe).</p> <p>Linux/macOS: Install msitools for MSI version extraction:</p> <pre><code># Debian/Ubuntu\nsudo apt-get install msitools\n\n# RHEL/Fedora\nsudo dnf install msitools\n\n# macOS\nbrew install msitools\n</code></pre> <p>Windows: No additional requirements (uses native PowerShell COM API).</p> <p>See the Cross-Platform Support section for CI/CD workflows and detailed examples.</p>"},{"location":"quick-start/#basic-usage","title":"Basic Usage","text":"<p>\ud83d\udca1 Tip: Use <code>napt &lt;command&gt; --help</code> (or <code>-h</code>) to see detailed help and examples for any command. For example: <code>napt discover --help</code></p>"},{"location":"quick-start/#validate-a-recipe","title":"Validate a Recipe","text":"<p>Quick validation checks syntax and configuration without downloading anything:</p> <pre><code># Basic validation\nnapt validate recipes/Google/chrome.yaml\n\n# With verbose output\nnapt validate recipes/Google/chrome.yaml --verbose\n</code></pre>"},{"location":"quick-start/#discover-latest-version","title":"Discover Latest Version","text":"<p>Download the installer and extract version information:</p> <pre><code># Discover version and download installer\n# State tracking enabled by default for efficient re-runs\nnapt discover recipes/Google/chrome.yaml\n\n# Specify custom output directory\nnapt discover recipes/Google/chrome.yaml --output-dir ./cache\n\n# Show verbose output with progress details\nnapt discover recipes/Google/chrome.yaml --verbose\n\n# Disable state tracking (always download, no caching)\nnapt discover recipes/Google/chrome.yaml --stateless\n\n# Show debug output with full configuration dumps\nnapt discover recipes/Google/chrome.yaml --debug\n</code></pre>"},{"location":"quick-start/#build-psadt-package","title":"Build PSADT Package","text":"<p>Create a complete PSADT package ready for deployment:</p> <pre><code># Build PSADT package from recipe and downloaded installer\nnapt build recipes/Google/chrome.yaml\n\n# Specify custom downloads and output directories\nnapt build recipes/Google/chrome.yaml --downloads-dir ./downloads --output-dir ./builds\n\n# Show verbose output\nnapt build recipes/Google/chrome.yaml --verbose\n</code></pre>"},{"location":"quick-start/#create-intunewin-package","title":"Create .intunewin Package","text":"<p>Package the PSADT build for Microsoft Intune:</p> <pre><code># Create .intunewin from build directory\nnapt package builds/napt-chrome/141.0.7390.123/\n\n# Specify output directory and clean source after packaging\nnapt package builds/napt-chrome/141.0.7390.123/ --output-dir ./packages --clean-source\n</code></pre> <p>\ud83d\udca1 Tip: Use <code>--verbose</code> to see progress details or <code>--debug</code> for full diagnostics including configuration dumps and backend selection</p>"},{"location":"quick-start/#example-workflows","title":"Example Workflows","text":""},{"location":"quick-start/#complete-workflow-recipe-to-package","title":"Complete Workflow: Recipe to Package","text":"<p>Here's a complete workflow from recipe validation to Intune package:</p> <pre><code># 1. Validate recipe\nnapt validate recipes/Google/chrome.yaml\n</code></pre> <p>Expected output: <pre><code>Validating recipe: recipes/Google/chrome.yaml\n\n======================================================================\nVALIDATION RESULTS\n======================================================================\nRecipe:      recipes/Google/chrome.yaml\nStatus:      VALID\nApp Count:   1\n\n======================================================================\n\n[SUCCESS] Recipe is valid!\n</code></pre></p> <pre><code># 2. Discover and download latest version\nnapt discover recipes/Google/chrome.yaml\n</code></pre> <p>Expected output: <pre><code>Discovering version for recipe: recipes/Google/chrome.yaml\nOutput directory: downloads\n\n======================================================================\nDISCOVERY RESULTS\n======================================================================\nApp Name:        Google Chrome\nApp ID:          napt-chrome\nStrategy:        url_download\nVersion:         142.0.7444.163\nVersion Source:  msi\nFile Path:       downloads/googlechromestandaloneenterprise64.msi\nSHA-256:         abc123...\nStatus:          downloaded\n\n======================================================================\n\n[SUCCESS] Version discovered successfully!\n</code></pre></p> <pre><code># 3. Build PSADT package\nnapt build recipes/Google/chrome.yaml\n</code></pre> <p>Expected output: <pre><code>Building PSADT package for recipe: recipes/Google/chrome.yaml\nDownloads directory: downloads\n\n======================================================================\nBUILD RESULTS\n======================================================================\nApp Name:        Google Chrome\nApp ID:          napt-chrome\nVersion:         142.0.7444.163\nPSADT Version:   4.1.7\nBuild Directory: builds/napt-chrome/142.0.7444.163\nStatus:          built\n\n======================================================================\n\n[SUCCESS] PSADT package built successfully!\n</code></pre></p> <pre><code># 4. Create .intunewin package\nnapt package builds/napt-chrome/142.0.7444.163/\n</code></pre> <p>Expected output: <pre><code>Creating .intunewin package from: builds/napt-chrome/142.0.7444.163\n\n======================================================================\nPACKAGE RESULTS\n======================================================================\nApp ID:          napt-chrome\nVersion:         142.0.7444.163\nPackage Path:    packages/napt-chrome/Invoke-AppDeployToolkit.intunewin\nBuild Directory: builds/napt-chrome/142.0.7444.163\nStatus:          packaged\n\n======================================================================\n\n[SUCCESS] .intunewin package created successfully!\n</code></pre></p> <p>Result: Ready-to-upload .intunewin file in <code>packages/napt-chrome/</code></p>"},{"location":"quick-start/#quick-check-workflow","title":"Quick Check Workflow","text":"<p>Check if a new version is available (skips re-downloading if unchanged):</p> <pre><code># Discover with verbose output to see what happens\nnapt discover recipes/Google/chrome.yaml --verbose\n</code></pre> <p>If the version hasn't changed since the last run and the file exists, you'll see: <pre><code>[1/4] Checking cached version...\n[2/4] Version unchanged (142.0.7444.163)\n[3/4] File exists, skipping download\n[4/4] Using cached file: downloads/googlechromestandaloneenterprise64.msi\n</code></pre></p> <p>Note: This requires having run <code>napt discover</code> at least once before to create the cached version.</p>"},{"location":"quick-start/#clean-build-workflow","title":"Clean Build Workflow","text":"<p>Force a fresh download and rebuild:</p> <pre><code># Always download (ignore cache)\nnapt discover recipes/Google/chrome.yaml --stateless\n\n# Build with custom output\nnapt build recipes/Google/chrome.yaml --output-dir ./my-builds\n\n# Package and clean up source\nnapt package builds/napt-chrome/142.0.7444.163/ --clean-source\n</code></pre>"},{"location":"quick-start/#common-tasks","title":"Common Tasks","text":"<p>For step-by-step guides on common workflows, see Common Tasks:</p> <ul> <li>Create a recipe for a GitHub release app</li> <li>Create a recipe for a vendor download page</li> <li>Create a recipe for a JSON API endpoint</li> <li>Troubleshoot discovery failures</li> </ul>"},{"location":"quick-start/#whats-next","title":"What's Next?","text":"<p>Now that you have NAPT installed and understand the basic commands, explore:</p> <ul> <li>Common Tasks - Step-by-step guides for common workflows</li> <li>User Guide - Learn about discovery strategies, configuration, and advanced features</li> <li>Creating Recipes - Write your own application recipes</li> <li>Examples - Browse example recipes for Chrome, Git, and more</li> </ul>"},{"location":"recipe-reference/","title":"Recipe Reference","text":"<p>Complete documentation of all recipe fields, options, and configuration patterns. Use this as a reference when writing recipes.</p> <p>\ud83d\udca1 Tip: For practical examples and workflows, see Common Tasks. For strategy selection guidance, see Discovery Strategies in the User Guide.</p>"},{"location":"recipe-reference/#top-level-fields","title":"Top-Level Fields","text":"<pre><code>apiVersion: v1  # Required: Recipe format version (currently v1)\napp:  # Required: Application configuration\n  name: \"Application Name\"\n  # ... app configuration\n</code></pre>"},{"location":"recipe-reference/#apiversion","title":"apiVersion","text":"<p>Type: <code>string</code> Required: Yes Values: <code>v1</code> (currently only version)</p> <p>Specifies the recipe format version. Currently only <code>v1</code> is supported.</p>"},{"location":"recipe-reference/#app","title":"app","text":"<p>Type: <code>object</code> Required: Yes</p> <p>Application configuration defining discovery, download, and packaging settings for a single application.</p>"},{"location":"recipe-reference/#app-configuration","title":"App Configuration","text":"<p>The <code>app</code> object defines the application:</p> <pre><code>app:\n  name: \"Application Name\"  # Required: Display name for the application\n  id: \"napt-app-id\"  # Required: Unique identifier (used for build directories, package names)\n  source:  # Required: Discovery configuration\n    # ... strategy-specific configuration\n  psadt:  # Required: PSAppDeployToolkit configuration\n    # ... PSADT settings\n</code></pre>"},{"location":"recipe-reference/#name","title":"name","text":"<p>Type: <code>string</code> Required: Yes</p> <p>Display name for the application. Used in PSADT dialogs and package metadata.</p>"},{"location":"recipe-reference/#id","title":"id","text":"<p>Type: <code>string</code> Required: Yes Format: Lowercase, alphanumeric, hyphens only (e.g., <code>napt-chrome</code>, <code>napt-git</code>)</p> <p>Unique identifier for the application. Used to generate:</p> <ul> <li>Build directory names: <code>builds/{id}/{version}/</code></li> <li>Package names: <code>packages/{id}/Invoke-AppDeployToolkit.intunewin</code></li> </ul> <p>Naming Convention: Use <code>napt-</code> prefix followed by application name (e.g., <code>napt-chrome</code>, <code>napt-git</code>).</p>"},{"location":"recipe-reference/#source","title":"source","text":"<p>Type: <code>object</code> Required: Yes</p> <p>Discovery configuration that defines how NAPT finds and downloads the installer. The structure depends on the chosen <code>strategy</code>.</p> <p>Common Fields (All Strategies):</p> <ul> <li><code>strategy</code>: Required. One of: <code>api_github</code>, <code>api_json</code>, <code>url_download</code>, <code>web_scrape</code></li> </ul> <p>See strategy-specific sections below for complete configuration options.</p>"},{"location":"recipe-reference/#psadt","title":"psadt","text":"<p>Type: <code>object</code> Required: Yes</p> <p>PSAppDeployToolkit configuration that defines PowerShell deployment scripts and PSADT variables.</p> <p>See PSADT Configuration section below for complete options.</p>"},{"location":"recipe-reference/#source-configuration","title":"Source Configuration","text":"<p>The <code>source</code> section configuration depends on the chosen discovery strategy.</p>"},{"location":"recipe-reference/#api_github-strategy","title":"api_github Strategy","text":"<p>Best for: Open-source projects on GitHub with releases and semantic versioned tags.</p> <p>Configuration:</p> <pre><code>source:\n  strategy: api_github  # Discovery strategy type\n  repo: \"owner/repository\"  # Required: GitHub repository in owner/repo format\n  asset_pattern: \".*\\\\.exe$\"  # Required: Regex pattern to match installer filename in release assets\n  version_pattern: \"v?([0-9.]+)\"  # Required: Regex pattern to extract version from Git tag\n  token: \"${GITHUB_TOKEN}\"  # Optional: GitHub personal access token (use env var for security)\n</code></pre>"},{"location":"recipe-reference/#repo","title":"repo","text":"<p>Type: <code>string</code> Required: Yes Format: <code>owner/repository</code> (e.g., <code>git-for-windows/git</code>)</p> <p>GitHub repository identifier in owner/repository format.</p>"},{"location":"recipe-reference/#asset_pattern","title":"asset_pattern","text":"<p>Type: <code>string</code> (regex) Required: Yes</p> <p>Regular expression pattern to match the installer filename in release assets. The pattern is matched against asset filenames from the GitHub Releases API.</p> <p>Examples: - <code>\"Git-.*-64-bit\\\\.exe$\"</code> - Matches Git installers for 64-bit - <code>\".*\\\\.msi$\"</code> - Matches any MSI file - <code>\"app-.*-x64\\\\.exe$\"</code> - Matches app installers for x64</p> <p>Note: Escape special regex characters (e.g., <code>\\\\.</code> for literal dot).</p>"},{"location":"recipe-reference/#version_pattern","title":"version_pattern","text":"<p>Type: <code>string</code> (regex) Required: Yes</p> <p>Regular expression pattern to extract version from the Git tag. Should include capture groups for version components.</p> <p>Examples: - <code>\"v?([0-9.]+)\"</code> - Extracts version from tags like <code>v2.51.2</code> or <code>2.51.2</code> - <code>\"release-([0-9]+\\\\.[0-9]+)\"</code> - Extracts version from tags like <code>release-1.5</code></p> <p>Note: The first capture group is used as the version string.</p>"},{"location":"recipe-reference/#token","title":"token","text":"<p>Type: <code>string</code> Required: No Default: None</p> <p>GitHub personal access token for authenticated API requests. Use environment variable substitution (e.g., <code>\"${GITHUB_TOKEN}\"</code>) for security.</p> <p>When to use:</p> <ul> <li>Avoid GitHub API rate limits (60 requests/hour unauthenticated, 5000/hour authenticated)</li> <li>Access private repositories</li> </ul> <p>How it works: Queries GitHub Releases API, finds the latest release, matches assets using <code>asset_pattern</code>, extracts version from tag using <code>version_pattern</code>.</p>"},{"location":"recipe-reference/#api_json-strategy","title":"api_json Strategy","text":"<p>Best for: Vendors with JSON REST APIs, cloud services with version endpoints, or APIs requiring authentication.</p> <p>Configuration:</p> <pre><code>source:\n  strategy: api_json  # Discovery strategy type\n  api_url: \"https://api.vendor.com/latest\"  # Required: JSON API endpoint URL\n  version_path: \"version\"  # Required: JSONPath to version field (e.g., \"version\" or \"data.version\")\n  download_url_path: \"download_url\"  # Required: JSONPath to download URL field\n  headers:  # Optional: HTTP headers for authentication\n    Authorization: \"Bearer ${API_TOKEN}\"  # Environment variable substitution supported\n</code></pre>"},{"location":"recipe-reference/#api_url","title":"api_url","text":"<p>Type: <code>string</code> (URL) Required: Yes</p> <p>JSON API endpoint URL that returns version and download URL information.</p>"},{"location":"recipe-reference/#version_path","title":"version_path","text":"<p>Type: <code>string</code> (JSONPath) Required: Yes</p> <p>JSONPath expression to extract the version field from the API response. Supports nested paths.</p> <p>Examples: - <code>\"version\"</code> - Direct field: <code>{\"version\": \"1.2.3\"}</code> - <code>\"data.version\"</code> - Nested field: <code>{\"data\": {\"version\": \"1.2.3\"}}</code> - <code>\"release.latest.version\"</code> - Deeply nested: <code>{\"release\": {\"latest\": {\"version\": \"1.2.3\"}}}</code></p>"},{"location":"recipe-reference/#download_url_path","title":"download_url_path","text":"<p>Type: <code>string</code> (JSONPath) Required: Yes</p> <p>JSONPath expression to extract the download URL field from the API response. Supports nested paths (same format as <code>version_path</code>).</p>"},{"location":"recipe-reference/#headers","title":"headers","text":"<p>Type: <code>object</code> (key-value pairs) Required: No Default: None</p> <p>HTTP headers to include in the API request. Useful for authentication tokens, API keys, or custom headers.</p> <p>Environment Variable Substitution: Use <code>${VARIABLE_NAME}</code> syntax. NAPT substitutes environment variables at runtime.</p> <p>Example: <pre><code>headers:\n  Authorization: \"Bearer ${API_TOKEN}\"\n  X-API-Key: \"${VENDOR_API_KEY}\"\n</code></pre></p> <p>How it works: Makes HTTP GET request to <code>api_url</code>, extracts version using <code>version_path</code>, extracts download URL using <code>download_url_path</code>. Supports nested JSON paths.</p>"},{"location":"recipe-reference/#url_download-strategy","title":"url_download Strategy","text":"<p>Best for: Vendors with stable download URLs and MSI installers with embedded ProductVersion.</p> <p>Configuration:</p> <pre><code>source:\n  strategy: url_download  # Discovery strategy type\n  url: \"https://vendor.com/installer.msi\"  # Required: Stable download URL (must not change with versions)\n</code></pre>"},{"location":"recipe-reference/#url","title":"url","text":"<p>Type: <code>string</code> (URL) Required: Yes</p> <p>Stable download URL for the installer. Important: This URL must not change when new versions are released. If the URL changes with each version, use <code>web_scrape</code> strategy instead.</p> <p>How it works: Downloads file from <code>url</code>, auto-detects MSI files by extension (<code>.msi</code>) and extracts version from MSI ProductVersion property. Uses HTTP conditional requests (ETags) for caching to avoid re-downloading unchanged files.</p> <p>Version Extraction: Automatically detected by file extension. MSI files (<code>.msi</code> extension) automatically extract ProductVersion. No configuration needed. Other file types are not supported for version extraction - use a version-first strategy (api_github, api_json, web_scrape) instead.</p>"},{"location":"recipe-reference/#web_scrape-strategy","title":"web_scrape Strategy","text":"<p>Best for: Vendors with download pages listing installers when no direct download URL or API is available.</p> <p>Configuration:</p> <pre><code>source:\n  strategy: web_scrape  # Discovery strategy type\n  page_url: \"https://vendor.com/download\"  # Required: URL of vendor download page\n  link_selector: 'a[href$=\".msi\"]'  # Required: CSS selector to find download link\n  version_pattern: \"app-(\\\\d+\\\\.\\\\d+)\\\\.msi\"  # Required: Regex to extract version from discovered URL\n  version_format: \"{0}\"  # Optional: Format string for captured groups (default: use first capture group)\n</code></pre>"},{"location":"recipe-reference/#page_url","title":"page_url","text":"<p>Type: <code>string</code> (URL) Required: Yes</p> <p>URL of the vendor download page that contains links to installer files.</p>"},{"location":"recipe-reference/#link_selector","title":"link_selector","text":"<p>Type: <code>string</code> (CSS selector) Required: Yes</p> <p>CSS selector to find the download link on the page. Uses standard CSS selector syntax.</p> <p>Examples: - <code>'a[href$=\".msi\"]'</code> - Matches links ending in <code>.msi</code> - <code>'a.download-link'</code> - Matches links with <code>download-link</code> class - <code>'#download-button'</code> - Matches element with <code>download-button</code> ID - <code>'a[href*=\"installer\"]'</code> - Matches links containing \"installer\"</p> <p>Note: The selector should match exactly one link. If multiple links match, the first match is used.</p>"},{"location":"recipe-reference/#version_pattern_1","title":"version_pattern","text":"<p>Type: <code>string</code> (regex) Required: Yes</p> <p>Regular expression pattern to extract version from the discovered download URL. Should include capture groups for version components.</p> <p>Examples: - <code>\"app-(\\\\d+\\\\.\\\\d+)\\\\.msi\"</code> - Extracts <code>1.5</code> from <code>app-1.5.msi</code> - <code>\"7z(\\\\d{2})(\\\\d{2})-x64\"</code> - Captures year and month from <code>7z2501-x64.msi</code> (groups: <code>25</code>, <code>01</code>) - <code>\"v([0-9.]+)\"</code> - Extracts version from <code>v2.51.2</code> (captures <code>2.51.2</code>)</p> <p>Note: Use capture groups <code>( )</code> to extract version components. The first capture group is used by default, or use <code>version_format</code> to combine multiple groups.</p>"},{"location":"recipe-reference/#version_format","title":"version_format","text":"<p>Type: <code>string</code> (format string) Required: No Default: Use first capture group as-is</p> <p>Format string to combine multiple capture groups from <code>version_pattern</code>. Uses Python format string syntax with <code>{0}</code>, <code>{1}</code>, etc. for capture groups.</p> <p>Examples: - <code>\"{0}.{1}\"</code> - Combines two groups: <code>\"25\"</code> + <code>\"01\"</code> \u2192 <code>\"25.01\"</code> - <code>\"{1}.{0}\"</code> - Reverses order: <code>\"01\"</code> + <code>\"25\"</code> \u2192 <code>\"01.25\"</code> - <code>\"v{0}\"</code> - Prefixes version: <code>\"2.51.2\"</code> \u2192 <code>\"v2.51.2\"</code></p> <p>How it works: Downloads HTML from <code>page_url</code>, finds link using CSS selector, extracts version from URL using regex pattern, formats version using <code>version_format</code> if provided.</p>"},{"location":"recipe-reference/#psadt-configuration","title":"PSADT Configuration","text":"<p>The <code>psadt</code> section defines PowerShell deployment scripts and PSADT variables:</p> <pre><code>psadt:\n  release: \"latest\"  # Optional: PSADT release version (default: \"latest\")\n  app_vars:  # Optional: PSADT application variables\n    AppName: \"Application Name\"  # Display name in PSADT dialogs\n    AppVersion: \"${discovered_version}\"  # Version (use ${discovered_version} for auto-substitution)\n    AppArch: \"x64\"  # Architecture: x64, x86, or All\n    # ... other PSADT variables\n  install: |  # Required: PowerShell script executed during installation\n    # Your installation logic here\n    Start-ADTMsiProcess -Action Install -Path \"$dirFiles\\installer.msi\" -Parameters \"ALLUSERS=1\"\n  uninstall: |  # Required: PowerShell script executed during uninstallation\n    # Your uninstallation logic here\n    Uninstall-ADTApplication -Name \"Application Name\"\n</code></pre>"},{"location":"recipe-reference/#release","title":"release","text":"<p>Type: <code>string</code> Required: No Default: <code>\"latest\"</code> (from organization defaults)</p> <p>PSADT release version to use. Can be:</p> <ul> <li><code>\"latest\"</code> - Use the latest PSADT release from GitHub</li> <li>Specific version: <code>\"4.1.7\"</code> - Use a specific PSADT version</li> </ul> <p>Note: This is typically set in organization defaults (<code>defaults/org.yaml</code>) rather than per-recipe.</p>"},{"location":"recipe-reference/#app_vars","title":"app_vars","text":"<p>Type: <code>object</code> (key-value pairs) Required: No Default: Merged from organization and vendor defaults</p> <p>PSADT application variables that are available in deployment scripts. These variables are set in the generated <code>Invoke-AppDeployToolkit.ps1</code> file.</p> <p>Common Variables:</p> <ul> <li><code>AppName</code>: Display name shown in PSADT dialogs</li> <li><code>AppVersion</code>: Application version (use <code>${discovered_version}</code> for auto-substitution)</li> <li><code>AppArch</code>: Architecture (<code>x64</code>, <code>x86</code>, or <code>All</code>)</li> <li><code>AppVendor</code>: Vendor name (typically set in vendor defaults)</li> <li><code>AppLang</code>: Application language</li> <li><code>AppMaint</code>: Maintenance mode flag</li> <li><code>DeployMode</code>: Deployment mode (<code>Install</code>, <code>Uninstall</code>, <code>Repair</code>)</li> </ul> <p>Special Variable:</p> <ul> <li><code>${discovered_version}</code>: Automatically substituted with the version discovered by NAPT. Use this in <code>AppVersion</code> to ensure the version matches the downloaded installer.</li> </ul> <p>Environment Variable Substitution:</p> <p>All values in <code>app_vars</code> support environment variable substitution using <code>${VARIABLE_NAME}</code> syntax. NAPT substitutes environment variables at runtime.</p> <p>Example: <pre><code>app_vars:\n  AppVersion: \"${discovered_version}\"  # NAPT auto-substitution\n  AppVendor: \"${ORG_NAME}\"  # Environment variable\n</code></pre></p>"},{"location":"recipe-reference/#install","title":"install","text":"<p>Type: <code>string</code> (multiline) Required: Yes</p> <p>PowerShell script executed during installation. This script is inserted into the generated <code>Invoke-AppDeployToolkit.ps1</code> file in the installation section.</p> <p>Available Variables:</p> <ul> <li><code>$dirFiles</code>: Path to installer files directory (contains downloaded installer)</li> <li><code>$discovered_version</code>: Version discovered by NAPT</li> <li>Standard PSADT variables: <code>$dirApp</code>, <code>$dirSupportFiles</code>, <code>$dirFiles</code>, etc.</li> <li>All <code>app_vars</code> are available as variables (e.g., <code>$AppName</code>, <code>$AppVersion</code>)</li> </ul> <p>Commonly Used PSADT Functions:</p> <p>These are some of the most frequently used PSADT functions. PSADT provides 134+ functions - see the PSADT Reference Documentation for the complete function reference.</p> <ul> <li><code>Start-ADTProcess</code>: Execute EXE installers with parameters</li> <li><code>Start-ADTMsiProcess</code>: Install MSI files with parameters</li> <li><code>Uninstall-ADTApplication</code>: Uninstall applications by name (handles ProductCode lookup automatically)</li> </ul> <p>Example: <pre><code>install: |\n  Start-ADTMsiProcess -Action Install -Path \"$dirFiles\\installer.msi\" -Parameters \"ALLUSERS=1 /qn\"\n</code></pre></p>"},{"location":"recipe-reference/#uninstall","title":"uninstall","text":"<p>Type: <code>string</code> (multiline) Required: Yes</p> <p>PowerShell script executed during uninstallation. This script is inserted into the generated <code>Invoke-AppDeployToolkit.ps1</code> file in the uninstallation section.</p> <p>Available Variables:</p> <p>Same as <code>install</code> script (see above).</p> <p>Example: <pre><code>uninstall: |\n  Uninstall-ADTApplication -Name \"Application Name\"\n</code></pre></p>"},{"location":"recipe-reference/#detection-configuration","title":"Detection Configuration","text":"<p>The <code>detection</code> section (in <code>defaults</code> or per-app) configures detection script generation for Intune Win32 app deployments. Detection scripts are automatically generated during the build process and check Windows uninstall registry keys to determine if an application is installed.</p> <p>Configuration Location:</p> <ul> <li>Organization defaults: <code>defaults/org.yaml</code> \u2192 <code>defaults.detection</code></li> <li>Vendor defaults: <code>defaults/vendors/&lt;Vendor&gt;.yaml</code> \u2192 <code>defaults.detection</code></li> <li>Recipe (per-app): <code>app.detection</code> (overrides defaults)</li> </ul> <p>Configuration:</p> <pre><code>defaults:\n  detection:\n    exact_match: false          # If true, version must match exactly. If false, installed &gt;= required passes.\n    fail_on_error: true         # If true, detection script generation failures abort the build.\n    log_rotation_mb: 3          # Maximum log file size in MB before rotation\n\n# Or per-app override:\napp:\n  name: \"My App\"\n  detection:\n    display_name: \"My Application\"  # Required for non-MSI installers, ignored for MSI\n      exact_match: true         # Override default for this app\n</code></pre>"},{"location":"recipe-reference/#display_name","title":"display_name","text":"<p>Type: <code>string</code> Required: Yes for non-MSI installers, ignored for MSI installers</p> <p>Application name used in detection script to match registry <code>DisplayName</code>. This value is used both in the detection script logic and in the generated script filename.</p> <p>Behavior: - MSI installers: This field is ignored (a warning is logged if set). MSI <code>ProductName</code> is used as the authoritative source since it directly corresponds to the registry <code>DisplayName</code>. - Non-MSI installers (EXE, etc.): Required. Must be set in recipe configuration. The detection script checks Windows uninstall registry keys for this exact <code>DisplayName</code> value.</p> <p>Note: The value is sanitized for use in Windows filenames (spaces become hyphens, invalid characters removed). The detection script filename follows the pattern: <code>{DisplayName}_{Version}-Detection.ps1</code>.</p> <p>Example: <pre><code>apps:\n  - name: \"My App\"\n    detection:\n      display_name: \"My Application\"  # Matches registry DisplayName for EXE installers\n</code></pre></p>"},{"location":"recipe-reference/#exact_match","title":"exact_match","text":"<p>Type: <code>boolean</code> Required: No Default: <code>false</code></p> <p>If <code>true</code>, the detection script requires an exact version match. If <code>false</code>, the detection script passes if the installed version is greater than or equal to the required version (minimum version check).</p> <p>Behavior: - <code>exact_match: false</code> (default): Allows users to have newer versions installed without triggering reinstall - <code>exact_match: true</code>: Requires exact version match (useful for compliance scenarios)</p>"},{"location":"recipe-reference/#fail_on_error","title":"fail_on_error","text":"<p>Type: <code>boolean</code> Required: No Default: <code>true</code></p> <p>If <code>true</code>, detection script generation failures will abort the build. If <code>false</code>, build continues even if detection script generation fails (useful for development/testing).</p> <p>Behavior: - <code>fail_on_error: true</code> (default): Build fails if detection script cannot be generated - <code>fail_on_error: false</code>: Build continues, detection script path will be <code>None</code> in BuildResult</p>"},{"location":"recipe-reference/#log_rotation_mb","title":"log_rotation_mb","text":"<p>Type: <code>integer</code> Required: No Default: <code>3</code></p> <p>Maximum log file size in megabytes before rotation. Detection scripts use a 2-file rotation scheme (<code>.log</code> and <code>.log.old</code>).</p> <p>Note: Detection scripts log to <code>C:\\ProgramData\\Microsoft\\IntuneManagementExtension\\Logs\\NAPTDetections.log</code> (system context) or <code>NAPTDetectionsUser.log</code> (user context) with automatic fallback to alternate locations if primary locations are unavailable.</p> <p>How Detection Scripts Work:</p> <ul> <li>App Name Detection:<ul> <li>MSI installers: Uses MSI <code>ProductName</code> property (authoritative source for registry <code>DisplayName</code>). The <code>display_name</code> field is ignored for MSI installers.</li> <li>Non-MSI installers: Requires <code>detection.display_name</code> in recipe configuration. This value is matched against the registry <code>DisplayName</code>.</li> </ul> </li> <li>Registry Checking: Checks Windows uninstall registry keys (HKLM/HKCU, native and Wow6432Node paths).</li> <li>Version Comparison: Uses <code>DisplayVersion</code> registry value, compares based on <code>exact_match</code> setting.</li> <li>Script Location: Generated scripts are saved as <code>{DisplayName}_{Version}-Detection.ps1</code> sibling to the <code>packagefiles/</code> directory (not included in <code>.intunewin</code> package - must be uploaded separately to Intune).</li> </ul> <p>See Detection Scripts in the User Guide for detailed information about how detection scripts work and how to use them in Intune.</p>"},{"location":"recipe-reference/#environment-variable-substitution","title":"Environment Variable Substitution","text":"<p>NAPT supports environment variable substitution throughout recipe files using <code>${VARIABLE_NAME}</code> syntax.</p>"},{"location":"recipe-reference/#where-it-works","title":"Where It Works","text":"<ul> <li>Source configuration: API tokens, authentication headers</li> <li>PSADT app_vars: Any variable value</li> <li>Special variable: <code>${discovered_version}</code> is automatically substituted with the discovered version</li> </ul>"},{"location":"recipe-reference/#syntax","title":"Syntax","text":"<pre><code>source:\n  token: \"${GITHUB_TOKEN}\"  # Environment variable\n  headers:\n    Authorization: \"Bearer ${API_TOKEN}\"  # Environment variable\n\npsadt:\n  app_vars:\n    AppVersion: \"${discovered_version}\"  # NAPT auto-substitution\n    AppVendor: \"${ORG_NAME}\"  # Environment variable\n</code></pre>"},{"location":"recipe-reference/#setting-environment-variables","title":"Setting Environment Variables","text":"<p>Windows (PowerShell): <pre><code>$env:GITHUB_TOKEN=\"your_token_here\"\n</code></pre></p> <p>Windows (Command Prompt): <pre><code>set GITHUB_TOKEN=your_token_here\n</code></pre></p> <p>Linux/macOS: <pre><code>export GITHUB_TOKEN=\"your_token_here\"\n</code></pre></p> <p>Note: For CI/CD, set environment variables in your pipeline configuration (GitHub Actions, Azure DevOps, etc.).</p>"},{"location":"recipe-reference/#complete-example","title":"Complete Example","text":"<pre><code>apiVersion: v1\n\napp:\n  name: \"Example Application\"\n  id: \"napt-example\"\n  source:\n      strategy: api_github\n      repo: \"owner/repo\"\n      asset_pattern: \".*-x64\\\\.exe$\"\n      version_pattern: \"v?([0-9.]+)\"\n    psadt:\n      app_vars:\n        AppName: \"Example Application\"\n        AppVersion: \"${discovered_version}\"\n        AppArch: \"x64\"\n      install: |\n        Start-ADTProcess -Path \"$dirFiles\\*.exe\" -Parameters \"/S\"\n      uninstall: |\n        Uninstall-ADTApplication -Name \"Example Application\"\n</code></pre>"},{"location":"recipe-reference/#see-also","title":"See Also","text":"<ul> <li>Common Tasks - Practical workflows and examples</li> <li>Discovery Strategies - Strategy selection guide</li> <li>User Guide - Complete user documentation</li> <li>PSADT Reference - Complete PSADT function reference</li> </ul>"},{"location":"roadmap/","title":"NAPT Roadmap","text":""},{"location":"roadmap/#philosophy","title":"Philosophy","text":"<p>This roadmap is a living document showing potential future directions for NAPT. Features listed here are ideas and possibilities, not commitments. Priorities may shift based on:</p> <ul> <li>User feedback and real-world usage</li> <li>Discovered technical challenges or opportunities</li> <li>New insights from development experience</li> <li>Community contributions</li> </ul> <p>Status Legend:</p> <ul> <li>\ud83d\udca1 Idea: Unformed thought, needs refinement</li> <li>\ud83d\udd2c Investigating: Researching feasibility/approach</li> <li>\ud83d\udccb Ready: Well-defined, ready for implementation</li> <li>\ud83d\udea7 In Progress: Actively being developed</li> <li>\u2705 Completed: Implemented and released</li> </ul>"},{"location":"roadmap/#quick-reference","title":"Quick Reference","text":"Feature Status Category Complexity Value Microsoft Intune Upload \ud83d\udd2c Investigating User-Facing High Very High Deployment Wave Management \ud83d\udd2c Investigating User-Facing Very High High Pre/Post Install/Uninstall Script Support \ud83d\udca1 Idea User-Facing Low Medium Enhanced CLI Help Menu \ud83d\udca1 Idea User-Facing Low Medium PowerShell Validation \ud83d\udca1 Idea Code Quality High High Recipe Linting &amp; Best Practices \ud83d\udca1 Idea Code Quality High Medium EXE Version Extraction \ud83d\udca1 Idea Technical High Medium Parallel Package Building \ud83d\udca1 Idea Technical Medium Medium IntuneWinAppUtil Version Tracking \ud83d\udca1 Idea Technical Low Low <p>Summary:</p> <ul> <li>\ud83d\udccb Ready: 0</li> <li>\ud83d\udd2c Investigating: 2</li> <li>\ud83d\udca1 Ideas: 7</li> <li>Total: 9 features</li> </ul>"},{"location":"roadmap/#active-work","title":"Active Work","text":""},{"location":"roadmap/#investigating","title":"Investigating \ud83d\udd2c","text":""},{"location":"roadmap/#microsoft-intune-upload","title":"Microsoft Intune Upload","text":"<p>Complexity: High (3-5 days) Value: Very High</p> <p>Description: Direct upload of .intunewin packages to Microsoft Intune via Graph API. Requires research into authentication strategies (OAuth, service principal, managed identity), Graph API endpoints and permissions, Win32 app metadata requirements, error handling, and rate limiting.</p> <p>Benefits:</p> <ul> <li>Streamlines deployment workflow by eliminating manual upload steps</li> <li>Enables automation of Intune app publishing</li> <li>Reduces time from package creation to deployment</li> <li>Useful for organizations managing multiple apps and frequent updates</li> </ul> <p>Dependencies:</p> <ul> <li>Requires Azure AD app registration</li> <li>May need different authentication approaches for different deployment scenarios</li> </ul> <p>Related:</p> <ul> <li>Microsoft Graph API - Win32 Apps</li> <li>Intune App Upload Process</li> </ul>"},{"location":"roadmap/#deployment-wave-management","title":"Deployment Wave Management","text":"<p>Complexity: Very High (5-10 days) Value: High</p> <p>Description: Phased deployment with rings (Pilot \u2192 Production) and gradual rollout.</p> <p>Benefits:</p> <ul> <li>Enables controlled, staged deployments to reduce risk</li> <li>Supports ring-based deployment (Pilot, UAT, Production)</li> <li>Allows gradual rollout with percentage-based scheduling</li> <li>Provides rollback capabilities for failed deployments</li> <li>Useful for organizations requiring careful change management</li> </ul> <p>Dependencies:</p> <ul> <li>Requires Intune upload implementation first</li> <li>Requires Graph API for assignment groups</li> <li>May need separate monitoring/alerting</li> </ul>"},{"location":"roadmap/#future-ideas-by-category","title":"Future Ideas (By Category)","text":"<p>Note: Categories are organized by how they impact users:</p> <ul> <li>User-Facing Features: Features and improvements that directly help recipe developers use NAPT more effectively, including new capabilities, UX enhancements, documentation, and tooling.</li> <li>Code Quality &amp; Validation: Tools that validate and improve recipe quality, including syntax checking, linting, and best practices enforcement.</li> <li>Technical Enhancements: Internal improvements and infrastructure enhancements that improve performance, add backend capabilities, or optimize the tool's operation.</li> </ul>"},{"location":"roadmap/#user-facing-features","title":"User-Facing Features","text":""},{"location":"roadmap/#prepost-installuninstall-script-support","title":"Pre/Post Install/Uninstall Script Support","text":"<p>Status: \ud83d\udca1 Idea Complexity: Low (few hours to 1 day) Value: Medium</p> <p>Description: Add support for pre-install, post-install, pre-uninstall, and post-uninstall script blocks in recipes, allowing separate script sections for each deployment phase.</p> <p>Benefits:</p> <ul> <li>More granular control over deployment lifecycle</li> <li>Separation of concerns (prep vs install vs cleanup)</li> <li>Aligns with PSADT's deployment phase structure</li> <li>Cleaner recipe organization</li> <li>Enables better error handling and rollback capabilities</li> </ul> <p>Related: PSADT already has these phases in the template structure</p>"},{"location":"roadmap/#enhanced-cli-help-menu","title":"Enhanced CLI Help Menu","text":"<p>Status: \ud83d\udca1 Idea Complexity: Low (few hours to 1 day) Value: Medium</p> <p>Description: Improve the <code>napt -h</code> help output with more detailed information, examples, and better organization.</p> <p>Benefits:</p> <ul> <li>Better discoverability of features</li> <li>Reduces need to consult docs for basic usage</li> <li>Improves new user onboarding experience</li> <li>Quick reference for command options</li> <li>Examples for common workflows directly in help text</li> <li>Grouped commands by category (Discovery, Building, Packaging)</li> <li>Tips for troubleshooting (--verbose, --debug flags)</li> </ul> <p>Related: CLI help currently minimal, relies on online documentation</p>"},{"location":"roadmap/#code-quality-validation","title":"Code Quality &amp; Validation","text":""},{"location":"roadmap/#powershell-validation","title":"PowerShell Validation","text":"<p>Status: \ud83d\udca1 Idea Complexity: High (3-5 days) Value: High</p> <p>Description: Validate PowerShell syntax in recipe install/uninstall blocks to catch errors before deployment.</p> <p>Benefits:</p> <ul> <li>Catch syntax errors at recipe validation time</li> <li>Prevent broken deployments</li> <li>Better developer experience</li> <li>Reduces debugging time during deployment</li> </ul> <p>Related: TODO in <code>notapkgtool/build/packager.py</code> - discovered during testing</p>"},{"location":"roadmap/#recipe-linting-best-practices","title":"Recipe Linting &amp; Best Practices","text":"<p>Status: \ud83d\udca1 Idea Complexity: High (3-5 days) Value: Medium</p> <p>Description: Advanced recipe validation beyond syntax checking, including PSADT function validation, deprecation warnings, anti-pattern detection, and style guide enforcement.</p> <p>Benefits:</p> <ul> <li>Higher quality recipes</li> <li>Consistent code style across all recipes</li> <li>Educational for new users</li> <li>Validates PSADT function names exist in v4</li> <li>Warns on deprecated patterns or old v3 functions</li> <li>Suggests improvements (e.g., use Uninstall-ADTApplication)</li> </ul>"},{"location":"roadmap/#technical-enhancements","title":"Technical Enhancements","text":""},{"location":"roadmap/#exe-version-extraction","title":"EXE Version Extraction","text":"<p>Status: \ud83d\udca1 Idea Complexity: High (3-5 days) Value: Medium</p> <p>Description: Extract version information from PE (Portable Executable) headers for .exe installers.</p> <p>Benefits:</p> <ul> <li>Enables version discovery for applications distributed as EXE</li> <li>Useful for vendors who don't provide version in URL or API</li> </ul> <p>Related: Mentioned in <code>notapkgtool/discovery/url_download.py</code> docstring</p>"},{"location":"roadmap/#parallel-package-building","title":"Parallel Package Building","text":"<p>Status: \ud83d\udca1 Idea Complexity: Medium (1-3 days) Value: Medium</p> <p>Description: Build multiple PSADT packages in parallel for faster multi-app workflows.</p> <p>Benefits:</p> <ul> <li>Significantly faster builds for organizations with 50+ apps</li> <li>Reduces time for monthly update cycles</li> <li>Improves CI/CD pipeline performance</li> <li>Progress reporting for multiple concurrent builds</li> </ul>"},{"location":"roadmap/#intunewinapputil-version-tracking","title":"IntuneWinAppUtil Version Tracking","text":"<p>Status: \ud83d\udca1 Idea Complexity: Low (few hours to 1 day) Value: Low</p> <p>Description: Track version of IntuneWinAppUtil.exe in cache metadata instead of always using latest from master, allowing pinning to specific commits/releases and optional configuration for tool version/source.</p> <p>Benefits:</p> <ul> <li>Reproducible builds (pin to known-good version)</li> <li>Control over tool updates</li> <li>Better for air-gapped environments</li> <li>Auto-detect when tool updates are available</li> </ul> <p>Related: TODO in <code>notapkgtool/build/packager.py:47</code></p>"},{"location":"roadmap/#declined-wont-implement","title":"Declined / Won't Implement","text":""},{"location":"roadmap/#recently-completed","title":"Recently Completed","text":""},{"location":"roadmap/#detection-script-generation","title":"Detection Script Generation \u2705","text":"<p>Status: \u2705 Completed Complexity: High (3-5 days) Value: High</p> <p>Description: Automatic PowerShell detection script generation for Intune Win32 app deployments during build process. Scripts check Windows uninstall registry keys, support exact or minimum version matching, and include CMTrace-formatted logging.</p> <p>Implementation Details:</p> <ul> <li>Extracts app name from MSI ProductName (for MSI installers) or uses <code>detection.display_name</code> (for non-MSI installers)</li> <li>Generates scripts that check Windows uninstall registry keys for installed software</li> <li>Supports exact match or minimum version (installed &gt;= expected) detection modes</li> <li>Includes CMTrace-formatted logging with log rotation</li> <li>Scripts saved as <code>{AppName}_{Version}-Detection.ps1</code> sibling to <code>packagefiles/</code> directory</li> <li>Configurable via <code>detection</code> section in defaults or recipe</li> </ul> <p>Related: Implemented in <code>notapkgtool/detection.py</code> and integrated into build process in <code>notapkgtool/build/manager.py</code>. See User Guide - Detection Scripts and Recipe Reference - Detection Configuration.</p> <p>v0.2.0 - PSADT building, packaging, and new discovery strategies v0.1.0 - Core validation, discovery, and configuration system</p> <p>See CHANGELOG.md for detailed release history.</p>"},{"location":"user-guide/","title":"User Guide","text":"<p>This guide covers NAPT's key features, configuration system, and advanced usage patterns.</p>"},{"location":"user-guide/#how-napt-works","title":"How NAPT Works","text":"<p>NAPT automates the complete workflow from version discovery to Intune package creation. Understanding how each step works helps you troubleshoot issues and customize recipes effectively.</p>"},{"location":"user-guide/#discovery-process-napt-discover","title":"Discovery Process (<code>napt discover</code>)","text":"<p>The discovery process finds the latest version and downloads the installer:</p> <ol> <li>Load Configuration - Merges organization defaults, vendor defaults, and recipe configuration</li> <li>Check Version - Uses the configured discovery strategy to check for new versions</li> <li>Compare with Cache - Compares discovered version to cached <code>known_version</code> in state file</li> <li>Skip or Download:<ul> <li>If version unchanged and file exists \u2192 Skip download </li> <li>If version changed or file missing \u2192 Download installer</li> </ul> </li> <li>Extract Version - Extracts version from installer (MSI ProductVersion) or uses discovered version</li> <li>Update State - Updates <code>state/versions.json</code> with new version, file path, SHA-256 hash, and ETag (if download occurred). </li> </ol> <p>Output: Downloaded installer in <code>downloads/</code> directory, updated state file</p>"},{"location":"user-guide/#build-process-napt-build","title":"Build Process (<code>napt build</code>)","text":"<p>The build process creates a complete PSADT package from the recipe and downloaded installer:</p> <ol> <li>Load Configuration - Merges configuration layers (org \u2192 vendor \u2192 recipe)</li> <li>Find Installer - Locates installer in <code>downloads/</code> directory (tries URL filename, then app name/id, then most recent)</li> <li>Extract Version - Extracts version from installer file (MSI files auto-detected by extension), otherwise uses state file version</li> <li>Get PSADT Release - Downloads/caches PSADT Template_v4 from GitHub if not already cached</li> <li>Create Build Directory - Creates versioned directory using discovered app version: <code>builds/{app_id}/{version}/</code></li> <li>Copy PSADT Template - Copies entire PSADT template structure (unmodified) from cache:<ul> <li><code>PSAppDeployToolkit/</code> - Core PSADT module</li> <li><code>PSAppDeployToolkit.Extensions/</code> - Extension modules</li> <li><code>Assets/</code> - Default icons and banners</li> <li><code>Config/</code> - Default configuration files</li> <li><code>Strings/</code> - Localization strings</li> <li><code>Files/</code> - Empty directory for installer files</li> <li><code>SupportFiles/</code> - Empty directory for additional files</li> <li><code>Invoke-AppDeployToolkit.exe</code> - Compiled launcher</li> <li><code>Invoke-AppDeployToolkit.ps1</code> - Template script (will be overwritten)</li> </ul> </li> <li>Generate Deployment Script - Generates <code>Invoke-AppDeployToolkit.ps1</code> from template:<ul> <li>Substitutes PSADT variables (<code>$appVendor</code>, <code>$appName</code>, <code>$appVersion</code>, etc.) from recipe configuration</li> <li>Inserts install script from <code>psadt.install</code> field</li> <li>Inserts uninstall script from <code>psadt.uninstall</code> field</li> <li>Sets dynamic values (AppScriptDate, discovered version, PSADT version)</li> <li>Preserves PSADT's structure and comments</li> </ul> </li> <li>Copy Installer - Copies downloaded installer file to <code>Files/</code> directory:<ul> <li>Source: <code>downloads/{installer_filename}</code></li> <li>Destination: <code>builds/{app_id}/{version}/Files/{installer_filename}</code></li> <li>Installer is accessible in scripts via <code>$dirFiles</code> variable</li> </ul> </li> <li>Apply Branding - Replaces PSADT default assets with custom branding (if configured):<ul> <li>Reads <code>brand_pack</code> configuration from org/vendor defaults</li> <li>Replaces files in <code>Assets/</code> directory (AppIcon.png, Banner.Classic.png, etc.)</li> <li>Uses pattern matching to find source files in brand pack directory</li> </ul> </li> <li>Generate Detection Script - Creates PowerShell detection script for Intune Win32 app deployment:<ul> <li>Extracts app name from MSI ProductName (for MSI installers) or uses detection.display_name (for non-MSI installers)</li> <li>Generates script that checks Windows uninstall registry keys</li> <li>Saves as <code>{AppName}_{Version}-Detection.ps1</code> sibling to <code>packagefiles/</code> directory</li> <li>Script uses CMTrace-formatted logging</li> <li>Configurable via <code>detection</code> section in defaults or recipe</li> </ul> </li> </ol> <p>Output: Complete PSADT package in <code>builds/{app_id}/{version}/</code> with detection script ready for deployment</p>"},{"location":"user-guide/#detection-scripts","title":"Detection Scripts","text":"<p>NAPT automatically generates PowerShell detection scripts during the build process (step 10). These scripts are used by Microsoft Intune to determine if an application is installed and whether it meets version requirements.</p> <p>How Detection Scripts Work:</p> <p>Detection scripts check Windows uninstall registry keys for installed software:</p> <ul> <li> <p>Registry Locations Checked:</p> <ul> <li><code>HKLM:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall</code> (machine-level, 64-bit)</li> <li><code>HKCU:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall</code> (user-level)</li> <li><code>HKLM:\\SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall</code> (machine-level, 32-bit on 64-bit OS)</li> <li><code>HKCU:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall</code> (user-level, 32-bit on 64-bit OS)</li> </ul> </li> <li> <p>Detection Logic:</p> <ul> <li>Matches by <code>DisplayName</code> (from MSI ProductName for MSI installers, or detection.display_name for non-MSI installers)</li> <li>Compares installed version to expected version</li> <li>Supports exact match or minimum version (installed &gt;= expected)</li> <li>Returns exit code 0 if installed and meets requirements, 1 otherwise</li> </ul> </li> <li> <p>App Name Determination:</p> <ul> <li>MSI installers: Uses MSI <code>ProductName</code> property (authoritative source for registry DisplayName)</li> <li>Non-MSI installers: Requires <code>detection.display_name</code> in recipe configuration</li> </ul> </li> <li> <p>Logging:</p> <ul> <li>Uses CMTrace format for Intune diagnostics</li> <li>Logs to <code>C:\\ProgramData\\Microsoft\\IntuneManagementExtension\\Logs\\NAPTDetections.log</code> (system context)</li> <li>Logs to <code>C:\\ProgramData\\Microsoft\\IntuneManagementExtension\\Logs\\NAPTDetectionsUser.log</code> (user context)</li> <li>Automatic log rotation (default: 3MB max size)</li> <li>Fallback locations if primary locations unavailable</li> </ul> </li> </ul> <p>Detection Script Files:</p> <p>Detection scripts are saved as siblings to the <code>packagefiles/</code> directory:</p> <pre><code>builds/napt-chrome/142.0.7444.163/\n  \u251c\u2500\u2500 packagefiles/              # PSADT package (packaged into .intunewin)\n  \u2502   \u2514\u2500\u2500 ...\n  \u2514\u2500\u2500 Google-Chrome-142.0.7444.163-Detection.ps1  # Detection script (upload separately)\n</code></pre> <p>Important: Detection scripts are NOT included in the <code>.intunewin</code> package. They must be uploaded separately to Intune when configuring the Win32 app. The script filename follows the pattern: <code>{AppName}_{Version}-Detection.ps1</code>.</p> <p>Configuration:</p> <p>Detection script behavior can be configured via the <code>detection</code> section in defaults or recipe. See Recipe Reference - Detection Configuration for complete options.</p>"},{"location":"user-guide/#package-process-napt-package","title":"Package Process (<code>napt package</code>)","text":"<p>The package process creates a <code>.intunewin</code> file from the built PSADT directory:</p> <ol> <li>Verify Structure - Validates build directory has required PSADT structure:<ul> <li><code>PSAppDeployToolkit/</code> directory</li> <li><code>Files/</code> directory</li> <li><code>Invoke-AppDeployToolkit.ps1</code> script</li> <li><code>Invoke-AppDeployToolkit.exe</code> launcher</li> </ul> </li> <li>Get IntuneWinAppUtil - Downloads/caches <code>IntuneWinAppUtil.exe</code> from Microsoft's GitHub repository if not already cached</li> <li>Create Package - Runs <code>IntuneWinAppUtil.exe</code> to create <code>.intunewin</code> file:<ul> <li>Input: Build directory (entire PSADT structure)</li> <li>Output: <code>Invoke-AppDeployToolkit.intunewin</code> file (named by IntuneWinAppUtil.exe based on setup file)</li> <li>Package contains all files from build directory in compressed format</li> </ul> </li> <li>Optional Cleanup - If <code>--clean-source</code> flag is used, removes the build directory after successful packaging</li> </ol> <p>Output: <code>.intunewin</code> package file in <code>packages/{app_id}/</code> directory, ready for Intune upload</p>"},{"location":"user-guide/#directory-structure","title":"Directory Structure","text":"<p>After a complete workflow, your directory structure looks like:</p> <pre><code>downloads/\n  \u2514\u2500\u2500 googlechromestandaloneenterprise64.msi\n\nbuilds/\n  \u2514\u2500\u2500 napt-chrome/\n      \u2514\u2500\u2500 142.0.7444.163/\n          \u251c\u2500\u2500 packagefiles/                # PSADT package contents\n          \u2502   \u251c\u2500\u2500 PSAppDeployToolkit/      # PSADT module (from template)\n          \u2502   \u251c\u2500\u2500 PSAppDeployToolkit.Extensions/\n          \u2502   \u251c\u2500\u2500 Assets/                  # Custom branding (if configured)\n          \u2502   \u251c\u2500\u2500 Config/\n          \u2502   \u251c\u2500\u2500 Strings/\n          \u2502   \u251c\u2500\u2500 Files/                   # Installer copied here\n          \u2502   \u2502   \u2514\u2500\u2500 googlechromestandaloneenterprise64.msi\n          \u2502   \u251c\u2500\u2500 SupportFiles/            # Empty (for additional files)\n          \u2502   \u251c\u2500\u2500 Invoke-AppDeployToolkit.ps1  # Generated script\n          \u2502   \u2514\u2500\u2500 Invoke-AppDeployToolkit.exe  # From template\n          \u2514\u2500\u2500 Google-Chrome-142.0.7444.163-Detection.ps1  # Detection script (upload separately to Intune)\n\npackages/\n  \u2514\u2500\u2500 napt-chrome/\n      \u2514\u2500\u2500 Invoke-AppDeployToolkit.intunewin\n\nstate/\n  \u2514\u2500\u2500 versions.json                        # Version tracking\n</code></pre>"},{"location":"user-guide/#commands-reference","title":"Commands Reference","text":"<p>\ud83d\udca1 Tip: All commands support <code>--help</code> (or <code>-h</code>) to show detailed usage, options, and examples. Try <code>napt discover --help</code> to see what's available.</p>"},{"location":"user-guide/#napt-validate","title":"napt validate","text":"<p>Validates recipe syntax and configuration without making network calls. Checks YAML syntax, required fields, and strategy configuration. Does not verify URLs are accessible or files can be downloaded.</p> <pre><code>napt validate recipes/Google/chrome.yaml [OPTIONS]\n</code></pre>"},{"location":"user-guide/#napt-discover","title":"napt discover","text":"<p>Discovers the latest version and downloads the installer. Uses version-based caching to skip downloads when versions haven't changed.</p> <pre><code>napt discover recipes/Google/chrome.yaml [OPTIONS]\n</code></pre>"},{"location":"user-guide/#napt-build","title":"napt build","text":"<p>Builds a complete PSADT package from a recipe and downloaded installer. Generates deployment scripts, applies branding, and creates versioned build directories.</p> <pre><code>napt build recipes/Google/chrome.yaml [OPTIONS]\n</code></pre>"},{"location":"user-guide/#napt-package","title":"napt package","text":"<p>Creates a .intunewin package from a built PSADT directory for Intune deployment.</p> <pre><code>napt package BUILD_DIR [OPTIONS]\n</code></pre>"},{"location":"user-guide/#output-modes","title":"Output Modes","text":"<p>All commands support verbosity flags to control output detail:</p> Flag What it shows (none) Clean output with step indicators (e.g., <code>[1/4]</code>) and progress <code>--verbose</code> or <code>-v</code> All of the above, plus HTTP requests/responses, file operations, SHA-256 hashes, and configuration loading <code>--debug</code> or <code>-d</code> All verbose output, plus full YAML config dumps (org/vendor/recipe/merged), backend selection details, and regex match groups <p>Debug mode includes all verbose output plus deep diagnostic information. Use <code>--verbose</code> for normal troubleshooting and <code>--debug</code> when you need to understand exactly what NAPT is doing internally.</p>"},{"location":"user-guide/#discovery-strategies","title":"Discovery Strategies","text":"<p>Discovery strategies are the core mechanism for obtaining application installers and extracting version information.</p>"},{"location":"user-guide/#available-strategies","title":"Available Strategies","text":"Strategy Version Source Use Case Unchanged Version Detection Speed api_github Git tags GitHub-hosted releases Fast (GitHub API ~100ms) api_json JSON API REST APIs with metadata Fast (API call ~100ms) url_download File metadata Fixed URLs, MSI installers Medium (HTTP conditional ~500ms) web_scrape Download page Vendors without APIs Fast (page scrape + regex) <p>Note: For complete configuration examples and field documentation for each strategy, see Recipe Reference. For implementation details, see Discovery Module in Developer Reference.</p>"},{"location":"user-guide/#decision-guide","title":"Decision Guide","text":"<p>Use this flowchart to choose the right strategy:</p> <pre><code>flowchart TD\n    Start{JSON API for&lt;br/&gt;version/download?}\n    Start --&gt;|Yes| JSON[api_json&lt;br/&gt;Fast version checks]\n    Start --&gt;|No| GitHub{App on&lt;br/&gt;GitHub?}\n    GitHub --&gt;|Yes| GHRelease[api_github&lt;br/&gt;Reliable API, fast checks]\n    GitHub --&gt;|No| DirectURL{Have direct&lt;br/&gt;download URL?}\n    DirectURL --&gt;|Yes| Static[url_download&lt;br/&gt;Must download to check]\n    DirectURL --&gt;|No| Scrape[web_scrape&lt;br/&gt;Scrape page for link]</code></pre> <p>Performance Note: Version-first strategies (everything except url_download) can skip downloads entirely when versions haven't changed, making them ideal for scheduled CI/CD checks.</p>"},{"location":"user-guide/#recipe-basics","title":"Recipe Basics","text":"<p>A recipe file defines how to discover, download, and package an application. Recipes are YAML files that specify:</p> <ul> <li>Discovery strategy - How to find the latest version and download URL</li> <li>PSADT configuration - PowerShell deployment scripts and variables</li> </ul>"},{"location":"user-guide/#basic-structure","title":"Basic Structure","text":"<pre><code>apiVersion: v1  # Recipe format version\napp:\n  name: \"Application Name\"  # Display name\n  id: \"napt-app-id\"  # Unique identifier\n  source:  # Discovery configuration\n    strategy: api_github  # One of: api_github, api_json, url_download, web_scrape\n    # ... strategy-specific fields\n  psadt:  # PSADT configuration\n    install: |  # Installation script\n        # PowerShell code here\n      uninstall: |  # Uninstallation script\n        # PowerShell code here\n</code></pre>"},{"location":"user-guide/#quick-reference","title":"Quick Reference","text":"<ul> <li>Top-level fields: <code>apiVersion</code> (required), <code>apps</code> (required)</li> <li>App fields: <code>name</code> (required), <code>id</code> (required), <code>source</code> (required), <code>psadt</code> (required)</li> <li>Discovery strategies: See Discovery Strategies section above for strategy selection and examples</li> <li>PSADT scripts: Use <code>${discovered_version}</code> for auto-substituted version, <code>$dirFiles</code> for installer path</li> </ul>"},{"location":"user-guide/#complete-documentation","title":"Complete Documentation","text":"<p>For complete field documentation, all options, and detailed examples, see the Recipe Reference page.</p> <p>For practical workflows and copy-paste examples, see Common Tasks.</p>"},{"location":"user-guide/#state-management-caching","title":"State Management &amp; Caching","text":"<p>NAPT automatically tracks discovered versions and optimizes subsequent runs by avoiding unnecessary downloads. This version-based caching is critical for CI/CD with frequent scheduled checks, providing fast feedback when applications haven't changed.</p>"},{"location":"user-guide/#how-it-works","title":"How It Works","text":"<p>NAPT uses two caching approaches depending on the discovery strategy:</p> <pre><code>flowchart TD\n    Start([napt discover]) --&gt; Strategy{Strategy Type?}\n\n    Strategy --&gt;|Version-First&lt;br/&gt;api_github, api_json, web_scrape| CheckVersion[Check Version via API/Page]\n    Strategy --&gt;|File-First&lt;br/&gt;url_download| CheckETag[Check File via HTTP ETag]\n\n    CheckVersion --&gt; VersionChanged{Version&lt;br/&gt;Changed?}\n    VersionChanged --&gt;|No| FileExists1{File&lt;br/&gt;Exists?}\n    VersionChanged --&gt;|Yes| Download1[Download File]\n\n    CheckETag --&gt; ETagResponse{Server&lt;br/&gt;Response?}\n    ETagResponse --&gt;|304 Not Modified| FileExists2{File&lt;br/&gt;Exists?}\n    ETagResponse --&gt;|200 OK Changed| Download2[Download File]\n\n    FileExists1 --&gt;|Yes| SkipDownload1([\u2713 Skip Download&lt;br/&gt;Use cached file])\n    FileExists1 --&gt;|No| Download1\n\n    FileExists2 --&gt;|Yes| SkipDownload2([\u2713 Skip Download&lt;br/&gt;Use cached file])\n    FileExists2 --&gt;|No| Download2\n\n    Download1 --&gt; UpdateState[Update state.json]\n    Download2 --&gt; UpdateState\n    SkipDownload1 --&gt; UpdateState\n    SkipDownload2 --&gt; UpdateState\n    UpdateState --&gt; Ready([\u2713 Ready for napt build])</code></pre> <p>Performance: Version-first strategies (api_github, api_json, web_scrape) check versions before downloading (~100-300ms) and skip downloads entirely if unchanged. File-first strategy (url_download) uses HTTP conditional requests (~500ms) with ETag caching.</p> <p>Note: State is updated after every discovery run, even when skipping downloads. This updates the <code>last_updated</code> timestamp and confirms the cached version is still current.</p> <p>Note: For state tracking implementation, see State Module in Developer Reference.</p>"},{"location":"user-guide/#default-behavior-stateful","title":"Default Behavior (Stateful)","text":"<pre><code># State tracking enabled by default\nnapt discover recipes/Google/chrome.yaml\n\n# Creates/updates: state/versions.json\n</code></pre>"},{"location":"user-guide/#stateless-mode","title":"Stateless Mode","text":"<pre><code># Disable state tracking for one-off checks\nnapt discover recipes/Google/chrome.yaml --stateless\n\n# Always downloads, no caching\n# Useful for CI/CD clean builds\n</code></pre>"},{"location":"user-guide/#configuration-layers","title":"Configuration Layers","text":"<p>NAPT uses a sophisticated 3-layer configuration system that promotes DRY (Don't Repeat Yourself) principles:</p>"},{"location":"user-guide/#the-three-layers","title":"The Three Layers","text":"<ol> <li> <p>Organization defaults (<code>defaults/org.yaml</code>) - Base configuration for all apps. Required if a defaults directory is found. Contains PSADT settings, update policies, and deployment waves.</p> </li> <li> <p>Vendor defaults (<code>defaults/vendors/&lt;Vendor&gt;.yaml</code>) - Vendor-specific overrides. Optional; only loaded if vendor is detected (e.g., Google-specific settings).</p> </li> <li> <p>Recipe configuration (<code>recipes/&lt;Vendor&gt;/&lt;app&gt;.yaml</code>) - App-specific settings. Always required; defines the specific app with final overrides. Any field defined in higher layers can be overridden.</p> </li> </ol>"},{"location":"user-guide/#example","title":"Example","text":"<pre><code># defaults/org.yaml\ndefaults:\n  psadt:\n    release: \"latest\"\n    app_vars:\n      AppVendor: \"Unknown\"\n</code></pre> <pre><code># defaults/vendors/Google.yaml\ndefaults:\n  psadt:\n    app_vars:\n      AppVendor: \"Google LLC\"\n</code></pre> <pre><code># recipes/Google/chrome.yaml\napp:\n  name: \"Google Chrome\"\n  # AppVendor will be \"Google LLC\" (from vendor defaults)\n  # release will be \"latest\" (from org defaults)\n</code></pre> <p>Note: For configuration loading implementation, see Config Module in Developer Reference.</p>"},{"location":"user-guide/#cross-platform-support","title":"Cross-Platform Support","text":"<p>NAPT is a Windows tool for Microsoft Intune packaging. Develop on any platform, package on Windows.</p>"},{"location":"user-guide/#platform-compatibility-matrix","title":"Platform Compatibility Matrix","text":"Platform Discover &amp; Download Build Package Windows \u2705 \u2705 \u2705 Linux \u2705 \u2705 \u26ab Windows Only macOS \u2705 \u2705 \u26ab Windows Only"},{"location":"user-guide/#why-windows-for-packaging","title":"Why Windows for Packaging?","text":"<p>The <code>napt package</code> command uses Microsoft's IntuneWinAppUtil.exe, which is a Windows-only .NET application. This is the official tool for creating .intunewin packages.</p>"},{"location":"user-guide/#recommended-workflows","title":"Recommended Workflows","text":""},{"location":"user-guide/#workflow-1-all-windows-simplest","title":"Workflow 1: All-Windows (Simplest)","text":"<pre><code># Run everything on Windows\nnapt discover recipes/Google/chrome.yaml\nnapt build recipes/Google/chrome.yaml\nnapt package builds/napt-chrome/142.0.7444.163/\n</code></pre>"},{"location":"user-guide/#workflow-2-mixed-platform-development","title":"Workflow 2: Mixed Platform Development","text":"<pre><code># On Linux/macOS: Discovery and build\nnapt discover recipes/Google/chrome.yaml\nnapt build recipes/Google/chrome.yaml\n\n# Transfer build directory to Windows (e.g., via shared storage)\n# On Windows: Package\nnapt package builds/napt-chrome/142.0.7444.163/\n</code></pre> <p>Note: For MSI extraction backend details and implementation information, see Versioning Module in Developer Reference.</p> <p>NAPT can be used as a Python library for automation and integration. For library usage, see Developer Reference.</p>"},{"location":"user-guide/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/#recipe-organization","title":"Recipe Organization","text":"<p>Organize recipes by vendor: <code>recipes/&lt;Vendor&gt;/&lt;app&gt;.yaml</code>. NAPT automatically detects vendor from directory structure and loads <code>defaults/vendors/&lt;Vendor&gt;.yaml</code> if it exists.</p>"},{"location":"user-guide/#state-management","title":"State Management","text":"<p>Production: Keep state tracking enabled (default), use version control for state files, run on schedule to detect updates, use <code>--verbose</code> in CI/CD.</p> <p>Development: Use <code>--stateless</code> for testing, <code>--debug</code> for troubleshooting, delete state file to force re-discovery.</p>"},{"location":"user-guide/#error-handling","title":"Error Handling","text":"<p>All commands return exit codes: <code>0</code> = Success, <code>1</code> = Error. Use in scripts:</p> <pre><code>if napt discover recipes/Google/chrome.yaml; then\n    napt build recipes/Google/chrome.yaml\nfi\n</code></pre> <p>When using NAPT as a Python library, catch exceptions directly. See Developer Reference for details.</p>"},{"location":"user-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/#common-issues","title":"Common Issues","text":"<p>Problem: MSI extraction fails on Linux/macOS</p> <pre><code># Solution: Install msitools\nsudo apt-get install msitools  # Debian/Ubuntu\nbrew install msitools           # macOS\n</code></pre> <p>Problem: State file corrupted</p> <pre><code># NAPT automatically creates backup\n# Backup saved to: state/versions.json.backup\n\n# Force re-download\nnapt discover recipes/app.yaml --stateless\n</code></pre> <p>Problem: GitHub API rate limit</p> <p>\u26a0\ufe0f Security Note: Never put tokens directly in recipe files (e.g., <code>token: \"ghp_abc123\"</code>). Always use environment variable substitution (<code>token: \"${GITHUB_TOKEN}\"</code>) to keep tokens out of version control. See Handle Authentication Tokens for best practices.</p> <pre><code># Solution: Use authentication token via environment variable\nsource:\n  strategy: api_github\n  token: \"${GITHUB_TOKEN}\"  # Environment variable substitution (secure)\n</code></pre> <p><pre><code># Set environment variable on Windows:\n$env:GITHUB_TOKEN=\"your_token_here\"\n</code></pre> <pre><code># Set environment variable on Linux/macOS: \nexport GITHUB_TOKEN=\"your_token_here\"\n</code></pre></p>"},{"location":"api/","title":"Developer Reference","text":"<p>Overview of NAPT's codebase structure, architecture, and key concepts for developers extending or integrating with NAPT.</p>"},{"location":"api/#code-organization","title":"Code Organization","text":"<p>NAPT's codebase structure matches the module organization. Here's the file structure:</p> <pre><code>notapkgtool/\n\u251c\u2500\u2500 __init__.py              # Package initialization and public API exports\n\u251c\u2500\u2500 cli.py                   # Command-line interface\n\u251c\u2500\u2500 core.py                  # Main public API functions (orchestration)\n\u251c\u2500\u2500 detection.py             # Detection script generation for Intune Win32 apps\n\u251c\u2500\u2500 exceptions.py            # Exception hierarchy\n\u251c\u2500\u2500 logging.py               # Logging configuration\n\u251c\u2500\u2500 results.py               # Public API return types (dataclasses)\n\u251c\u2500\u2500 validation.py            # Recipe validation logic\n\u2502\n\u251c\u2500\u2500 build/                   # PSADT package building\n\u2502   \u251c\u2500\u2500 manager.py              # Package building orchestration\n\u2502   \u251c\u2500\u2500 packager.py             # .intunewin package creation\n\u2502   \u2514\u2500\u2500 template.py             # PSADT template generation\n\u2502\n\u251c\u2500\u2500 config/                  # Configuration loading\n\u2502   \u2514\u2500\u2500 loader.py               # 3-layer configuration system\n\u2502\n\u251c\u2500\u2500 discovery/               # Discovery strategies\n\u2502   \u251c\u2500\u2500 api_github.py           # GitHub Releases API strategy\n\u2502   \u251c\u2500\u2500 api_json.py             # Generic JSON API strategy\n\u2502   \u251c\u2500\u2500 base.py                 # Strategy protocol and registry\n\u2502   \u251c\u2500\u2500 url_download.py         # Direct URL download strategy\n\u2502   \u2514\u2500\u2500 web_scrape.py           # Web scraping strategy\n\u2502\n\u251c\u2500\u2500 io/                      # File operations\n\u2502   \u251c\u2500\u2500 download.py             # HTTP file downloads with ETag support\n\u2502   \u2514\u2500\u2500 upload.py               # File upload operations (planned)\n\u2502\n\u251c\u2500\u2500 policy/                  # Update policy enforcement (planned)\n\u2502   \u2514\u2500\u2500 updates.py              # Update policy logic\n\u2502\n\u251c\u2500\u2500 psadt/                   # PSADT release management\n\u2502   \u2514\u2500\u2500 release.py              # PSADT release download and caching\n\u2502\n\u251c\u2500\u2500 state/                   # Version tracking and caching\n\u2502   \u2514\u2500\u2500 tracker.py              # State file management\n\u2502\n\u2514\u2500\u2500 versioning/              # Version extraction and comparison\n    \u251c\u2500\u2500 keys.py                 # Version key extraction (DiscoveredVersion)\n    \u2514\u2500\u2500 msi.py                  # MSI version extraction backends\n</code></pre>"},{"location":"api/#data-flow","title":"Data Flow","text":"<pre><code>Recipe YAML\n    \u2193\n[config/loader.py] Load and merge configuration\n    \u2193\n[core.py] Orchestrate workflow\n    \u2193\n[discovery/] Discover version and download\n    \u2193\n[state/tracker.py] Update version cache\n    \u2193\n[build/manager.py] Build PSADT package\n    \u2193\n[build/packager.py] Create .intunewin\n    \u2193\nResult (dataclass)\n</code></pre>"},{"location":"api/#quick-start","title":"Quick Start","text":"<ul> <li>Using NAPT as a library: Start with <code>core.py</code> - <code>discover_recipe()</code>, <code>build_package()</code>, <code>create_intunewin()</code></li> <li>Extending the CLI: See <code>cli.py</code> for command registration patterns</li> <li>Adding discovery strategies: Implement <code>DiscoveryStrategy</code> protocol from <code>discovery/base.py</code></li> </ul>"},{"location":"api/#key-concepts","title":"Key Concepts","text":"<ul> <li>Discovery Strategies: Protocol-based, stateless, registered in global registry. Two paths: version-first (api_github, api_json, web_scrape) and file-first (url_download with ETag)</li> <li>Configuration: 3-layer system (org \u2192 vendor \u2192 recipe) with deep merging</li> <li>State Management: Tracks versions in <code>state/versions.json</code> for caching</li> <li>Exceptions: All NAPT domain errors use custom exceptions inheriting from <code>NAPTError</code> (ConfigError, NetworkError, PackagingError) - allows catching all NAPT errors or specific types</li> <li>Return Types: Frozen dataclasses from <code>results.py</code> for public API functions only (type-safe, immutable returns)</li> </ul>"},{"location":"api/#design-principles","title":"Design Principles","text":"<ul> <li>Single Responsibility per module</li> <li>Protocol-based interfaces (typing.Protocol)</li> <li>Stateless strategies (instantiated on-demand)</li> <li>Structured returns (frozen dataclasses)</li> <li>Exception-based error handling</li> <li>Immutable configuration</li> </ul>"},{"location":"api/#extending-napt","title":"Extending NAPT","text":"<ul> <li>New discovery strategy: Implement <code>DiscoveryStrategy</code>, register with <code>register_strategy()</code>, add to <code>discovery/__init__.py</code></li> <li>New CLI command: Add parser in <code>cli.py</code>, create <code>cmd_&lt;name&gt;()</code> handler, register with <code>set_defaults()</code></li> <li>New config option: Update schema in <code>config/loader.py</code>, add validation in <code>validation.py</code>, document in recipe schema</li> </ul>"},{"location":"api/#see-also","title":"See Also","text":"<ul> <li>Core API - Main orchestration functions</li> <li>Discovery API - Discovery strategy implementations</li> <li>Build API - Package building functions</li> <li>Config API - Configuration loading</li> <li>Exceptions API - Exception hierarchy</li> </ul>"},{"location":"api/build/","title":"build","text":""},{"location":"api/build/#notapkgtool.build.manager","title":"notapkgtool.build.manager","text":"<p>Build manager for PSADT package creation.</p> <p>This module orchestrates the complete build process for creating PSADT packages from recipes and downloaded installers.</p> Design Principles <ul> <li>Filesystem is source of truth for version information</li> <li>Entire PSADT Template_v4 structure copied pristine</li> <li>Invoke-AppDeployToolkit.ps1 is generated from template (not copied)</li> <li>Build directories are versioned: {app_id}/{version}/</li> <li>Branding applied by replacing files in root Assets/ directory (v4 structure)</li> </ul> Example <p>Basic usage:     <pre><code>from pathlib import Path\nfrom notapkgtool.build import build_package\n\nresult = build_package(\n    recipe_path=Path(\"recipes/Google/chrome.yaml\"),\n    downloads_dir=Path(\"downloads\"),\n)\n\nprint(f\"Built: {result.build_dir}\")\n</code></pre></p>"},{"location":"api/build/#notapkgtool.build.manager.build_package","title":"build_package","text":"<pre><code>build_package(recipe_path: Path, downloads_dir: Path | None = None, output_dir: Path | None = None) -&gt; BuildResult\n</code></pre> <p>Build a PSADT package from a recipe and downloaded installer.</p> <p>This is the main entry point for the build process. It:</p> <ol> <li>Loads the recipe configuration</li> <li>Finds the downloaded installer</li> <li>Extracts version from installer (filesystem is truth)</li> <li>Gets/downloads PSADT release</li> <li>Creates build directory structure</li> <li>Copies PSADT files (pristine)</li> <li>Generates Invoke-AppDeployToolkit.ps1 from template</li> <li>Copies installer to Files/</li> <li>Applies custom branding</li> <li>Generates detection script for Intune Win32 app deployment</li> </ol> <p>Parameters:</p> Name Type Description Default <code>recipe_path</code> <code>Path</code> <p>Path to the recipe YAML file.</p> required <code>downloads_dir</code> <code>Path | None</code> <p>Directory containing the downloaded installer. Default: Path(\"downloads\")</p> <code>None</code> <code>output_dir</code> <code>Path | None</code> <p>Base directory for build output. Default: From config or Path(\"builds\")</p> <code>None</code> <p>Returns:</p> Type Description <code>BuildResult</code> <p>BuildResult dataclass with the following fields:</p> <ul> <li>app_id (str): Unique application identifier from recipe configuration.</li> <li>app_name (str): Application display name from recipe configuration.</li> <li>version (str): Application version extracted from installer file (filesystem     is source of truth).</li> <li>build_dir (Path): Path to the created build directory, following the pattern     {output_dir}/{app_id}/{version}/.</li> <li>psadt_version (str): PSADT version used for the build (e.g., \"4.1.7\").</li> <li>status (str): Build status, typically \"success\" for completed builds.</li> <li>detection_script_path (Path | None): Path to the generated detection script,     or None if detection script generation was skipped or failed (non-fatal).</li> </ul> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If recipe or installer doesn't exist.</p> <code>PackagingError</code> <p>If build process fails or detection script generation fails (when fail_on_error=true in detection config).</p> <code>ConfigError</code> <p>If required configuration is missing.</p> Example <p>Basic build:     <pre><code>result = build_package(Path(\"recipes/Google/chrome.yaml\"))\nprint(result.build_dir)  # builds/napt-chrome/141.0.7390.123\n</code></pre></p> <p>Custom output directory:     <pre><code>result = build_package(\n    Path(\"recipes/Google/chrome.yaml\"),\n    output_dir=Path(\"custom/builds\")\n)\n</code></pre></p> Note <p>Requires installer to be downloaded first (run 'napt discover'). Version extracted from installer file, not state cache. Overwrites existing build directory if it exists. PSADT files are copied pristine from cache. Invoke-AppDeployToolkit.ps1 is generated (not copied). Detection script is generated as a sibling to the packagefiles directory (not included in .intunewin package - must be uploaded separately to Intune). Detection script generation can be configured as non-fatal via detection.fail_on_error setting in recipe configuration.</p> Source code in <code>notapkgtool/build/manager.py</code> <pre><code>def build_package(\n    recipe_path: Path,\n    downloads_dir: Path | None = None,\n    output_dir: Path | None = None,\n) -&gt; BuildResult:\n    \"\"\"Build a PSADT package from a recipe and downloaded installer.\n\n    This is the main entry point for the build process. It:\n\n    1. Loads the recipe configuration\n    2. Finds the downloaded installer\n    3. Extracts version from installer (filesystem is truth)\n    4. Gets/downloads PSADT release\n    5. Creates build directory structure\n    6. Copies PSADT files (pristine)\n    7. Generates Invoke-AppDeployToolkit.ps1 from template\n    8. Copies installer to Files/\n    9. Applies custom branding\n    10. Generates detection script for Intune Win32 app deployment\n\n    Args:\n        recipe_path: Path to the recipe YAML file.\n        downloads_dir: Directory containing the downloaded\n            installer. Default: Path(\"downloads\")\n        output_dir: Base directory for build output.\n            Default: From config or Path(\"builds\")\n\n    Returns:\n        BuildResult dataclass with the following fields:\n\n            - app_id (str): Unique application identifier from recipe configuration.\n            - app_name (str): Application display name from recipe configuration.\n            - version (str): Application version extracted from installer file (filesystem\n                is source of truth).\n            - build_dir (Path): Path to the created build directory, following the pattern\n                {output_dir}/{app_id}/{version}/.\n            - psadt_version (str): PSADT version used for the build (e.g., \"4.1.7\").\n            - status (str): Build status, typically \"success\" for completed builds.\n            - detection_script_path (Path | None): Path to the generated detection script,\n                or None if detection script generation was skipped or failed (non-fatal).\n\n    Raises:\n        FileNotFoundError: If recipe or installer doesn't exist.\n        PackagingError: If build process fails or detection script generation fails\n            (when fail_on_error=true in detection config).\n        ConfigError: If required configuration is missing.\n\n    Example:\n        Basic build:\n            ```python\n            result = build_package(Path(\"recipes/Google/chrome.yaml\"))\n            print(result.build_dir)  # builds/napt-chrome/141.0.7390.123\n            ```\n\n        Custom output directory:\n            ```python\n            result = build_package(\n                Path(\"recipes/Google/chrome.yaml\"),\n                output_dir=Path(\"custom/builds\")\n            )\n            ```\n\n    Note:\n        Requires installer to be downloaded first (run 'napt discover').\n        Version extracted from installer file, not state cache. Overwrites\n        existing build directory if it exists. PSADT files are copied pristine\n        from cache. Invoke-AppDeployToolkit.ps1 is generated (not copied).\n        Detection script is generated as a sibling to the packagefiles directory\n        (not included in .intunewin package - must be uploaded separately to Intune).\n        Detection script generation can be configured as non-fatal via\n        detection.fail_on_error setting in recipe configuration.\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    # Load configuration\n    logger.step(1, 6, \"Loading configuration...\")\n    config = load_effective_config(recipe_path)\n\n    app = config[\"app\"]\n    app_id = app.get(\"id\", \"unknown-app\")\n    app_name = app.get(\"name\", \"Unknown App\")\n\n    # Set defaults\n    if downloads_dir is None:\n        downloads_dir = Path(\"downloads\")\n\n    if output_dir is None:\n        output_dir = Path(\n            config.get(\"defaults\", {}).get(\"build\", {}).get(\"output_dir\", \"builds\")\n        )\n\n    # Find installer file\n    logger.step(2, 6, \"Finding installer...\")\n    state_file = Path(\"state/versions.json\")  # Default state file location\n    installer_file = _find_installer_file(downloads_dir, config, state_file)\n\n    # Extract version from installer or state (filesystem + state are truth)\n    logger.step(3, 6, \"Determining version...\")\n    version = _get_installer_version(installer_file, config, state_file)\n\n    logger.verbose(\"BUILD\", f\"Building {app_name} v{version}\")\n\n    # Get PSADT release\n    logger.step(4, 6, \"Getting PSADT release...\")\n    psadt_config = config.get(\"defaults\", {}).get(\"psadt\", {})\n    release_spec = psadt_config.get(\"release\", \"latest\")\n    cache_dir = Path(psadt_config.get(\"cache_dir\", \"cache/psadt\"))\n\n    psadt_cache_dir = get_psadt_release(release_spec, cache_dir)\n    psadt_version = psadt_cache_dir.name  # Directory name is the version\n\n    logger.verbose(\"BUILD\", f\"Using PSADT {psadt_version}\")\n\n    # Create build directory\n    logger.step(5, 6, \"Creating build structure...\")\n    build_dir = _create_build_directory(output_dir, app_id, version)\n\n    # Copy PSADT files (pristine)\n    _copy_psadt_pristine(psadt_cache_dir, build_dir)\n\n    # Generate Invoke-AppDeployToolkit.ps1\n    from .template import generate_invoke_script\n\n    template_path = psadt_cache_dir / \"Invoke-AppDeployToolkit.ps1\"\n    invoke_script = generate_invoke_script(\n        template_path, config, version, psadt_version\n    )\n\n    # Write generated script\n    script_dest = build_dir / \"Invoke-AppDeployToolkit.ps1\"\n    script_dest.write_text(invoke_script, encoding=\"utf-8\")\n    logger.verbose(\"BUILD\", \"[OK] Generated Invoke-AppDeployToolkit.ps1\")\n\n    # Copy installer\n    _copy_installer(installer_file, build_dir)\n\n    # Apply branding\n    logger.step(6, 7, \"Applying branding...\")\n    _apply_branding(config, build_dir)\n\n    # Generate detection script\n    logger.step(7, 7, \"Generating detection script...\")\n    detection_script_path = None\n    try:\n        detection_script_path = _generate_detection_script(\n            installer_file, config, version, app_id, build_dir\n        )\n        logger.verbose(\"BUILD\", \"[OK] Detection script generated\")\n    except Exception as err:\n        detection_config = config.get(\"defaults\", {}).get(\"detection\", {}) or app.get(\n            \"detection\", {}\n        )\n        fail_on_error = detection_config.get(\"fail_on_error\", True)\n\n        if fail_on_error:\n            raise PackagingError(\n                f\"Detection script generation failed (fail_on_error=true): {err}\"\n            ) from err\n        else:\n            logger.warning(\n                \"BUILD\",\n                f\"Detection script generation failed (non-fatal): {err}\",\n            )\n            logger.verbose(\"BUILD\", \"Continuing build without detection script...\")\n\n    logger.verbose(\"BUILD\", f\"[OK] Build complete: {build_dir}\")\n\n    return BuildResult(\n        app_id=app_id,\n        app_name=app_name,\n        version=version,\n        build_dir=build_dir,\n        psadt_version=psadt_version,\n        status=\"success\",\n        detection_script_path=detection_script_path,\n    )\n</code></pre>"},{"location":"api/build/#notapkgtool.build.template","title":"notapkgtool.build.template","text":"<p>Invoke-AppDeployToolkit.ps1 template generation for NAPT.</p> <p>This module handles generating the Invoke-AppDeployToolkit.ps1 script by reading PSADT's template, substituting configuration values, and inserting recipe-specific install/uninstall code.</p> Design Principles <ul> <li>PSADT template remains pristine in cache</li> <li>Generate script by substitution, not modification</li> <li>Preserve PSADT's structure and comments</li> <li>Support dynamic values (AppScriptDate, discovered version)</li> <li>Merge org defaults with recipe overrides</li> </ul> Example <p>Basic usage:     <pre><code>from pathlib import Path\nfrom notapkgtool.build.template import generate_invoke_script\n\nscript = generate_invoke_script(\n    template_path=Path(\"cache/psadt/4.1.7/Invoke-AppDeployToolkit.ps1\"),\n    config=recipe_config,\n    version=\"141.0.7390.123\",\n    psadt_version=\"4.1.7\"\n)\n\nPath(\"builds/app/version/Invoke-AppDeployToolkit.ps1\").write_text(script)\n</code></pre></p>"},{"location":"api/build/#notapkgtool.build.template.generate_invoke_script","title":"generate_invoke_script","text":"<pre><code>generate_invoke_script(template_path: Path, config: dict[str, Any], version: str, psadt_version: str) -&gt; str\n</code></pre> <p>Generate Invoke-AppDeployToolkit.ps1 from PSADT template and config.</p> <p>Reads the PSADT template, replaces the $adtSession hashtable with values from the configuration, and inserts recipe-specific install/ uninstall code.</p> <p>Parameters:</p> Name Type Description Default <code>template_path</code> <code>Path</code> <p>Path to PSADT's Invoke-AppDeployToolkit.ps1 template.</p> required <code>config</code> <code>dict[str, Any]</code> <p>Merged configuration (org + vendor + recipe).</p> required <code>version</code> <code>str</code> <p>Application version (from filesystem).</p> required <code>psadt_version</code> <code>str</code> <p>PSADT version being used.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Generated PowerShell script text.</p> <p>Raises:</p> Type Description <code>PackagingError</code> <p>If template doesn't exist or template parsing fails.</p> Example <p>Generate deployment script from template:     <pre><code>from pathlib import Path\n\nscript = generate_invoke_script(\n    Path(\"cache/psadt/4.1.7/Invoke-AppDeployToolkit.ps1\"),\n    config,\n    \"141.0.7390.123\",\n    \"4.1.7\"\n)\n</code></pre></p> Source code in <code>notapkgtool/build/template.py</code> <pre><code>def generate_invoke_script(\n    template_path: Path,\n    config: dict[str, Any],\n    version: str,\n    psadt_version: str,\n) -&gt; str:\n    \"\"\"Generate Invoke-AppDeployToolkit.ps1 from PSADT template and config.\n\n    Reads the PSADT template, replaces the $adtSession hashtable with\n    values from the configuration, and inserts recipe-specific install/\n    uninstall code.\n\n    Args:\n        template_path: Path to PSADT's Invoke-AppDeployToolkit.ps1 template.\n        config: Merged configuration (org + vendor + recipe).\n        version: Application version (from filesystem).\n        psadt_version: PSADT version being used.\n\n    Returns:\n        Generated PowerShell script text.\n\n    Raises:\n        PackagingError: If template doesn't exist or template parsing fails.\n\n    Example:\n        Generate deployment script from template:\n            ```python\n            from pathlib import Path\n\n            script = generate_invoke_script(\n                Path(\"cache/psadt/4.1.7/Invoke-AppDeployToolkit.ps1\"),\n                config,\n                \"141.0.7390.123\",\n                \"4.1.7\"\n            )\n            ```\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    if not template_path.exists():\n        raise PackagingError(f\"PSADT template not found: {template_path}\")\n\n    logger.verbose(\"BUILD\", f\"Reading PSADT template: {template_path.name}\")\n\n    # Read template\n    template = template_path.read_text(encoding=\"utf-8\")\n\n    # Build $adtSession variables\n    logger.verbose(\"BUILD\", \"Building $adtSession variables...\")\n    session_vars = _build_adtsession_vars(config, version, psadt_version)\n\n    logger.debug(\"BUILD\", \"--- $adtSession Variables ---\")\n    for key, value in session_vars.items():\n        logger.debug(\"BUILD\", f\"  {key} = {value}\")\n\n    # Replace $adtSession block\n    script = _replace_session_block(template, session_vars)\n    logger.verbose(\"BUILD\", \"[OK] Replaced $adtSession hashtable\")\n\n    # Insert recipe code\n    app = config[\"app\"]\n    psadt_config = app.get(\"psadt\", {})\n    install_code = psadt_config.get(\"install\")\n    uninstall_code = psadt_config.get(\"uninstall\")\n\n    if install_code:\n        logger.verbose(\"BUILD\", \"Inserting install code from recipe\")\n    if uninstall_code:\n        logger.verbose(\"BUILD\", \"Inserting uninstall code from recipe\")\n\n    script = _insert_recipe_code(script, install_code, uninstall_code)\n\n    logger.verbose(\"BUILD\", \"[OK] Script generation complete\")\n\n    return script\n</code></pre>"},{"location":"api/build/#notapkgtool.build.packager","title":"notapkgtool.build.packager","text":"<p>.intunewin package generation for NAPT.</p> <p>This module handles creating .intunewin packages from built PSADT directories using Microsoft's IntuneWinAppUtil.exe tool.</p> Design Principles <ul> <li>IntuneWinAppUtil.exe is cached globally (not per-build)</li> <li>Package output is named by IntuneWinAppUtil.exe: Invoke-AppDeployToolkit.intunewin</li> <li>Build directory can optionally be cleaned after packaging</li> <li>Tool is downloaded from Microsoft's official GitHub repository</li> </ul> Example <p>Basic usage:     <pre><code>from pathlib import Path\nfrom notapkgtool.build.packager import create_intunewin\n\nresult = create_intunewin(\n    build_dir=Path(\"builds/napt-chrome/141.0.7390.123\"),\n    output_dir=Path(\"packages\")\n)\n\nprint(f\"Package: {result.package_path}\")\n</code></pre></p>"},{"location":"api/build/#notapkgtool.build.packager.create_intunewin","title":"create_intunewin","text":"<pre><code>create_intunewin(build_dir: Path, output_dir: Path | None = None, clean_source: bool = False) -&gt; PackageResult\n</code></pre> <p>Create a .intunewin package from a PSADT build directory.</p> <p>Uses Microsoft's IntuneWinAppUtil.exe tool to package a PSADT build directory into a .intunewin file suitable for Intune deployment.</p> <p>Parameters:</p> Name Type Description Default <code>build_dir</code> <code>Path</code> <p>Path to the built PSADT package directory.</p> required <code>output_dir</code> <code>Path | None</code> <p>Directory for the .intunewin output. Default: packages/{app_id}/</p> <code>None</code> <code>clean_source</code> <code>bool</code> <p>If True, remove the build directory after packaging. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>PackageResult</code> <p>PackageResult dataclass with the following fields:</p> <ul> <li>build_dir (Path): Path to the PSADT build directory that was packaged.     This directory may have been removed if clean_source=True.</li> <li>package_path (Path): Path to the created .intunewin file, located at     {output_dir}/{app_id}/Invoke-AppDeployToolkit.intunewin (named by IntuneWinAppUtil.exe).</li> <li>app_id (str): Unique application identifier extracted from build directory     structure.</li> <li>version (str): Application version extracted from build directory structure.</li> <li>status (str): Packaging status, typically \"success\" for completed packaging.</li> </ul> <p>Raises:</p> Type Description <code>ConfigError</code> <p>If build directory structure is invalid.</p> <code>PackagingError</code> <p>If packaging fails.</p> <code>NetworkError</code> <p>If IntuneWinAppUtil.exe download fails.</p> Example <p>Basic packaging:     <pre><code>result = create_intunewin(\n    build_dir=Path(\"builds/napt-chrome/141.0.7390.123\")\n)\nprint(result.package_path)\n# packages/napt-chrome/Invoke-AppDeployToolkit.intunewin\n</code></pre></p> <p>With cleanup:     <pre><code>result = create_intunewin(\n    build_dir=Path(\"builds/napt-chrome/141.0.7390.123\"),\n    clean_source=True\n)\n# Build directory is removed after packaging\n</code></pre></p> Note <p>Requires build directory from 'napt build' command. IntuneWinAppUtil.exe is downloaded and cached on first use. Setup file is always \"Invoke-AppDeployToolkit.exe\". Output file is named by IntuneWinAppUtil.exe: packages/{app_id}/Invoke-AppDeployToolkit.intunewin</p> Source code in <code>notapkgtool/build/packager.py</code> <pre><code>def create_intunewin(\n    build_dir: Path,\n    output_dir: Path | None = None,\n    clean_source: bool = False,\n) -&gt; PackageResult:\n    \"\"\"Create a .intunewin package from a PSADT build directory.\n\n    Uses Microsoft's IntuneWinAppUtil.exe tool to package a PSADT build\n    directory into a .intunewin file suitable for Intune deployment.\n\n    Args:\n        build_dir: Path to the built PSADT package directory.\n        output_dir: Directory for the .intunewin output.\n            Default: packages/{app_id}/\n        clean_source: If True, remove the build directory\n            after packaging. Default is False.\n\n    Returns:\n        PackageResult dataclass with the following fields:\n\n            - build_dir (Path): Path to the PSADT build directory that was packaged.\n                This directory may have been removed if clean_source=True.\n            - package_path (Path): Path to the created .intunewin file, located at\n                {output_dir}/{app_id}/Invoke-AppDeployToolkit.intunewin (named by IntuneWinAppUtil.exe).\n            - app_id (str): Unique application identifier extracted from build directory\n                structure.\n            - version (str): Application version extracted from build directory structure.\n            - status (str): Packaging status, typically \"success\" for completed packaging.\n\n    Raises:\n        ConfigError: If build directory structure is invalid.\n        PackagingError: If packaging fails.\n        NetworkError: If IntuneWinAppUtil.exe download fails.\n\n    Example:\n        Basic packaging:\n            ```python\n            result = create_intunewin(\n                build_dir=Path(\"builds/napt-chrome/141.0.7390.123\")\n            )\n            print(result.package_path)\n            # packages/napt-chrome/Invoke-AppDeployToolkit.intunewin\n            ```\n\n        With cleanup:\n            ```python\n            result = create_intunewin(\n                build_dir=Path(\"builds/napt-chrome/141.0.7390.123\"),\n                clean_source=True\n            )\n            # Build directory is removed after packaging\n            ```\n\n    Note:\n        Requires build directory from 'napt build' command. IntuneWinAppUtil.exe\n        is downloaded and cached on first use. Setup file is always\n        \"Invoke-AppDeployToolkit.exe\". Output file is named by IntuneWinAppUtil.exe:\n        packages/{app_id}/Invoke-AppDeployToolkit.intunewin\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n\n    build_dir = build_dir.resolve()\n\n    if not build_dir.exists():\n        raise PackagingError(f\"Build directory not found: {build_dir}\")\n\n    # Extract app_id and version from directory structure (app_id/version/)\n    version = build_dir.name\n    app_id = build_dir.parent.name\n\n    logger.verbose(\"PACKAGE\", f\"Packaging {app_id} v{version}\")\n\n    # Verify build structure\n    logger.step(1, 4, \"Verifying build structure...\")\n    _verify_build_structure(build_dir)\n\n    # Determine output directory\n    if output_dir is None:\n        output_dir = Path(\"packages\") / app_id\n\n    output_dir = output_dir.resolve()\n\n    # Get IntuneWinAppUtil tool\n    logger.step(2, 4, \"Getting IntuneWinAppUtil tool...\")\n    tool_cache = Path(\"cache/tools\")\n    tool_path = _get_intunewin_tool(tool_cache)\n\n    # Create .intunewin package\n    logger.step(3, 4, \"Creating .intunewin package...\")\n    package_path = _execute_packaging(\n        tool_path,\n        build_dir,\n        \"Invoke-AppDeployToolkit.exe\",\n        output_dir,\n    )\n\n    # Optionally clean source\n    if clean_source:\n        logger.step(4, 4, \"Cleaning source build directory...\")\n        shutil.rmtree(build_dir)\n        logger.verbose(\"PACKAGE\", f\"[OK] Removed build directory: {build_dir}\")\n    else:\n        logger.step(4, 4, \"Package complete\")\n\n    logger.verbose(\"PACKAGE\", f\"[OK] Package created: {package_path}\")\n\n    return PackageResult(\n        build_dir=build_dir,\n        package_path=package_path,\n        app_id=app_id,\n        version=version,\n        status=\"success\",\n    )\n</code></pre>"},{"location":"api/cli/","title":"cli","text":""},{"location":"api/cli/#notapkgtool.cli","title":"notapkgtool.cli","text":"<p>Command-line interface for NAPT.</p> <p>This module provides the main CLI entry point for the napt tool, offering commands for recipe validation, package building, and deployment management.</p> <p>Commands:</p> <pre><code>validate: Validate recipe syntax and configuration\ndiscover: Discover latest version and download installer\nbuild: Build PSADT package from recipe\npackage: Create .intunewin package for Intune\n</code></pre> Example <p>Validate recipe syntax:     <pre><code>$ napt validate recipes/Google/chrome.yaml\n</code></pre></p> <p>Discover latest version:     <pre><code>$ napt discover recipes/Google/chrome.yaml\n</code></pre></p> <p>Build PSADT package:     <pre><code>$ napt build recipes/Google/chrome.yaml\n</code></pre></p> <p>Create .intunewin package:     <pre><code>$ napt package builds/napt-chrome/142.0.7444.60/\n</code></pre></p> <p>Enable verbose output:     <pre><code>$ napt discover recipes/Google/chrome.yaml --verbose\n</code></pre></p> <p>Enable debug output:     <pre><code>$ napt discover recipes/Google/chrome.yaml --debug\n</code></pre></p> <p>Exit Codes:</p> <ul> <li>0: Success</li> <li>1: Error (configuration, download, or validation failure)</li> </ul> Note <p>The CLI uses argparse for command parsing (stdlib, zero dependencies). Commands are registered with subparsers for clean organization. Each command has its own handler function (cmd_). Verbose mode shows full tracebacks on errors for debugging. Debug mode implies verbose mode and shows detailed configuration dumps."},{"location":"api/cli/#notapkgtool.cli.cmd_validate","title":"cmd_validate","text":"<pre><code>cmd_validate(args: Namespace) -&gt; int\n</code></pre> <p>Handler for 'napt validate' command.</p> <p>Validates recipe syntax and configuration without downloading files or making network calls. This is useful for quick feedback during recipe development and for CI/CD pre-checks.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Parsed command-line arguments containing recipe path and verbose flag.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Exit code (0 for valid recipe, 1 for invalid).</p> Note <p>Prints validation results, errors, and warnings to stdout.</p> Source code in <code>notapkgtool/cli.py</code> <pre><code>def cmd_validate(args: argparse.Namespace) -&gt; int:\n    \"\"\"Handler for 'napt validate' command.\n\n    Validates recipe syntax and configuration without downloading files or\n    making network calls. This is useful for quick feedback during recipe\n    development and for CI/CD pre-checks.\n\n    Args:\n        args: Parsed command-line arguments containing\n            recipe path and verbose flag.\n\n    Returns:\n        Exit code (0 for valid recipe, 1 for invalid).\n\n    Note:\n        Prints validation results, errors, and warnings to stdout.\n\n    \"\"\"\n    # Configure global logger\n    logger = get_logger(verbose=args.verbose, debug=args.debug)\n    set_global_logger(logger)\n\n    recipe_path = Path(args.recipe).resolve()\n\n    print(f\"Validating recipe: {recipe_path}\")\n    print()\n\n    # Validate the recipe\n    result = validate_recipe(recipe_path)\n\n    # Display results\n    print(\"=\" * 70)\n    print(\"VALIDATION RESULTS\")\n    print(\"=\" * 70)\n    print(f\"Recipe:      {result.recipe_path}\")\n    print(f\"Status:      {result.status.upper()}\")\n    print(f\"App Count:   {result.app_count}\")\n    print()\n\n    # Show warnings if any\n    if result.warnings:\n        print(f\"Warnings ({len(result.warnings)}):\")\n        for warning in result.warnings:\n            print(f\"  [WARNING] {warning}\")\n        print()\n\n    # Show errors if any\n    if result.errors:\n        print(f\"Errors ({len(result.errors)}):\")\n        for error in result.errors:\n            print(f\"  [X] {error}\")\n        print()\n\n    print(\"=\" * 70)\n\n    if result.status == \"valid\":\n        print()\n        print(\"[SUCCESS] Recipe is valid!\")\n        return 0\n    else:\n        print()\n        print(f\"[FAILED] Recipe validation failed with {len(result.errors)} error(s).\")\n        return 1\n</code></pre>"},{"location":"api/cli/#notapkgtool.cli.cmd_discover","title":"cmd_discover","text":"<pre><code>cmd_discover(args: Namespace) -&gt; int\n</code></pre> <p>Handler for 'napt discover' command.</p> <p>Discovers the latest version of an application by querying the source and downloading the installer. This command validates the recipe YAML, uses the configured discovery strategy to find the latest version, downloads the installer (or uses cached version via ETag), extracts version information, and updates the state file with caching info.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Parsed command-line arguments containing recipe path, output directory, state file path, and flags.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Exit code (0 for success, 1 for failure).</p> Note <p>Downloads installer file to output_dir (or uses cached version). Updates state file with version and ETag information. Prints progress and results to stdout. Prints errors with optional traceback if verbose/debug.</p> Source code in <code>notapkgtool/cli.py</code> <pre><code>def cmd_discover(args: argparse.Namespace) -&gt; int:\n    \"\"\"Handler for 'napt discover' command.\n\n    Discovers the latest version of an application by querying the source\n    and downloading the installer. This command validates the recipe YAML,\n    uses the configured discovery strategy to find the latest version,\n    downloads the installer (or uses cached version via ETag), extracts\n    version information, and updates the state file with caching info.\n\n    Args:\n        args: Parsed command-line arguments containing\n            recipe path, output directory, state file path, and flags.\n\n    Returns:\n        Exit code (0 for success, 1 for failure).\n\n    Note:\n        Downloads installer file to output_dir (or uses cached version).\n        Updates state file with version and ETag information. Prints progress\n        and results to stdout. Prints errors with optional traceback if verbose/debug.\n\n    \"\"\"\n    # Configure global logger\n    logger = get_logger(verbose=args.verbose, debug=args.debug)\n    set_global_logger(logger)\n\n    recipe_path = Path(args.recipe).resolve()\n    output_dir = Path(args.output_dir).resolve()\n\n    if not recipe_path.exists():\n        print(f\"Error: Recipe file not found: {recipe_path}\")\n        return 1\n\n    print(f\"Discovering version for recipe: {recipe_path}\")\n    print(f\"Output directory: {output_dir}\")\n    print()\n\n    try:\n        result = discover_recipe(\n            recipe_path,\n            output_dir,\n            state_file=args.state_file if not args.stateless else None,\n            stateless=args.stateless,\n        )\n    except (ConfigError, NetworkError, PackagingError) as err:\n        print(f\"Error: {err}\")\n        if args.verbose or args.debug:\n            import traceback\n\n            traceback.print_exc()\n        return 1\n    except NAPTError as err:\n        # Catch any other NAPT errors we might have missed\n        print(f\"Error: {err}\")\n        if args.verbose or args.debug:\n            import traceback\n\n            traceback.print_exc()\n        return 1\n\n    # Display results\n    print(\"=\" * 70)\n    print(\"DISCOVERY RESULTS\")\n    print(\"=\" * 70)\n    print(f\"App Name:        {result.app_name}\")\n    print(f\"App ID:          {result.app_id}\")\n    print(f\"Strategy:        {result.strategy}\")\n    print(f\"Version:         {result.version}\")\n    print(f\"Version Source:  {result.version_source}\")\n    print(f\"File Path:       {result.file_path}\")\n    print(f\"SHA-256:         {result.sha256}\")\n    print(f\"Status:          {result.status}\")\n    print(\"=\" * 70)\n    print()\n    print(\"[SUCCESS] Version discovered successfully!\")\n\n    return 0\n</code></pre>"},{"location":"api/cli/#notapkgtool.cli.cmd_build","title":"cmd_build","text":"<pre><code>cmd_build(args: Namespace) -&gt; int\n</code></pre> <p>Handler for 'napt build' command.</p> <p>Builds a PSADT package from a recipe and downloaded installer. This command loads the recipe configuration, finds the downloaded installer, extracts version from the installer file (filesystem is truth), downloads/caches the specified PSADT release, creates build directory structure, copies PSADT files pristine from cache, generates Invoke-AppDeployToolkit.ps1 with recipe values, copies installer to Files/ directory, and applies custom branding.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Parsed command-line arguments containing recipe path, downloads directory, output directory, and flags.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Exit code (0 for success, 1 for failure).</p> Note <p>Creates build directory structure. Downloads PSADT release if not cached. Generates Invoke-AppDeployToolkit.ps1. Copies files to build directory. Prints progress and results to stdout.</p> Source code in <code>notapkgtool/cli.py</code> <pre><code>def cmd_build(args: argparse.Namespace) -&gt; int:\n    \"\"\"Handler for 'napt build' command.\n\n    Builds a PSADT package from a recipe and downloaded installer. This command\n    loads the recipe configuration, finds the downloaded installer, extracts\n    version from the installer file (filesystem is truth), downloads/caches\n    the specified PSADT release, creates build directory structure, copies\n    PSADT files pristine from cache, generates Invoke-AppDeployToolkit.ps1\n    with recipe values, copies installer to Files/ directory, and applies\n    custom branding.\n\n    Args:\n        args: Parsed command-line arguments containing\n            recipe path, downloads directory, output directory, and flags.\n\n    Returns:\n        Exit code (0 for success, 1 for failure).\n\n    Note:\n        Creates build directory structure. Downloads PSADT release if not cached.\n        Generates Invoke-AppDeployToolkit.ps1. Copies files to build directory.\n        Prints progress and results to stdout.\n\n    \"\"\"\n    # Configure global logger\n    logger = get_logger(verbose=args.verbose, debug=args.debug)\n    set_global_logger(logger)\n\n    recipe_path = Path(args.recipe).resolve()\n    downloads_dir = Path(args.downloads_dir).resolve()\n    output_dir = Path(args.output_dir) if args.output_dir else None\n\n    if not recipe_path.exists():\n        print(f\"Error: Recipe file not found: {recipe_path}\")\n        return 1\n\n    if not downloads_dir.exists():\n        print(f\"Error: Downloads directory not found: {downloads_dir}\")\n        print(\"Run 'napt discover' first to download the installer.\")\n        return 1\n\n    print(f\"Building PSADT package for recipe: {recipe_path}\")\n    print(f\"Downloads directory: {downloads_dir}\")\n    if output_dir:\n        print(f\"Output directory: {output_dir}\")\n    print()\n\n    try:\n        result = build_package(\n            recipe_path,\n            downloads_dir=downloads_dir,\n            output_dir=output_dir,\n        )\n    except (ConfigError, NetworkError, PackagingError) as err:\n        print(f\"Error: {err}\")\n        if args.verbose or args.debug:\n            import traceback\n\n            traceback.print_exc()\n        return 1\n    except NAPTError as err:\n        # Catch any other NAPT errors we might have missed\n        print(f\"Error: {err}\")\n        if args.verbose or args.debug:\n            import traceback\n\n            traceback.print_exc()\n        return 1\n\n    # Display results\n    print(\"=\" * 70)\n    print(\"BUILD RESULTS\")\n    print(\"=\" * 70)\n    print(f\"App Name:        {result.app_name}\")\n    print(f\"App ID:          {result.app_id}\")\n    print(f\"Version:         {result.version}\")\n    print(f\"PSADT Version:   {result.psadt_version}\")\n    print(f\"Build Directory: {result.build_dir}\")\n    print(f\"Status:          {result.status}\")\n    print(\"=\" * 70)\n    print()\n    print(\"[SUCCESS] PSADT package built successfully!\")\n\n    return 0\n</code></pre>"},{"location":"api/cli/#notapkgtool.cli.cmd_package","title":"cmd_package","text":"<pre><code>cmd_package(args: Namespace) -&gt; int\n</code></pre> <p>Handler for 'napt package' command.</p> <p>Creates a .intunewin package from a built PSADT directory. This command verifies the build directory has valid PSADT structure, downloads/caches IntuneWinAppUtil.exe if needed, runs IntuneWinAppUtil.exe to create .intunewin package, and optionally cleans the source build directory after packaging.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Parsed command-line arguments containing build directory path, output directory, clean flag, and debug flags.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Exit code (0 for success, 1 for failure).</p> Note <p>Creates .intunewin file in output directory. Downloads IntuneWinAppUtil.exe if not cached. Optionally removes build directory if --clean-source. Prints progress and results to stdout.</p> Source code in <code>notapkgtool/cli.py</code> <pre><code>def cmd_package(args: argparse.Namespace) -&gt; int:\n    \"\"\"Handler for 'napt package' command.\n\n    Creates a .intunewin package from a built PSADT directory. This command\n    verifies the build directory has valid PSADT structure, downloads/caches\n    IntuneWinAppUtil.exe if needed, runs IntuneWinAppUtil.exe to create\n    .intunewin package, and optionally cleans the source build directory\n    after packaging.\n\n    Args:\n        args: Parsed command-line arguments containing\n            build directory path, output directory, clean flag, and debug flags.\n\n    Returns:\n        Exit code (0 for success, 1 for failure).\n\n    Note:\n        Creates .intunewin file in output directory. Downloads IntuneWinAppUtil.exe\n        if not cached. Optionally removes build directory if --clean-source.\n        Prints progress and results to stdout.\n\n    \"\"\"\n    # Configure global logger\n    logger = get_logger(verbose=args.verbose, debug=args.debug)\n    set_global_logger(logger)\n\n    build_dir = Path(args.build_dir).resolve()\n    output_dir = Path(args.output_dir) if args.output_dir else None\n\n    if not build_dir.exists():\n        print(f\"Error: Build directory not found: {build_dir}\")\n        return 1\n\n    print(f\"Creating .intunewin package from: {build_dir}\")\n    if output_dir:\n        print(f\"Output directory: {output_dir}\")\n    print()\n\n    try:\n        result = create_intunewin(\n            build_dir,\n            output_dir=output_dir,\n            clean_source=args.clean_source,\n        )\n    except (ConfigError, NetworkError, PackagingError) as err:\n        print(f\"Error: {err}\")\n        if args.verbose or args.debug:\n            import traceback\n\n            traceback.print_exc()\n        return 1\n    except NAPTError as err:\n        # Catch any other NAPT errors we might have missed\n        print(f\"Error: {err}\")\n        if args.verbose or args.debug:\n            import traceback\n\n            traceback.print_exc()\n        return 1\n\n    # Display results\n    print(\"=\" * 70)\n    print(\"PACKAGE RESULTS\")\n    print(\"=\" * 70)\n    print(f\"App ID:          {result.app_id}\")\n    print(f\"Version:         {result.version}\")\n    print(f\"Package Path:    {result.package_path}\")\n    if args.clean_source:\n        print(f\"Build Directory: {result.build_dir} (removed)\")\n    else:\n        print(f\"Build Directory: {result.build_dir}\")\n    print(f\"Status:          {result.status}\")\n    print(\"=\" * 70)\n    print()\n    print(\"[SUCCESS] .intunewin package created successfully!\")\n\n    return 0\n</code></pre>"},{"location":"api/cli/#notapkgtool.cli.main","title":"main","text":"<pre><code>main() -&gt; None\n</code></pre> <p>Main entry point for the napt CLI.</p> <p>This function is registered as the 'napt' console script in pyproject.toml.</p> Source code in <code>notapkgtool/cli.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the napt CLI.\n\n    This function is registered as the 'napt' console script in pyproject.toml.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        prog=\"napt\",\n        description=\"NAPT - Not a Pkg Tool for Windows/Intune packaging with PSADT\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n    )\n\n    parser.add_argument(\n        \"--version\",\n        action=\"version\",\n        version=f\"napt {version('notapkgtool')}\",\n    )\n\n    subparsers = parser.add_subparsers(\n        dest=\"command\",\n        help=\"Available commands\",\n        required=True,\n    )\n\n    # 'validate' command\n    parser_validate = subparsers.add_parser(\n        \"validate\",\n        help=\"Validate recipe syntax and configuration (no downloads)\",\n        description=(\n            \"Check recipe YAML for syntax errors and configuration issues \"\n            \"without making network calls.\\n\\n\"\n            \"Examples:\\n\"\n            \"  napt validate recipes/Google/chrome.yaml\\n\"\n            \"  napt validate recipes/Google/chrome.yaml --verbose\\n\\n\"\n            \"See docs for more examples and workflows.\"\n        ),\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n    )\n    parser_validate.add_argument(\n        \"recipe\",\n        help=\"Path to the recipe YAML file\",\n    )\n    parser_validate.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"Show validation progress and details\",\n    )\n    parser_validate.add_argument(\n        \"-d\",\n        \"--debug\",\n        action=\"store_true\",\n        help=\"Show detailed debugging output (implies --verbose)\",\n    )\n    parser_validate.set_defaults(func=cmd_validate)\n\n    # 'discover' command\n    parser_discover = subparsers.add_parser(\n        \"discover\",\n        help=\"Discover latest version and download installer\",\n        description=(\n            \"Find the latest version using the configured discovery strategy \"\n            \"and download the installer.\\n\\n\"\n            \"Examples:\\n\"\n            \"  napt discover recipes/Google/chrome.yaml\\n\"\n            \"  napt discover recipes/Google/chrome.yaml --verbose\\n\"\n            \"  napt discover recipes/Google/chrome.yaml --stateless\\n\\n\"\n            \"See docs for more examples and workflows.\"\n        ),\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n    )\n    parser_discover.add_argument(\n        \"recipe\",\n        help=\"Path to the recipe YAML file\",\n    )\n    parser_discover.add_argument(\n        \"--output-dir\",\n        default=\"./downloads\",\n        help=\"Directory to save downloaded files (default: ./downloads)\",\n    )\n    parser_discover.add_argument(\n        \"--state-file\",\n        type=Path,\n        default=Path(\"state/versions.json\"),\n        help=(\n            \"State file for version tracking and ETag caching \"\n            \"(default: state/versions.json)\"\n        ),\n    )\n    parser_discover.add_argument(\n        \"--stateless\",\n        action=\"store_true\",\n        help=\"Disable state tracking (no caching, always download full files)\",\n    )\n    parser_discover.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"Show progress and high-level status updates\",\n    )\n    parser_discover.add_argument(\n        \"-d\",\n        \"--debug\",\n        action=\"store_true\",\n        help=\"Show detailed debugging output (implies --verbose)\",\n    )\n    parser_discover.set_defaults(func=cmd_discover)\n\n    # 'build' command\n    parser_build = subparsers.add_parser(\n        \"build\",\n        help=\"Build PSADT package from recipe and installer\",\n        description=(\n            \"Create a PSADT deployment package from a recipe and \"\n            \"downloaded installer.\\n\\n\"\n            \"Examples:\\n\"\n            \"  napt build recipes/Google/chrome.yaml\\n\"\n            \"  napt build recipes/Google/chrome.yaml --verbose\\n\"\n            \"  napt build recipes/Google/chrome.yaml --output-dir ./builds\\n\\n\"\n            \"See docs for more examples and workflows.\"\n        ),\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n    )\n    parser_build.add_argument(\n        \"recipe\",\n        help=\"Path to the recipe YAML file\",\n    )\n    parser_build.add_argument(\n        \"--downloads-dir\",\n        default=\"./downloads\",\n        help=\"Directory containing the downloaded installer (default: ./downloads)\",\n    )\n    parser_build.add_argument(\n        \"--output-dir\",\n        default=None,\n        help=\"Base directory for build output (default: from config or ./builds)\",\n    )\n    parser_build.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"Show progress and high-level status updates\",\n    )\n    parser_build.add_argument(\n        \"-d\",\n        \"--debug\",\n        action=\"store_true\",\n        help=\"Show detailed debugging output (implies --verbose)\",\n    )\n    parser_build.set_defaults(func=cmd_build)\n\n    # 'package' command\n    parser_package = subparsers.add_parser(\n        \"package\",\n        help=\"Create .intunewin package from PSADT build directory\",\n        description=(\n            \"Package a built PSADT directory into a .intunewin file \"\n            \"for Intune deployment.\\n\\n\"\n            \"Examples:\\n\"\n            \"  napt package builds/napt-chrome/142.0.7444.60/\\n\"\n            \"  napt package builds/napt-chrome/142.0.7444.60/ --clean-source\\n\"\n            \"  napt package builds/napt-chrome/142.0.7444.60/ --verbose\\n\\n\"\n            \"See docs for more examples and workflows.\"\n        ),\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n    )\n    parser_package.add_argument(\n        \"build_dir\",\n        help=\"Path to the built PSADT package directory\",\n    )\n    parser_package.add_argument(\n        \"--output-dir\",\n        default=None,\n        help=\"Directory for .intunewin output (default: packages/{app_id}/)\",\n    )\n    parser_package.add_argument(\n        \"--clean-source\",\n        action=\"store_true\",\n        help=\"Remove the build directory after packaging\",\n    )\n    parser_package.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"Show progress and high-level status updates\",\n    )\n    parser_package.add_argument(\n        \"-d\",\n        \"--debug\",\n        action=\"store_true\",\n        help=\"Show detailed debugging output (implies --verbose)\",\n    )\n    parser_package.set_defaults(func=cmd_package)\n\n    # Parse and dispatch\n    args = parser.parse_args()\n\n    # Call the appropriate command handler\n    exit_code = args.func(args)\n    sys.exit(exit_code)\n</code></pre>"},{"location":"api/config/","title":"config","text":""},{"location":"api/config/#notapkgtool.config","title":"notapkgtool.config","text":"<p>Configuration loading and management for NAPT.</p> <p>This module provides tools for loading, merging, and validating YAML-based configuration files with a layered approach:</p> <ul> <li>Organization-wide defaults (defaults/org.yaml)</li> <li>Vendor-specific defaults (defaults/vendors/.yaml) <li>Recipe-specific configuration (recipes//.yaml) <p>The loader performs deep merging where dicts are merged recursively and lists/scalars are replaced (last wins). Relative paths are resolved against the recipe file location for relocatability.</p> Example <p>Basic usage:     <pre><code>from pathlib import Path\nfrom notapkgtool.config import load_effective_config\n\nconfig = load_effective_config(Path(\"recipes/Google/chrome.yaml\"))\napp = config.get(\"app\")\nprint(app[\"name\"])  # \"Google Chrome\"\n</code></pre></p>"},{"location":"api/config/#notapkgtool.config.load_effective_config","title":"load_effective_config","text":"<pre><code>load_effective_config(recipe_path: Path, *, vendor: str | None = None) -&gt; dict[str, Any]\n</code></pre> <p>Load and merge the effective configuration for a recipe.</p> Steps <ol> <li>Read recipe YAML</li> <li>Find defaults root by scanning upwards for 'defaults/org.yaml'</li> <li>Load org defaults (required if defaults root exists)</li> <li>Determine vendor (param 'vendor' &gt; folder name &gt; recipe contents)</li> <li>Load vendor defaults if present</li> <li>Merge: org -&gt; vendor -&gt; recipe (dicts deep-merge, lists replace)</li> <li>Resolve known relative paths (relative to the recipe directory)</li> <li>Inject dynamic fields (AppScriptDate = today if absent)</li> </ol> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>A merged configuration dict ready for downstream processors.</p> <code>dict[str, Any]</code> <p>If no defaults were found in the tree, the recipe is returned</p> <code>dict[str, Any]</code> <p>as-is (with path resolution + injection).</p> <p>Raises:</p> Type Description <code>ConfigError</code> <p>On YAML parse errors, empty files, invalid structure, or if the recipe file is missing.</p> Source code in <code>notapkgtool/config/loader.py</code> <pre><code>def load_effective_config(\n    recipe_path: Path,\n    *,\n    vendor: str | None = None,\n) -&gt; dict[str, Any]:\n    \"\"\"Load and merge the effective configuration for a recipe.\n\n    Steps:\n        1. Read recipe YAML\n        2. Find defaults root by scanning upwards for 'defaults/org.yaml'\n        3. Load org defaults (required if defaults root exists)\n        4. Determine vendor (param 'vendor' &gt; folder name &gt; recipe contents)\n        5. Load vendor defaults if present\n        6. Merge: org -&gt; vendor -&gt; recipe (dicts deep-merge, lists replace)\n        7. Resolve known relative paths (relative to the recipe directory)\n        8. Inject dynamic fields (AppScriptDate = today if absent)\n\n    Returns:\n        A merged configuration dict ready for downstream processors.\n        If no defaults were found in the tree, the recipe is returned\n        as-is (with path resolution + injection).\n\n    Raises:\n        ConfigError: On YAML parse errors, empty files, invalid structure,\n            or if the recipe file is missing.\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    recipe_path = recipe_path.resolve()\n    recipe_dir = recipe_path.parent\n\n    logger.verbose(\"CONFIG\", f\"Loading recipe: {recipe_path}\")\n\n    # 1) Read recipe\n    recipe_obj = _load_yaml_file(recipe_path)\n    if not isinstance(recipe_obj, dict):\n        raise ConfigError(f\"top-level YAML must be a mapping (dict): {recipe_path}\")\n\n    # 2) Find defaults root\n    defaults_root = _find_defaults_root(recipe_dir)\n    if defaults_root:\n        logger.verbose(\"CONFIG\", f\"Found defaults root: {defaults_root}\")\n\n    merged: dict[str, Any] = {}\n    layers_merged = 0\n\n    org_defaults_path: Path | None = None\n    vendor_name: str | None = vendor\n\n    if defaults_root:\n        # 3) Load org defaults\n        org_defaults_path = defaults_root / \"org.yaml\"\n        if org_defaults_path.exists():\n            logger.verbose(\n                \"CONFIG\",\n                f\"Loading: {org_defaults_path.relative_to(defaults_root.parent)}\",\n            )\n            org_defaults = _load_yaml_file(org_defaults_path)\n            if isinstance(org_defaults, dict):\n                logger.debug(\"CONFIG\", \"--- Content from org.yaml ---\")\n                _print_yaml_content(org_defaults)\n                merged = _deep_merge_dicts(merged, org_defaults)\n                layers_merged += 1\n\n        # 4) Determine vendor\n        if vendor_name is None:\n            vendor_name = _detect_vendor(recipe_path, recipe_obj)\n\n        if vendor_name:\n            logger.verbose(\"CONFIG\", f\"Detected vendor: {vendor_name}\")\n\n        # 5) Load vendor defaults if present\n        if vendor_name:\n            candidate = defaults_root / \"vendors\" / f\"{vendor_name}.yaml\"\n            if candidate.exists():\n                logger.verbose(\n                    \"CONFIG\", f\"Loading: {candidate.relative_to(defaults_root.parent)}\"\n                )\n                vendor_defaults = _load_yaml_file(candidate)\n                if isinstance(vendor_defaults, dict):\n                    logger.debug(\"CONFIG\", f\"--- Content from {vendor_name}.yaml ---\")\n                    _print_yaml_content(vendor_defaults)\n                    merged = _deep_merge_dicts(merged, vendor_defaults)\n                    layers_merged += 1\n\n    # Show recipe content\n    logger.verbose(\"CONFIG\", f\"Loading: {recipe_path.name}\")\n    logger.debug(\"CONFIG\", f\"--- Content from {recipe_path.name} ---\")\n    _print_yaml_content(recipe_obj)\n\n    # 6) Merge recipe on top\n    merged = _deep_merge_dicts(merged, recipe_obj)\n    layers_merged += 1\n\n    logger.verbose(\"CONFIG\", f\"Deep merging {layers_merged} layer(s)\")\n    # Show final config structure\n    top_level_keys = list(merged.keys())\n    logger.verbose(\n        \"CONFIG\",\n        (\n            f\"Final config has {len(top_level_keys)} top-level keys: \"\n            f\"{', '.join(top_level_keys)}\"\n        ),\n    )\n    # Show the complete merged configuration in debug mode\n    logger.debug(\"CONFIG\", \"--- Final Merged Configuration ---\")\n    _print_yaml_content(merged)\n\n    # 7) Resolve relative paths (branding paths relative to defaults_root)\n    _resolve_known_paths(merged, recipe_dir, defaults_root)\n\n    # 8) Inject dynamic values (e.g., AppScriptDate)\n    _inject_dynamic_values(merged)\n\n    # Optionally attach context for debugging (commented out by default)\n    # merged[\"_load_context\"] = LoadContext(\n    #     recipe_path=recipe_path,\n    #     defaults_root=defaults_root,\n    #     vendor_name=vendor_name,\n    #     org_defaults_path=org_defaults_path,\n    #     vendor_defaults_path=vendor_defaults_path,\n    # ).__dict__\n\n    return merged\n</code></pre>"},{"location":"api/core/","title":"core","text":""},{"location":"api/core/#notapkgtool.core","title":"notapkgtool.core","text":"<p>Core orchestration for NAPT.</p> <p>This module provides high-level orchestration functions that coordinate the complete workflow for recipe validation, package building, and deployment.</p> <p>Two-Path Architecture:</p> <p>The orchestration automatically selects the optimal path based on what each discovery strategy can do:</p> <ul> <li> <p>Version-First Path (web_scrape, api_github, api_json): These strategies     can check the version without downloading the file. NAPT compares the     discovered version to the cached version. If they match and the file     already exists, the download is skipped entirely. This makes update checks     very fast (~100-300ms) since no large installer files are downloaded.</p> </li> <li> <p>File-First Path (url_download): This strategy requires downloading the     file to extract the version. NAPT uses HTTP ETag headers to check if the     file has changed. If the server responds with HTTP 304 (Not Modified),     the existing cached file is reused, avoiding unnecessary re-downloads.</p> </li> </ul> <p>Design Principles:</p> <ul> <li>Each function has a single, clear responsibility</li> <li>Functions return structured data (dataclasses) for easy testing and extension</li> <li>Error handling uses exceptions; CLI layer formats for user display</li> <li>Discovery strategies are dynamically loaded via registry pattern</li> <li>Configuration is immutable once loaded</li> </ul> Example <p>Programmatic usage:     <pre><code>from pathlib import Path\nfrom notapkgtool.core import discover_recipe\n\nresult = discover_recipe(\n    recipe_path=Path(\"recipes/Google/chrome.yaml\"),\n    output_dir=Path(\"./downloads\"),\n)\n\nprint(f\"App: {result.app_name}\")\nprint(f\"Version: {result.version}\")\nprint(f\"SHA-256: {result.sha256}\")\n\n# Version-first strategies: may have skipped download if unchanged!\n</code></pre></p>"},{"location":"api/core/#notapkgtool.core.derive_file_path_from_url","title":"derive_file_path_from_url","text":"<pre><code>derive_file_path_from_url(url: str, output_dir: Path) -&gt; Path\n</code></pre> <p>Derive file path from URL using same logic as download_file.</p> <p>This function ensures version-first strategies can locate cached files without downloading by following the same naming convention as the download module.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Download URL.</p> required <code>output_dir</code> <code>Path</code> <p>Directory where file would be downloaded.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Expected path to the file.</p> Example <p>Get expected file path for a download URL:     <pre><code>from pathlib import Path\n\npath = derive_file_path_from_url(\n    \"https://example.com/app.msi\",\n    Path(\"./downloads\")\n)\n# Returns: Path('./downloads/app.msi')\n</code></pre></p> Source code in <code>notapkgtool/core.py</code> <pre><code>def derive_file_path_from_url(url: str, output_dir: Path) -&gt; Path:\n    \"\"\"Derive file path from URL using same logic as download_file.\n\n    This function ensures version-first strategies can locate cached files\n    without downloading by following the same naming convention as the\n    download module.\n\n    Args:\n        url: Download URL.\n        output_dir: Directory where file would be downloaded.\n\n    Returns:\n        Expected path to the file.\n\n    Example:\n        Get expected file path for a download URL:\n            ```python\n            from pathlib import Path\n\n            path = derive_file_path_from_url(\n                \"https://example.com/app.msi\",\n                Path(\"./downloads\")\n            )\n            # Returns: Path('./downloads/app.msi')\n            ```\n\n    \"\"\"\n    from urllib.parse import urlparse\n\n    filename = Path(urlparse(url).path).name\n    return output_dir / filename\n</code></pre>"},{"location":"api/core/#notapkgtool.core.discover_recipe","title":"discover_recipe","text":"<pre><code>discover_recipe(recipe_path: Path, output_dir: Path, state_file: Path | None = Path('state/versions.json'), stateless: bool = False) -&gt; DiscoverResult\n</code></pre> <p>Discover the latest version by loading config and downloading installer.</p> <p>This is the main entry point for the 'napt discover' command. It orchestrates the entire discovery workflow using a two-path architecture optimized for version-first strategies.</p> <p>The function uses duck typing to detect strategy capabilities:</p> <p>VERSION-FIRST PATH (if strategy has get_version_info method):</p> <ol> <li>Load effective configuration (org + vendor + recipe merged)</li> <li>Call strategy.get_version_info() to discover version (no download)</li> <li>Compare discovered version to cached known_version</li> <li>If match and file exists -&gt; skip download entirely (fast path!)</li> <li>If changed or missing -&gt; download installer via download_file()</li> <li>Update state and return results</li> </ol> <p>FILE-FIRST PATH (if strategy has only discover_version method):</p> <ol> <li>Load effective configuration (org + vendor + recipe merged)</li> <li>Call strategy.discover_version() with cached ETag</li> <li>Strategy handles conditional request (HTTP 304 vs 200)</li> <li>Extract version from downloaded file</li> <li>Update state and return results</li> </ol> <p>Parameters:</p> Name Type Description Default <code>recipe_path</code> <code>Path</code> <p>Path to the recipe YAML file. Must exist and be readable. The path is resolved to absolute form.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to download the installer to. Created if it doesn't exist. The downloaded file will be named based on Content-Disposition header or URL path.</p> required <code>state_file</code> <code>Path | None</code> <p>Path to state file for version tracking and ETag caching. Default is \"state/versions.json\". Set to None to disable.</p> <code>Path('state/versions.json')</code> <code>stateless</code> <code>bool</code> <p>If True, disable state tracking (no caching, always download). Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>DiscoverResult</code> <p>DiscoverResult dataclass with the following fields:</p> <ul> <li>app_name (str): Application display name from recipe configuration.</li> <li>app_id (str): Unique application identifier from recipe configuration.</li> <li>strategy (str): Discovery strategy used (e.g., \"web_scrape\", \"api_github\",     \"api_json\", \"url_download\").</li> <li>version (str): Extracted version string (e.g., \"141.0.7390.123\").</li> <li>version_source (str): How version was determined (e.g., \"regex_in_url\",     \"msi\", \"api_tag\", \"api_json\").</li> <li>file_path (Path): Path to the downloaded installer file in output_dir.</li> <li>sha256 (str): SHA-256 hash of the downloaded file for integrity     verification.</li> <li>status (str): Always \"success\" for successful discovery operations.</li> </ul> <p>Raises:</p> Type Description <code>ConfigError</code> <p>On missing or invalid configuration fields (no app defined, missing 'source.strategy' field, unknown discovery strategy name), YAML parse errors (from config loader), or if recipe file doesn't exist.</p> <code>NetworkError</code> <p>On download failures or version extraction errors.</p> Example <p>Basic version discovery:     <pre><code>from pathlib import Path\nresult = discover_recipe(\n    Path(\"recipes/Google/chrome.yaml\"),\n    Path(\"./downloads\")\n)\nprint(result.version)  # 141.0.7390.123\n</code></pre></p> <p>Handling errors:     <pre><code>try:\n    result = discover_recipe(Path(\"invalid.yaml\"), Path(\".\"))\nexcept ConfigError as e:\n    print(f\"Config error: {e}\")\nexcept NetworkError as e:\n    print(f\"Network error: {e}\")\n</code></pre></p> Note <p>The discovery strategy must be registered before calling this function. Version-first strategies (web_scrape, api_github, api_json) can skip downloads entirely when version unchanged (fast path optimization). File-first strategy (url_download) uses ETag conditional requests. Downloaded files are written atomically (.part then renamed). Progress output goes to stdout via the download module. Strategy type detected via duck typing (hasattr for get_version_info).</p> Source code in <code>notapkgtool/core.py</code> <pre><code>def discover_recipe(\n    recipe_path: Path,\n    output_dir: Path,\n    state_file: Path | None = Path(\"state/versions.json\"),\n    stateless: bool = False,\n) -&gt; DiscoverResult:\n    \"\"\"Discover the latest version by loading config and downloading installer.\n\n    This is the main entry point for the 'napt discover' command. It orchestrates\n    the entire discovery workflow using a two-path architecture optimized for\n    version-first strategies.\n\n    The function uses duck typing to detect strategy capabilities:\n\n    VERSION-FIRST PATH (if strategy has get_version_info method):\n\n    1. Load effective configuration (org + vendor + recipe merged)\n    2. Call strategy.get_version_info() to discover version (no download)\n    3. Compare discovered version to cached known_version\n    4. If match and file exists -&gt; skip download entirely (fast path!)\n    5. If changed or missing -&gt; download installer via download_file()\n    6. Update state and return results\n\n    FILE-FIRST PATH (if strategy has only discover_version method):\n\n    1. Load effective configuration (org + vendor + recipe merged)\n    2. Call strategy.discover_version() with cached ETag\n    3. Strategy handles conditional request (HTTP 304 vs 200)\n    4. Extract version from downloaded file\n    5. Update state and return results\n\n    Args:\n        recipe_path: Path to the recipe YAML file. Must exist and be\n            readable. The path is resolved to absolute form.\n        output_dir: Directory to download the installer to. Created if\n            it doesn't exist. The downloaded file will be named based on\n            Content-Disposition header or URL path.\n        state_file: Path to state file for version tracking\n            and ETag caching. Default is \"state/versions.json\". Set to None\n            to disable.\n        stateless: If True, disable state tracking (no caching,\n            always download). Default is False.\n\n    Returns:\n        DiscoverResult dataclass with the following fields:\n\n            - app_name (str): Application display name from recipe configuration.\n            - app_id (str): Unique application identifier from recipe configuration.\n            - strategy (str): Discovery strategy used (e.g., \"web_scrape\", \"api_github\",\n                \"api_json\", \"url_download\").\n            - version (str): Extracted version string (e.g., \"141.0.7390.123\").\n            - version_source (str): How version was determined (e.g., \"regex_in_url\",\n                \"msi\", \"api_tag\", \"api_json\").\n            - file_path (Path): Path to the downloaded installer file in output_dir.\n            - sha256 (str): SHA-256 hash of the downloaded file for integrity\n                verification.\n            - status (str): Always \"success\" for successful discovery operations.\n\n    Raises:\n        ConfigError: On missing or invalid configuration fields (no app defined,\n            missing 'source.strategy' field, unknown discovery strategy name),\n            YAML parse errors (from config loader), or if recipe file doesn't exist.\n        NetworkError: On download failures or version extraction errors.\n\n    Example:\n        Basic version discovery:\n            ```python\n            from pathlib import Path\n            result = discover_recipe(\n                Path(\"recipes/Google/chrome.yaml\"),\n                Path(\"./downloads\")\n            )\n            print(result.version)  # 141.0.7390.123\n            ```\n\n        Handling errors:\n            ```python\n            try:\n                result = discover_recipe(Path(\"invalid.yaml\"), Path(\".\"))\n            except ConfigError as e:\n                print(f\"Config error: {e}\")\n            except NetworkError as e:\n                print(f\"Network error: {e}\")\n            ```\n\n    Note:\n        The discovery strategy must be registered before calling this function.\n        Version-first strategies (web_scrape, api_github, api_json) can skip\n        downloads entirely when version unchanged (fast path optimization).\n        File-first strategy (url_download) uses ETag conditional requests.\n        Downloaded files are written atomically (.part then renamed). Progress\n        output goes to stdout via the download module. Strategy type detected\n        via duck typing (hasattr for get_version_info).\n\n    \"\"\"\n    logger = get_global_logger()\n\n    # Load state file unless running in stateless mode\n    state = None\n    if not stateless and state_file:\n        try:\n            state = load_state(state_file)\n            logger.verbose(\"STATE\", f\"Loaded state from {state_file}\")\n        except FileNotFoundError:\n            logger.verbose(\"STATE\", f\"State file not found, will create: {state_file}\")\n            state = {\n                \"metadata\": {\"napt_version\": __version__, \"schema_version\": \"2\"},\n                \"apps\": {},\n            }\n        except Exception as err:\n            logger.warning(\"STATE\", f\"Failed to load state: {err}\")\n            logger.verbose(\"STATE\", \"Continuing without state tracking\")\n            state = None\n\n    # 1. Load and merge configuration\n    logger.step(1, 4, \"Loading configuration...\")\n    config = load_effective_config(recipe_path)\n\n    # 2. Extract the app configuration\n    logger.step(2, 4, \"Discovering version...\")\n    app = config.get(\"app\")\n    if not app:\n        raise ConfigError(f\"No app defined in recipe: {recipe_path}\")\n\n    app_name = app.get(\"name\", \"Unknown\")\n    app_id = app.get(\"id\", \"unknown-id\")\n\n    # 3. Get the discovery strategy name\n    source = app.get(\"source\", {})\n    strategy_name = source.get(\"strategy\")\n    if not strategy_name:\n        raise ConfigError(f\"No 'source.strategy' defined for app: {app_name}\")\n\n    # 4. Get the strategy implementation\n    # Import strategies to ensure they're registered\n    import notapkgtool.discovery.api_github  # noqa: F401\n    import notapkgtool.discovery.api_json  # noqa: F401\n    import notapkgtool.discovery.url_download  # noqa: F401\n    import notapkgtool.discovery.web_scrape  # noqa: F401\n\n    strategy = get_strategy(strategy_name)\n\n    # Get cache for this recipe from state\n    cache = None\n    if state and app_id:\n        cache = state.get(\"apps\", {}).get(app_id)\n        if cache:\n            logger.verbose(\"STATE\", f\"Using cache for {app_id}\")\n            if cache.get(\"known_version\"):\n                logger.verbose(\n                    \"STATE\", f\"  Cached version: {cache.get('known_version')}\"\n                )\n            if cache.get(\"etag\"):\n                logger.verbose(\"STATE\", f\"  Cached ETag: {cache.get('etag')}\")\n\n    # 5. Run discovery: version-first or file-first path\n    logger.step(3, 4, \"Discovering version...\")\n\n    # Check if strategy supports version-first (has get_version_info method)\n    download_url = None  # Track actual download URL for state file\n    if hasattr(strategy, \"get_version_info\"):\n        # VERSION-FIRST PATH (web_scrape, api_github, api_json)\n        # Get version without downloading\n        version_info = strategy.get_version_info(app)\n        download_url = version_info.download_url  # Save for state file\n\n        logger.verbose(\"DISCOVERY\", f\"Version discovered: {version_info.version}\")\n\n        # Check if we can use cached file (version match + file exists)\n        if cache and cache.get(\"known_version\") == version_info.version:\n            # Derive file path from URL using same logic as download_file\n            file_path = derive_file_path_from_url(version_info.download_url, output_dir)\n\n            if file_path.exists():\n                # Fast path: version unchanged, file exists, skip download!\n                logger.verbose(\n                    \"CACHE\",\n                    f\"Version {version_info.version} unchanged, using cached file\",\n                )\n                logger.step(4, 4, \"Using cached file...\")\n                sha256 = cache.get(\"sha256\")\n                discovered_version = DiscoveredVersion(\n                    version_info.version, version_info.source\n                )\n                headers = {}  # No download occurred, no headers\n            else:\n                # File was deleted, re-download\n                logger.verbose(\n                    \"WARNING\",\n                    f\"Cached file {file_path} not found, re-downloading\",\n                )\n                logger.step(4, 4, \"Downloading installer...\")\n                file_path, sha256, headers = download_file(\n                    version_info.download_url,\n                    output_dir,\n                )\n                discovered_version = DiscoveredVersion(\n                    version_info.version, version_info.source\n                )\n        else:\n            # Version changed or no cache, download new version\n            if cache:\n                logger.verbose(\n                    \"DISCOVERY\",\n                    (\n                        f\"Version changed: {cache.get('known_version')} -&gt; \"\n                        f\"{version_info.version}\"\n                    ),\n                )\n            logger.step(4, 4, \"Downloading installer...\")\n            file_path, sha256, headers = download_file(\n                version_info.download_url,\n                output_dir,\n            )\n            discovered_version = DiscoveredVersion(\n                version_info.version, version_info.source\n            )\n    else:\n        # FILE-FIRST PATH (url_download only)\n        # Must download to extract version\n        logger.step(4, 4, \"Downloading installer...\")\n        discovered_version, file_path, sha256, headers = strategy.discover_version(\n            app, output_dir, cache=cache\n        )\n        download_url = str(app.get(\"source\", {}).get(\"url\", \"\"))  # Use source.url\n\n    # Update state with discovered information\n    if state and app_id and state_file:\n        from datetime import UTC, datetime\n\n        if \"apps\" not in state:\n            state[\"apps\"] = {}\n\n        # Extract ETag and Last-Modified from headers for next run\n        etag = headers.get(\"ETag\")\n        last_modified = headers.get(\"Last-Modified\")\n\n        if etag:\n            logger.verbose(\"STATE\", f\"Saving ETag for next run: {etag}\")\n        if last_modified:\n            logger.verbose(\n                \"STATE\", f\"Saving Last-Modified for next run: {last_modified}\"\n            )\n\n        # Build cache entry with new schema v2\n        cache_entry = {\n            \"url\": download_url\n            or \"\",  # Actual download URL (from version_info or source.url)\n            \"etag\": etag if etag else None,  # Only useful for url_download\n            \"last_modified\": (\n                last_modified if last_modified else None\n            ),  # Only useful for url_download\n            \"sha256\": sha256,\n        }\n\n        # Optional fields\n        if discovered_version.version:\n            cache_entry[\"known_version\"] = discovered_version.version\n        if strategy_name:\n            cache_entry[\"strategy\"] = strategy_name\n\n        state[\"apps\"][app_id] = cache_entry\n\n        state[\"metadata\"] = {\n            \"napt_version\": __version__,\n            \"last_updated\": datetime.now(UTC).isoformat(),\n            \"schema_version\": \"2\",\n        }\n\n        try:\n            save_state(state, state_file)\n            logger.verbose(\"STATE\", f\"Updated state file: {state_file}\")\n        except Exception as err:\n            logger.warning(\"STATE\", f\"Failed to save state: {err}\")\n\n    # 6. Return results\n    return DiscoverResult(\n        app_name=app_name,\n        app_id=app_id,\n        strategy=strategy_name,\n        version=discovered_version.version,\n        version_source=discovered_version.source,\n        file_path=file_path,\n        sha256=sha256,\n        status=\"success\",\n    )\n</code></pre>"},{"location":"api/detection/","title":"detection","text":""},{"location":"api/detection/#notapkgtool.detection","title":"notapkgtool.detection","text":"<p>Detection script generation for Intune Win32 apps.</p> <p>This module generates PowerShell detection scripts for Intune Win32 app deployments. Scripts check Windows uninstall registry keys for installed software and version information using CMTrace-formatted logging.</p> Detection Logic <ul> <li>Checks HKLM:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall (always)</li> <li>Checks HKCU:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall (always)</li> <li>Checks HKLM:\\SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall     (only on 64-bit OS with 64-bit PowerShell process)</li> <li>Checks HKCU:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall     (only on 64-bit OS with 64-bit PowerShell process)</li> <li>Matches by DisplayName (using AppName from recipe or MSI ProductName)</li> <li>Compares version (exact or minimum version match based on config)</li> <li>Provides verbose logging with detailed detection results, registry paths,     installed vs expected versions, and match type information</li> </ul> Logging <ul> <li>Primary (System): C:\\ProgramData\\Microsoft\\IntuneManagementExtension\\Logs\\NAPTDetections.log</li> <li>Primary (User): C:\\ProgramData\\Microsoft\\IntuneManagementExtension\\Logs\\NAPTDetectionsUser.log</li> <li>Fallback (System): C:\\ProgramData\\NAPT\\NAPTDetections.log</li> <li>Fallback (User): %LOCALAPPDATA%\\NAPT\\NAPTDetectionsUser.log</li> <li>Log rotation: 2-file rotation (.log and .log.old), configurable max size     (default: 3MB)</li> <li>Format: CMTrace format for compatibility with Intune diagnostics</li> <li>Features: Write permission testing with automatic fallback to alternate     locations, verbose component-based logging with dynamic component names     based on app name and version, detailed detection workflow logging</li> </ul> Example <p>Generate detection script:     <pre><code>from pathlib import Path\nfrom notapkgtool.detection import DetectionConfig, generate_detection_script\n\nconfig = DetectionConfig(\n    app_name=\"Google Chrome\",\n    version=\"131.0.6778.86\",\n    log_format=\"cmtrace\",\n    log_level=\"INFO\",\n)\nscript_path = generate_detection_script(\n    config=config,\n    output_path=Path(\"builds/chrome/131.0.6778.86/Google-Chrome-131.0.6778.86-Detection.ps1\"),\n)\n</code></pre></p> Note <p>Detection scripts are saved as siblings to the packagefiles directory to prevent them from being included in the .intunewin package. They should be uploaded separately to Intune alongside the package.</p>"},{"location":"api/detection/#notapkgtool.detection.DetectionConfig","title":"DetectionConfig  <code>dataclass</code>","text":"<p>Configuration for detection script generation.</p> <p>Attributes:</p> Name Type Description <code>app_name</code> <code>str</code> <p>Application name to search for in registry DisplayName.</p> <code>version</code> <code>str</code> <p>Expected version string to match.</p> <code>log_format</code> <code>LogFormat</code> <p>Log format (currently only \"cmtrace\" supported).</p> <code>log_level</code> <code>LogLevel</code> <p>Minimum log level (INFO, WARNING, ERROR, DEBUG).</p> <code>log_rotation_mb</code> <code>int</code> <p>Maximum log file size in MB before rotation.</p> <code>exact_match</code> <code>bool</code> <p>If True, version must match exactly. If False, minimum version comparison (remote &gt;= expected).</p> <code>app_id</code> <code>str</code> <p>Application ID (used for fallback if app_name sanitization results in empty string).</p> Source code in <code>notapkgtool/detection.py</code> <pre><code>@dataclass(frozen=True)\nclass DetectionConfig:\n    \"\"\"Configuration for detection script generation.\n\n    Attributes:\n        app_name: Application name to search for in registry DisplayName.\n        version: Expected version string to match.\n        log_format: Log format (currently only \"cmtrace\" supported).\n        log_level: Minimum log level (INFO, WARNING, ERROR, DEBUG).\n        log_rotation_mb: Maximum log file size in MB before rotation.\n        exact_match: If True, version must match exactly. If False, minimum\n            version comparison (remote &gt;= expected).\n        app_id: Application ID (used for fallback if app_name sanitization\n            results in empty string).\n\n    \"\"\"\n\n    app_name: str\n    version: str\n    log_format: LogFormat = \"cmtrace\"\n    log_level: LogLevel = \"INFO\"\n    log_rotation_mb: int = 3\n    exact_match: bool = False\n    app_id: str = \"\"\n</code></pre>"},{"location":"api/detection/#notapkgtool.detection.sanitize_filename","title":"sanitize_filename","text":"<pre><code>sanitize_filename(name: str, app_id: str = '') -&gt; str\n</code></pre> <p>Sanitize string for use in Windows filename.</p> Rules <ul> <li>Replace spaces with hyphens</li> <li>Remove invalid Windows filename characters (&lt; &gt; : \" | ? * \\ /)</li> <li>Normalize multiple consecutive hyphens to single hyphen</li> <li>Remove leading/trailing hyphens and dots</li> <li>If result is empty, fallback to app_id (or \"app\" if app_id is empty)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>String to sanitize (e.g., \"Google Chrome\").</p> required <code>app_id</code> <code>str</code> <p>Fallback identifier if name becomes empty after sanitization.</p> <code>''</code> <p>Returns:</p> Type Description <code>str</code> <p>Sanitized filename-safe string (e.g., \"Google-Chrome\").</p> Example <p>Basic sanitization:     <pre><code>sanitize_filename(\"Google Chrome\")  # Returns: \"Google-Chrome\"\nsanitize_filename(\"My App v2.0\")    # Returns: \"My-App-v2.0\"\nsanitize_filename(\"Test&lt;&gt;App\")      # Returns: \"TestApp\"\n</code></pre></p> <p>Fallback behavior:     <pre><code>sanitize_filename(\"  \", \"my-app\")   # Returns: \"my-app\"\nsanitize_filename(\"\", \"test\")       # Returns: \"test\"\n</code></pre></p> Source code in <code>notapkgtool/detection.py</code> <pre><code>def sanitize_filename(name: str, app_id: str = \"\") -&gt; str:\n    \"\"\"Sanitize string for use in Windows filename.\n\n    Rules:\n        - Replace spaces with hyphens\n        - Remove invalid Windows filename characters (&lt; &gt; : \" | ? * \\\\ /)\n        - Normalize multiple consecutive hyphens to single hyphen\n        - Remove leading/trailing hyphens and dots\n        - If result is empty, fallback to app_id (or \"app\" if app_id is empty)\n\n    Args:\n        name: String to sanitize (e.g., \"Google Chrome\").\n        app_id: Fallback identifier if name becomes empty after sanitization.\n\n    Returns:\n        Sanitized filename-safe string (e.g., \"Google-Chrome\").\n\n    Example:\n        Basic sanitization:\n            ```python\n            sanitize_filename(\"Google Chrome\")  # Returns: \"Google-Chrome\"\n            sanitize_filename(\"My App v2.0\")    # Returns: \"My-App-v2.0\"\n            sanitize_filename(\"Test&lt;&gt;App\")      # Returns: \"TestApp\"\n            ```\n\n        Fallback behavior:\n            ```python\n            sanitize_filename(\"  \", \"my-app\")   # Returns: \"my-app\"\n            sanitize_filename(\"\", \"test\")       # Returns: \"test\"\n            ```\n\n    \"\"\"\n    # Replace spaces with hyphens\n    sanitized = name.replace(\" \", \"-\")\n\n    # Remove invalid Windows filename characters: &lt; &gt; : \" | ? * \\ /\n    invalid_chars = '&lt;&gt;:\"|?*\\\\/'\n    for char in invalid_chars:\n        sanitized = sanitized.replace(char, \"\")\n\n    # Normalize multiple consecutive hyphens to single hyphen\n    sanitized = re.sub(r\"-+\", \"-\", sanitized)\n\n    # Remove leading/trailing hyphens and dots\n    sanitized = sanitized.strip(\".-\")\n\n    # Fallback to app_id if empty\n    if not sanitized:\n        sanitized = app_id if app_id else \"app\"\n\n    return sanitized\n</code></pre>"},{"location":"api/detection/#notapkgtool.detection.generate_detection_script","title":"generate_detection_script","text":"<pre><code>generate_detection_script(config: DetectionConfig, output_path: Path) -&gt; Path\n</code></pre> <p>Generate PowerShell detection script for Intune Win32 app.</p> <p>Creates a PowerShell script that checks Windows uninstall registry keys for software installation and version. The script uses CMTrace-formatted logging with verbose output, includes log rotation logic, and performs write permission testing with automatic fallback to alternate log locations if primary locations are unavailable.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>DetectionConfig</code> <p>Detection configuration (app name, version, logging settings).</p> required <code>output_path</code> <code>Path</code> <p>Path where the detection script will be saved.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to the generated detection script.</p> <p>Raises:</p> Type Description <code>OSError</code> <p>If the script file cannot be written.</p> Example <p>Generate script with default settings:     <pre><code>from pathlib import Path\nfrom notapkgtool.detection import DetectionConfig, generate_detection_script\n\nconfig = DetectionConfig(\n    app_name=\"Google Chrome\",\n    version=\"131.0.6778.86\",\n)\nscript_path = generate_detection_script(\n    config,\n    Path(\"detection.ps1\")\n)\n</code></pre></p> Note <p>The script is saved with UTF-8 BOM encoding for proper PowerShell execution on Windows systems.</p> Source code in <code>notapkgtool/detection.py</code> <pre><code>def generate_detection_script(config: DetectionConfig, output_path: Path) -&gt; Path:\n    \"\"\"Generate PowerShell detection script for Intune Win32 app.\n\n    Creates a PowerShell script that checks Windows uninstall registry keys\n    for software installation and version. The script uses CMTrace-formatted\n    logging with verbose output, includes log rotation logic, and performs\n    write permission testing with automatic fallback to alternate log locations\n    if primary locations are unavailable.\n\n    Args:\n        config: Detection configuration (app name, version, logging settings).\n        output_path: Path where the detection script will be saved.\n\n    Returns:\n        Path to the generated detection script.\n\n    Raises:\n        OSError: If the script file cannot be written.\n\n    Example:\n        Generate script with default settings:\n            ```python\n            from pathlib import Path\n            from notapkgtool.detection import DetectionConfig, generate_detection_script\n\n            config = DetectionConfig(\n                app_name=\"Google Chrome\",\n                version=\"131.0.6778.86\",\n            )\n            script_path = generate_detection_script(\n                config,\n                Path(\"detection.ps1\")\n            )\n            ```\n\n    Note:\n        The script is saved with UTF-8 BOM encoding for proper PowerShell\n        execution on Windows systems.\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n\n    logger.verbose(\"DETECTION\", f\"Generating detection script: {output_path.name}\")\n\n    # Generate script content from template\n    # Use safe_substitute() so PowerShell variables ($$Variable) are preserved\n    # as $Variable without raising KeyError for missing placeholders\n    script_content = string.Template(_DETECTION_SCRIPT_TEMPLATE).safe_substitute(\n        app_name=config.app_name,\n        version=config.version,\n        exact_match=\"$True\" if config.exact_match else \"$False\",\n        log_rotation_mb=config.log_rotation_mb,\n    )\n\n    # Ensure output directory exists\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n\n    # Write script with UTF-8 BOM encoding (required for PowerShell)\n    try:\n        script_bytes = script_content.encode(\"utf-8-sig\")\n        output_path.write_bytes(script_bytes)\n        logger.verbose(\"DETECTION\", f\"Detection script written to: {output_path}\")\n    except OSError as err:\n        raise OSError(\n            f\"Failed to write detection script to {output_path}: {err}\"\n        ) from err\n\n    return output_path\n</code></pre>"},{"location":"api/discovery/","title":"discovery","text":""},{"location":"api/discovery/#notapkgtool.discovery.base","title":"notapkgtool.discovery.base","text":"<p>Discovery strategy base protocol and registry for NAPT.</p> <p>This module defines the foundational components for the discovery system:</p> <ul> <li>DiscoveryStrategy protocol: Interface that all strategies must implement</li> <li>Strategy registry: Global dict mapping strategy names to implementations</li> <li>Registration and lookup functions: register_strategy() and get_strategy()</li> </ul> <p>The discovery system uses a strategy pattern to support multiple ways of obtaining application installers and their versions:</p> <ul> <li>url_download: Direct download from a static URL (FILE-FIRST)</li> <li>web_scrape: Scrape vendor download pages to find links and extract versions     (VERSION-FIRST)</li> <li>api_github: Fetch from GitHub releases API (VERSION-FIRST)</li> <li>api_json: Query JSON API endpoints for version and download URL (VERSION-FIRST)</li> </ul> Design Philosophy <ul> <li>Strategies are Protocol classes (structural subtyping, not inheritance)</li> <li>Registration happens at module import time (strategies self-register)</li> <li>Registry is a simple dict (no complex dependency injection needed)</li> <li>Each strategy is stateless and can be instantiated on-demand</li> </ul> <p>Protocol Benefits:</p> <p>Using typing.Protocol instead of ABC allows:</p> <ul> <li>Duck typing: Classes don't need explicit inheritance</li> <li>Better IDE support: Type checkers verify interface compliance</li> <li>Flexibility: Third-party code can add strategies without touching base</li> </ul> Example <p>Implementing a custom strategy:     <pre><code>from notapkgtool.discovery.base import register_strategy, DiscoveryStrategy\nfrom pathlib import Path\nfrom typing import Any\nfrom notapkgtool.versioning.keys import DiscoveredVersion\n\nclass MyCustomStrategy:\n    def discover_version(\n        self, app_config: dict[str, Any], output_dir: Path\n    ) -&gt; tuple[DiscoveredVersion, Path, str]:\n        # Implement your discovery logic here\n        ...\n\n# Register it (typically at module import)\nregister_strategy(\"my_custom\", MyCustomStrategy)\n\n# Now it can be used in recipes:\n# source:\n#   strategy: my_custom\n#   ...\n</code></pre></p>"},{"location":"api/discovery/#notapkgtool.discovery.base.DiscoveryStrategy","title":"DiscoveryStrategy","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for version discovery strategies.</p> <p>Each strategy must implement discover_version() which downloads and extracts version information based on the app config.</p> <p>Strategies may optionally implement validate_config() to provide strategy-specific configuration validation without network calls.</p> Source code in <code>notapkgtool/discovery/base.py</code> <pre><code>class DiscoveryStrategy(Protocol):\n    \"\"\"Protocol for version discovery strategies.\n\n    Each strategy must implement discover_version() which downloads\n    and extracts version information based on the app config.\n\n    Strategies may optionally implement validate_config() to provide\n    strategy-specific configuration validation without network calls.\n    \"\"\"\n\n    def discover_version(\n        self, app_config: dict[str, Any], output_dir: Path\n    ) -&gt; tuple[DiscoveredVersion, Path, str, dict]:\n        \"\"\"Discover and download an application version.\n\n        Args:\n            app_config: The app configuration from the recipe\n                (`config[\"app\"]`).\n            output_dir: Directory to download the installer to.\n\n        Returns:\n            A tuple (discovered_version, file_path, sha256, headers), where\n                discovered_version is the version information, file_path is\n                the path to the downloaded file, sha256 is the SHA-256 hash,\n                and headers contains HTTP response headers for caching.\n\n        Raises:\n            ValueError: On discovery or download failures.\n            RuntimeError: On discovery or download failures.\n\n        \"\"\"\n        ...\n\n    def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n        \"\"\"Validate strategy-specific configuration (optional).\n\n        This method validates the app configuration for strategy-specific\n        requirements without making network calls or downloading files.\n        Useful for quick feedback during recipe development.\n\n        Args:\n            app_config: The app configuration from the recipe\n                (`config[\"app\"]`).\n\n        Returns:\n            List of error messages. Empty list if configuration is valid.\n            Each error should be a human-readable description of the issue.\n\n        Example:\n            Check required fields:\n                ```python\n                def validate_config(self, app_config):\n                    errors = []\n                    source = app_config.get(\"source\", {})\n                    if \"url\" not in source:\n                        errors.append(\"Missing required field: source.url\")\n                    return errors\n                ```\n\n        Note:\n            This method is optional; strategies without it will skip validation.\n            Should NOT make network calls or download files. Should check field\n            presence, types, and format only. Used by 'napt validate' command\n            for fast recipe checking.\n\n        \"\"\"\n        ...\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.base.DiscoveryStrategy.discover_version","title":"discover_version","text":"<pre><code>discover_version(app_config: dict[str, Any], output_dir: Path) -&gt; tuple[DiscoveredVersion, Path, str, dict]\n</code></pre> <p>Discover and download an application version.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>The app configuration from the recipe (<code>config[\"app\"]</code>).</p> required <code>output_dir</code> <code>Path</code> <p>Directory to download the installer to.</p> required <p>Returns:</p> Type Description <code>tuple[DiscoveredVersion, Path, str, dict]</code> <p>A tuple (discovered_version, file_path, sha256, headers), where discovered_version is the version information, file_path is the path to the downloaded file, sha256 is the SHA-256 hash, and headers contains HTTP response headers for caching.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>On discovery or download failures.</p> <code>RuntimeError</code> <p>On discovery or download failures.</p> Source code in <code>notapkgtool/discovery/base.py</code> <pre><code>def discover_version(\n    self, app_config: dict[str, Any], output_dir: Path\n) -&gt; tuple[DiscoveredVersion, Path, str, dict]:\n    \"\"\"Discover and download an application version.\n\n    Args:\n        app_config: The app configuration from the recipe\n            (`config[\"app\"]`).\n        output_dir: Directory to download the installer to.\n\n    Returns:\n        A tuple (discovered_version, file_path, sha256, headers), where\n            discovered_version is the version information, file_path is\n            the path to the downloaded file, sha256 is the SHA-256 hash,\n            and headers contains HTTP response headers for caching.\n\n    Raises:\n        ValueError: On discovery or download failures.\n        RuntimeError: On discovery or download failures.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.base.DiscoveryStrategy.validate_config","title":"validate_config","text":"<pre><code>validate_config(app_config: dict[str, Any]) -&gt; list[str]\n</code></pre> <p>Validate strategy-specific configuration (optional).</p> <p>This method validates the app configuration for strategy-specific requirements without making network calls or downloading files. Useful for quick feedback during recipe development.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>The app configuration from the recipe (<code>config[\"app\"]</code>).</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of error messages. Empty list if configuration is valid.</p> <code>list[str]</code> <p>Each error should be a human-readable description of the issue.</p> Example <p>Check required fields:     <pre><code>def validate_config(self, app_config):\n    errors = []\n    source = app_config.get(\"source\", {})\n    if \"url\" not in source:\n        errors.append(\"Missing required field: source.url\")\n    return errors\n</code></pre></p> Note <p>This method is optional; strategies without it will skip validation. Should NOT make network calls or download files. Should check field presence, types, and format only. Used by 'napt validate' command for fast recipe checking.</p> Source code in <code>notapkgtool/discovery/base.py</code> <pre><code>def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n    \"\"\"Validate strategy-specific configuration (optional).\n\n    This method validates the app configuration for strategy-specific\n    requirements without making network calls or downloading files.\n    Useful for quick feedback during recipe development.\n\n    Args:\n        app_config: The app configuration from the recipe\n            (`config[\"app\"]`).\n\n    Returns:\n        List of error messages. Empty list if configuration is valid.\n        Each error should be a human-readable description of the issue.\n\n    Example:\n        Check required fields:\n            ```python\n            def validate_config(self, app_config):\n                errors = []\n                source = app_config.get(\"source\", {})\n                if \"url\" not in source:\n                    errors.append(\"Missing required field: source.url\")\n                return errors\n            ```\n\n    Note:\n        This method is optional; strategies without it will skip validation.\n        Should NOT make network calls or download files. Should check field\n        presence, types, and format only. Used by 'napt validate' command\n        for fast recipe checking.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.base.register_strategy","title":"register_strategy","text":"<pre><code>register_strategy(name: str, strategy_class: type[DiscoveryStrategy]) -&gt; None\n</code></pre> <p>Register a discovery strategy by name in the global registry.</p> <p>This function should be called when a strategy module is imported, typically at module level. Registering the same name twice will overwrite the previous registration (allows monkey-patching for tests).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Strategy name (e.g., \"url_download\"). This is the value used in recipe YAML files under source.strategy. Names should be lowercase with underscores for readability.</p> required <code>strategy_class</code> <code>type[DiscoveryStrategy]</code> <p>The strategy class to register. Must implement the DiscoveryStrategy protocol (have a discover_version method with the correct signature).</p> required Example <p>Register at module import time:     <pre><code># In discovery/my_strategy.py\nfrom .base import register_strategy\n\nclass MyStrategy:\n    def discover_version(self, app_config, output_dir):\n        ...\n\nregister_strategy(\"my_strategy\", MyStrategy)\n</code></pre></p> Note <p>No validation is performed at registration time. Type checkers will verify protocol compliance at static analysis time. Runtime errors occur at strategy instantiation or invocation.</p> Source code in <code>notapkgtool/discovery/base.py</code> <pre><code>def register_strategy(name: str, strategy_class: type[DiscoveryStrategy]) -&gt; None:\n    \"\"\"Register a discovery strategy by name in the global registry.\n\n    This function should be called when a strategy module is imported,\n    typically at module level. Registering the same name twice will\n    overwrite the previous registration (allows monkey-patching for tests).\n\n    Args:\n        name: Strategy name (e.g., \"url_download\"). This is the value\n            used in recipe YAML files under source.strategy. Names should be\n            lowercase with underscores for readability.\n        strategy_class: The strategy class to\n            register. Must implement the DiscoveryStrategy protocol (have a\n            discover_version method with the correct signature).\n\n    Example:\n        Register at module import time:\n            ```python\n            # In discovery/my_strategy.py\n            from .base import register_strategy\n\n            class MyStrategy:\n                def discover_version(self, app_config, output_dir):\n                    ...\n\n            register_strategy(\"my_strategy\", MyStrategy)\n            ```\n\n    Note:\n        No validation is performed at registration time. Type checkers will\n        verify protocol compliance at static analysis time. Runtime errors\n        occur at strategy instantiation or invocation.\n\n    \"\"\"\n    _STRATEGY_REGISTRY[name] = strategy_class\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.base.get_strategy","title":"get_strategy","text":"<pre><code>get_strategy(name: str) -&gt; DiscoveryStrategy\n</code></pre> <p>Get a discovery strategy instance by name from the global registry.</p> <p>The strategy is instantiated on-demand (strategies are stateless, so a new instance is created for each call). The strategy module must have been imported first for registration to occur.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Strategy name (e.g., \"url_download\"). Must exactly match a name registered via register_strategy(). Case-sensitive.</p> required <p>Returns:</p> Type Description <code>DiscoveryStrategy</code> <p>A new instance of the requested strategy, ready to use.</p> <p>Raises:</p> Type Description <code>ConfigError</code> <p>If the strategy name is not registered. The error message includes a list of available strategies for troubleshooting.</p> Example <p>Get and use a strategy:     <pre><code>from notapkgtool.discovery import get_strategy\nstrategy = get_strategy(\"url_download\")\n# Use strategy.discover_version(...)\n</code></pre></p> <p>Handle unknown strategy:     <pre><code>try:\n    strategy = get_strategy(\"nonexistent\")\nexcept ConfigError as e:\n    print(f\"Strategy not found: {e}\")\n</code></pre></p> Note <p>Strategies must be registered before they can be retrieved. The url_download strategy is auto-registered when imported. New strategies can be added by creating a module and registering.</p> Source code in <code>notapkgtool/discovery/base.py</code> <pre><code>def get_strategy(name: str) -&gt; DiscoveryStrategy:\n    \"\"\"Get a discovery strategy instance by name from the global registry.\n\n    The strategy is instantiated on-demand (strategies are stateless, so\n    a new instance is created for each call). The strategy module must\n    have been imported first for registration to occur.\n\n    Args:\n        name: Strategy name (e.g., \"url_download\"). Must exactly match\n            a name registered via register_strategy(). Case-sensitive.\n\n    Returns:\n        A new instance of the requested strategy, ready\n            to use.\n\n    Raises:\n        ConfigError: If the strategy name is not registered. The error message\n            includes a list of available strategies for troubleshooting.\n\n    Example:\n        Get and use a strategy:\n            ```python\n            from notapkgtool.discovery import get_strategy\n            strategy = get_strategy(\"url_download\")\n            # Use strategy.discover_version(...)\n            ```\n\n        Handle unknown strategy:\n            ```python\n            try:\n                strategy = get_strategy(\"nonexistent\")\n            except ConfigError as e:\n                print(f\"Strategy not found: {e}\")\n            ```\n\n    Note:\n        Strategies must be registered before they can be retrieved. The\n        url_download strategy is auto-registered when imported. New strategies\n        can be added by creating a module and registering.\n\n    \"\"\"\n    if name not in _STRATEGY_REGISTRY:\n        available = \", \".join(_STRATEGY_REGISTRY.keys())\n        raise ConfigError(\n            f\"Unknown discovery strategy: {name!r}. Available: {available or '(none)'}\"\n        )\n    return _STRATEGY_REGISTRY[name]()\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.url_download","title":"notapkgtool.discovery.url_download","text":"<p>URL download discovery strategy for NAPT.</p> <p>This is a FILE-FIRST strategy that downloads an installer from a fixed HTTP(S) URL and extracts version information from the downloaded file. Uses HTTP ETag conditional requests to avoid re-downloading unchanged files.</p> <p>Key Advantages:</p> <ul> <li>Works with any fixed URL (version not required in URL)</li> <li>Extracts accurate version directly from installer metadata</li> <li>Uses ETag-based conditional requests for efficiency (~500ms vs full download)</li> <li>Simple and reliable for vendors with stable download URLs</li> <li>Fallback strategy when version not available via API/URL pattern</li> </ul> <p>Supported Version Extraction:</p> <ul> <li>MSI files (<code>.msi</code> extension): Automatically detected, extracts   ProductVersion property from MSI files</li> <li>Other file types: Not supported. Use a version-first strategy   (api_github, api_json, web_scrape) or ensure file is an MSI installer.</li> <li>(Future) EXE files: Auto-detect and extract FileVersion from PE headers</li> </ul> <p>Use Cases:</p> <ul> <li>Google Chrome: Fixed enterprise MSI URL, version embedded in MSI</li> <li>Mozilla Firefox: Fixed enterprise MSI URL, version embedded in MSI</li> <li>Vendors with stable download URLs and embedded version metadata</li> <li>When version not available via API, URL pattern, or GitHub tags</li> </ul> <p>Recipe Configuration:</p> <pre><code>source:\n  strategy: url_download\n  url: \"https://vendor.com/installer.msi\"          # Required: download URL\n</code></pre> <p>Configuration Fields:</p> <ul> <li>url (str, required): HTTP(S) URL to download the installer from. The URL     should be stable and point to the latest version.</li> </ul> <p>Version Extraction: Automatically detected by file extension. MSI files     (<code>.msi</code> extension) have versions extracted from ProductVersion property.     Other file types are not supported for version extraction - use a     version-first strategy (api_github, api_json, web_scrape) instead.</p> <p>Error Handling:</p> <ul> <li>ConfigError: Missing or invalid configuration fields</li> <li>NetworkError: Download failures, version extraction errors</li> <li>Errors are chained with 'from err' for better debugging</li> </ul> Example <p>In a recipe YAML:     <pre><code>apps:\n  - name: \"My App\"\n    id: \"my-app\"\n    source:\n      strategy: url_download\n      url: \"https://example.com/myapp-setup.msi\"\n</code></pre></p> <p>From Python: <pre><code>from pathlib import Path\nfrom notapkgtool.discovery.url_download import UrlDownloadStrategy\n\nstrategy = UrlDownloadStrategy()\napp_config = {\n    \"source\": {\n        \"url\": \"https://example.com/app.msi\",\n    }\n}\n\n# With cache for ETag optimization\ncache = {\"etag\": 'W/\"abc123\"', \"sha256\": \"...\"}\ndiscovered, file_path, sha256, headers = strategy.discover_version(\n    app_config, Path(\"./downloads\"), cache=cache\n)\nprint(f\"Version {discovered.version} at {file_path}\")\n</code></pre></p> <p>From Python (using core orchestration):     <pre><code>from pathlib import Path\nfrom notapkgtool.core import discover_recipe\n\n# Automatically uses ETag optimization\nresult = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\nprint(f\"Version {result.version} at {result.file_path}\")\n</code></pre></p> Note <ul> <li>Must download file to extract version (architectural constraint)</li> <li>ETag optimization reduces bandwidth but still requires network round-trip</li> <li>Core orchestration automatically provides cached ETag if available</li> <li>Server must support ETag or Last-Modified headers for optimization</li> <li>If server doesn't support conditional requests, full download occurs every time</li> <li>Consider version-first strategies (web_scrape, api_github, api_json) for   better performance when version available via web scraping or API</li> </ul>"},{"location":"api/discovery/#notapkgtool.discovery.url_download.UrlDownloadStrategy","title":"UrlDownloadStrategy","text":"<p>Discovery strategy for static HTTP(S) URLs.</p> Configuration example <p>source:   strategy: url_download   url: \"https://example.com/installer.msi\"</p> Source code in <code>notapkgtool/discovery/url_download.py</code> <pre><code>class UrlDownloadStrategy:\n    \"\"\"Discovery strategy for static HTTP(S) URLs.\n\n    Configuration example:\n        source:\n          strategy: url_download\n          url: \"https://example.com/installer.msi\"\n    \"\"\"\n\n    def discover_version(\n        self,\n        app_config: dict[str, Any],\n        output_dir: Path,\n        cache: dict[str, Any] | None = None,\n    ) -&gt; tuple[DiscoveredVersion, Path, str, dict]:\n        \"\"\"Download from static URL and extract version from the file.\n\n        Args:\n            app_config: App configuration containing source.url and\n                source.version.\n            output_dir: Directory to save the downloaded file.\n            cache: Cached state with etag, last_modified,\n                file_path, and sha256 for conditional requests. If provided\n                and file is unchanged (HTTP 304), the cached file is returned.\n\n        Returns:\n            A tuple (version_info, file_path, sha256, headers), where\n                version_info contains the discovered version information,\n                file_path is the Path to the downloaded file, sha256 is the\n                SHA-256 hash, and headers contains HTTP response headers.\n\n        Raises:\n            ConfigError: If required config fields are missing or invalid.\n            NetworkError: If download or version extraction fails.\n\n        \"\"\"\n        from notapkgtool.logging import get_global_logger\n\n        logger = get_global_logger()\n        source = app_config.get(\"source\", {})\n        url = source.get(\"url\")\n        if not url:\n            raise ConfigError(\"url_download strategy requires 'source.url' in config\")\n\n        logger.verbose(\"DISCOVERY\", \"Strategy: url_download (file-first)\")\n        logger.verbose(\"DISCOVERY\", f\"Source URL: {url}\")\n\n        # Extract ETag/Last-Modified from cache if available\n        etag = cache.get(\"etag\") if cache else None\n        last_modified = cache.get(\"last_modified\") if cache else None\n\n        if etag:\n            logger.verbose(\"DISCOVERY\", f\"Using cached ETag: {etag}\")\n        if last_modified:\n            logger.verbose(\"DISCOVERY\", f\"Using cached Last-Modified: {last_modified}\")\n\n        # Download the file (with conditional request if cache available)\n        try:\n            file_path, sha256, headers = download_file(\n                url,\n                output_dir,\n                etag=etag,\n                last_modified=last_modified,\n            )\n        except NotModifiedError:\n            # File unchanged (HTTP 304), use cached version\n            # Use convention-based path: derive filename from URL\n            logger.verbose(\n                \"DISCOVERY\", \"File not modified (HTTP 304), using cached version\"\n            )\n\n            if not cache or \"sha256\" not in cache:\n                raise NetworkError(\n                    \"Cache indicates file not modified, but missing SHA-256. \"\n                    \"Try running with --stateless to force re-download.\"\n                ) from None\n\n            # Derive file path from URL (convention-based, schema v2)\n            from urllib.parse import urlparse\n\n            filename = Path(urlparse(url).path).name\n            cached_file = output_dir / filename\n\n            if not cached_file.exists():\n                raise NetworkError(\n                    f\"Cached file {cached_file} not found. \"\n                    f\"File may have been deleted. Try running with --stateless.\"\n                ) from None\n\n            # Extract version from cached file (auto-detect by extension)\n            if cached_file.suffix.lower() == \".msi\":\n                logger.verbose(\n                    \"DISCOVERY\", \"Auto-detected MSI file, extracting version\"\n                )\n                try:\n                    discovered = version_from_msi_product_version(cached_file)\n                except Exception as err:\n                    raise NetworkError(\n                        f\"Failed to extract MSI ProductVersion from cached \"\n                        f\"file {cached_file}: {err}\"\n                    ) from err\n            else:\n                raise ConfigError(\n                    f\"Cannot extract version from file type: {cached_file.suffix!r}. \"\n                    f\"url_download strategy currently supports MSI files only. \"\n                    f\"For other file types, use a version-first strategy (api_github, \"\n                    f\"api_json, web_scrape) or ensure the file is an MSI installer.\"\n                ) from None\n\n            # Return cached info with preserved headers (prevents overwriting ETag)\n            # When 304, no new headers received, so return cached values to\n            # preserve them\n            preserved_headers = {}\n            if cache.get(\"etag\"):\n                preserved_headers[\"ETag\"] = cache[\"etag\"]\n            if cache.get(\"last_modified\"):\n                preserved_headers[\"Last-Modified\"] = cache[\"last_modified\"]\n\n            return discovered, cached_file, cache[\"sha256\"], preserved_headers\n        except Exception as err:\n            if isinstance(err, (NetworkError, ConfigError)):\n                raise\n            raise NetworkError(f\"Failed to download {url}: {err}\") from err\n\n        # File was downloaded (not cached), extract version from it (auto-detect by extension)\n        if file_path.suffix.lower() == \".msi\":\n            logger.verbose(\"DISCOVERY\", \"Auto-detected MSI file, extracting version\")\n            try:\n                discovered = version_from_msi_product_version(file_path)\n            except Exception as err:\n                raise NetworkError(\n                    f\"Failed to extract MSI ProductVersion from {file_path}: {err}\"\n                ) from err\n        else:\n            raise ConfigError(\n                f\"Cannot extract version from file type: {file_path.suffix!r}. \"\n                f\"url_download strategy currently supports MSI files only. \"\n                f\"For other file types, use a version-first strategy (api_github, \"\n                f\"api_json, web_scrape) or ensure the file is an MSI installer.\"\n            )\n\n        return discovered, file_path, sha256, headers\n\n    def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n        \"\"\"Validate url_download strategy configuration.\n\n        Checks for required fields and correct types without making network calls.\n\n        Args:\n            app_config: The app configuration from the recipe.\n\n        Returns:\n            List of error messages (empty if valid).\n\n        \"\"\"\n        errors = []\n        source = app_config.get(\"source\", {})\n\n        # Check required fields\n        if \"url\" not in source:\n            errors.append(\"Missing required field: source.url\")\n        elif not isinstance(source[\"url\"], str):\n            errors.append(\"source.url must be a string\")\n        elif not source[\"url\"].strip():\n            errors.append(\"source.url cannot be empty\")\n\n        # Version extraction is now auto-detected by file extension\n        # No version configuration validation needed\n\n        return errors\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.url_download.UrlDownloadStrategy.discover_version","title":"discover_version","text":"<pre><code>discover_version(app_config: dict[str, Any], output_dir: Path, cache: dict[str, Any] | None = None) -&gt; tuple[DiscoveredVersion, Path, str, dict]\n</code></pre> <p>Download from static URL and extract version from the file.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>App configuration containing source.url and source.version.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the downloaded file.</p> required <code>cache</code> <code>dict[str, Any] | None</code> <p>Cached state with etag, last_modified, file_path, and sha256 for conditional requests. If provided and file is unchanged (HTTP 304), the cached file is returned.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[DiscoveredVersion, Path, str, dict]</code> <p>A tuple (version_info, file_path, sha256, headers), where version_info contains the discovered version information, file_path is the Path to the downloaded file, sha256 is the SHA-256 hash, and headers contains HTTP response headers.</p> <p>Raises:</p> Type Description <code>ConfigError</code> <p>If required config fields are missing or invalid.</p> <code>NetworkError</code> <p>If download or version extraction fails.</p> Source code in <code>notapkgtool/discovery/url_download.py</code> <pre><code>def discover_version(\n    self,\n    app_config: dict[str, Any],\n    output_dir: Path,\n    cache: dict[str, Any] | None = None,\n) -&gt; tuple[DiscoveredVersion, Path, str, dict]:\n    \"\"\"Download from static URL and extract version from the file.\n\n    Args:\n        app_config: App configuration containing source.url and\n            source.version.\n        output_dir: Directory to save the downloaded file.\n        cache: Cached state with etag, last_modified,\n            file_path, and sha256 for conditional requests. If provided\n            and file is unchanged (HTTP 304), the cached file is returned.\n\n    Returns:\n        A tuple (version_info, file_path, sha256, headers), where\n            version_info contains the discovered version information,\n            file_path is the Path to the downloaded file, sha256 is the\n            SHA-256 hash, and headers contains HTTP response headers.\n\n    Raises:\n        ConfigError: If required config fields are missing or invalid.\n        NetworkError: If download or version extraction fails.\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    source = app_config.get(\"source\", {})\n    url = source.get(\"url\")\n    if not url:\n        raise ConfigError(\"url_download strategy requires 'source.url' in config\")\n\n    logger.verbose(\"DISCOVERY\", \"Strategy: url_download (file-first)\")\n    logger.verbose(\"DISCOVERY\", f\"Source URL: {url}\")\n\n    # Extract ETag/Last-Modified from cache if available\n    etag = cache.get(\"etag\") if cache else None\n    last_modified = cache.get(\"last_modified\") if cache else None\n\n    if etag:\n        logger.verbose(\"DISCOVERY\", f\"Using cached ETag: {etag}\")\n    if last_modified:\n        logger.verbose(\"DISCOVERY\", f\"Using cached Last-Modified: {last_modified}\")\n\n    # Download the file (with conditional request if cache available)\n    try:\n        file_path, sha256, headers = download_file(\n            url,\n            output_dir,\n            etag=etag,\n            last_modified=last_modified,\n        )\n    except NotModifiedError:\n        # File unchanged (HTTP 304), use cached version\n        # Use convention-based path: derive filename from URL\n        logger.verbose(\n            \"DISCOVERY\", \"File not modified (HTTP 304), using cached version\"\n        )\n\n        if not cache or \"sha256\" not in cache:\n            raise NetworkError(\n                \"Cache indicates file not modified, but missing SHA-256. \"\n                \"Try running with --stateless to force re-download.\"\n            ) from None\n\n        # Derive file path from URL (convention-based, schema v2)\n        from urllib.parse import urlparse\n\n        filename = Path(urlparse(url).path).name\n        cached_file = output_dir / filename\n\n        if not cached_file.exists():\n            raise NetworkError(\n                f\"Cached file {cached_file} not found. \"\n                f\"File may have been deleted. Try running with --stateless.\"\n            ) from None\n\n        # Extract version from cached file (auto-detect by extension)\n        if cached_file.suffix.lower() == \".msi\":\n            logger.verbose(\n                \"DISCOVERY\", \"Auto-detected MSI file, extracting version\"\n            )\n            try:\n                discovered = version_from_msi_product_version(cached_file)\n            except Exception as err:\n                raise NetworkError(\n                    f\"Failed to extract MSI ProductVersion from cached \"\n                    f\"file {cached_file}: {err}\"\n                ) from err\n        else:\n            raise ConfigError(\n                f\"Cannot extract version from file type: {cached_file.suffix!r}. \"\n                f\"url_download strategy currently supports MSI files only. \"\n                f\"For other file types, use a version-first strategy (api_github, \"\n                f\"api_json, web_scrape) or ensure the file is an MSI installer.\"\n            ) from None\n\n        # Return cached info with preserved headers (prevents overwriting ETag)\n        # When 304, no new headers received, so return cached values to\n        # preserve them\n        preserved_headers = {}\n        if cache.get(\"etag\"):\n            preserved_headers[\"ETag\"] = cache[\"etag\"]\n        if cache.get(\"last_modified\"):\n            preserved_headers[\"Last-Modified\"] = cache[\"last_modified\"]\n\n        return discovered, cached_file, cache[\"sha256\"], preserved_headers\n    except Exception as err:\n        if isinstance(err, (NetworkError, ConfigError)):\n            raise\n        raise NetworkError(f\"Failed to download {url}: {err}\") from err\n\n    # File was downloaded (not cached), extract version from it (auto-detect by extension)\n    if file_path.suffix.lower() == \".msi\":\n        logger.verbose(\"DISCOVERY\", \"Auto-detected MSI file, extracting version\")\n        try:\n            discovered = version_from_msi_product_version(file_path)\n        except Exception as err:\n            raise NetworkError(\n                f\"Failed to extract MSI ProductVersion from {file_path}: {err}\"\n            ) from err\n    else:\n        raise ConfigError(\n            f\"Cannot extract version from file type: {file_path.suffix!r}. \"\n            f\"url_download strategy currently supports MSI files only. \"\n            f\"For other file types, use a version-first strategy (api_github, \"\n            f\"api_json, web_scrape) or ensure the file is an MSI installer.\"\n        )\n\n    return discovered, file_path, sha256, headers\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.url_download.UrlDownloadStrategy.validate_config","title":"validate_config","text":"<pre><code>validate_config(app_config: dict[str, Any]) -&gt; list[str]\n</code></pre> <p>Validate url_download strategy configuration.</p> <p>Checks for required fields and correct types without making network calls.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>The app configuration from the recipe.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of error messages (empty if valid).</p> Source code in <code>notapkgtool/discovery/url_download.py</code> <pre><code>def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n    \"\"\"Validate url_download strategy configuration.\n\n    Checks for required fields and correct types without making network calls.\n\n    Args:\n        app_config: The app configuration from the recipe.\n\n    Returns:\n        List of error messages (empty if valid).\n\n    \"\"\"\n    errors = []\n    source = app_config.get(\"source\", {})\n\n    # Check required fields\n    if \"url\" not in source:\n        errors.append(\"Missing required field: source.url\")\n    elif not isinstance(source[\"url\"], str):\n        errors.append(\"source.url must be a string\")\n    elif not source[\"url\"].strip():\n        errors.append(\"source.url cannot be empty\")\n\n    # Version extraction is now auto-detected by file extension\n    # No version configuration validation needed\n\n    return errors\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.web_scrape","title":"notapkgtool.discovery.web_scrape","text":"<p>Web scraping discovery strategy for NAPT.</p> <p>This is a VERSION-FIRST strategy that scrapes vendor download pages to find download links and extract version information from those links. This enables version discovery for vendors that don't provide APIs or static URLs.</p> <p>Key Advantages:</p> <ul> <li>Discovers versions from vendor download pages</li> <li>Works for vendors without APIs or GitHub releases</li> <li>Version-first caching (can skip downloads when version unchanged)</li> <li>Supports both CSS selectors (recommended) and regex (fallback)</li> <li>No dependency on HTML structure stability (with good selectors)</li> <li>Handles relative and absolute URLs automatically</li> </ul> <p>Supported Link Finding:</p> <ul> <li>CSS selectors: Modern, robust, recommended approach</li> <li>Regex patterns: Fallback for edge cases or when CSS won't work</li> </ul> <p>Version Extraction:</p> <ul> <li>Extract version from the discovered download URL using regex</li> <li>Support for captured groups with formatting</li> <li>Transform version numbers (e.g., \"2501\" -&gt; \"25.01\")</li> </ul> <p>Use Cases:</p> <ul> <li>Vendors with download pages listing multiple versions (7-Zip, etc.)</li> <li>Legacy software without modern APIs</li> <li>Small vendors with simple download pages</li> <li>When GitHub releases and JSON APIs aren't available</li> </ul> Recipe Configuration <pre><code>source:\n  strategy: web_scrape\n  page_url: \"https://www.7-zip.org/download.html\"\n  link_selector: 'a[href$=\"-x64.msi\"]'        # CSS (recommended)\n  version_pattern: \"7z(\\d{2})(\\d{2})-x64\"   # Extract from URL\n  version_format: \"{0}.{1}\"                    # Transform to \"25.01\"\n</code></pre> Alternative with regex <pre><code>source:\n  strategy: web_scrape\n  page_url: \"https://vendor.com/downloads\"\n  link_pattern: 'href=\"(/files/app-v[0-9.]+-x64\\.msi)\"'\n  version_pattern: \"app-v([0-9.]+)-x64\"\n</code></pre> <p>Configuration Fields:</p> <ul> <li>page_url (str, required): URL of the page to scrape for download links</li> <li>link_selector (str, optional): CSS selector to find download link.     Recommended approach. Example: 'a[href$=\".msi\"]' finds links ending with .msi</li> <li>link_pattern (str, optional): Regex pattern as fallback when CSS won't     work. Must have one capture group for the URL. Example: 'href=\"([^\"]*.msi)\"'</li> <li>version_pattern (str, required): Regex pattern to extract version from     the discovered URL. Use capture groups to extract version parts. Example:     \"app-(\\d+.\\d+)\" or \"7z(\\d{2})(\\d{2})\"</li> <li>version_format (str, optional): Python format string to combine captured     groups. Use {0}, {1}, etc. for groups. Example: \"{0}.{1}\" transforms     captures \"25\", \"01\" into \"25.01\". Defaults to \"{0}\" (first capture group     only).</li> </ul> <p>Error Handling:</p> <ul> <li>ValueError: Missing or invalid configuration fields</li> <li>RuntimeError: Page download failures, selector/pattern not found</li> <li>Errors are chained with 'from err' for better debugging</li> </ul> <p>Finding CSS Selectors:</p> <pre><code>Use browser DevTools:\n\n1. Open download page in Chrome/Edge/Firefox\n2. Right-click download link -&gt; Inspect\n3. Right-click highlighted element -&gt; Copy -&gt; Copy selector\n4. Simplify selector (e.g., 'a[href$=\".msi\"]' instead of complex nth-child)\n</code></pre> <p>Common CSS Patterns:</p> <ul> <li>'a[href$=\".msi\"]' - Links ending with .msi</li> <li>'a[href*=\"x64\"]' - Links containing \"x64\"</li> <li>'a.download' - Links with class=\"download\"</li> <li>'a[href$=\"-x64.msi\"]:first-of-type' - First matching link</li> </ul> Example <p>In a recipe YAML:     <pre><code>apps:\n  - name: \"7-Zip\"\n    id: \"napt-7zip\"\n    source:\n      strategy: web_scrape\n      page_url: \"https://www.7-zip.org/download.html\"\n      link_selector: 'a[href$=\"-x64.msi\"]'\n      version_pattern: \"7z(\\d{2})(\\d{2})-x64\"\n      version_format: \"{0}.{1}\"\n</code></pre></p> <p>From Python (version-first approach):     <pre><code>from notapkgtool.discovery.web_scrape import WebScrapeStrategy\nfrom notapkgtool.io import download_file\n\nstrategy = WebScrapeStrategy()\napp_config = {\n    \"source\": {\n        \"page_url\": \"https://www.7-zip.org/download.html\",\n        \"link_selector\": 'a[href$=\"-x64.msi\"]',\n        \"version_pattern\": \"7z(\\d{2})(\\d{2})-x64\",\n        \"version_format\": \"{0}.{1}\",\n    }\n}\n\n# Get version WITHOUT downloading installer\nversion_info = strategy.get_version_info(app_config)\nprint(f\"Latest version: {version_info.version}\")\n\n# Download only if needed\nif need_to_download:\n    file_path, sha256, headers = download_file(\n        version_info.download_url, Path(\"./downloads\")\n    )\n    print(f\"Downloaded to {file_path}\")\n</code></pre></p> <p>From Python (using core orchestration):     <pre><code>from pathlib import Path\nfrom notapkgtool.core import discover_recipe\n\n# Automatically uses version-first optimization\nresult = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\nprint(f\"Version {result.version} at {result.file_path}\")\n</code></pre></p> Note <ul> <li>Version discovery via web scraping (no installer download required)</li> <li>Core orchestration automatically skips download if version unchanged</li> <li>CSS selectors are recommended (more robust than regex)</li> <li>Use browser DevTools to find selectors easily</li> <li>Selector should match exactly one link (first match is used)</li> <li>BeautifulSoup4 required for CSS selectors</li> <li>Regex fallback works without BeautifulSoup</li> </ul>"},{"location":"api/discovery/#notapkgtool.discovery.web_scrape.WebScrapeStrategy","title":"WebScrapeStrategy","text":"<p>Discovery strategy for web scraping download pages.</p> Configuration example <pre><code>source:\n  strategy: web_scrape\n  page_url: \"https://vendor.com/download.html\"\n  link_selector: 'a[href$=\".msi\"]'\n  version_pattern: \"app-v([0-9.]+)\"\n</code></pre> Source code in <code>notapkgtool/discovery/web_scrape.py</code> <pre><code>class WebScrapeStrategy:\n    \"\"\"Discovery strategy for web scraping download pages.\n\n    Configuration example:\n        ```yaml\n        source:\n          strategy: web_scrape\n          page_url: \"https://vendor.com/download.html\"\n          link_selector: 'a[href$=\".msi\"]'\n          version_pattern: \"app-v([0-9.]+)\"\n        ```\n    \"\"\"\n\n    def get_version_info(\n        self,\n        app_config: dict[str, Any],\n    ) -&gt; VersionInfo:\n        \"\"\"Scrape download page for version and URL without downloading\n        (version-first path).\n\n        This method scrapes an HTML page, finds a download link using CSS selector\n        or regex, extracts the version from that link, and returns version info.\n        If the version matches cached state, the download can be skipped entirely.\n\n        Args:\n            app_config: App configuration containing source.page_url,\n                source.link_selector or source.link_pattern, and\n                source.version_pattern.\n\n        Returns:\n            Version info with version string, download URL, and\n                source name.\n\n        Raises:\n            ValueError: If required config fields are missing, invalid, or if\n                selectors/patterns don't match anything.\n            RuntimeError: If page download fails (chained with 'from err').\n\n        Example:\n            Scrape 7-Zip download page:\n                ```python\n                strategy = WebScrapeStrategy()\n                config = {\n                    \"source\": {\n                        \"page_url\": \"https://www.7-zip.org/download.html\",\n                        \"link_selector\": 'a[href$=\"-x64.msi\"]',\n                        \"version_pattern\": \"7z(\\\\d{2})(\\\\d{2})-x64\",\n                        \"version_format\": \"{0}.{1}\"\n                    }\n                }\n                version_info = strategy.get_version_info(config)\n                # version_info.version returns: '25.01'\n                ```\n\n        \"\"\"\n        from notapkgtool.logging import get_global_logger\n\n        logger = get_global_logger()\n        # Validate configuration\n        source = app_config.get(\"source\", {})\n        page_url = source.get(\"page_url\")\n        if not page_url:\n            raise ConfigError(\n                \"web_scrape strategy requires 'source.page_url' in config\"\n            )\n\n        link_selector = source.get(\"link_selector\")\n        link_pattern = source.get(\"link_pattern\")\n\n        if not link_selector and not link_pattern:\n            raise ConfigError(\n                \"web_scrape strategy requires either 'source.link_selector' or \"\n                \"'source.link_pattern' in config\"\n            )\n\n        version_pattern = source.get(\"version_pattern\")\n        if not version_pattern:\n            raise ConfigError(\n                \"web_scrape strategy requires 'source.version_pattern' in config\"\n            )\n\n        version_format = source.get(\"version_format\", \"{0}\")\n\n        logger.verbose(\"DISCOVERY\", \"Strategy: web_scrape (version-first)\")\n        logger.verbose(\"DISCOVERY\", f\"Page URL: {page_url}\")\n        if link_selector:\n            logger.verbose(\"DISCOVERY\", f\"Link selector (CSS): {link_selector}\")\n        if link_pattern:\n            logger.verbose(\"DISCOVERY\", f\"Link pattern (regex): {link_pattern}\")\n        logger.verbose(\"DISCOVERY\", f\"Version pattern: {version_pattern}\")\n\n        # Download the HTML page\n        logger.verbose(\"DISCOVERY\", f\"Fetching page: {page_url}\")\n        try:\n            response = requests.get(page_url, timeout=30)\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as err:\n            raise NetworkError(\n                f\"Failed to fetch page: {response.status_code} {response.reason}\"\n            ) from err\n        except requests.exceptions.RequestException as err:\n            raise NetworkError(f\"Failed to fetch page: {err}\") from err\n\n        html_content = response.text\n        logger.verbose(\"DISCOVERY\", f\"Page fetched ({len(html_content)} bytes)\")\n\n        # Find download link using CSS selector or regex\n        download_url = None\n\n        if link_selector:\n            # Use CSS selector with BeautifulSoup4\n            soup = BeautifulSoup(html_content, \"html.parser\")\n            element = soup.select_one(link_selector)\n\n            if not element:\n                raise ConfigError(\n                    f\"CSS selector {link_selector!r} did not match any elements on page\"\n                )\n\n            # Get href attribute\n            href = element.get(\"href\")\n            if not href:\n                raise ConfigError(\n                    f\"Element matched by {link_selector!r} has no href attribute\"\n                )\n\n            logger.verbose(\"DISCOVERY\", f\"Found link via CSS: {href}\")\n\n            # Build absolute URL\n            download_url = urljoin(page_url, href)\n\n        elif link_pattern:\n            # Use regex fallback\n            try:\n                pattern = re.compile(link_pattern)\n                match = pattern.search(html_content)\n\n                if not match:\n                    raise ConfigError(\n                        f\"Regex pattern {link_pattern!r} did not match anything on page\"\n                    )\n\n                # Get first capture group or full match\n                if pattern.groups &gt; 0:\n                    href = match.group(1)\n                else:\n                    href = match.group(0)\n\n                logger.verbose(\"DISCOVERY\", f\"Found link via regex: {href}\")\n\n                # Build absolute URL\n                download_url = urljoin(page_url, href)\n\n            except re.error as err:\n                raise ConfigError(\n                    f\"Invalid link_pattern regex: {link_pattern!r}\"\n                ) from err\n\n        logger.verbose(\"DISCOVERY\", f\"Download URL: {download_url}\")\n\n        # Extract version from the download URL\n        try:\n            version_regex = re.compile(version_pattern)\n            match = version_regex.search(download_url)\n\n            if not match:\n                raise ConfigError(\n                    f\"Version pattern {version_pattern!r} did not match \"\n                    f\"URL {download_url!r}\"\n                )\n\n            # Get captured groups\n            groups = match.groups()\n\n            if not groups:\n                # No capture groups, use full match\n                version_str = match.group(0)\n            else:\n                # Format using captured groups\n                try:\n                    version_str = version_format.format(*groups)\n                except (IndexError, KeyError) as err:\n                    raise ConfigError(\n                        f\"version_format {version_format!r} failed with \"\n                        f\"groups {groups}: {err}\"\n                    ) from err\n\n        except re.error as err:\n            raise ConfigError(\n                f\"Invalid version_pattern regex: {version_pattern!r}\"\n            ) from err\n\n        logger.verbose(\"DISCOVERY\", f\"Extracted version: {version_str}\")\n\n        return VersionInfo(\n            version=version_str,\n            download_url=download_url,\n            source=\"web_scrape\",\n        )\n\n    def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n        \"\"\"Validate web_scrape strategy configuration.\n\n        Checks for required fields and correct types without making network calls.\n\n        Args:\n            app_config: The app configuration from the recipe.\n\n        Returns:\n            List of error messages (empty if valid).\n\n        \"\"\"\n        errors = []\n        source = app_config.get(\"source\", {})\n\n        # Check page_url\n        if \"page_url\" not in source:\n            errors.append(\"Missing required field: source.page_url\")\n        elif not isinstance(source[\"page_url\"], str):\n            errors.append(\"source.page_url must be a string\")\n        elif not source[\"page_url\"].strip():\n            errors.append(\"source.page_url cannot be empty\")\n\n        # Check that at least one link finding method is provided\n        link_selector = source.get(\"link_selector\")\n        link_pattern = source.get(\"link_pattern\")\n\n        if not link_selector and not link_pattern:\n            errors.append(\n                \"Missing required field: must provide either \"\n                \"source.link_selector or source.link_pattern\"\n            )\n\n        # Validate link_selector if provided\n        if link_selector:\n            if not isinstance(link_selector, str):\n                errors.append(\"source.link_selector must be a string\")\n            elif not link_selector.strip():\n                errors.append(\"source.link_selector cannot be empty\")\n            else:\n                # Try to validate CSS selector syntax\n                try:\n                    # Test if selector is parseable\n                    soup = BeautifulSoup(\"&lt;html&gt;&lt;/html&gt;\", \"html.parser\")\n                    soup.select_one(link_selector)  # Will raise if invalid\n                except Exception as err:\n                    errors.append(f\"Invalid CSS selector: {err}\")\n\n        # Validate link_pattern if provided\n        if link_pattern:\n            if not isinstance(link_pattern, str):\n                errors.append(\"source.link_pattern must be a string\")\n            elif not link_pattern.strip():\n                errors.append(\"source.link_pattern cannot be empty\")\n            else:\n                # Validate regex compiles\n                try:\n                    re.compile(link_pattern)\n                except re.error as err:\n                    errors.append(f\"Invalid link_pattern regex: {err}\")\n\n        # Check version_pattern\n        if \"version_pattern\" not in source:\n            errors.append(\"Missing required field: source.version_pattern\")\n        elif not isinstance(source[\"version_pattern\"], str):\n            errors.append(\"source.version_pattern must be a string\")\n        elif not source[\"version_pattern\"].strip():\n            errors.append(\"source.version_pattern cannot be empty\")\n        else:\n            # Validate regex compiles\n            try:\n                re.compile(source[\"version_pattern\"])\n            except re.error as err:\n                errors.append(f\"Invalid version_pattern regex: {err}\")\n\n        # Validate version_format if provided\n        if \"version_format\" in source:\n            if not isinstance(source[\"version_format\"], str):\n                errors.append(\"source.version_format must be a string\")\n            elif not source[\"version_format\"].strip():\n                errors.append(\"source.version_format cannot be empty\")\n\n        return errors\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.web_scrape.WebScrapeStrategy.get_version_info","title":"get_version_info","text":"<pre><code>get_version_info(app_config: dict[str, Any]) -&gt; VersionInfo\n</code></pre> <p>Scrape download page for version and URL without downloading (version-first path).</p> <p>This method scrapes an HTML page, finds a download link using CSS selector or regex, extracts the version from that link, and returns version info. If the version matches cached state, the download can be skipped entirely.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>App configuration containing source.page_url, source.link_selector or source.link_pattern, and source.version_pattern.</p> required <p>Returns:</p> Type Description <code>VersionInfo</code> <p>Version info with version string, download URL, and source name.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If required config fields are missing, invalid, or if selectors/patterns don't match anything.</p> <code>RuntimeError</code> <p>If page download fails (chained with 'from err').</p> Example <p>Scrape 7-Zip download page:     <pre><code>strategy = WebScrapeStrategy()\nconfig = {\n    \"source\": {\n        \"page_url\": \"https://www.7-zip.org/download.html\",\n        \"link_selector\": 'a[href$=\"-x64.msi\"]',\n        \"version_pattern\": \"7z(\\d{2})(\\d{2})-x64\",\n        \"version_format\": \"{0}.{1}\"\n    }\n}\nversion_info = strategy.get_version_info(config)\n# version_info.version returns: '25.01'\n</code></pre></p> Source code in <code>notapkgtool/discovery/web_scrape.py</code> <pre><code>def get_version_info(\n    self,\n    app_config: dict[str, Any],\n) -&gt; VersionInfo:\n    \"\"\"Scrape download page for version and URL without downloading\n    (version-first path).\n\n    This method scrapes an HTML page, finds a download link using CSS selector\n    or regex, extracts the version from that link, and returns version info.\n    If the version matches cached state, the download can be skipped entirely.\n\n    Args:\n        app_config: App configuration containing source.page_url,\n            source.link_selector or source.link_pattern, and\n            source.version_pattern.\n\n    Returns:\n        Version info with version string, download URL, and\n            source name.\n\n    Raises:\n        ValueError: If required config fields are missing, invalid, or if\n            selectors/patterns don't match anything.\n        RuntimeError: If page download fails (chained with 'from err').\n\n    Example:\n        Scrape 7-Zip download page:\n            ```python\n            strategy = WebScrapeStrategy()\n            config = {\n                \"source\": {\n                    \"page_url\": \"https://www.7-zip.org/download.html\",\n                    \"link_selector\": 'a[href$=\"-x64.msi\"]',\n                    \"version_pattern\": \"7z(\\\\d{2})(\\\\d{2})-x64\",\n                    \"version_format\": \"{0}.{1}\"\n                }\n            }\n            version_info = strategy.get_version_info(config)\n            # version_info.version returns: '25.01'\n            ```\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    # Validate configuration\n    source = app_config.get(\"source\", {})\n    page_url = source.get(\"page_url\")\n    if not page_url:\n        raise ConfigError(\n            \"web_scrape strategy requires 'source.page_url' in config\"\n        )\n\n    link_selector = source.get(\"link_selector\")\n    link_pattern = source.get(\"link_pattern\")\n\n    if not link_selector and not link_pattern:\n        raise ConfigError(\n            \"web_scrape strategy requires either 'source.link_selector' or \"\n            \"'source.link_pattern' in config\"\n        )\n\n    version_pattern = source.get(\"version_pattern\")\n    if not version_pattern:\n        raise ConfigError(\n            \"web_scrape strategy requires 'source.version_pattern' in config\"\n        )\n\n    version_format = source.get(\"version_format\", \"{0}\")\n\n    logger.verbose(\"DISCOVERY\", \"Strategy: web_scrape (version-first)\")\n    logger.verbose(\"DISCOVERY\", f\"Page URL: {page_url}\")\n    if link_selector:\n        logger.verbose(\"DISCOVERY\", f\"Link selector (CSS): {link_selector}\")\n    if link_pattern:\n        logger.verbose(\"DISCOVERY\", f\"Link pattern (regex): {link_pattern}\")\n    logger.verbose(\"DISCOVERY\", f\"Version pattern: {version_pattern}\")\n\n    # Download the HTML page\n    logger.verbose(\"DISCOVERY\", f\"Fetching page: {page_url}\")\n    try:\n        response = requests.get(page_url, timeout=30)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as err:\n        raise NetworkError(\n            f\"Failed to fetch page: {response.status_code} {response.reason}\"\n        ) from err\n    except requests.exceptions.RequestException as err:\n        raise NetworkError(f\"Failed to fetch page: {err}\") from err\n\n    html_content = response.text\n    logger.verbose(\"DISCOVERY\", f\"Page fetched ({len(html_content)} bytes)\")\n\n    # Find download link using CSS selector or regex\n    download_url = None\n\n    if link_selector:\n        # Use CSS selector with BeautifulSoup4\n        soup = BeautifulSoup(html_content, \"html.parser\")\n        element = soup.select_one(link_selector)\n\n        if not element:\n            raise ConfigError(\n                f\"CSS selector {link_selector!r} did not match any elements on page\"\n            )\n\n        # Get href attribute\n        href = element.get(\"href\")\n        if not href:\n            raise ConfigError(\n                f\"Element matched by {link_selector!r} has no href attribute\"\n            )\n\n        logger.verbose(\"DISCOVERY\", f\"Found link via CSS: {href}\")\n\n        # Build absolute URL\n        download_url = urljoin(page_url, href)\n\n    elif link_pattern:\n        # Use regex fallback\n        try:\n            pattern = re.compile(link_pattern)\n            match = pattern.search(html_content)\n\n            if not match:\n                raise ConfigError(\n                    f\"Regex pattern {link_pattern!r} did not match anything on page\"\n                )\n\n            # Get first capture group or full match\n            if pattern.groups &gt; 0:\n                href = match.group(1)\n            else:\n                href = match.group(0)\n\n            logger.verbose(\"DISCOVERY\", f\"Found link via regex: {href}\")\n\n            # Build absolute URL\n            download_url = urljoin(page_url, href)\n\n        except re.error as err:\n            raise ConfigError(\n                f\"Invalid link_pattern regex: {link_pattern!r}\"\n            ) from err\n\n    logger.verbose(\"DISCOVERY\", f\"Download URL: {download_url}\")\n\n    # Extract version from the download URL\n    try:\n        version_regex = re.compile(version_pattern)\n        match = version_regex.search(download_url)\n\n        if not match:\n            raise ConfigError(\n                f\"Version pattern {version_pattern!r} did not match \"\n                f\"URL {download_url!r}\"\n            )\n\n        # Get captured groups\n        groups = match.groups()\n\n        if not groups:\n            # No capture groups, use full match\n            version_str = match.group(0)\n        else:\n            # Format using captured groups\n            try:\n                version_str = version_format.format(*groups)\n            except (IndexError, KeyError) as err:\n                raise ConfigError(\n                    f\"version_format {version_format!r} failed with \"\n                    f\"groups {groups}: {err}\"\n                ) from err\n\n    except re.error as err:\n        raise ConfigError(\n            f\"Invalid version_pattern regex: {version_pattern!r}\"\n        ) from err\n\n    logger.verbose(\"DISCOVERY\", f\"Extracted version: {version_str}\")\n\n    return VersionInfo(\n        version=version_str,\n        download_url=download_url,\n        source=\"web_scrape\",\n    )\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.web_scrape.WebScrapeStrategy.validate_config","title":"validate_config","text":"<pre><code>validate_config(app_config: dict[str, Any]) -&gt; list[str]\n</code></pre> <p>Validate web_scrape strategy configuration.</p> <p>Checks for required fields and correct types without making network calls.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>The app configuration from the recipe.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of error messages (empty if valid).</p> Source code in <code>notapkgtool/discovery/web_scrape.py</code> <pre><code>def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n    \"\"\"Validate web_scrape strategy configuration.\n\n    Checks for required fields and correct types without making network calls.\n\n    Args:\n        app_config: The app configuration from the recipe.\n\n    Returns:\n        List of error messages (empty if valid).\n\n    \"\"\"\n    errors = []\n    source = app_config.get(\"source\", {})\n\n    # Check page_url\n    if \"page_url\" not in source:\n        errors.append(\"Missing required field: source.page_url\")\n    elif not isinstance(source[\"page_url\"], str):\n        errors.append(\"source.page_url must be a string\")\n    elif not source[\"page_url\"].strip():\n        errors.append(\"source.page_url cannot be empty\")\n\n    # Check that at least one link finding method is provided\n    link_selector = source.get(\"link_selector\")\n    link_pattern = source.get(\"link_pattern\")\n\n    if not link_selector and not link_pattern:\n        errors.append(\n            \"Missing required field: must provide either \"\n            \"source.link_selector or source.link_pattern\"\n        )\n\n    # Validate link_selector if provided\n    if link_selector:\n        if not isinstance(link_selector, str):\n            errors.append(\"source.link_selector must be a string\")\n        elif not link_selector.strip():\n            errors.append(\"source.link_selector cannot be empty\")\n        else:\n            # Try to validate CSS selector syntax\n            try:\n                # Test if selector is parseable\n                soup = BeautifulSoup(\"&lt;html&gt;&lt;/html&gt;\", \"html.parser\")\n                soup.select_one(link_selector)  # Will raise if invalid\n            except Exception as err:\n                errors.append(f\"Invalid CSS selector: {err}\")\n\n    # Validate link_pattern if provided\n    if link_pattern:\n        if not isinstance(link_pattern, str):\n            errors.append(\"source.link_pattern must be a string\")\n        elif not link_pattern.strip():\n            errors.append(\"source.link_pattern cannot be empty\")\n        else:\n            # Validate regex compiles\n            try:\n                re.compile(link_pattern)\n            except re.error as err:\n                errors.append(f\"Invalid link_pattern regex: {err}\")\n\n    # Check version_pattern\n    if \"version_pattern\" not in source:\n        errors.append(\"Missing required field: source.version_pattern\")\n    elif not isinstance(source[\"version_pattern\"], str):\n        errors.append(\"source.version_pattern must be a string\")\n    elif not source[\"version_pattern\"].strip():\n        errors.append(\"source.version_pattern cannot be empty\")\n    else:\n        # Validate regex compiles\n        try:\n            re.compile(source[\"version_pattern\"])\n        except re.error as err:\n            errors.append(f\"Invalid version_pattern regex: {err}\")\n\n    # Validate version_format if provided\n    if \"version_format\" in source:\n        if not isinstance(source[\"version_format\"], str):\n            errors.append(\"source.version_format must be a string\")\n        elif not source[\"version_format\"].strip():\n            errors.append(\"source.version_format cannot be empty\")\n\n    return errors\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.api_github","title":"notapkgtool.discovery.api_github","text":"<p>GitHub API discovery strategy for NAPT.</p> <p>This is a VERSION-FIRST strategy that queries the GitHub API to get version and download URL WITHOUT downloading the installer. This enables fast version checks and efficient caching.</p> <p>Key Advantages:</p> <ul> <li>Fast version discovery (GitHub API call ~100ms)</li> <li>Can skip downloads entirely when version unchanged</li> <li>Direct access to latest releases via stable GitHub API</li> <li>Version extraction from Git tags (semantic versioning friendly)</li> <li>Asset pattern matching for multi-platform releases</li> <li>Optional authentication for higher rate limits</li> <li>No web scraping required</li> <li>Ideal for CI/CD with scheduled checks</li> </ul> <p>Supported Version Extraction:</p> <ul> <li>Tag-based: Extract version from release tag names<ul> <li>Supports named capture groups: (?P...) <li>Default pattern strips \"v\" prefix: v1.2.3 -&gt; 1.2.3</li> <li>Falls back to full tag if no pattern match</li> <p>Use Cases:</p> <ul> <li>Open-source projects (Git, VS Code, Node.js, etc.)</li> <li>Projects with GitHub releases (Firefox, Chrome alternatives)</li> <li>Vendors who publish installers as release assets</li> <li>Projects with semantic versioned tags</li> <li>CI/CD pipelines with frequent version checks</li> </ul> Recipe Configuration <pre><code>source:\n    strategy: api_github\n    repo: \"git-for-windows/git\"                    # Required: owner/repo\n    asset_pattern: \"Git-.*-64-bit\\.exe$\"          # Required: regex for asset\n    version_pattern: \"v?([0-9.]+)\"                 # Optional: version extraction\n    prerelease: false                              # Optional: include prereleases\n    token: \"${GITHUB_TOKEN}\"                       # Optional: auth token\n</code></pre> <p>Configuration Fields:</p> <ul> <li>repo (str, required): GitHub repository in \"owner/name\" format     (e.g., \"git-for-windows/git\")</li> <li>asset_pattern (str, required): Regular expression to match asset     filename. If multiple assets match, the first match is used. Example:     \".*-x64.msi$\" matches assets ending with \"-x64.msi\"</li> <li>version_pattern (str, optional): Regular expression to extract version     from the release tag name. Use a named capture group (?P...) or     the entire match. Default: \"v?([0-9.]+)\" strips optional \"v\" prefix.     Example: \"release-([0-9.]+)\" for tags like \"release-1.2.3\".<ul> <li>prerelease (bool, optional): If True, include pre-release versions. If False   (default), only stable releases are considered. Uses GitHub's prerelease flag.</li> <li>token (str, optional): GitHub personal access token for authentication.   Increases rate limit from 60 to 5000 requests per hour. Can use environment   variable substitution: \"${GITHUB_TOKEN}\". No special permissions needed for   public repositories.</li> </ul> <p>Error Handling:</p> <ul> <li>ValueError: Missing or invalid configuration fields</li> <li>RuntimeError: API failures, no releases, no matching assets</li> <li>Errors are chained with 'from err' for better debugging</li> </ul> <p>Rate Limits:</p> <ul> <li>Unauthenticated: 60 requests/hour per IP</li> <li>Authenticated: 5000 requests/hour per token</li> <li>Tip: Use a token for production use or frequent checks</li> </ul> Example <p>In a recipe YAML:     <pre><code>apps:\n  - name: \"Git for Windows\"\n    id: \"git\"\n    source:\n      strategy: api_github\n      repo: \"git-for-windows/git\"\n      asset_pattern: \"Git-.*-64-bit\\.exe$\"\n</code></pre></p> <p>From Python (version-first approach):     <pre><code>from notapkgtool.discovery.api_github import ApiGithubStrategy\nfrom notapkgtool.io import download_file\n\nstrategy = ApiGithubStrategy()\napp_config = {\n    \"source\": {\n        \"repo\": \"git-for-windows/git\",\n        \"asset_pattern\": \".*-64-bit\\.exe$\",\n    }\n}\n\n# Get version WITHOUT downloading\nversion_info = strategy.get_version_info(app_config)\nprint(f\"Latest version: {version_info.version}\")\n\n# Download only if needed\nif need_to_download:\n    file_path, sha256, headers = download_file(\n        version_info.download_url, Path(\"./downloads\")\n    )\n    print(f\"Downloaded to {file_path}\")\n</code></pre></p> <p>From Python (using core orchestration):     <pre><code>from pathlib import Path\nfrom notapkgtool.core import discover_recipe\n\n# Automatically uses version-first optimization\nresult = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\nprint(f\"Version {result.version} at {result.file_path}\")\n</code></pre></p> Note <p>Version discovery via API only (no download required). Core orchestration automatically skips download if version unchanged. The GitHub API is stable and well-documented. Releases are fetched in order (latest first). Asset matching is case-sensitive by default (use (?i) for case-insensitive). Consider url_download if you need a direct download URL instead.</p>"},{"location":"api/discovery/#notapkgtool.discovery.api_github.ApiGithubStrategy","title":"ApiGithubStrategy","text":"<p>Discovery strategy for GitHub releases.</p> Configuration example <p>source:   strategy: api_github   repo: \"owner/repository\"   asset_pattern: \".*.msi$\"   version_pattern: \"v?([0-9.]+)\"   prerelease: false   token: \"${GITHUB_TOKEN}\"</p> Source code in <code>notapkgtool/discovery/api_github.py</code> <pre><code>class ApiGithubStrategy:\n    \"\"\"Discovery strategy for GitHub releases.\n\n    Configuration example:\n        source:\n          strategy: api_github\n          repo: \"owner/repository\"\n          asset_pattern: \".*\\\\.msi$\"\n          version_pattern: \"v?([0-9.]+)\"\n          prerelease: false\n          token: \"${GITHUB_TOKEN}\"\n    \"\"\"\n\n    def get_version_info(\n        self,\n        app_config: dict[str, Any],\n    ) -&gt; VersionInfo:\n        \"\"\"Fetch latest release from GitHub API without downloading\n        (version-first path).\n\n        This method queries the GitHub API for the latest release and extracts\n        the version from the tag name and the download URL from matching assets.\n        If the version matches cached state, the download can be skipped entirely.\n\n        Args:\n            app_config: App configuration containing source.repo and\n                optional fields.\n\n        Returns:\n            Version info with version string, download URL, and\n                source name.\n\n        Raises:\n            ValueError: If required config fields are missing, invalid, or if\n                no matching assets are found.\n            RuntimeError: If API call fails or release has no assets.\n\n        Example:\n            Get version from GitHub releases:\n                ```python\n                strategy = ApiGithubStrategy()\n                config = {\n                    \"source\": {\n                        \"repo\": \"owner/repo\",\n                        \"asset_pattern\": \".*\\\\.msi$\"\n                    }\n                }\n                version_info = strategy.get_version_info(config)\n                # version_info.version returns: '1.0.0'\n                ```\n\n        \"\"\"\n        from notapkgtool.logging import get_global_logger\n\n        logger = get_global_logger()\n        # Validate configuration\n        source = app_config.get(\"source\", {})\n        repo = source.get(\"repo\")\n        if not repo:\n            raise ConfigError(\"api_github strategy requires 'source.repo' in config\")\n\n        # Validate repo format\n        if \"/\" not in repo or repo.count(\"/\") != 1:\n            raise ConfigError(\n                f\"Invalid repo format: {repo!r}. Expected 'owner/repository'\"\n            )\n\n        # Optional configuration\n        asset_pattern = source.get(\"asset_pattern\")\n        if not asset_pattern:\n            raise ConfigError(\n                \"api_github strategy requires 'source.asset_pattern' in config\"\n            )\n\n        version_pattern = source.get(\"version_pattern\", r\"v?([0-9.]+)\")\n        prerelease = source.get(\"prerelease\", False)\n        token = source.get(\"token\")\n\n        # Expand environment variables in token (e.g., ${GITHUB_TOKEN})\n        if token:\n            if token.startswith(\"${\") and token.endswith(\"}\"):\n                env_var = token[2:-1]\n                token = os.environ.get(env_var)\n                if not token:\n                    logger.verbose(\n                        \"DISCOVERY\",\n                        f\"Warning: Environment variable {env_var} not set\",\n                    )\n\n        logger.verbose(\"DISCOVERY\", \"Strategy: api_github (version-first)\")\n        logger.verbose(\"DISCOVERY\", f\"Repository: {repo}\")\n        logger.verbose(\"DISCOVERY\", f\"Version pattern: {version_pattern}\")\n        if asset_pattern:\n            logger.verbose(\"DISCOVERY\", f\"Asset pattern: {asset_pattern}\")\n        if prerelease:\n            logger.verbose(\"DISCOVERY\", \"Including pre-releases\")\n\n        # Fetch latest release from GitHub API\n        api_url = f\"https://api.github.com/repos/{repo}/releases/latest\"\n        headers = {\n            \"Accept\": \"application/vnd.github+json\",\n            \"X-GitHub-Api-Version\": \"2022-11-28\",\n        }\n\n        # Add authentication if token provided\n        if token:\n            headers[\"Authorization\"] = f\"token {token}\"\n            logger.verbose(\"DISCOVERY\", \"Using authenticated API request\")\n\n        logger.verbose(\"DISCOVERY\", f\"Fetching release from: {api_url}\")\n\n        try:\n            response = requests.get(api_url, headers=headers, timeout=30)\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as err:\n            if response.status_code == 404:\n                raise NetworkError(\n                    f\"Repository {repo!r} not found or has no releases\"\n                ) from err\n            elif response.status_code == 403:\n                raise NetworkError(\n                    f\"GitHub API rate limit exceeded. Consider using a token. \"\n                    f\"Status: {response.status_code}\"\n                ) from err\n            else:\n                raise NetworkError(\n                    f\"GitHub API request failed: {response.status_code} \"\n                    f\"{response.reason}\"\n                ) from err\n        except requests.exceptions.RequestException as err:\n            raise NetworkError(f\"Failed to fetch GitHub release: {err}\") from err\n\n        release_data = response.json()\n\n        # Check if this is a prerelease and we don't want those\n        if release_data.get(\"prerelease\", False) and not prerelease:\n            raise NetworkError(\n                f\"Latest release is a pre-release and prerelease=false. \"\n                f\"Tag: {release_data.get('tag_name')}\"\n            )\n\n        # Extract version from tag name\n        tag_name = release_data.get(\"tag_name\", \"\")\n        if not tag_name:\n            raise NetworkError(\"Release has no tag_name field\")\n\n        logger.verbose(\"DISCOVERY\", f\"Release tag: {tag_name}\")\n\n        try:\n            pattern = re.compile(version_pattern)\n            match = pattern.search(tag_name)\n            if not match:\n                raise ConfigError(\n                    f\"Version pattern {version_pattern!r} did not match \"\n                    f\"tag {tag_name!r}\"\n                )\n\n            # Try to get named capture group 'version' first, else use group 1,\n            # else full match\n            if \"version\" in pattern.groupindex:\n                version_str = match.group(\"version\")\n            elif pattern.groups &gt; 0:\n                version_str = match.group(1)\n            else:\n                version_str = match.group(0)\n\n        except re.error as err:\n            raise ConfigError(\n                f\"Invalid version_pattern regex: {version_pattern!r}\"\n            ) from err\n        except (ValueError, IndexError) as err:\n            raise ConfigError(\n                f\"Failed to extract version from tag {tag_name!r} \"\n                f\"using pattern {version_pattern!r}: {err}\"\n            ) from err\n\n        logger.verbose(\"DISCOVERY\", f\"Extracted version: {version_str}\")\n\n        # Find matching asset\n        assets = release_data.get(\"assets\", [])\n        if not assets:\n            raise NetworkError(\n                f\"Release {tag_name} has no assets. \"\n                f\"Check if assets were uploaded to the release.\"\n            )\n\n        logger.verbose(\"DISCOVERY\", f\"Release has {len(assets)} asset(s)\")\n\n        # Match asset by pattern\n        matched_asset = None\n        try:\n            pattern = re.compile(asset_pattern)\n        except re.error as err:\n            raise ConfigError(\n                f\"Invalid asset_pattern regex: {asset_pattern!r}\"\n            ) from err\n\n        for asset in assets:\n            asset_name = asset.get(\"name\", \"\")\n            if pattern.search(asset_name):\n                matched_asset = asset\n                logger.verbose(\"DISCOVERY\", f\"Matched asset: {asset_name}\")\n                break\n\n        if not matched_asset:\n            available = [a.get(\"name\", \"(unnamed)\") for a in assets]\n            raise ConfigError(\n                f\"No assets matched pattern {asset_pattern!r}. \"\n                f\"Available assets: {', '.join(available)}\"\n            )\n\n        # Get download URL\n        download_url = matched_asset.get(\"browser_download_url\")\n        if not download_url:\n            raise NetworkError(f\"Asset {matched_asset.get('name')} has no download URL\")\n\n        logger.verbose(\"DISCOVERY\", f\"Download URL: {download_url}\")\n\n        return VersionInfo(\n            version=version_str,\n            download_url=download_url,\n            source=\"api_github\",\n        )\n\n    def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n        \"\"\"Validate api_github strategy configuration.\n\n        Checks for required fields and correct types without making network calls.\n\n        Args:\n            app_config: The app configuration from the recipe.\n\n        Returns:\n            List of error messages (empty if valid).\n\n        \"\"\"\n        errors = []\n        source = app_config.get(\"source\", {})\n\n        # Check required fields\n        if \"repo\" not in source:\n            errors.append(\"Missing required field: source.repo\")\n        elif not isinstance(source[\"repo\"], str):\n            errors.append(\"source.repo must be a string\")\n        elif not source[\"repo\"].strip():\n            errors.append(\"source.repo cannot be empty\")\n        else:\n            # Validate repo format\n            repo = source[\"repo\"]\n            if repo.count(\"/\") != 1:\n                errors.append(\n                    \"source.repo must be in format 'owner/repo' (e.g., 'git/git')\"\n                )\n\n        if \"asset_pattern\" not in source:\n            errors.append(\"Missing required field: source.asset_pattern\")\n        elif not isinstance(source[\"asset_pattern\"], str):\n            errors.append(\"source.asset_pattern must be a string\")\n        elif not source[\"asset_pattern\"].strip():\n            errors.append(\"source.asset_pattern cannot be empty\")\n        else:\n            # Validate regex pattern syntax\n            pattern = source[\"asset_pattern\"]\n            import re\n\n            try:\n                re.compile(pattern)\n            except re.error as err:\n                errors.append(f\"Invalid asset_pattern regex: {err}\")\n\n        # Optional fields validation\n        if \"version_pattern\" in source:\n            if not isinstance(source[\"version_pattern\"], str):\n                errors.append(\"source.version_pattern must be a string\")\n            else:\n                pattern = source[\"version_pattern\"]\n                import re\n\n                try:\n                    re.compile(pattern)\n                except re.error as err:\n                    errors.append(f\"Invalid version_pattern regex: {err}\")\n\n        return errors\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.api_github.ApiGithubStrategy.get_version_info","title":"get_version_info","text":"<pre><code>get_version_info(app_config: dict[str, Any]) -&gt; VersionInfo\n</code></pre> <p>Fetch latest release from GitHub API without downloading (version-first path).</p> <p>This method queries the GitHub API for the latest release and extracts the version from the tag name and the download URL from matching assets. If the version matches cached state, the download can be skipped entirely.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>App configuration containing source.repo and optional fields.</p> required <p>Returns:</p> Type Description <code>VersionInfo</code> <p>Version info with version string, download URL, and source name.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If required config fields are missing, invalid, or if no matching assets are found.</p> <code>RuntimeError</code> <p>If API call fails or release has no assets.</p> Example <p>Get version from GitHub releases:     <pre><code>strategy = ApiGithubStrategy()\nconfig = {\n    \"source\": {\n        \"repo\": \"owner/repo\",\n        \"asset_pattern\": \".*\\.msi$\"\n    }\n}\nversion_info = strategy.get_version_info(config)\n# version_info.version returns: '1.0.0'\n</code></pre></p> Source code in <code>notapkgtool/discovery/api_github.py</code> <pre><code>def get_version_info(\n    self,\n    app_config: dict[str, Any],\n) -&gt; VersionInfo:\n    \"\"\"Fetch latest release from GitHub API without downloading\n    (version-first path).\n\n    This method queries the GitHub API for the latest release and extracts\n    the version from the tag name and the download URL from matching assets.\n    If the version matches cached state, the download can be skipped entirely.\n\n    Args:\n        app_config: App configuration containing source.repo and\n            optional fields.\n\n    Returns:\n        Version info with version string, download URL, and\n            source name.\n\n    Raises:\n        ValueError: If required config fields are missing, invalid, or if\n            no matching assets are found.\n        RuntimeError: If API call fails or release has no assets.\n\n    Example:\n        Get version from GitHub releases:\n            ```python\n            strategy = ApiGithubStrategy()\n            config = {\n                \"source\": {\n                    \"repo\": \"owner/repo\",\n                    \"asset_pattern\": \".*\\\\.msi$\"\n                }\n            }\n            version_info = strategy.get_version_info(config)\n            # version_info.version returns: '1.0.0'\n            ```\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    # Validate configuration\n    source = app_config.get(\"source\", {})\n    repo = source.get(\"repo\")\n    if not repo:\n        raise ConfigError(\"api_github strategy requires 'source.repo' in config\")\n\n    # Validate repo format\n    if \"/\" not in repo or repo.count(\"/\") != 1:\n        raise ConfigError(\n            f\"Invalid repo format: {repo!r}. Expected 'owner/repository'\"\n        )\n\n    # Optional configuration\n    asset_pattern = source.get(\"asset_pattern\")\n    if not asset_pattern:\n        raise ConfigError(\n            \"api_github strategy requires 'source.asset_pattern' in config\"\n        )\n\n    version_pattern = source.get(\"version_pattern\", r\"v?([0-9.]+)\")\n    prerelease = source.get(\"prerelease\", False)\n    token = source.get(\"token\")\n\n    # Expand environment variables in token (e.g., ${GITHUB_TOKEN})\n    if token:\n        if token.startswith(\"${\") and token.endswith(\"}\"):\n            env_var = token[2:-1]\n            token = os.environ.get(env_var)\n            if not token:\n                logger.verbose(\n                    \"DISCOVERY\",\n                    f\"Warning: Environment variable {env_var} not set\",\n                )\n\n    logger.verbose(\"DISCOVERY\", \"Strategy: api_github (version-first)\")\n    logger.verbose(\"DISCOVERY\", f\"Repository: {repo}\")\n    logger.verbose(\"DISCOVERY\", f\"Version pattern: {version_pattern}\")\n    if asset_pattern:\n        logger.verbose(\"DISCOVERY\", f\"Asset pattern: {asset_pattern}\")\n    if prerelease:\n        logger.verbose(\"DISCOVERY\", \"Including pre-releases\")\n\n    # Fetch latest release from GitHub API\n    api_url = f\"https://api.github.com/repos/{repo}/releases/latest\"\n    headers = {\n        \"Accept\": \"application/vnd.github+json\",\n        \"X-GitHub-Api-Version\": \"2022-11-28\",\n    }\n\n    # Add authentication if token provided\n    if token:\n        headers[\"Authorization\"] = f\"token {token}\"\n        logger.verbose(\"DISCOVERY\", \"Using authenticated API request\")\n\n    logger.verbose(\"DISCOVERY\", f\"Fetching release from: {api_url}\")\n\n    try:\n        response = requests.get(api_url, headers=headers, timeout=30)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as err:\n        if response.status_code == 404:\n            raise NetworkError(\n                f\"Repository {repo!r} not found or has no releases\"\n            ) from err\n        elif response.status_code == 403:\n            raise NetworkError(\n                f\"GitHub API rate limit exceeded. Consider using a token. \"\n                f\"Status: {response.status_code}\"\n            ) from err\n        else:\n            raise NetworkError(\n                f\"GitHub API request failed: {response.status_code} \"\n                f\"{response.reason}\"\n            ) from err\n    except requests.exceptions.RequestException as err:\n        raise NetworkError(f\"Failed to fetch GitHub release: {err}\") from err\n\n    release_data = response.json()\n\n    # Check if this is a prerelease and we don't want those\n    if release_data.get(\"prerelease\", False) and not prerelease:\n        raise NetworkError(\n            f\"Latest release is a pre-release and prerelease=false. \"\n            f\"Tag: {release_data.get('tag_name')}\"\n        )\n\n    # Extract version from tag name\n    tag_name = release_data.get(\"tag_name\", \"\")\n    if not tag_name:\n        raise NetworkError(\"Release has no tag_name field\")\n\n    logger.verbose(\"DISCOVERY\", f\"Release tag: {tag_name}\")\n\n    try:\n        pattern = re.compile(version_pattern)\n        match = pattern.search(tag_name)\n        if not match:\n            raise ConfigError(\n                f\"Version pattern {version_pattern!r} did not match \"\n                f\"tag {tag_name!r}\"\n            )\n\n        # Try to get named capture group 'version' first, else use group 1,\n        # else full match\n        if \"version\" in pattern.groupindex:\n            version_str = match.group(\"version\")\n        elif pattern.groups &gt; 0:\n            version_str = match.group(1)\n        else:\n            version_str = match.group(0)\n\n    except re.error as err:\n        raise ConfigError(\n            f\"Invalid version_pattern regex: {version_pattern!r}\"\n        ) from err\n    except (ValueError, IndexError) as err:\n        raise ConfigError(\n            f\"Failed to extract version from tag {tag_name!r} \"\n            f\"using pattern {version_pattern!r}: {err}\"\n        ) from err\n\n    logger.verbose(\"DISCOVERY\", f\"Extracted version: {version_str}\")\n\n    # Find matching asset\n    assets = release_data.get(\"assets\", [])\n    if not assets:\n        raise NetworkError(\n            f\"Release {tag_name} has no assets. \"\n            f\"Check if assets were uploaded to the release.\"\n        )\n\n    logger.verbose(\"DISCOVERY\", f\"Release has {len(assets)} asset(s)\")\n\n    # Match asset by pattern\n    matched_asset = None\n    try:\n        pattern = re.compile(asset_pattern)\n    except re.error as err:\n        raise ConfigError(\n            f\"Invalid asset_pattern regex: {asset_pattern!r}\"\n        ) from err\n\n    for asset in assets:\n        asset_name = asset.get(\"name\", \"\")\n        if pattern.search(asset_name):\n            matched_asset = asset\n            logger.verbose(\"DISCOVERY\", f\"Matched asset: {asset_name}\")\n            break\n\n    if not matched_asset:\n        available = [a.get(\"name\", \"(unnamed)\") for a in assets]\n        raise ConfigError(\n            f\"No assets matched pattern {asset_pattern!r}. \"\n            f\"Available assets: {', '.join(available)}\"\n        )\n\n    # Get download URL\n    download_url = matched_asset.get(\"browser_download_url\")\n    if not download_url:\n        raise NetworkError(f\"Asset {matched_asset.get('name')} has no download URL\")\n\n    logger.verbose(\"DISCOVERY\", f\"Download URL: {download_url}\")\n\n    return VersionInfo(\n        version=version_str,\n        download_url=download_url,\n        source=\"api_github\",\n    )\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.api_github.ApiGithubStrategy.validate_config","title":"validate_config","text":"<pre><code>validate_config(app_config: dict[str, Any]) -&gt; list[str]\n</code></pre> <p>Validate api_github strategy configuration.</p> <p>Checks for required fields and correct types without making network calls.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>The app configuration from the recipe.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of error messages (empty if valid).</p> Source code in <code>notapkgtool/discovery/api_github.py</code> <pre><code>def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n    \"\"\"Validate api_github strategy configuration.\n\n    Checks for required fields and correct types without making network calls.\n\n    Args:\n        app_config: The app configuration from the recipe.\n\n    Returns:\n        List of error messages (empty if valid).\n\n    \"\"\"\n    errors = []\n    source = app_config.get(\"source\", {})\n\n    # Check required fields\n    if \"repo\" not in source:\n        errors.append(\"Missing required field: source.repo\")\n    elif not isinstance(source[\"repo\"], str):\n        errors.append(\"source.repo must be a string\")\n    elif not source[\"repo\"].strip():\n        errors.append(\"source.repo cannot be empty\")\n    else:\n        # Validate repo format\n        repo = source[\"repo\"]\n        if repo.count(\"/\") != 1:\n            errors.append(\n                \"source.repo must be in format 'owner/repo' (e.g., 'git/git')\"\n            )\n\n    if \"asset_pattern\" not in source:\n        errors.append(\"Missing required field: source.asset_pattern\")\n    elif not isinstance(source[\"asset_pattern\"], str):\n        errors.append(\"source.asset_pattern must be a string\")\n    elif not source[\"asset_pattern\"].strip():\n        errors.append(\"source.asset_pattern cannot be empty\")\n    else:\n        # Validate regex pattern syntax\n        pattern = source[\"asset_pattern\"]\n        import re\n\n        try:\n            re.compile(pattern)\n        except re.error as err:\n            errors.append(f\"Invalid asset_pattern regex: {err}\")\n\n    # Optional fields validation\n    if \"version_pattern\" in source:\n        if not isinstance(source[\"version_pattern\"], str):\n            errors.append(\"source.version_pattern must be a string\")\n        else:\n            pattern = source[\"version_pattern\"]\n            import re\n\n            try:\n                re.compile(pattern)\n            except re.error as err:\n                errors.append(f\"Invalid version_pattern regex: {err}\")\n\n    return errors\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.api_json","title":"notapkgtool.discovery.api_json","text":"<p>JSON API discovery strategy for NAPT.</p> <p>This is a VERSION-FIRST strategy that queries JSON API endpoints to get version and download URL WITHOUT downloading the installer. This enables fast version checks and efficient caching.</p> <p>Key Advantages:</p> <ul> <li>Fast version discovery (API call ~100ms)</li> <li>Can skip downloads entirely when version unchanged</li> <li>Direct API access for version and download URL</li> <li>Support for complex JSON structures with JSONPath</li> <li>Custom headers for authentication</li> <li>Support for GET and POST requests</li> <li>No file parsing required</li> <li>Ideal for CI/CD with scheduled checks</li> </ul> <p>Supported Features:</p> <ul> <li>JSONPath navigation for nested structures</li> <li>Array indexing and filtering</li> <li>Custom HTTP headers (Authorization, etc.)</li> <li>POST requests with JSON body</li> <li>Environment variable expansion in values</li> </ul> <p>Use Cases:</p> <ul> <li>Vendors with JSON APIs (Microsoft, Mozilla, etc.)</li> <li>Cloud services with version endpoints</li> <li>CDNs that provide metadata APIs</li> <li>Applications with update check APIs</li> <li>APIs requiring authentication or custom headers</li> <li>CI/CD pipelines with frequent version checks</li> </ul> Recipe Configuration <pre><code>source:\n    strategy: api_json\n    api_url: \"https://vendor.com/api/latest\"\n    version_path: \"version\"                      # JSONPath to version\n    download_url_path: \"download_url\"            # JSONPath to URL\n    method: \"GET\"                                # Optional: GET or POST\n    headers:                                     # Optional: custom headers\n    Authorization: \"Bearer ${API_TOKEN}\"\n    Accept: \"application/json\"\n    body:                                        # Optional: POST body\n    platform: \"windows\"\n    arch: \"x64\"\n    timeout: 30                                  # Optional: timeout in seconds\n</code></pre> <p>Configuration Fields:</p> <ul> <li>api_url (str, required): API endpoint URL that returns JSON with version     and download information</li> <li>version_path (str, required): JSONPath expression to extract version from     the API response. Examples: \"version\", \"release.version\", \"data.version\"</li> <li>download_url_path (str, required): JSONPath expression to extract     download URL from the API response. Examples: \"download_url\", \"assets.url\",     \"platforms.windows.x64\"</li> <li>method (str, optional): HTTP method to use. Either \"GET\" or \"POST\".     Default is \"GET\"</li> <li>headers (dict, optional): Custom HTTP headers to send with the request.     Useful for authentication or setting Accept headers. Values support     environment variable expansion. Example: {\"Authorization\": \"Bearer ${API_TOKEN}\"}</li> <li>body (dict, optional): Request body for POST requests. Sent as JSON.     Only used when method=\"POST\". Example: {\"platform\": \"windows\", \"arch\": \"x64\"}<ul> <li>timeout (int, optional): Request timeout in seconds. Default is 30.</li> </ul> </li> </ul> <p>JSONPath Syntax:</p> <ul> <li>Simple paths: \"version\", \"release.version\"</li> <li>Array indexing: \"data.version\", \"releases.version\"</li> <li>Nested paths: \"data.latest.download.url\", \"response.assets.browser_download_url\"</li> </ul> <p>Error Handling:</p> <ul> <li>ValueError: Missing or invalid configuration, invalid JSONPath, path not found</li> <li>RuntimeError: API failures, invalid JSON response</li> <li>Errors are chained with 'from err' for better debugging</li> </ul> Example <p>In a recipe YAML (simple API):     <pre><code>apps:\n  - name: \"My App\"\n    id: \"my-app\"\n    source:\n      strategy: api_json\n      api_url: \"https://api.vendor.com/latest\"\n      version_path: \"version\"\n      download_url_path: \"download_url\"\n</code></pre></p> <p>In a recipe YAML (nested structure):     <pre><code>apps:\n  - name: \"My App\"\n    id: \"my-app\"\n    source:\n      strategy: api_json\n      api_url: \"https://api.vendor.com/releases\"\n      version_path: \"stable.version\"\n      download_url_path: \"stable.platforms.windows.x64\"\n      headers:\n        Authorization: \"Bearer ${API_TOKEN}\"\n</code></pre></p> <p>From Python (version-first approach):     <pre><code>from notapkgtool.discovery.api_json import ApiJsonStrategy\nfrom notapkgtool.io import download_file\n\nstrategy = ApiJsonStrategy()\napp_config = {\n    \"source\": {\n        \"api_url\": \"https://api.vendor.com/latest\",\n        \"version_path\": \"version\",\n        \"download_url_path\": \"download_url\",\n    }\n}\n\n# Get version WITHOUT downloading\nversion_info = strategy.get_version_info(app_config)\nprint(f\"Latest version: {version_info.version}\")\n\n# Download only if needed\nif need_to_download:\n    file_path, sha256, headers = download_file(\n        version_info.download_url, Path(\"./downloads\")\n    )\n    print(f\"Downloaded to {file_path}\")\n</code></pre></p> <p>From Python (using core orchestration):     <pre><code>from pathlib import Path\nfrom notapkgtool.core import discover_recipe\n\n# Automatically uses version-first optimization\nresult = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\nprint(f\"Version {result.version} at {result.file_path}\")\n</code></pre></p> Note <ul> <li>Version discovery via API only (no download required)</li> <li>Core orchestration automatically skips download if version unchanged</li> <li>JSONPath uses jsonpath-ng library for robust parsing</li> <li>Environment variable expansion works in headers and other string values</li> <li>POST body is sent as JSON (Content-Type: application/json)</li> <li>Timeout defaults to 30 seconds to prevent hanging on slow APIs</li> </ul>"},{"location":"api/discovery/#notapkgtool.discovery.api_json.ApiJsonStrategy","title":"ApiJsonStrategy","text":"<p>Discovery strategy for JSON API endpoints.</p> Configuration example <p>source:   strategy: api_json   api_url: \"https://api.vendor.com/latest\"   version_path: \"version\"   download_url_path: \"download_url\"   method: \"GET\"   headers:     Authorization: \"Bearer ${API_TOKEN}\"</p> Source code in <code>notapkgtool/discovery/api_json.py</code> <pre><code>class ApiJsonStrategy:\n    \"\"\"Discovery strategy for JSON API endpoints.\n\n    Configuration example:\n        source:\n          strategy: api_json\n          api_url: \"https://api.vendor.com/latest\"\n          version_path: \"version\"\n          download_url_path: \"download_url\"\n          method: \"GET\"\n          headers:\n            Authorization: \"Bearer ${API_TOKEN}\"\n    \"\"\"\n\n    def get_version_info(\n        self,\n        app_config: dict[str, Any],\n    ) -&gt; VersionInfo:\n        \"\"\"Query JSON API for version and download URL without downloading\n        (version-first path).\n\n        This method calls a JSON API, extracts version and download URL using\n        JSONPath expressions. If the version matches cached state, the download\n        can be skipped entirely.\n\n        Args:\n            app_config: App configuration containing source.api_url,\n                source.version_path, and source.download_url_path.\n\n        Returns:\n            Version info with version string, download URL, and\n                source name.\n\n        Raises:\n            ValueError: If required config fields are missing, invalid, or if\n                JSONPath expressions don't match anything in the response.\n            RuntimeError: If API call fails (chained with 'from err').\n\n        Example:\n            Get version info from JSON API:\n                ```python\n                strategy = ApiJsonStrategy()\n                config = {\n                    \"source\": {\n                        \"api_url\": \"https://api.vendor.com/latest\",\n                        \"version_path\": \"version\",\n                        \"download_url_path\": \"download_url\"\n                    }\n                }\n                version_info = strategy.get_version_info(config)\n                # version_info.version returns: '1.0.0'\n                ```\n\n        \"\"\"\n        from notapkgtool.logging import get_global_logger\n\n        logger = get_global_logger()\n        # Validate configuration\n        source = app_config.get(\"source\", {})\n        api_url = source.get(\"api_url\")\n        if not api_url:\n            raise ConfigError(\"api_json strategy requires 'source.api_url' in config\")\n\n        version_path = source.get(\"version_path\")\n        if not version_path:\n            raise ConfigError(\n                \"api_json strategy requires 'source.version_path' in config\"\n            )\n\n        download_url_path = source.get(\"download_url_path\")\n        if not download_url_path:\n            raise ConfigError(\n                \"api_json strategy requires 'source.download_url_path' in config\"\n            )\n\n        # Optional configuration\n        method = source.get(\"method\", \"GET\").upper()\n        if method not in (\"GET\", \"POST\"):\n            raise ConfigError(f\"Invalid method: {method!r}. Must be 'GET' or 'POST'\")\n\n        headers = source.get(\"headers\", {})\n        body = source.get(\"body\", {})\n        timeout = source.get(\"timeout\", 30)\n\n        logger.verbose(\"DISCOVERY\", \"Strategy: api_json (version-first)\")\n        logger.verbose(\"DISCOVERY\", f\"API URL: {api_url}\")\n        logger.verbose(\"DISCOVERY\", f\"Method: {method}\")\n        logger.verbose(\"DISCOVERY\", f\"Version path: {version_path}\")\n        logger.verbose(\"DISCOVERY\", f\"Download URL path: {download_url_path}\")\n\n        # Expand environment variables in headers\n        expanded_headers = {}\n        for key, value in headers.items():\n            if (\n                isinstance(value, str)\n                and value.startswith(\"${\")\n                and value.endswith(\"}\")\n            ):\n                env_var = value[2:-1]\n                env_value = os.environ.get(env_var)\n                if not env_value:\n                    logger.verbose(\n                        \"DISCOVERY\",\n                        f\"Warning: Environment variable {env_var} not set\",\n                    )\n                else:\n                    expanded_headers[key] = env_value\n            else:\n                expanded_headers[key] = value\n\n        # Make API request\n        logger.verbose(\"DISCOVERY\", f\"Calling API: {method} {api_url}\")\n        try:\n            if method == \"GET\":\n                response = requests.get(\n                    api_url, headers=expanded_headers, timeout=timeout\n                )\n            else:  # POST\n                response = requests.post(\n                    api_url,\n                    headers=expanded_headers,\n                    json=body,\n                    timeout=timeout,\n                )\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as err:\n            raise NetworkError(\n                f\"API request failed: {response.status_code} {response.reason}\"\n            ) from err\n        except requests.exceptions.RequestException as err:\n            raise NetworkError(f\"Failed to call API: {err}\") from err\n\n        logger.verbose(\"DISCOVERY\", f\"API response: {response.status_code} OK\")\n\n        # Parse JSON response\n        try:\n            json_data = response.json()\n        except json.JSONDecodeError as err:\n            raise NetworkError(\n                f\"Invalid JSON response from API. Response: {response.text[:200]}\"\n            ) from err\n\n        logger.debug(\"DISCOVERY\", f\"JSON response: {json.dumps(json_data, indent=2)}\")\n\n        # Extract version using JSONPath\n        logger.verbose(\"DISCOVERY\", f\"Extracting version from path: {version_path}\")\n        try:\n            version_expr = jsonpath_parse(version_path)\n            version_matches = version_expr.find(json_data)\n\n            if not version_matches:\n                raise ConfigError(\n                    f\"Version path {version_path!r} did not match anything \"\n                    f\"in API response\"\n                )\n\n            version_str = str(version_matches[0].value)\n        except Exception as err:\n            if isinstance(err, ConfigError):\n                raise\n            raise ConfigError(\n                f\"Failed to extract version using path {version_path!r}: {err}\"\n            ) from err\n\n        logger.verbose(\"DISCOVERY\", f\"Extracted version: {version_str}\")\n\n        # Extract download URL using JSONPath\n        logger.verbose(\n            \"DISCOVERY\", f\"Extracting download URL from path: {download_url_path}\"\n        )\n        try:\n            url_expr = jsonpath_parse(download_url_path)\n            url_matches = url_expr.find(json_data)\n\n            if not url_matches:\n                raise ConfigError(\n                    f\"Download URL path {download_url_path!r} did not match \"\n                    f\"anything in API response\"\n                )\n\n            download_url = str(url_matches[0].value)\n        except Exception as err:\n            if isinstance(err, ConfigError):\n                raise\n            raise ConfigError(\n                f\"Failed to extract download URL using path \"\n                f\"{download_url_path!r}: {err}\"\n            ) from err\n\n        logger.verbose(\"DISCOVERY\", f\"Download URL: {download_url}\")\n\n        return VersionInfo(\n            version=version_str,\n            download_url=download_url,\n            source=\"api_json\",\n        )\n\n    def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n        \"\"\"Validate api_json strategy configuration.\n\n        Checks for required fields and correct types without making network calls.\n\n        Args:\n            app_config: The app configuration from the recipe.\n\n        Returns:\n            List of error messages (empty if valid).\n\n        \"\"\"\n        errors = []\n        source = app_config.get(\"source\", {})\n\n        # Check required fields\n        if \"api_url\" not in source:\n            errors.append(\"Missing required field: source.api_url\")\n        elif not isinstance(source[\"api_url\"], str):\n            errors.append(\"source.api_url must be a string\")\n        elif not source[\"api_url\"].strip():\n            errors.append(\"source.api_url cannot be empty\")\n\n        if \"version_path\" not in source:\n            errors.append(\"Missing required field: source.version_path\")\n        elif not isinstance(source[\"version_path\"], str):\n            errors.append(\"source.version_path must be a string\")\n        elif not source[\"version_path\"].strip():\n            errors.append(\"source.version_path cannot be empty\")\n        else:\n            # Validate JSONPath syntax\n            from jsonpath_ng import parse as jsonpath_parse\n\n            try:\n                jsonpath_parse(source[\"version_path\"])\n            except Exception as err:\n                errors.append(f\"Invalid version_path JSONPath: {err}\")\n\n        if \"download_url_path\" not in source:\n            errors.append(\"Missing required field: source.download_url_path\")\n        elif not isinstance(source[\"download_url_path\"], str):\n            errors.append(\"source.download_url_path must be a string\")\n        elif not source[\"download_url_path\"].strip():\n            errors.append(\"source.download_url_path cannot be empty\")\n        else:\n            # Validate JSONPath syntax\n            from jsonpath_ng import parse as jsonpath_parse\n\n            try:\n                jsonpath_parse(source[\"download_url_path\"])\n            except Exception as err:\n                errors.append(f\"Invalid download_url_path JSONPath: {err}\")\n\n        # Optional fields validation\n        if \"method\" in source:\n            method = source[\"method\"]\n            if not isinstance(method, str):\n                errors.append(\"source.method must be a string\")\n            elif method.upper() not in [\"GET\", \"POST\"]:\n                errors.append(\"source.method must be 'GET' or 'POST'\")\n\n        if \"headers\" in source and not isinstance(source[\"headers\"], dict):\n            errors.append(\"source.headers must be a dictionary\")\n\n        if \"body\" in source and not isinstance(source[\"body\"], dict):\n            errors.append(\"source.body must be a dictionary\")\n\n        return errors\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.api_json.ApiJsonStrategy.get_version_info","title":"get_version_info","text":"<pre><code>get_version_info(app_config: dict[str, Any]) -&gt; VersionInfo\n</code></pre> <p>Query JSON API for version and download URL without downloading (version-first path).</p> <p>This method calls a JSON API, extracts version and download URL using JSONPath expressions. If the version matches cached state, the download can be skipped entirely.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>App configuration containing source.api_url, source.version_path, and source.download_url_path.</p> required <p>Returns:</p> Type Description <code>VersionInfo</code> <p>Version info with version string, download URL, and source name.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If required config fields are missing, invalid, or if JSONPath expressions don't match anything in the response.</p> <code>RuntimeError</code> <p>If API call fails (chained with 'from err').</p> Example <p>Get version info from JSON API:     <pre><code>strategy = ApiJsonStrategy()\nconfig = {\n    \"source\": {\n        \"api_url\": \"https://api.vendor.com/latest\",\n        \"version_path\": \"version\",\n        \"download_url_path\": \"download_url\"\n    }\n}\nversion_info = strategy.get_version_info(config)\n# version_info.version returns: '1.0.0'\n</code></pre></p> Source code in <code>notapkgtool/discovery/api_json.py</code> <pre><code>def get_version_info(\n    self,\n    app_config: dict[str, Any],\n) -&gt; VersionInfo:\n    \"\"\"Query JSON API for version and download URL without downloading\n    (version-first path).\n\n    This method calls a JSON API, extracts version and download URL using\n    JSONPath expressions. If the version matches cached state, the download\n    can be skipped entirely.\n\n    Args:\n        app_config: App configuration containing source.api_url,\n            source.version_path, and source.download_url_path.\n\n    Returns:\n        Version info with version string, download URL, and\n            source name.\n\n    Raises:\n        ValueError: If required config fields are missing, invalid, or if\n            JSONPath expressions don't match anything in the response.\n        RuntimeError: If API call fails (chained with 'from err').\n\n    Example:\n        Get version info from JSON API:\n            ```python\n            strategy = ApiJsonStrategy()\n            config = {\n                \"source\": {\n                    \"api_url\": \"https://api.vendor.com/latest\",\n                    \"version_path\": \"version\",\n                    \"download_url_path\": \"download_url\"\n                }\n            }\n            version_info = strategy.get_version_info(config)\n            # version_info.version returns: '1.0.0'\n            ```\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    # Validate configuration\n    source = app_config.get(\"source\", {})\n    api_url = source.get(\"api_url\")\n    if not api_url:\n        raise ConfigError(\"api_json strategy requires 'source.api_url' in config\")\n\n    version_path = source.get(\"version_path\")\n    if not version_path:\n        raise ConfigError(\n            \"api_json strategy requires 'source.version_path' in config\"\n        )\n\n    download_url_path = source.get(\"download_url_path\")\n    if not download_url_path:\n        raise ConfigError(\n            \"api_json strategy requires 'source.download_url_path' in config\"\n        )\n\n    # Optional configuration\n    method = source.get(\"method\", \"GET\").upper()\n    if method not in (\"GET\", \"POST\"):\n        raise ConfigError(f\"Invalid method: {method!r}. Must be 'GET' or 'POST'\")\n\n    headers = source.get(\"headers\", {})\n    body = source.get(\"body\", {})\n    timeout = source.get(\"timeout\", 30)\n\n    logger.verbose(\"DISCOVERY\", \"Strategy: api_json (version-first)\")\n    logger.verbose(\"DISCOVERY\", f\"API URL: {api_url}\")\n    logger.verbose(\"DISCOVERY\", f\"Method: {method}\")\n    logger.verbose(\"DISCOVERY\", f\"Version path: {version_path}\")\n    logger.verbose(\"DISCOVERY\", f\"Download URL path: {download_url_path}\")\n\n    # Expand environment variables in headers\n    expanded_headers = {}\n    for key, value in headers.items():\n        if (\n            isinstance(value, str)\n            and value.startswith(\"${\")\n            and value.endswith(\"}\")\n        ):\n            env_var = value[2:-1]\n            env_value = os.environ.get(env_var)\n            if not env_value:\n                logger.verbose(\n                    \"DISCOVERY\",\n                    f\"Warning: Environment variable {env_var} not set\",\n                )\n            else:\n                expanded_headers[key] = env_value\n        else:\n            expanded_headers[key] = value\n\n    # Make API request\n    logger.verbose(\"DISCOVERY\", f\"Calling API: {method} {api_url}\")\n    try:\n        if method == \"GET\":\n            response = requests.get(\n                api_url, headers=expanded_headers, timeout=timeout\n            )\n        else:  # POST\n            response = requests.post(\n                api_url,\n                headers=expanded_headers,\n                json=body,\n                timeout=timeout,\n            )\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as err:\n        raise NetworkError(\n            f\"API request failed: {response.status_code} {response.reason}\"\n        ) from err\n    except requests.exceptions.RequestException as err:\n        raise NetworkError(f\"Failed to call API: {err}\") from err\n\n    logger.verbose(\"DISCOVERY\", f\"API response: {response.status_code} OK\")\n\n    # Parse JSON response\n    try:\n        json_data = response.json()\n    except json.JSONDecodeError as err:\n        raise NetworkError(\n            f\"Invalid JSON response from API. Response: {response.text[:200]}\"\n        ) from err\n\n    logger.debug(\"DISCOVERY\", f\"JSON response: {json.dumps(json_data, indent=2)}\")\n\n    # Extract version using JSONPath\n    logger.verbose(\"DISCOVERY\", f\"Extracting version from path: {version_path}\")\n    try:\n        version_expr = jsonpath_parse(version_path)\n        version_matches = version_expr.find(json_data)\n\n        if not version_matches:\n            raise ConfigError(\n                f\"Version path {version_path!r} did not match anything \"\n                f\"in API response\"\n            )\n\n        version_str = str(version_matches[0].value)\n    except Exception as err:\n        if isinstance(err, ConfigError):\n            raise\n        raise ConfigError(\n            f\"Failed to extract version using path {version_path!r}: {err}\"\n        ) from err\n\n    logger.verbose(\"DISCOVERY\", f\"Extracted version: {version_str}\")\n\n    # Extract download URL using JSONPath\n    logger.verbose(\n        \"DISCOVERY\", f\"Extracting download URL from path: {download_url_path}\"\n    )\n    try:\n        url_expr = jsonpath_parse(download_url_path)\n        url_matches = url_expr.find(json_data)\n\n        if not url_matches:\n            raise ConfigError(\n                f\"Download URL path {download_url_path!r} did not match \"\n                f\"anything in API response\"\n            )\n\n        download_url = str(url_matches[0].value)\n    except Exception as err:\n        if isinstance(err, ConfigError):\n            raise\n        raise ConfigError(\n            f\"Failed to extract download URL using path \"\n            f\"{download_url_path!r}: {err}\"\n        ) from err\n\n    logger.verbose(\"DISCOVERY\", f\"Download URL: {download_url}\")\n\n    return VersionInfo(\n        version=version_str,\n        download_url=download_url,\n        source=\"api_json\",\n    )\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.api_json.ApiJsonStrategy.validate_config","title":"validate_config","text":"<pre><code>validate_config(app_config: dict[str, Any]) -&gt; list[str]\n</code></pre> <p>Validate api_json strategy configuration.</p> <p>Checks for required fields and correct types without making network calls.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>The app configuration from the recipe.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of error messages (empty if valid).</p> Source code in <code>notapkgtool/discovery/api_json.py</code> <pre><code>def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n    \"\"\"Validate api_json strategy configuration.\n\n    Checks for required fields and correct types without making network calls.\n\n    Args:\n        app_config: The app configuration from the recipe.\n\n    Returns:\n        List of error messages (empty if valid).\n\n    \"\"\"\n    errors = []\n    source = app_config.get(\"source\", {})\n\n    # Check required fields\n    if \"api_url\" not in source:\n        errors.append(\"Missing required field: source.api_url\")\n    elif not isinstance(source[\"api_url\"], str):\n        errors.append(\"source.api_url must be a string\")\n    elif not source[\"api_url\"].strip():\n        errors.append(\"source.api_url cannot be empty\")\n\n    if \"version_path\" not in source:\n        errors.append(\"Missing required field: source.version_path\")\n    elif not isinstance(source[\"version_path\"], str):\n        errors.append(\"source.version_path must be a string\")\n    elif not source[\"version_path\"].strip():\n        errors.append(\"source.version_path cannot be empty\")\n    else:\n        # Validate JSONPath syntax\n        from jsonpath_ng import parse as jsonpath_parse\n\n        try:\n            jsonpath_parse(source[\"version_path\"])\n        except Exception as err:\n            errors.append(f\"Invalid version_path JSONPath: {err}\")\n\n    if \"download_url_path\" not in source:\n        errors.append(\"Missing required field: source.download_url_path\")\n    elif not isinstance(source[\"download_url_path\"], str):\n        errors.append(\"source.download_url_path must be a string\")\n    elif not source[\"download_url_path\"].strip():\n        errors.append(\"source.download_url_path cannot be empty\")\n    else:\n        # Validate JSONPath syntax\n        from jsonpath_ng import parse as jsonpath_parse\n\n        try:\n            jsonpath_parse(source[\"download_url_path\"])\n        except Exception as err:\n            errors.append(f\"Invalid download_url_path JSONPath: {err}\")\n\n    # Optional fields validation\n    if \"method\" in source:\n        method = source[\"method\"]\n        if not isinstance(method, str):\n            errors.append(\"source.method must be a string\")\n        elif method.upper() not in [\"GET\", \"POST\"]:\n            errors.append(\"source.method must be 'GET' or 'POST'\")\n\n    if \"headers\" in source and not isinstance(source[\"headers\"], dict):\n        errors.append(\"source.headers must be a dictionary\")\n\n    if \"body\" in source and not isinstance(source[\"body\"], dict):\n        errors.append(\"source.body must be a dictionary\")\n\n    return errors\n</code></pre>"},{"location":"api/exceptions/","title":"exceptions","text":""},{"location":"api/exceptions/#notapkgtool.exceptions","title":"notapkgtool.exceptions","text":"<p>Exception hierarchy for NAPT.</p> <p>This module defines a custom exception hierarchy that allows library users to distinguish between different types of errors. All exceptions inherit from NAPTError, allowing users to catch all NAPT errors with a single except clause if needed.</p> Example <p>Catching specific error types:     <pre><code>from notapkgtool.core import discover_recipe\nfrom notapkgtool.exceptions import ConfigError, NetworkError\n\ntry:\n    result = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\nexcept ConfigError as e:\n    print(f\"Configuration error: {e}\")\nexcept NetworkError as e:\n    print(f\"Network error: {e}\")\n</code></pre></p> <p>Catching all NAPT errors:     <pre><code>from notapkgtool.exceptions import NAPTError\n\ntry:\n    result = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\nexcept NAPTError as e:\n    print(f\"NAPT error: {e}\")\n</code></pre></p>"},{"location":"api/exceptions/#notapkgtool.exceptions.NAPTError","title":"NAPTError","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for all NAPT errors.</p> <p>All NAPT-specific exceptions inherit from this class, allowing users to catch all NAPT errors with a single except clause if needed.</p> Source code in <code>notapkgtool/exceptions.py</code> <pre><code>class NAPTError(Exception):\n    \"\"\"Base exception for all NAPT errors.\n\n    All NAPT-specific exceptions inherit from this class, allowing users\n    to catch all NAPT errors with a single except clause if needed.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/exceptions/#notapkgtool.exceptions.ConfigError","title":"ConfigError","text":"<p>               Bases: <code>NAPTError</code></p> <p>Raised for configuration-related errors.</p> <p>This exception is raised when there are problems with:</p> <ul> <li>YAML parse errors (syntax errors, invalid structure)</li> <li>Missing required configuration fields (e.g., no apps defined, missing     'source.strategy' field)</li> <li>Invalid strategy configuration (unknown strategy name, invalid strategy     parameters)</li> <li>Missing recipe files (file not found)</li> <li>Recipe validation failures (invalid recipe structure, missing required     app fields)</li> </ul> Example <p>Catching configuration errors:     <pre><code>from notapkgtool.exceptions import ConfigError\n\ntry:\n    config = load_effective_config(Path(\"invalid.yaml\"))\nexcept ConfigError as e:\n    print(f\"Config error: {e}\")\n</code></pre></p> Source code in <code>notapkgtool/exceptions.py</code> <pre><code>class ConfigError(NAPTError):\n    \"\"\"Raised for configuration-related errors.\n\n    This exception is raised when there are problems with:\n\n    - YAML parse errors (syntax errors, invalid structure)\n    - Missing required configuration fields (e.g., no apps defined, missing\n        'source.strategy' field)\n    - Invalid strategy configuration (unknown strategy name, invalid strategy\n        parameters)\n    - Missing recipe files (file not found)\n    - Recipe validation failures (invalid recipe structure, missing required\n        app fields)\n\n    Example:\n        Catching configuration errors:\n            ```python\n            from notapkgtool.exceptions import ConfigError\n\n            try:\n                config = load_effective_config(Path(\"invalid.yaml\"))\n            except ConfigError as e:\n                print(f\"Config error: {e}\")\n            ```\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/exceptions/#notapkgtool.exceptions.NetworkError","title":"NetworkError","text":"<p>               Bases: <code>NAPTError</code></p> <p>Raised for network/download-related errors.</p> <p>This exception is raised when there are problems with:</p> <ul> <li>Download failures (HTTP errors, connection timeouts, network     unreachable)</li> <li>API call failures (GitHub API errors, JSON API endpoint failures,     authentication issues)</li> <li>Network-related version extraction errors (API response parsing     failures)</li> </ul> Example <p>Catching network errors:     <pre><code>from notapkgtool.exceptions import NetworkError\n\ntry:\n    result = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\nexcept NetworkError as e:\n    print(f\"Network error: {e}\")\n</code></pre></p> Source code in <code>notapkgtool/exceptions.py</code> <pre><code>class NetworkError(NAPTError):\n    \"\"\"Raised for network/download-related errors.\n\n    This exception is raised when there are problems with:\n\n    - Download failures (HTTP errors, connection timeouts, network\n        unreachable)\n    - API call failures (GitHub API errors, JSON API endpoint failures,\n        authentication issues)\n    - Network-related version extraction errors (API response parsing\n        failures)\n\n    Example:\n        Catching network errors:\n            ```python\n            from notapkgtool.exceptions import NetworkError\n\n            try:\n                result = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\n            except NetworkError as e:\n                print(f\"Network error: {e}\")\n            ```\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/exceptions/#notapkgtool.exceptions.PackagingError","title":"PackagingError","text":"<p>               Bases: <code>NAPTError</code></p> <p>Raised for packaging/build-related errors.</p> <p>This exception is raised when there are problems with:</p> <ul> <li>Build failures (PSADT template processing errors, file operations,     directory creation failures)</li> <li>Missing build tools (IntuneWinAppUtil.exe not found, PSADT template     missing)</li> <li>MSI extraction errors (failed to read MSI ProductVersion, unsupported     MSI format)</li> <li>Packaging operations (IntuneWinAppUtil.exe execution failures, invalid     build directory structure)</li> </ul> Example <p>Catching packaging errors:     <pre><code>from notapkgtool.exceptions import PackagingError\n\ntry:\n    build_package(Path(\"recipe.yaml\"), Path(\"./builds\"))\nexcept PackagingError as e:\n    print(f\"Packaging error: {e}\")\n</code></pre></p> Source code in <code>notapkgtool/exceptions.py</code> <pre><code>class PackagingError(NAPTError):\n    \"\"\"Raised for packaging/build-related errors.\n\n    This exception is raised when there are problems with:\n\n    - Build failures (PSADT template processing errors, file operations,\n        directory creation failures)\n    - Missing build tools (IntuneWinAppUtil.exe not found, PSADT template\n        missing)\n    - MSI extraction errors (failed to read MSI ProductVersion, unsupported\n        MSI format)\n    - Packaging operations (IntuneWinAppUtil.exe execution failures, invalid\n        build directory structure)\n\n    Example:\n        Catching packaging errors:\n            ```python\n            from notapkgtool.exceptions import PackagingError\n\n            try:\n                build_package(Path(\"recipe.yaml\"), Path(\"./builds\"))\n            except PackagingError as e:\n                print(f\"Packaging error: {e}\")\n            ```\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/io/","title":"io","text":""},{"location":"api/io/#notapkgtool.io.download","title":"notapkgtool.io.download","text":"<p>Robust HTTP(S) file download for NAPT.</p> <p>This module provides production-grade file downloading with features designed for reliability, reproducibility, and efficiency in automated packaging workflows.</p> <p>Key Features:</p> <ul> <li>Retry Logic with Exponential Backoff - Automatically retries on     transient failures (429, 500, 502, 503, 504) with exponential backoff.     Configurable via urllib3.util.Retry.</li> <li>Conditional Requests (HTTP 304 Not Modified) - Supports ETag and     Last-Modified headers to avoid re-downloading unchanged files.</li> <li>Atomic Writes - Downloads to temporary .part files with atomic rename     on success to prevent partial files.</li> <li>Integrity Verification - SHA-256 hashing during download with     optional checksum validation. Corrupted files are automatically removed.</li> <li>Smart Filename Detection - Respects Content-Disposition headers,     falls back to URL path, handles edge cases.</li> <li>Stable ETags - Forces Accept-Encoding: identity to avoid     representation-specific ETags and prevent false cache misses.</li> </ul> <p>Exception Classes:</p> <ul> <li>NotModifiedError: Raised when conditional request returns HTTP 304     (not an error condition).</li> </ul> <p>Constants:</p> <ul> <li>DEFAULT_CHUNK (int): Stream chunk size (1 MiB). Balance memory vs.     progress granularity.</li> </ul> Example <p>Basic download:     <pre><code>from pathlib import Path\nfrom notapkgtool.io import download_file\n\npath, sha256, headers = download_file(\n    url=\"https://example.com/installer.msi\",\n    destination_folder=Path(\"./downloads\"),\n)\nprint(f\"Downloaded to {path}\")\nprint(f\"SHA-256: {sha256}\")\n</code></pre></p> <p>Conditional download (avoid re-downloading):     <pre><code>from notapkgtool.io import NotModifiedError\n\ntry:\n    path, sha256, headers = download_file(\n        url=\"https://example.com/installer.msi\",\n        destination_folder=Path(\"./downloads\"),\n        etag=previous_etag,\n    )\nexcept NotModifiedError:\n    print(\"File unchanged, using cached version\")\n</code></pre></p> <p>Checksum validation:     <pre><code>try:\n    path, sha256, headers = download_file(\n        url=\"https://example.com/installer.msi\",\n        destination_folder=Path(\"./downloads\"),\n        expected_sha256=\"abc123...\",\n    )\nexcept NetworkError as e:\n    print(f\"Checksum mismatch: {e}\")\n</code></pre></p> <p>Design Decisions:</p> <ul> <li>Why identity encoding? CDNs like Cloudflare compute     representation-specific ETags. Requesting gzip vs identity yields     different ETags for the same content, causing unnecessary re-downloads.     We pin to identity for stability.</li> <li>Why atomic writes? Prevents partial files from appearing in the     destination. Critical for automation where another process might start     using a file before download completes.</li> <li>Why stream hashing? Computing SHA-256 while streaming avoids a second     file read, improving I/O efficiency especially for large installers.</li> </ul> Note <ul> <li>Progress output goes to stdout (can be captured/redirected)</li> <li>User-Agent identifies NAPT to help with debugging/support</li> <li>All HTTP errors are chained for better debugging</li> <li>Timeouts are per-request, not total download time</li> </ul>"},{"location":"api/io/#notapkgtool.io.download.NotModifiedError","title":"NotModifiedError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a conditional request (If-None-Match / If-Modified-Since) returns HTTP 304 Not Modified. Caller can treat this as \"no work to do\".</p> Source code in <code>notapkgtool/io/download.py</code> <pre><code>class NotModifiedError(Exception):\n    \"\"\"Raised when a conditional request (If-None-Match / If-Modified-Since)\n    returns HTTP 304 Not Modified. Caller can treat this as \"no work to do\".\n    \"\"\"\n</code></pre>"},{"location":"api/io/#notapkgtool.io.download.make_session","title":"make_session","text":"<pre><code>make_session() -&gt; requests.Session\n</code></pre> <p>Create a requests.Session with sane retry/backoff defaults.</p> <ul> <li>Retries on common transient status codes.</li> <li>Applies exponential backoff.</li> <li>Sets a helpful User-Agent to avoid being blocked.</li> </ul> <p>Notes on Accept-Encoding:</p> <ul> <li>We force 'Accept-Encoding: identity' to request the raw (uncompressed) bytes.</li> <li>Many CDNs compute representation-specific ETags (e.g., gzip vs identity).   That can cause conditional requests (If-None-Match) to miss and trigger   unnecessary re-downloads. Pinning identity stabilizes ETags for binary   installers (MSI/EXE/MSIX/ZIP), which are already compressed.</li> </ul> Source code in <code>notapkgtool/io/download.py</code> <pre><code>def make_session() -&gt; requests.Session:\n    \"\"\"Create a requests.Session with sane retry/backoff defaults.\n\n    - Retries on common transient status codes.\n    - Applies exponential backoff.\n    - Sets a helpful User-Agent to avoid being blocked.\n\n    Notes on Accept-Encoding:\n\n    - We force 'Accept-Encoding: identity' to request the raw (uncompressed) bytes.\n    - Many CDNs compute representation-specific ETags (e.g., gzip vs identity).\n      That can cause conditional requests (If-None-Match) to miss and trigger\n      unnecessary re-downloads. Pinning identity stabilizes ETags for binary\n      installers (MSI/EXE/MSIX/ZIP), which are already compressed.\n    \"\"\"\n    s = requests.Session()\n    retries = Retry(\n        total=5,\n        backoff_factor=0.5,\n        status_forcelist=(429, 500, 502, 503, 504),\n        allowed_methods=(\"GET\", \"HEAD\"),\n        raise_on_status=False,\n    )\n    s.headers.update(\n        {\n            \"User-Agent\": \"napt/0.1 (+https://github.com/RogerCibrian/notapkgtool)\",\n            # Request the raw, uncompressed representation to keep ETags stable\n            # across runs and avoid spurious 200s when a CDN flips to gzip.\n            \"Accept-Encoding\": \"identity\",\n        }\n    )\n    s.mount(\"http://\", HTTPAdapter(max_retries=retries))\n    s.mount(\"https://\", HTTPAdapter(max_retries=retries))\n    return s\n</code></pre>"},{"location":"api/io/#notapkgtool.io.download.download_file","title":"download_file","text":"<pre><code>download_file(url: str, destination_folder: Path, *, expected_sha256: str | None = None, validate_content_type: bool = False, timeout: int = 60, etag: str | None = None, last_modified: str | None = None) -&gt; tuple[Path, str, dict]\n</code></pre> <p>Download a URL to destination_folder with robustness and reproducibility.</p> <p>Follows redirects and retries transient failures. Writes to .part then renames to  on success (atomic). Sends conditional headers if etag/last_modified provided. Validates checksum if expected_sha256 is set. <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Source URL.</p> required <code>destination_folder</code> <code>Path</code> <p>Folder to save into (created if missing).</p> required <code>expected_sha256</code> <code>str | None</code> <p>Optional known SHA-256 (hex). If set and mismatched, raises ValueError.</p> <code>None</code> <code>validate_content_type</code> <code>bool</code> <p>If True, rejects responses with text/html content-type.</p> <code>False</code> <code>timeout</code> <code>int</code> <p>Per-request timeout (seconds).</p> <code>60</code> <code>etag</code> <code>str | None</code> <p>Previous ETag to use for If-None-Match (conditional GET).</p> <code>None</code> <code>last_modified</code> <code>str | None</code> <p>Previous Last-Modified to use for If-Modified-Since (conditional GET).</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[Path, str, dict]</code> <p>A tuple (file_path, sha256_hex, headers_dict), where file_path is the Path to the downloaded file, sha256_hex is the SHA-256 hash of the file, and headers_dict contains HTTP response headers.</p> <p>Raises:</p> Type Description <code>NotModifiedError</code> <p>On HTTP 304 (conditional request satisfied).</p> <code>NetworkError</code> <p>For non-2xx responses (after retries) or checksum mismatch.</p> <code>ConfigError</code> <p>For content-type mismatch.</p> Source code in <code>notapkgtool/io/download.py</code> <pre><code>def download_file(\n    url: str,\n    destination_folder: Path,\n    *,\n    expected_sha256: str | None = None,\n    validate_content_type: bool = False,\n    timeout: int = 60,\n    etag: str | None = None,\n    last_modified: str | None = None,\n) -&gt; tuple[Path, str, dict]:\n    \"\"\"Download a URL to destination_folder with robustness and reproducibility.\n\n    Follows redirects and retries transient failures. Writes to &lt;filename&gt;.part\n    then renames to &lt;filename&gt; on success (atomic). Sends conditional headers\n    if etag/last_modified provided. Validates checksum if expected_sha256 is set.\n\n    Args:\n        url: Source URL.\n        destination_folder: Folder to save into (created if missing).\n        expected_sha256: Optional known SHA-256 (hex). If set and mismatched,\n            raises ValueError.\n        validate_content_type: If True, rejects responses with text/html content-type.\n        timeout: Per-request timeout (seconds).\n        etag: Previous ETag to use for If-None-Match (conditional GET).\n        last_modified: Previous Last-Modified to use for If-Modified-Since\n            (conditional GET).\n\n    Returns:\n        A tuple (file_path, sha256_hex, headers_dict), where file_path is\n            the Path to the downloaded file, sha256_hex is the SHA-256 hash\n            of the file, and headers_dict contains HTTP response headers.\n\n    Raises:\n        NotModifiedError: On HTTP 304 (conditional request satisfied).\n        NetworkError: For non-2xx responses (after retries) or checksum mismatch.\n        ConfigError: For content-type mismatch.\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    destination_folder = Path(destination_folder)\n    destination_folder.mkdir(parents=True, exist_ok=True)\n\n    headers: dict[str, str] = {}\n    if etag:\n        headers[\"If-None-Match\"] = etag\n        logger.verbose(\"HTTP\", f\"Using conditional request with ETag: {etag}\")\n    elif last_modified:\n        headers[\"If-Modified-Since\"] = last_modified\n        logger.verbose(\n            \"HTTP\", f\"Using conditional request with Last-Modified: {last_modified}\"\n        )\n\n    logger.verbose(\"HTTP\", f\"GET {url}\")\n    logger.verbose(\n        \"HTTP\",\n        \"Request headers: Accept-Encoding: identity, User-Agent: napt/0.1.0\",\n    )\n\n    with make_session() as session:\n        # Stream response so we can hash while writing.\n        resp = session.get(\n            url, stream=True, allow_redirects=True, timeout=timeout, headers=headers\n        )\n\n        # Log redirects\n        if len(resp.history) &gt; 0:\n            for hist in resp.history:\n                logger.verbose(\n                    \"HTTP\",\n                    (\n                        f\"Redirect {hist.status_code} -&gt; \"\n                        f\"{hist.headers.get('Location', 'unknown')}\"\n                    ),\n                )\n\n        # Conditional request satisfied: nothing changed since last time.\n        if resp.status_code == 304:\n            logger.verbose(\"HTTP\", \"Response: 304 Not Modified\")\n            resp.close()\n            raise NotModifiedError(\"Remote content not modified (HTTP 304).\")\n\n        # Raise for other HTTP errors after retries.\n        try:\n            resp.raise_for_status()\n        except requests.HTTPError as err:\n            # Chain for better context.\n            raise NetworkError(f\"download failed for {url}: {err}\") from err\n\n        logger.verbose(\"HTTP\", f\"Response: {resp.status_code} {resp.reason}\")\n\n        # Content-Disposition beats URL when naming the file.\n        cd_name = _filename_from_cd(resp.headers.get(\"Content-Disposition\", \"\"))\n        filename = cd_name or _filename_from_url(resp.url)\n        target = destination_folder / filename\n\n        # Log response details\n        content_length = resp.headers.get(\"Content-Length\", \"unknown\")\n        if content_length != \"unknown\":\n            size_mb = int(content_length) / (1024 * 1024)\n            logger.verbose(\n                \"HTTP\", f\"Content-Length: {content_length} ({size_mb:.1f} MB)\"\n            )\n            etag_value = resp.headers.get(\"ETag\", \"not provided\")\n            logger.verbose(\"HTTP\", f\"ETag: {etag_value}\")\n            cd_header = resp.headers.get(\"Content-Disposition\", \"not provided\")\n            logger.verbose(\"HTTP\", f\"Content-Disposition: {cd_header}\")\n\n        # Optional content-type sanity check.\n        if validate_content_type:\n            ctype = resp.headers.get(\"Content-Type\", \"\")\n            if \"text/html\" in ctype.lower():\n                resp.close()\n                raise ConfigError(f\"expected binary, got content-type={ctype}\")\n\n        total_size = int(resp.headers.get(\"Content-Length\", \"0\") or 0)\n\n        tmp = target.with_suffix(target.suffix + \".part\")\n        logger.verbose(\"FILE\", f\"Downloading to: {tmp}\")\n\n        sha = hashlib.sha256()\n        downloaded = 0\n        last_percent = -1\n        started_at = time.time()\n\n        with tmp.open(\"wb\") as f:\n            for chunk in resp.iter_content(chunk_size=DEFAULT_CHUNK):\n                if not chunk:\n                    continue\n                f.write(chunk)\n                sha.update(chunk)\n                downloaded += len(chunk)\n\n                # Optional lightweight progress indicator.\n                if total_size:\n                    pct = int(downloaded * 100 / total_size)\n                    if pct != last_percent:\n                        print(f\"download progress: {pct}%\", end=\"\\r\")\n                        last_percent = pct\n\n        # Cleanup response socket.\n        resp.close()\n\n        digest = sha.hexdigest()\n        logger.verbose(\"FILE\", f\"SHA-256: {digest} (computed during download)\")\n\n        # Atomically \"commit\" the file.\n        logger.verbose(\"FILE\", f\"Atomic rename: {tmp.name} -&gt; {target.name}\")\n        tmp.replace(target)\n\n        # Validate checksum if the caller expects a specific digest.\n        if expected_sha256 and digest.lower() != expected_sha256.lower():\n            logger.verbose(\n                \"FILE\", f\"Checksum mismatch! Expected: {expected_sha256}, Got: {digest}\"\n            )\n            try:\n                target.unlink()\n            except OSError:\n                pass\n            raise NetworkError(\n                f\"sha256 mismatch for {filename}: got {digest}, \"\n                f\"expected {expected_sha256}\"\n            )\n\n        elapsed = time.time() - started_at\n        # Always show completion message\n        logger.step(0, 0, f\"Download complete: {target} ({digest}) in {elapsed:.1f}s\")\n        # Show detailed info in verbose mode\n        logger.verbose(\"FILE\", f\"Download complete: {target}\")\n        logger.verbose(\"FILE\", f\"Time elapsed: {elapsed:.1f}s\")\n\n        # Hand back headers the caller may want to persist (ETag, Last-Modified).\n        return target, digest, dict(resp.headers)\n</code></pre>"},{"location":"api/io/#notapkgtool.io.upload","title":"notapkgtool.io.upload","text":""},{"location":"api/logging/","title":"logging","text":""},{"location":"api/logging/#notapkgtool.logging","title":"notapkgtool.logging","text":"<p>Logging interface for NAPT.</p> <p>This module provides a configurable logging interface that library modules can use for output without depending on the CLI. The logger can be configured globally or passed as a parameter for better isolation.</p> <p>The logger supports four output levels:</p> <ul> <li>Step: Always printed (for progress indicators)</li> <li>Warning: Always printed (for important warnings that users should see)</li> <li>Verbose: Only printed when verbose mode is enabled</li> <li>Debug: Only printed when debug mode is enabled (implies verbose)</li> </ul> Example <p>Configure global logger:     <pre><code>from notapkgtool.logging import get_logger, set_global_logger\n\nlogger = get_logger(verbose=True, debug=False)\nset_global_logger(logger)\n</code></pre></p> <p>Use in library code:     <pre><code>from notapkgtool.logging import get_logger\n\nlogger = get_logger()\nlogger.step(1, 4, \"Loading configuration...\")\nlogger.warning(\"DETECTION\", \"Could not extract MSI metadata\")\nlogger.verbose(\"STATE\", \"Loaded state from file\")\nlogger.debug(\"VERSION\", \"Trying backend: msilib...\")\n</code></pre></p> <p>Use with dependency injection:</p> <pre><code>def my_function(logger=None):\n    if logger is None:\n        logger = get_logger()\n    logger.verbose(\"MODULE\", \"Processing...\")\n</code></pre> Note <p>The default logger is silent (verbose=False, debug=False), so library functions won't print anything unless explicitly configured. The CLI configures the global logger when commands are executed.</p>"},{"location":"api/logging/#notapkgtool.logging.Logger","title":"Logger","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for logger implementations.</p> Source code in <code>notapkgtool/logging.py</code> <pre><code>class Logger(Protocol):\n    \"\"\"Protocol for logger implementations.\"\"\"\n\n    def step(self, step: int, total: int, message: str) -&gt; None:\n        \"\"\"Print a step indicator for non-verbose mode.\n\n        Args:\n            step: Current step number (1-based).\n            total: Total number of steps.\n            message: Step description.\n        \"\"\"\n        ...\n\n    def warning(self, prefix: str, message: str) -&gt; None:\n        \"\"\"Print a warning message (always visible).\n\n        Args:\n            prefix: Message prefix (e.g., \"DETECTION\", \"BUILD\").\n            message: Warning message.\n        \"\"\"\n        ...\n\n    def verbose(self, prefix: str, message: str) -&gt; None:\n        \"\"\"Print a verbose log message.\n\n        Args:\n            prefix: Message prefix (e.g., \"STATE\", \"BUILD\").\n            message: Log message.\n        \"\"\"\n        ...\n\n    def debug(self, prefix: str, message: str) -&gt; None:\n        \"\"\"Print a debug log message.\n\n        Args:\n            prefix: Message prefix (e.g., \"VERSION\", \"HTTP\").\n            message: Log message.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.Logger.step","title":"step","text":"<pre><code>step(step: int, total: int, message: str) -&gt; None\n</code></pre> <p>Print a step indicator for non-verbose mode.</p> <p>Parameters:</p> Name Type Description Default <code>step</code> <code>int</code> <p>Current step number (1-based).</p> required <code>total</code> <code>int</code> <p>Total number of steps.</p> required <code>message</code> <code>str</code> <p>Step description.</p> required Source code in <code>notapkgtool/logging.py</code> <pre><code>def step(self, step: int, total: int, message: str) -&gt; None:\n    \"\"\"Print a step indicator for non-verbose mode.\n\n    Args:\n        step: Current step number (1-based).\n        total: Total number of steps.\n        message: Step description.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.Logger.warning","title":"warning","text":"<pre><code>warning(prefix: str, message: str) -&gt; None\n</code></pre> <p>Print a warning message (always visible).</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Message prefix (e.g., \"DETECTION\", \"BUILD\").</p> required <code>message</code> <code>str</code> <p>Warning message.</p> required Source code in <code>notapkgtool/logging.py</code> <pre><code>def warning(self, prefix: str, message: str) -&gt; None:\n    \"\"\"Print a warning message (always visible).\n\n    Args:\n        prefix: Message prefix (e.g., \"DETECTION\", \"BUILD\").\n        message: Warning message.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.Logger.verbose","title":"verbose","text":"<pre><code>verbose(prefix: str, message: str) -&gt; None\n</code></pre> <p>Print a verbose log message.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Message prefix (e.g., \"STATE\", \"BUILD\").</p> required <code>message</code> <code>str</code> <p>Log message.</p> required Source code in <code>notapkgtool/logging.py</code> <pre><code>def verbose(self, prefix: str, message: str) -&gt; None:\n    \"\"\"Print a verbose log message.\n\n    Args:\n        prefix: Message prefix (e.g., \"STATE\", \"BUILD\").\n        message: Log message.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.Logger.debug","title":"debug","text":"<pre><code>debug(prefix: str, message: str) -&gt; None\n</code></pre> <p>Print a debug log message.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Message prefix (e.g., \"VERSION\", \"HTTP\").</p> required <code>message</code> <code>str</code> <p>Log message.</p> required Source code in <code>notapkgtool/logging.py</code> <pre><code>def debug(self, prefix: str, message: str) -&gt; None:\n    \"\"\"Print a debug log message.\n\n    Args:\n        prefix: Message prefix (e.g., \"VERSION\", \"HTTP\").\n        message: Log message.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.DefaultLogger","title":"DefaultLogger","text":"<p>Default logger implementation that prints to stdout.</p> <p>This logger respects verbose and debug flags and formats output consistently with the CLI output format.</p> Source code in <code>notapkgtool/logging.py</code> <pre><code>class DefaultLogger:\n    \"\"\"Default logger implementation that prints to stdout.\n\n    This logger respects verbose and debug flags and formats output\n    consistently with the CLI output format.\n    \"\"\"\n\n    def __init__(self, verbose: bool = False, debug: bool = False) -&gt; None:\n        \"\"\"Initialize logger with verbosity settings.\n\n        Args:\n            verbose: If True, print verbose messages.\n            debug: If True, print debug messages (implies verbose).\n        \"\"\"\n        self._verbose = verbose or debug\n        self._debug = debug\n\n    def step(self, step: int, total: int, message: str) -&gt; None:\n        \"\"\"Print a step indicator for non-verbose mode.\"\"\"\n        print(f\"[{step}/{total}] {message}\")\n\n    def warning(self, prefix: str, message: str) -&gt; None:\n        \"\"\"Print a warning message (always visible).\"\"\"\n        print(f\"[{prefix}] {message}\")\n\n    def verbose(self, prefix: str, message: str) -&gt; None:\n        \"\"\"Print a verbose log message (only when verbose mode is active).\"\"\"\n        if self._verbose:\n            print(f\"[{prefix}] {message}\")\n\n    def debug(self, prefix: str, message: str) -&gt; None:\n        \"\"\"Print a debug log message (only when debug mode is active).\"\"\"\n        if self._debug:\n            print(f\"[{prefix}] {message}\")\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.DefaultLogger.__init__","title":"__init__","text":"<pre><code>__init__(verbose: bool = False, debug: bool = False) -&gt; None\n</code></pre> <p>Initialize logger with verbosity settings.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>If True, print verbose messages.</p> <code>False</code> <code>debug</code> <code>bool</code> <p>If True, print debug messages (implies verbose).</p> <code>False</code> Source code in <code>notapkgtool/logging.py</code> <pre><code>def __init__(self, verbose: bool = False, debug: bool = False) -&gt; None:\n    \"\"\"Initialize logger with verbosity settings.\n\n    Args:\n        verbose: If True, print verbose messages.\n        debug: If True, print debug messages (implies verbose).\n    \"\"\"\n    self._verbose = verbose or debug\n    self._debug = debug\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.DefaultLogger.step","title":"step","text":"<pre><code>step(step: int, total: int, message: str) -&gt; None\n</code></pre> <p>Print a step indicator for non-verbose mode.</p> Source code in <code>notapkgtool/logging.py</code> <pre><code>def step(self, step: int, total: int, message: str) -&gt; None:\n    \"\"\"Print a step indicator for non-verbose mode.\"\"\"\n    print(f\"[{step}/{total}] {message}\")\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.DefaultLogger.warning","title":"warning","text":"<pre><code>warning(prefix: str, message: str) -&gt; None\n</code></pre> <p>Print a warning message (always visible).</p> Source code in <code>notapkgtool/logging.py</code> <pre><code>def warning(self, prefix: str, message: str) -&gt; None:\n    \"\"\"Print a warning message (always visible).\"\"\"\n    print(f\"[{prefix}] {message}\")\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.DefaultLogger.verbose","title":"verbose","text":"<pre><code>verbose(prefix: str, message: str) -&gt; None\n</code></pre> <p>Print a verbose log message (only when verbose mode is active).</p> Source code in <code>notapkgtool/logging.py</code> <pre><code>def verbose(self, prefix: str, message: str) -&gt; None:\n    \"\"\"Print a verbose log message (only when verbose mode is active).\"\"\"\n    if self._verbose:\n        print(f\"[{prefix}] {message}\")\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.DefaultLogger.debug","title":"debug","text":"<pre><code>debug(prefix: str, message: str) -&gt; None\n</code></pre> <p>Print a debug log message (only when debug mode is active).</p> Source code in <code>notapkgtool/logging.py</code> <pre><code>def debug(self, prefix: str, message: str) -&gt; None:\n    \"\"\"Print a debug log message (only when debug mode is active).\"\"\"\n    if self._debug:\n        print(f\"[{prefix}] {message}\")\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.SilentLogger","title":"SilentLogger","text":"<p>Logger that suppresses all output.</p> <p>Useful for programmatic usage when output is not desired.</p> Source code in <code>notapkgtool/logging.py</code> <pre><code>class SilentLogger:\n    \"\"\"Logger that suppresses all output.\n\n    Useful for programmatic usage when output is not desired.\n    \"\"\"\n\n    def step(self, step: int, total: int, message: str) -&gt; None:\n        \"\"\"Suppress step output.\"\"\"\n        pass\n\n    def warning(self, prefix: str, message: str) -&gt; None:\n        \"\"\"Suppress warning output.\"\"\"\n        pass\n\n    def verbose(self, prefix: str, message: str) -&gt; None:\n        \"\"\"Suppress verbose output.\"\"\"\n        pass\n\n    def debug(self, prefix: str, message: str) -&gt; None:\n        \"\"\"Suppress debug output.\"\"\"\n        pass\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.SilentLogger.step","title":"step","text":"<pre><code>step(step: int, total: int, message: str) -&gt; None\n</code></pre> <p>Suppress step output.</p> Source code in <code>notapkgtool/logging.py</code> <pre><code>def step(self, step: int, total: int, message: str) -&gt; None:\n    \"\"\"Suppress step output.\"\"\"\n    pass\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.SilentLogger.warning","title":"warning","text":"<pre><code>warning(prefix: str, message: str) -&gt; None\n</code></pre> <p>Suppress warning output.</p> Source code in <code>notapkgtool/logging.py</code> <pre><code>def warning(self, prefix: str, message: str) -&gt; None:\n    \"\"\"Suppress warning output.\"\"\"\n    pass\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.SilentLogger.verbose","title":"verbose","text":"<pre><code>verbose(prefix: str, message: str) -&gt; None\n</code></pre> <p>Suppress verbose output.</p> Source code in <code>notapkgtool/logging.py</code> <pre><code>def verbose(self, prefix: str, message: str) -&gt; None:\n    \"\"\"Suppress verbose output.\"\"\"\n    pass\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.SilentLogger.debug","title":"debug","text":"<pre><code>debug(prefix: str, message: str) -&gt; None\n</code></pre> <p>Suppress debug output.</p> Source code in <code>notapkgtool/logging.py</code> <pre><code>def debug(self, prefix: str, message: str) -&gt; None:\n    \"\"\"Suppress debug output.\"\"\"\n    pass\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.get_logger","title":"get_logger","text":"<pre><code>get_logger(verbose: bool = False, debug: bool = False) -&gt; Logger\n</code></pre> <p>Get a logger instance with specified verbosity.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>If True, logger will print verbose messages.</p> <code>False</code> <code>debug</code> <code>bool</code> <p>If True, logger will print debug messages (implies verbose).</p> <code>False</code> <p>Returns:</p> Type Description <code>Logger</code> <p>A logger instance configured with the specified verbosity.</p> Example <p>Get a verbose logger:     <pre><code>logger = get_logger(verbose=True)\nlogger.verbose(\"MODULE\", \"Processing...\")\n</code></pre></p> <p>Get a debug logger:     <pre><code>logger = get_logger(debug=True)\nlogger.debug(\"MODULE\", \"Debug info...\")\n</code></pre></p> Source code in <code>notapkgtool/logging.py</code> <pre><code>def get_logger(verbose: bool = False, debug: bool = False) -&gt; Logger:\n    \"\"\"Get a logger instance with specified verbosity.\n\n    Args:\n        verbose: If True, logger will print verbose messages.\n        debug: If True, logger will print debug messages (implies verbose).\n\n    Returns:\n        A logger instance configured with the specified verbosity.\n\n    Example:\n        Get a verbose logger:\n            ```python\n            logger = get_logger(verbose=True)\n            logger.verbose(\"MODULE\", \"Processing...\")\n            ```\n\n        Get a debug logger:\n            ```python\n            logger = get_logger(debug=True)\n            logger.debug(\"MODULE\", \"Debug info...\")\n            ```\n    \"\"\"\n    return DefaultLogger(verbose=verbose, debug=debug)\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.get_global_logger","title":"get_global_logger","text":"<pre><code>get_global_logger() -&gt; Logger\n</code></pre> <p>Get the global logger instance.</p> <p>Returns:</p> Type Description <code>Logger</code> <p>The current global logger instance.</p> Note <p>The default global logger is silent. Use set_global_logger() to configure it, or pass a logger instance directly to functions.</p> Source code in <code>notapkgtool/logging.py</code> <pre><code>def get_global_logger() -&gt; Logger:\n    \"\"\"Get the global logger instance.\n\n    Returns:\n        The current global logger instance.\n\n    Note:\n        The default global logger is silent. Use set_global_logger() to\n        configure it, or pass a logger instance directly to functions.\n    \"\"\"\n    return _global_logger\n</code></pre>"},{"location":"api/logging/#notapkgtool.logging.set_global_logger","title":"set_global_logger","text":"<pre><code>set_global_logger(logger: Logger) -&gt; None\n</code></pre> <p>Set the global logger instance.</p> <p>Parameters:</p> Name Type Description Default <code>logger</code> <code>Logger</code> <p>Logger instance to use as the global logger.</p> required Example <p>Configure global logger from CLI:     <pre><code>from notapkgtool.logging import get_logger, set_global_logger\n\nlogger = get_logger(verbose=args.verbose, debug=args.debug)\nset_global_logger(logger)\n</code></pre></p> Note <p>This affects all library functions that use get_logger() without passing a logger instance. For better isolation, pass logger instances directly to functions instead of using the global logger.</p> Source code in <code>notapkgtool/logging.py</code> <pre><code>def set_global_logger(logger: Logger) -&gt; None:\n    \"\"\"Set the global logger instance.\n\n    Args:\n        logger: Logger instance to use as the global logger.\n\n    Example:\n        Configure global logger from CLI:\n            ```python\n            from notapkgtool.logging import get_logger, set_global_logger\n\n            logger = get_logger(verbose=args.verbose, debug=args.debug)\n            set_global_logger(logger)\n            ```\n\n    Note:\n        This affects all library functions that use get_logger() without\n        passing a logger instance. For better isolation, pass logger\n        instances directly to functions instead of using the global logger.\n    \"\"\"\n    global _global_logger\n    _global_logger = logger\n</code></pre>"},{"location":"api/policy/","title":"policy","text":""},{"location":"api/policy/#notapkgtool.policy.updates","title":"notapkgtool.policy.updates","text":"<p>Update decision policy for NAPT.</p> <p>Determines whether a newly discovered remote artifact should be staged, based on version, hash, and org policy.</p> Example <p>Check if a new version should be staged:</p> <pre><code>from notapkgtool.policy.updates import should_stage, UpdatePolicy\n\ndecision = should_stage(\n    remote_version=\"124.0.6367.91\",\n    remote_hash=\"abc...\",\n    current_version=\"124.0.6367.70\",\n    current_hash=\"def...\",\n    policy=UpdatePolicy(\n        strategy=\"version_then_hash\",\n        allow_same_version_hash_change=True,\n        comparator=\"semver\"\n    ),\n)\n</code></pre>"},{"location":"api/policy/#notapkgtool.policy.updates.should_stage","title":"should_stage","text":"<pre><code>should_stage(*, remote_version: str, remote_hash: str, current_version: str | None, current_hash: str | None, policy: UpdatePolicy) -&gt; bool\n</code></pre> <p>Decide whether to stage a newly discovered artifact.</p> <p>Compares remote version/hash against current state using the configured policy strategy to determine if the new artifact should be staged.</p> <p>Parameters:</p> Name Type Description Default <code>remote_version</code> <code>str</code> <p>Version found during discovery.</p> required <code>remote_hash</code> <code>str</code> <p>SHA-256 hash of the newly downloaded artifact.</p> required <code>current_version</code> <code>str | None</code> <p>Version we last staged/deployed (None if none).</p> required <code>current_hash</code> <code>str | None</code> <p>Hash we last staged/deployed (None if none).</p> required <code>policy</code> <code>UpdatePolicy</code> <p>UpdatePolicy controlling the decision algorithm.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the new artifact should be staged, False otherwise.</p> Source code in <code>notapkgtool/policy/updates.py</code> <pre><code>def should_stage(\n    *,\n    remote_version: str,\n    remote_hash: str,\n    current_version: str | None,\n    current_hash: str | None,\n    policy: UpdatePolicy,\n) -&gt; bool:\n    \"\"\"Decide whether to stage a newly discovered artifact.\n\n    Compares remote version/hash against current state using the configured\n    policy strategy to determine if the new artifact should be staged.\n\n    Args:\n        remote_version: Version found during discovery.\n        remote_hash: SHA-256 hash of the newly downloaded artifact.\n        current_version: Version we last staged/deployed (None if none).\n        current_hash: Hash we last staged/deployed (None if none).\n        policy: UpdatePolicy controlling the decision algorithm.\n\n    Returns:\n        True if the new artifact should be staged, False otherwise.\n\n    \"\"\"\n    # If we have no prior state, stage the first artifact.\n    if current_version is None and current_hash is None:\n        return True\n\n    # Normalized comparisons\n    version_changed = (\n        True\n        if current_version is None\n        else is_newer_any(remote_version, current_version, policy.comparator)\n        or remote_version != current_version\n        # Treat \"different version string\" as change even if comparator\n        # treats them equal\n    )\n\n    hash_changed = (current_hash or \"\").lower() != (remote_hash or \"\").lower()\n\n    if policy.strategy == \"version_only\":\n        return version_changed\n\n    if policy.strategy == \"version_then_hash\":\n        if version_changed:\n            return True\n        if not version_changed and policy.allow_same_version_hash_change:\n            # Same version string but bits changed (repack, resign, silent fix)\n            return hash_changed\n        return False\n\n    if policy.strategy == \"hash_or_version\":\n        return version_changed or hash_changed\n\n    if policy.strategy == \"hash_only\":\n        return hash_changed\n\n    # Safe default: do not stage on unknown strategy\n    return False\n</code></pre>"},{"location":"api/psadt/","title":"psadt","text":""},{"location":"api/psadt/#notapkgtool.psadt.release","title":"notapkgtool.psadt.release","text":"<p>PSADT release management for NAPT.</p> <p>This module handles fetching, downloading, and caching PSAppDeployToolkit releases from the official GitHub repository. It reuses NAPT's existing GitHub release discovery infrastructure for consistency.</p> <p>Key Features:</p> <ul> <li>Fetch latest PSADT version from GitHub API</li> <li>Download and cache specific PSADT versions</li> <li>Extract releases to cache directory</li> <li>Version resolution (\"latest\" keyword support)</li> </ul> Example <p>Get and cache PSADT releases:     <pre><code>from pathlib import Path\nfrom notapkgtool.psadt import get_psadt_release, is_psadt_cached\n\n# Get latest PSADT\npsadt_dir = get_psadt_release(\"latest\", Path(\"cache/psadt\"))\n\n# Get specific version\npsadt_dir = get_psadt_release(\"4.1.7\", Path(\"cache/psadt\"))\n\n# Check if cached\nif is_psadt_cached(\"4.1.7\", Path(\"cache/psadt\")):\n    print(\"Already cached!\")\n</code></pre></p> Note <ul> <li>Reuses notapkgtool.discovery.api_github for API calls</li> <li>Caches releases by version: cache/psadt/{version}/</li> <li>Downloads .zip releases and extracts to cache</li> <li>Validates extracted PSADT structure (PSAppDeployToolkit/ folder exists)</li> </ul>"},{"location":"api/psadt/#notapkgtool.psadt.release.fetch_latest_psadt_version","title":"fetch_latest_psadt_version","text":"<pre><code>fetch_latest_psadt_version() -&gt; str\n</code></pre> <p>Fetch the latest PSADT release version from GitHub.</p> <p>Queries the GitHub API for the latest release and extracts the version number from the tag name (e.g., \"4.1.7\" from tag \"4.1.7\").</p> <p>Returns:</p> Type Description <code>str</code> <p>Version number (e.g., \"4.1.7\").</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the GitHub API request fails or version cannot be extracted.</p> Example <p>Get latest PSADT version from GitHub:     <pre><code>version = fetch_latest_psadt_version()\nprint(version)  # Output: \"4.1.7\"\n</code></pre></p> Note <ul> <li>Uses GitHub's public API (60 requests/hour limit without auth)</li> <li>Version is extracted from release tag name</li> <li>For higher rate limits, set GITHUB_TOKEN environment variable</li> </ul> Source code in <code>notapkgtool/psadt/release.py</code> <pre><code>def fetch_latest_psadt_version() -&gt; str:\n    \"\"\"Fetch the latest PSADT release version from GitHub.\n\n    Queries the GitHub API for the latest release and extracts the version\n    number from the tag name (e.g., \"4.1.7\" from tag \"4.1.7\").\n\n    Args:\n            Defaults to False.\n\n    Returns:\n        Version number (e.g., \"4.1.7\").\n\n    Raises:\n        RuntimeError: If the GitHub API request fails or version cannot be\n            extracted.\n\n    Example:\n        Get latest PSADT version from GitHub:\n            ```python\n            version = fetch_latest_psadt_version()\n            print(version)  # Output: \"4.1.7\"\n            ```\n\n    Note:\n        - Uses GitHub's public API (60 requests/hour limit without auth)\n        - Version is extracted from release tag name\n        - For higher rate limits, set GITHUB_TOKEN environment variable\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    logger.verbose(\"PSADT\", f\"Querying GitHub API: {PSADT_GITHUB_API}\")\n\n    try:\n        headers = {\n            \"Accept\": \"application/vnd.github+json\",\n            \"X-GitHub-Api-Version\": \"2022-11-28\",\n        }\n\n        response = requests.get(PSADT_GITHUB_API, headers=headers, timeout=30)\n        response.raise_for_status()\n    except requests.RequestException as err:\n        raise NetworkError(\n            f\"Failed to fetch latest PSADT release from GitHub: {err}\"\n        ) from err\n\n    data = response.json()\n    tag_name = data.get(\"tag_name\", \"\")\n\n    if not tag_name:\n        raise NetworkError(\"GitHub API response missing 'tag_name' field\")\n\n    # Extract version from tag (e.g., \"4.1.7\" or \"v4.1.7\")\n    # PSADT uses tags without 'v' prefix\n    version_match = re.match(r\"v?(\\d+\\.\\d+\\.\\d+)\", tag_name)\n    if not version_match:\n        raise NetworkError(f\"Could not extract version from tag: {tag_name!r}\")\n\n    version = version_match.group(1)\n    logger.verbose(\"PSADT\", f\"Latest PSADT version: {version}\")\n\n    return version\n</code></pre>"},{"location":"api/psadt/#notapkgtool.psadt.release.is_psadt_cached","title":"is_psadt_cached","text":"<pre><code>is_psadt_cached(version: str, cache_dir: Path) -&gt; bool\n</code></pre> <p>Check if a PSADT version is already cached.</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>str</code> <p>PSADT version to check (e.g., \"4.1.7\").</p> required <code>cache_dir</code> <code>Path</code> <p>Base cache directory (e.g., Path(\"cache/psadt\")).</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the version is cached and valid, False otherwise.</p> Example <p>Check if PSADT version is cached:     <pre><code>from pathlib import Path\n\nif is_psadt_cached(\"4.1.7\", Path(\"cache/psadt\")):\n    print(\"Already downloaded!\")\n</code></pre></p> Note <p>Validates that the cache contains the expected PSADT structure:</p> <ul> <li>PSAppDeployToolkit/ folder must exist</li> <li>PSAppDeployToolkit.psd1 manifest must exist</li> </ul> Source code in <code>notapkgtool/psadt/release.py</code> <pre><code>def is_psadt_cached(version: str, cache_dir: Path) -&gt; bool:\n    \"\"\"Check if a PSADT version is already cached.\n\n    Args:\n        version: PSADT version to check (e.g., \"4.1.7\").\n        cache_dir: Base cache directory (e.g., Path(\"cache/psadt\")).\n\n    Returns:\n        True if the version is cached and valid, False otherwise.\n\n    Example:\n        Check if PSADT version is cached:\n            ```python\n            from pathlib import Path\n\n            if is_psadt_cached(\"4.1.7\", Path(\"cache/psadt\")):\n                print(\"Already downloaded!\")\n            ```\n\n    Note:\n        Validates that the cache contains the expected PSADT structure:\n\n        - PSAppDeployToolkit/ folder must exist\n        - PSAppDeployToolkit.psd1 manifest must exist\n\n    \"\"\"\n    version_dir = cache_dir / version\n    psadt_dir = version_dir / \"PSAppDeployToolkit\"\n    manifest = psadt_dir / \"PSAppDeployToolkit.psd1\"\n\n    return psadt_dir.exists() and manifest.exists()\n</code></pre>"},{"location":"api/psadt/#notapkgtool.psadt.release.get_psadt_release","title":"get_psadt_release","text":"<pre><code>get_psadt_release(release_spec: str, cache_dir: Path) -&gt; Path\n</code></pre> <p>Download and extract a PSADT release to the cache directory.</p> <p>Resolves \"latest\" to the current latest version from GitHub, then downloads the release .zip file and extracts it to the cache.</p> <p>Parameters:</p> Name Type Description Default <code>release_spec</code> <code>str</code> <p>Version specifier - either \"latest\" or specific version (e.g., \"4.1.7\").</p> required <code>cache_dir</code> <code>Path</code> <p>Base cache directory for PSADT releases.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to the cached PSADT directory (cache_dir/{version}).</p> <p>Raises:</p> Type Description <code>NetworkError</code> <p>If download fails.</p> <code>PackagingError</code> <p>If extraction fails.</p> <code>ConfigError</code> <p>If release_spec is invalid.</p> Example <p>Get latest version:     <pre><code>from pathlib import Path\n\npsadt = get_psadt_release(\"latest\", Path(\"cache/psadt\"))\nprint(psadt)  # Output: cache/psadt/4.1.7\n</code></pre></p> <p>Get specific version:     <pre><code>psadt = get_psadt_release(\"4.1.7\", Path(\"cache/psadt\"))\n</code></pre></p> Note <ul> <li>Caches by version: cache/psadt/{version}/PSAppDeployToolkit/</li> <li>If already cached, returns path immediately (no re-download)</li> <li>Downloads from GitHub releases as .zip files</li> <li>Extracts entire archive to version directory</li> </ul> Source code in <code>notapkgtool/psadt/release.py</code> <pre><code>def get_psadt_release(release_spec: str, cache_dir: Path) -&gt; Path:\n    \"\"\"Download and extract a PSADT release to the cache directory.\n\n    Resolves \"latest\" to the current latest version from GitHub, then\n    downloads the release .zip file and extracts it to the cache.\n\n    Args:\n        release_spec: Version specifier - either \"latest\" or specific version\n            (e.g., \"4.1.7\").\n        cache_dir: Base cache directory for PSADT releases.\n\n    Returns:\n        Path to the cached PSADT directory (cache_dir/{version}).\n\n    Raises:\n        NetworkError: If download fails.\n        PackagingError: If extraction fails.\n        ConfigError: If release_spec is invalid.\n\n    Example:\n        Get latest version:\n            ```python\n            from pathlib import Path\n\n            psadt = get_psadt_release(\"latest\", Path(\"cache/psadt\"))\n            print(psadt)  # Output: cache/psadt/4.1.7\n            ```\n\n        Get specific version:\n            ```python\n            psadt = get_psadt_release(\"4.1.7\", Path(\"cache/psadt\"))\n            ```\n\n    Note:\n        - Caches by version: cache/psadt/{version}/PSAppDeployToolkit/\n        - If already cached, returns path immediately (no re-download)\n        - Downloads from GitHub releases as .zip files\n        - Extracts entire archive to version directory\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    # Resolve \"latest\" to actual version\n    if release_spec == \"latest\":\n        logger.verbose(\"PSADT\", \"Resolving 'latest' to current version...\")\n        version = fetch_latest_psadt_version()\n    else:\n        version = release_spec\n\n    logger.verbose(\"PSADT\", f\"PSADT version: {version}\")\n\n    # Check if already cached\n    if is_psadt_cached(version, cache_dir):\n        version_dir = cache_dir / version\n        logger.verbose(\"PSADT\", f\"Using cached PSADT: {version_dir}\")\n        return version_dir\n\n    # Need to download\n    logger.verbose(\"PSADT\", f\"Downloading PSADT {version}...\")\n\n    # Get release info from GitHub\n    release_url = f\"https://api.github.com/repos/{PSADT_REPO}/releases/tags/{version}\"\n\n    try:\n        headers = {\n            \"Accept\": \"application/vnd.github+json\",\n            \"X-GitHub-Api-Version\": \"2022-11-28\",\n        }\n\n        response = requests.get(release_url, headers=headers, timeout=30)\n        response.raise_for_status()\n    except requests.RequestException as err:\n        raise NetworkError(\n            f\"Failed to fetch PSADT release {version} from GitHub: {err}\"\n        ) from err\n\n    release_data = response.json()\n\n    # Find the Template_v4 .zip asset (the full v4 template structure)\n    assets = release_data.get(\"assets\", [])\n    zip_asset = None\n\n    # Look for Template_v4 version specifically\n    for asset in assets:\n        name = asset.get(\"name\", \"\")\n        if name.endswith(\".zip\") and \"Template_v4\" in name:\n            zip_asset = asset\n            break\n\n    # Fallback to any PSADT zip if Template_v4 not found\n    if not zip_asset:\n        for asset in assets:\n            name = asset.get(\"name\", \"\")\n            if name.endswith(\".zip\") and \"PSAppDeployToolkit\" in name:\n                zip_asset = asset\n                break\n\n    if not zip_asset:\n        raise NetworkError(\n            f\"No .zip asset found in PSADT release {version}. \"\n            f\"Available assets: {[a.get('name') for a in assets]}\"\n        )\n\n    download_url = zip_asset.get(\"browser_download_url\")\n    if not download_url:\n        raise NetworkError(f\"Asset missing download URL: {zip_asset}\")\n\n    logger.verbose(\"PSADT\", f\"Downloading: {zip_asset['name']}\")\n\n    # Download the .zip file\n    try:\n        zip_response = requests.get(download_url, timeout=300)\n        zip_response.raise_for_status()\n    except requests.RequestException as err:\n        raise NetworkError(f\"Failed to download PSADT release: {err}\") from err\n\n    # Create cache directory\n    version_dir = cache_dir / version\n    version_dir.mkdir(parents=True, exist_ok=True)\n\n    # Save .zip temporarily\n    zip_path = version_dir / f\"psadt_{version}.zip\"\n    zip_path.write_bytes(zip_response.content)\n\n    logger.verbose(\"PSADT\", f\"Extracting to: {version_dir}\")\n\n    # Extract .zip\n    try:\n        with zipfile.ZipFile(zip_path, \"r\") as zf:\n            zf.extractall(version_dir)\n    except zipfile.BadZipFile as err:\n        raise PackagingError(f\"Failed to extract PSADT archive: {err}\") from err\n    finally:\n        # Clean up .zip file\n        if zip_path.exists():\n            zip_path.unlink()\n\n    # Verify extracted structure\n    if not is_psadt_cached(version, cache_dir):\n        raise PackagingError(\n            f\"PSADT extraction failed: PSAppDeployToolkit/ folder \"\n            f\"not found in {version_dir}\"\n        )\n\n    logger.verbose(\"PSADT\", f\"PSADT {version} cached successfully\")\n\n    return version_dir\n</code></pre>"},{"location":"api/results/","title":"Results","text":""},{"location":"api/results/#notapkgtool.results","title":"notapkgtool.results","text":"<p>Public API return types for NAPT.</p> <p>This module defines dataclasses for return values from public API functions. These types represent the results of operations like discovery, building, packaging, and validation.</p> <p>All dataclasses are frozen (immutable) to prevent accidental mutation of return values.</p> Example <p>Using result types:     <pre><code>from pathlib import Path\nfrom notapkgtool.core import discover_recipe\nfrom notapkgtool.results import DiscoverResult\n\nresult: DiscoverResult = discover_recipe(\n    Path(\"recipes/Google/chrome.yaml\"),\n    Path(\"./downloads\")\n)\nprint(result.version)  # Attribute access, not dict access\n</code></pre></p> Note <p>Only public API return types belong in this module. Domain types (like DiscoveredVersion) and internal types (like LoadContext) should remain co-located with their related logic.</p>"},{"location":"api/results/#notapkgtool.results.DiscoverResult","title":"DiscoverResult  <code>dataclass</code>","text":"<p>Result from discovering a version and downloading an installer.</p> <p>Attributes:</p> Name Type Description <code>app_name</code> <code>str</code> <p>Application display name.</p> <code>app_id</code> <code>str</code> <p>Unique application identifier.</p> <code>strategy</code> <code>str</code> <p>Discovery strategy used (e.g., \"web_scrape\", \"api_github\").</p> <code>version</code> <code>str</code> <p>Extracted version string.</p> <code>version_source</code> <code>str</code> <p>How version was determined (e.g., \"regex_in_url\", \"msi\").</p> <code>file_path</code> <code>Path</code> <p>Path to the downloaded installer file.</p> <code>sha256</code> <code>str</code> <p>SHA-256 hash of the downloaded file.</p> <code>status</code> <code>str</code> <p>Always \"success\" for successful discovery.</p> Source code in <code>notapkgtool/results.py</code> <pre><code>@dataclass(frozen=True)\nclass DiscoverResult:\n    \"\"\"Result from discovering a version and downloading an installer.\n\n    Attributes:\n        app_name: Application display name.\n        app_id: Unique application identifier.\n        strategy: Discovery strategy used (e.g., \"web_scrape\", \"api_github\").\n        version: Extracted version string.\n        version_source: How version was determined (e.g., \"regex_in_url\", \"msi\").\n        file_path: Path to the downloaded installer file.\n        sha256: SHA-256 hash of the downloaded file.\n        status: Always \"success\" for successful discovery.\n    \"\"\"\n\n    app_name: str\n    app_id: str\n    strategy: str\n    version: str\n    version_source: str\n    file_path: Path\n    sha256: str\n    status: str\n</code></pre>"},{"location":"api/results/#notapkgtool.results.BuildResult","title":"BuildResult  <code>dataclass</code>","text":"<p>Result from building a PSADT package.</p> <p>Attributes:</p> Name Type Description <code>app_id</code> <code>str</code> <p>Unique application identifier.</p> <code>app_name</code> <code>str</code> <p>Application display name.</p> <code>version</code> <code>str</code> <p>Application version.</p> <code>build_dir</code> <code>Path</code> <p>Path to the build directory (packagefiles subdirectory).</p> <code>psadt_version</code> <code>str</code> <p>PSADT version used for the build.</p> <code>status</code> <code>str</code> <p>Build status (typically \"success\").</p> <code>detection_script_path</code> <code>Path | None</code> <p>Path to the generated detection script, if created. None if detection script generation was skipped or failed (and fail_on_error was False).</p> Source code in <code>notapkgtool/results.py</code> <pre><code>@dataclass(frozen=True)\nclass BuildResult:\n    \"\"\"Result from building a PSADT package.\n\n    Attributes:\n        app_id: Unique application identifier.\n        app_name: Application display name.\n        version: Application version.\n        build_dir: Path to the build directory (packagefiles subdirectory).\n        psadt_version: PSADT version used for the build.\n        status: Build status (typically \"success\").\n        detection_script_path: Path to the generated detection script, if\n            created. None if detection script generation was skipped or failed\n            (and fail_on_error was False).\n    \"\"\"\n\n    app_id: str\n    app_name: str\n    version: str\n    build_dir: Path\n    psadt_version: str\n    status: str\n    detection_script_path: Path | None = None\n</code></pre>"},{"location":"api/results/#notapkgtool.results.PackageResult","title":"PackageResult  <code>dataclass</code>","text":"<p>Result from creating a .intunewin package.</p> <p>Attributes:</p> Name Type Description <code>build_dir</code> <code>Path</code> <p>Path to the build directory.</p> <code>package_path</code> <code>Path</code> <p>Path to the created .intunewin file.</p> <code>app_id</code> <code>str</code> <p>Unique application identifier.</p> <code>version</code> <code>str</code> <p>Application version.</p> <code>status</code> <code>str</code> <p>Packaging status (typically \"success\").</p> Source code in <code>notapkgtool/results.py</code> <pre><code>@dataclass(frozen=True)\nclass PackageResult:\n    \"\"\"Result from creating a .intunewin package.\n\n    Attributes:\n        build_dir: Path to the build directory.\n        package_path: Path to the created .intunewin file.\n        app_id: Unique application identifier.\n        version: Application version.\n        status: Packaging status (typically \"success\").\n    \"\"\"\n\n    build_dir: Path\n    package_path: Path\n    app_id: str\n    version: str\n    status: str\n</code></pre>"},{"location":"api/results/#notapkgtool.results.ValidationResult","title":"ValidationResult  <code>dataclass</code>","text":"<p>Result from validating a recipe.</p> <p>Attributes:</p> Name Type Description <code>status</code> <code>str</code> <p>Validation status (\"valid\" or \"invalid\").</p> <code>errors</code> <code>list[str]</code> <p>List of error messages (empty if valid).</p> <code>warnings</code> <code>list[str]</code> <p>List of warning messages.</p> <code>app_count</code> <code>int</code> <p>Number of apps in the recipe.</p> <code>recipe_path</code> <code>str</code> <p>String path to the validated recipe file.</p> Source code in <code>notapkgtool/results.py</code> <pre><code>@dataclass(frozen=True)\nclass ValidationResult:\n    \"\"\"Result from validating a recipe.\n\n    Attributes:\n        status: Validation status (\"valid\" or \"invalid\").\n        errors: List of error messages (empty if valid).\n        warnings: List of warning messages.\n        app_count: Number of apps in the recipe.\n        recipe_path: String path to the validated recipe file.\n    \"\"\"\n\n    status: str\n    errors: list[str]\n    warnings: list[str]\n    app_count: int\n    recipe_path: str\n</code></pre>"},{"location":"api/state/","title":"state","text":""},{"location":"api/state/#notapkgtool.state","title":"notapkgtool.state","text":"<p>State tracking and version management for NAPT.</p> <p>This module provides state persistence for tracking discovered application versions, ETags, and file metadata between runs. This enables:</p> <ul> <li>Efficient conditional downloads (HTTP 304 Not Modified)</li> <li>Version change detection</li> <li>Bandwidth optimization for scheduled workflows</li> </ul> <p>The state file is a JSON file that stores:</p> <ul> <li>Discovered versions from vendors</li> <li>HTTP ETags and Last-Modified headers for conditional requests</li> <li>File paths and SHA-256 hashes for cached installers</li> <li>Last checked timestamps for monitoring</li> </ul> <p>State tracking is enabled by default and can be disabled with --stateless flag.</p> Example <p>Basic usage:</p> <pre><code>from pathlib import Path\nfrom notapkgtool.state import load_state, save_state\n\nstate = load_state(Path(\"state/versions.json\"))\n\napp_id = \"napt-chrome\"\ncache = state.get(\"apps\", {}).get(app_id)\n\nstate[\"apps\"][app_id] = {\n    \"url\": \"https://dl.google.com/chrome.msi\",\n    \"etag\": 'W/\"abc123\"',\n    \"sha256\": \"abc123...\",\n    \"known_version\": \"130.0.0\"\n}\n\nsave_state(state, Path(\"state/versions.json\"))\n</code></pre>"},{"location":"api/state/#notapkgtool.state.StateTracker","title":"StateTracker","text":"<p>Manages application state tracking with automatic persistence.</p> <p>This class provides a high-level interface for loading, querying, and updating the state file. It handles file I/O, error recovery, and provides convenience methods for common operations.</p> <p>Attributes:</p> Name Type Description <code>state_file</code> <p>Path to the JSON state file.</p> <code>state</code> <code>dict[str, Any]</code> <p>In-memory state dictionary.</p> Example <p>Basic usage:     <pre><code>from pathlib import Path\n\ntracker = StateTracker(Path(\"state/versions.json\"))\ntracker.load()\ncache = tracker.get_cache(\"napt-chrome\")\ntracker.update_cache(\n    \"napt-chrome\",\n    url=\"https://...\",\n    sha256=\"...\",\n    known_version=\"130.0.0\"\n)\ntracker.save()\n</code></pre></p> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>class StateTracker:\n    \"\"\"Manages application state tracking with automatic persistence.\n\n    This class provides a high-level interface for loading, querying, and\n    updating the state file. It handles file I/O, error recovery, and\n    provides convenience methods for common operations.\n\n    Attributes:\n        state_file: Path to the JSON state file.\n        state: In-memory state dictionary.\n\n    Example:\n        Basic usage:\n            ```python\n            from pathlib import Path\n\n            tracker = StateTracker(Path(\"state/versions.json\"))\n            tracker.load()\n            cache = tracker.get_cache(\"napt-chrome\")\n            tracker.update_cache(\n                \"napt-chrome\",\n                url=\"https://...\",\n                sha256=\"...\",\n                known_version=\"130.0.0\"\n            )\n            tracker.save()\n            ```\n\n    \"\"\"\n\n    def __init__(self, state_file: Path):\n        \"\"\"Initialize state tracker.\n\n        Args:\n            state_file: Path to JSON state file. Created if doesn't exist.\n\n        \"\"\"\n        self.state_file = state_file\n        self.state: dict[str, Any] = {}\n\n    def load(self) -&gt; dict[str, Any]:\n        \"\"\"Load state from file.\n\n        Creates default state structure if file doesn't exist.\n        Handles corrupted files by creating backup and starting fresh.\n\n        Returns:\n            Loaded state dictionary.\n\n        Raises:\n            OSError: If file permissions prevent reading.\n\n        \"\"\"\n        try:\n            self.state = load_state(self.state_file)\n        except FileNotFoundError:\n            # First run, create default state\n            self.state = create_default_state()\n            self.state_file.parent.mkdir(parents=True, exist_ok=True)\n            self.save()\n        except json.JSONDecodeError as err:\n            # Corrupted file, backup and create new\n            backup = self.state_file.with_suffix(\".json.backup\")\n            self.state_file.rename(backup)\n            self.state = create_default_state()\n            self.save()\n            raise PackagingError(\n                f\"Corrupted state file backed up to {backup}. \"\n                f\"Created fresh state file.\"\n            ) from err\n\n        return self.state\n\n    def save(self) -&gt; None:\n        \"\"\"Save current state to file.\n\n        Updates metadata.last_updated timestamp automatically.\n        Creates parent directories if needed.\n\n        Raises:\n            OSError: If file permissions prevent writing.\n\n        \"\"\"\n        # Update metadata\n        self.state.setdefault(\"metadata\", {})\n        self.state[\"metadata\"][\"last_updated\"] = datetime.now(UTC).isoformat()\n\n        # Ensure parent directory exists\n        self.state_file.parent.mkdir(parents=True, exist_ok=True)\n\n        save_state(self.state, self.state_file)\n\n    def get_cache(self, recipe_id: str) -&gt; dict[str, Any] | None:\n        \"\"\"Get cached information for a recipe.\n\n        Args:\n            recipe_id: Recipe identifier (from recipe's 'id' field).\n\n        Returns:\n            Cached data if available, None otherwise.\n\n        Example:\n            Retrieve cached information:\n                ```python\n                cache = tracker.get_cache(\"napt-chrome\")\n                if cache:\n                    etag = cache.get('etag')\n                    known_version = cache.get('known_version')\n                ```\n\n        \"\"\"\n        return self.state.get(\"apps\", {}).get(recipe_id)\n\n    def update_cache(\n        self,\n        recipe_id: str,\n        url: str,\n        sha256: str,\n        etag: str | None = None,\n        last_modified: str | None = None,\n        known_version: str | None = None,\n        strategy: str | None = None,\n    ) -&gt; None:\n        \"\"\"Update cached information for a recipe.\n\n        Args:\n            recipe_id: Recipe identifier.\n            url: Download URL for provenance tracking. For version-first strategies\n                (url_pattern, api_github, api_json), this is the actual download URL\n                from version_info. For file-first (url_download), this is source.url.\n            sha256: SHA-256 hash of file (for integrity checks).\n            etag: ETag header from download response. Used by url_download for HTTP 304\n                conditional requests. Saved but unused by version-first strategies.\n            last_modified: Last-Modified header from download response.\n                Used by url_download as fallback for conditional requests.\n                Saved but unused by version-first.\n            known_version: Version string. PRIMARY cache key for\n                version-first strategies (compared to skip downloads).\n                Informational only for url_download.\n            strategy: Discovery strategy used (for debugging).\n\n        Example:\n            Update cache entry:\n                ```python\n                tracker.update_cache(\n                    \"napt-chrome\",\n                    url=\"https://dl.google.com/chrome.msi\",\n                    sha256=\"abc123...\",\n                    etag='W/\"def456\"',\n                    known_version=\"130.0.0\"\n                )\n                ```\n\n        Note:\n            Schema v2: Removed file_path, last_checked, and renamed\n            version -&gt; known_version.\n\n            Field usage differs by strategy type:\n\n            - Version-first: known_version is PRIMARY cache key,\n                etag/last_modified unused\n            - File-first: etag/last_modified are PRIMARY cache keys,\n                known_version informational\n\n            Filesystem is the source of truth; state is for optimization only.\n\n        \"\"\"\n        if \"apps\" not in self.state:\n            self.state[\"apps\"] = {}\n\n        cache_entry = {\n            \"url\": url,\n            \"etag\": etag,\n            \"last_modified\": last_modified,\n            \"sha256\": sha256,\n        }\n\n        # Optional fields (only add if provided)\n        if known_version is not None:\n            cache_entry[\"known_version\"] = known_version\n        if strategy is not None:\n            cache_entry[\"strategy\"] = strategy\n\n        self.state[\"apps\"][recipe_id] = cache_entry\n\n    def has_version_changed(self, recipe_id: str, new_version: str) -&gt; bool:\n        \"\"\"Check if discovered version differs from cached known_version.\n\n        Args:\n            recipe_id: Recipe identifier.\n            new_version: Newly discovered version.\n\n        Returns:\n            True if version changed or no cached version exists.\n\n        Example:\n            Check if version has changed:\n                ```python\n                if tracker.has_version_changed(\"napt-chrome\", \"130.0.0\"):\n                    print(\"New version available!\")\n                ```\n\n        Note:\n            Uses 'known_version' field which is informational only.\n            Real version should be extracted from filesystem during build.\n\n        \"\"\"\n        cache = self.get_cache(recipe_id)\n        if not cache:\n            return True  # No cache, treat as changed\n\n        return cache.get(\"known_version\") != new_version\n</code></pre>"},{"location":"api/state/#notapkgtool.state.StateTracker.__init__","title":"__init__","text":"<pre><code>__init__(state_file: Path)\n</code></pre> <p>Initialize state tracker.</p> <p>Parameters:</p> Name Type Description Default <code>state_file</code> <code>Path</code> <p>Path to JSON state file. Created if doesn't exist.</p> required Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def __init__(self, state_file: Path):\n    \"\"\"Initialize state tracker.\n\n    Args:\n        state_file: Path to JSON state file. Created if doesn't exist.\n\n    \"\"\"\n    self.state_file = state_file\n    self.state: dict[str, Any] = {}\n</code></pre>"},{"location":"api/state/#notapkgtool.state.StateTracker.load","title":"load","text":"<pre><code>load() -&gt; dict[str, Any]\n</code></pre> <p>Load state from file.</p> <p>Creates default state structure if file doesn't exist. Handles corrupted files by creating backup and starting fresh.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Loaded state dictionary.</p> <p>Raises:</p> Type Description <code>OSError</code> <p>If file permissions prevent reading.</p> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def load(self) -&gt; dict[str, Any]:\n    \"\"\"Load state from file.\n\n    Creates default state structure if file doesn't exist.\n    Handles corrupted files by creating backup and starting fresh.\n\n    Returns:\n        Loaded state dictionary.\n\n    Raises:\n        OSError: If file permissions prevent reading.\n\n    \"\"\"\n    try:\n        self.state = load_state(self.state_file)\n    except FileNotFoundError:\n        # First run, create default state\n        self.state = create_default_state()\n        self.state_file.parent.mkdir(parents=True, exist_ok=True)\n        self.save()\n    except json.JSONDecodeError as err:\n        # Corrupted file, backup and create new\n        backup = self.state_file.with_suffix(\".json.backup\")\n        self.state_file.rename(backup)\n        self.state = create_default_state()\n        self.save()\n        raise PackagingError(\n            f\"Corrupted state file backed up to {backup}. \"\n            f\"Created fresh state file.\"\n        ) from err\n\n    return self.state\n</code></pre>"},{"location":"api/state/#notapkgtool.state.StateTracker.save","title":"save","text":"<pre><code>save() -&gt; None\n</code></pre> <p>Save current state to file.</p> <p>Updates metadata.last_updated timestamp automatically. Creates parent directories if needed.</p> <p>Raises:</p> Type Description <code>OSError</code> <p>If file permissions prevent writing.</p> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def save(self) -&gt; None:\n    \"\"\"Save current state to file.\n\n    Updates metadata.last_updated timestamp automatically.\n    Creates parent directories if needed.\n\n    Raises:\n        OSError: If file permissions prevent writing.\n\n    \"\"\"\n    # Update metadata\n    self.state.setdefault(\"metadata\", {})\n    self.state[\"metadata\"][\"last_updated\"] = datetime.now(UTC).isoformat()\n\n    # Ensure parent directory exists\n    self.state_file.parent.mkdir(parents=True, exist_ok=True)\n\n    save_state(self.state, self.state_file)\n</code></pre>"},{"location":"api/state/#notapkgtool.state.StateTracker.get_cache","title":"get_cache","text":"<pre><code>get_cache(recipe_id: str) -&gt; dict[str, Any] | None\n</code></pre> <p>Get cached information for a recipe.</p> <p>Parameters:</p> Name Type Description Default <code>recipe_id</code> <code>str</code> <p>Recipe identifier (from recipe's 'id' field).</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>Cached data if available, None otherwise.</p> Example <p>Retrieve cached information:     <pre><code>cache = tracker.get_cache(\"napt-chrome\")\nif cache:\n    etag = cache.get('etag')\n    known_version = cache.get('known_version')\n</code></pre></p> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def get_cache(self, recipe_id: str) -&gt; dict[str, Any] | None:\n    \"\"\"Get cached information for a recipe.\n\n    Args:\n        recipe_id: Recipe identifier (from recipe's 'id' field).\n\n    Returns:\n        Cached data if available, None otherwise.\n\n    Example:\n        Retrieve cached information:\n            ```python\n            cache = tracker.get_cache(\"napt-chrome\")\n            if cache:\n                etag = cache.get('etag')\n                known_version = cache.get('known_version')\n            ```\n\n    \"\"\"\n    return self.state.get(\"apps\", {}).get(recipe_id)\n</code></pre>"},{"location":"api/state/#notapkgtool.state.StateTracker.update_cache","title":"update_cache","text":"<pre><code>update_cache(recipe_id: str, url: str, sha256: str, etag: str | None = None, last_modified: str | None = None, known_version: str | None = None, strategy: str | None = None) -&gt; None\n</code></pre> <p>Update cached information for a recipe.</p> <p>Parameters:</p> Name Type Description Default <code>recipe_id</code> <code>str</code> <p>Recipe identifier.</p> required <code>url</code> <code>str</code> <p>Download URL for provenance tracking. For version-first strategies (url_pattern, api_github, api_json), this is the actual download URL from version_info. For file-first (url_download), this is source.url.</p> required <code>sha256</code> <code>str</code> <p>SHA-256 hash of file (for integrity checks).</p> required <code>etag</code> <code>str | None</code> <p>ETag header from download response. Used by url_download for HTTP 304 conditional requests. Saved but unused by version-first strategies.</p> <code>None</code> <code>last_modified</code> <code>str | None</code> <p>Last-Modified header from download response. Used by url_download as fallback for conditional requests. Saved but unused by version-first.</p> <code>None</code> <code>known_version</code> <code>str | None</code> <p>Version string. PRIMARY cache key for version-first strategies (compared to skip downloads). Informational only for url_download.</p> <code>None</code> <code>strategy</code> <code>str | None</code> <p>Discovery strategy used (for debugging).</p> <code>None</code> Example <p>Update cache entry:     <pre><code>tracker.update_cache(\n    \"napt-chrome\",\n    url=\"https://dl.google.com/chrome.msi\",\n    sha256=\"abc123...\",\n    etag='W/\"def456\"',\n    known_version=\"130.0.0\"\n)\n</code></pre></p> Note <p>Schema v2: Removed file_path, last_checked, and renamed version -&gt; known_version.</p> <p>Field usage differs by strategy type:</p> <ul> <li>Version-first: known_version is PRIMARY cache key,     etag/last_modified unused</li> <li>File-first: etag/last_modified are PRIMARY cache keys,     known_version informational</li> </ul> <p>Filesystem is the source of truth; state is for optimization only.</p> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def update_cache(\n    self,\n    recipe_id: str,\n    url: str,\n    sha256: str,\n    etag: str | None = None,\n    last_modified: str | None = None,\n    known_version: str | None = None,\n    strategy: str | None = None,\n) -&gt; None:\n    \"\"\"Update cached information for a recipe.\n\n    Args:\n        recipe_id: Recipe identifier.\n        url: Download URL for provenance tracking. For version-first strategies\n            (url_pattern, api_github, api_json), this is the actual download URL\n            from version_info. For file-first (url_download), this is source.url.\n        sha256: SHA-256 hash of file (for integrity checks).\n        etag: ETag header from download response. Used by url_download for HTTP 304\n            conditional requests. Saved but unused by version-first strategies.\n        last_modified: Last-Modified header from download response.\n            Used by url_download as fallback for conditional requests.\n            Saved but unused by version-first.\n        known_version: Version string. PRIMARY cache key for\n            version-first strategies (compared to skip downloads).\n            Informational only for url_download.\n        strategy: Discovery strategy used (for debugging).\n\n    Example:\n        Update cache entry:\n            ```python\n            tracker.update_cache(\n                \"napt-chrome\",\n                url=\"https://dl.google.com/chrome.msi\",\n                sha256=\"abc123...\",\n                etag='W/\"def456\"',\n                known_version=\"130.0.0\"\n            )\n            ```\n\n    Note:\n        Schema v2: Removed file_path, last_checked, and renamed\n        version -&gt; known_version.\n\n        Field usage differs by strategy type:\n\n        - Version-first: known_version is PRIMARY cache key,\n            etag/last_modified unused\n        - File-first: etag/last_modified are PRIMARY cache keys,\n            known_version informational\n\n        Filesystem is the source of truth; state is for optimization only.\n\n    \"\"\"\n    if \"apps\" not in self.state:\n        self.state[\"apps\"] = {}\n\n    cache_entry = {\n        \"url\": url,\n        \"etag\": etag,\n        \"last_modified\": last_modified,\n        \"sha256\": sha256,\n    }\n\n    # Optional fields (only add if provided)\n    if known_version is not None:\n        cache_entry[\"known_version\"] = known_version\n    if strategy is not None:\n        cache_entry[\"strategy\"] = strategy\n\n    self.state[\"apps\"][recipe_id] = cache_entry\n</code></pre>"},{"location":"api/state/#notapkgtool.state.StateTracker.has_version_changed","title":"has_version_changed","text":"<pre><code>has_version_changed(recipe_id: str, new_version: str) -&gt; bool\n</code></pre> <p>Check if discovered version differs from cached known_version.</p> <p>Parameters:</p> Name Type Description Default <code>recipe_id</code> <code>str</code> <p>Recipe identifier.</p> required <code>new_version</code> <code>str</code> <p>Newly discovered version.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if version changed or no cached version exists.</p> Example <p>Check if version has changed:     <pre><code>if tracker.has_version_changed(\"napt-chrome\", \"130.0.0\"):\n    print(\"New version available!\")\n</code></pre></p> Note <p>Uses 'known_version' field which is informational only. Real version should be extracted from filesystem during build.</p> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def has_version_changed(self, recipe_id: str, new_version: str) -&gt; bool:\n    \"\"\"Check if discovered version differs from cached known_version.\n\n    Args:\n        recipe_id: Recipe identifier.\n        new_version: Newly discovered version.\n\n    Returns:\n        True if version changed or no cached version exists.\n\n    Example:\n        Check if version has changed:\n            ```python\n            if tracker.has_version_changed(\"napt-chrome\", \"130.0.0\"):\n                print(\"New version available!\")\n            ```\n\n    Note:\n        Uses 'known_version' field which is informational only.\n        Real version should be extracted from filesystem during build.\n\n    \"\"\"\n    cache = self.get_cache(recipe_id)\n    if not cache:\n        return True  # No cache, treat as changed\n\n    return cache.get(\"known_version\") != new_version\n</code></pre>"},{"location":"api/state/#notapkgtool.state.load_state","title":"load_state","text":"<pre><code>load_state(state_file: Path) -&gt; dict[str, Any]\n</code></pre> <p>Load state from JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>state_file</code> <code>Path</code> <p>Path to JSON state file.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Loaded state dictionary.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If state file doesn't exist.</p> <code>JSONDecodeError</code> <p>If file contains invalid JSON.</p> <code>OSError</code> <p>If file cannot be read due to permissions.</p> Example <p>Load state from file:     <pre><code>from pathlib import Path\n\nstate = load_state(Path(\"state/versions.json\"))\napps = state.get(\"apps\", {})\n</code></pre></p> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def load_state(state_file: Path) -&gt; dict[str, Any]:\n    \"\"\"Load state from JSON file.\n\n    Args:\n        state_file: Path to JSON state file.\n\n    Returns:\n        Loaded state dictionary.\n\n    Raises:\n        FileNotFoundError: If state file doesn't exist.\n        json.JSONDecodeError: If file contains invalid JSON.\n        OSError: If file cannot be read due to permissions.\n\n    Example:\n        Load state from file:\n            ```python\n            from pathlib import Path\n\n            state = load_state(Path(\"state/versions.json\"))\n            apps = state.get(\"apps\", {})\n            ```\n\n    \"\"\"\n    with open(state_file, encoding=\"utf-8\") as f:\n        return json.load(f)\n</code></pre>"},{"location":"api/state/#notapkgtool.state.save_state","title":"save_state","text":"<pre><code>save_state(state: dict[str, Any], state_file: Path) -&gt; None\n</code></pre> <p>Save state to JSON file with pretty-printing.</p> <p>Creates parent directories if needed. Uses 2-space indentation and sorted keys for consistent diffs in version control.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>dict[str, Any]</code> <p>State dictionary to save.</p> required <code>state_file</code> <code>Path</code> <p>Path to JSON state file.</p> required <p>Raises:</p> Type Description <code>OSError</code> <p>If file cannot be written due to permissions.</p> Example <p>Save state to file:     <pre><code>from pathlib import Path\n\nstate = {\"metadata\": {}, \"apps\": {}}\nsave_state(state, Path(\"state/versions.json\"))\n</code></pre></p> Note <ul> <li>Uses 2-space indentation for readability</li> <li>Sorts keys alphabetically for consistent diffs</li> <li>Adds trailing newline for git compatibility</li> </ul> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def save_state(state: dict[str, Any], state_file: Path) -&gt; None:\n    \"\"\"Save state to JSON file with pretty-printing.\n\n    Creates parent directories if needed. Uses 2-space indentation\n    and sorted keys for consistent diffs in version control.\n\n    Args:\n        state: State dictionary to save.\n        state_file: Path to JSON state file.\n\n    Raises:\n        OSError: If file cannot be written due to permissions.\n\n    Example:\n        Save state to file:\n            ```python\n            from pathlib import Path\n\n            state = {\"metadata\": {}, \"apps\": {}}\n            save_state(state, Path(\"state/versions.json\"))\n            ```\n\n    Note:\n        - Uses 2-space indentation for readability\n        - Sorts keys alphabetically for consistent diffs\n        - Adds trailing newline for git compatibility\n\n    \"\"\"\n    state_file.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(state_file, \"w\", encoding=\"utf-8\") as f:\n        json.dump(state, f, indent=2, sort_keys=True)\n        f.write(\"\\n\")  # Trailing newline for git\n</code></pre>"},{"location":"api/validation/","title":"validation","text":""},{"location":"api/validation/#notapkgtool.validation","title":"notapkgtool.validation","text":"<p>Recipe validation module.</p> <p>This module provides validation functions for checking recipe syntax and configuration without making network calls or downloading files. This is useful for quick feedback during recipe development and in CI/CD pipelines.</p> <p>Validation Checks:</p> <ul> <li>YAML syntax is valid</li> <li>Required top-level fields present (apiVersion, app)</li> <li>apiVersion is supported</li> <li>App has required fields (name, id, source)</li> <li>Discovery strategy exists and is registered</li> <li>Strategy-specific configuration is valid</li> </ul> Example <p>Validate a recipe and handle results:     <pre><code>from pathlib import Path\nfrom notapkgtool.validation import validate_recipe\n\nresult = validate_recipe(Path(\"recipes/Google/chrome.yaml\"))\nif result.status == \"valid\":\n    print(f\"Recipe is valid with {result.app_count} app(s)\")\nelse:\n    for error in result.errors:\n        print(f\"Error: {error}\")\n</code></pre></p>"},{"location":"api/validation/#notapkgtool.validation.validate_recipe","title":"validate_recipe","text":"<pre><code>validate_recipe(recipe_path: Path) -&gt; ValidationResult\n</code></pre> <p>Validate a recipe file without downloading anything.</p> <p>This function checks:</p> <ol> <li>YAML file can be parsed</li> <li>Required top-level fields are present</li> <li>apiVersion is supported</li> <li>App has required fields</li> <li>Discovery strategies exist</li> <li>Strategy-specific configuration is valid</li> </ol> <p>Does NOT:</p> <ul> <li>Make network calls</li> <li>Download files</li> <li>Verify URLs are accessible</li> <li>Check if versions can be extracted</li> </ul> <p>Parameters:</p> Name Type Description Default <code>recipe_path</code> <code>Path</code> <p>Path to the recipe YAML file to validate.</p> required <p>Returns:</p> Type Description <code>ValidationResult</code> <p>ValidationResult dataclass with the following fields:</p> <ul> <li>status (str): Validation status, either \"valid\" (no errors) or \"invalid\"     (has errors). Warnings do not affect status.</li> <li>errors (list[str]): List of error messages found during validation. Empty     list if recipe is valid. Each error describes a specific validation     failure (e.g., missing required field, invalid strategy configuration).</li> <li>warnings (list[str]): List of warning messages found during validation.     Warnings indicate potential issues but do not prevent validation from     passing (e.g., unsupported apiVersion, deprecated configuration).</li> <li>app_count (int): Always 1 for valid recipes (single app format). Zero if recipe     structure is invalid.</li> <li>recipe_path (str): String path to the validated recipe file, useful for     error reporting and logging.</li> </ul> Example <p>Validate a recipe and check results:     <pre><code>from pathlib import Path\n\nresult = validate_recipe(Path(\"recipes/app.yaml\"))\nif result.status == \"valid\":\n    print(\"Recipe is valid!\")\nelse:\n    for error in result.errors:\n        print(f\"Error: {error}\")\n</code></pre></p> Source code in <code>notapkgtool/validation.py</code> <pre><code>def validate_recipe(recipe_path: Path) -&gt; ValidationResult:\n    \"\"\"Validate a recipe file without downloading anything.\n\n    This function checks:\n\n    1. YAML file can be parsed\n    2. Required top-level fields are present\n    3. apiVersion is supported\n    4. App has required fields\n    5. Discovery strategies exist\n    6. Strategy-specific configuration is valid\n\n    Does NOT:\n\n    - Make network calls\n    - Download files\n    - Verify URLs are accessible\n    - Check if versions can be extracted\n\n    Args:\n        recipe_path: Path to the recipe YAML file to validate.\n\n    Returns:\n        ValidationResult dataclass with the following fields:\n\n            - status (str): Validation status, either \"valid\" (no errors) or \"invalid\"\n                (has errors). Warnings do not affect status.\n            - errors (list[str]): List of error messages found during validation. Empty\n                list if recipe is valid. Each error describes a specific validation\n                failure (e.g., missing required field, invalid strategy configuration).\n            - warnings (list[str]): List of warning messages found during validation.\n                Warnings indicate potential issues but do not prevent validation from\n                passing (e.g., unsupported apiVersion, deprecated configuration).\n            - app_count (int): Always 1 for valid recipes (single app format). Zero if recipe\n                structure is invalid.\n            - recipe_path (str): String path to the validated recipe file, useful for\n                error reporting and logging.\n\n    Example:\n        Validate a recipe and check results:\n            ```python\n            from pathlib import Path\n\n            result = validate_recipe(Path(\"recipes/app.yaml\"))\n            if result.status == \"valid\":\n                print(\"Recipe is valid!\")\n            else:\n                for error in result.errors:\n                    print(f\"Error: {error}\")\n            ```\n\n    \"\"\"\n    logger = get_global_logger()\n\n    errors = []\n    warnings = []\n    app_count = 0\n\n    logger.verbose(\"VALIDATION\", f\"Validating recipe: {recipe_path}\")\n\n    # Check file exists\n    if not recipe_path.exists():\n        errors.append(f\"Recipe file not found: {recipe_path}\")\n        return ValidationResult(\n            status=\"invalid\",\n            errors=errors,\n            warnings=warnings,\n            app_count=0,\n            recipe_path=str(recipe_path),\n        )\n\n    # Parse YAML\n    try:\n        with open(recipe_path, encoding=\"utf-8\") as f:\n            recipe = yaml.safe_load(f)\n    except yaml.YAMLError as err:\n        errors.append(f\"Invalid YAML syntax: {err}\")\n        return ValidationResult(\n            status=\"invalid\",\n            errors=errors,\n            warnings=warnings,\n            app_count=0,\n            recipe_path=str(recipe_path),\n        )\n    except Exception as err:\n        errors.append(f\"Failed to read recipe file: {err}\")\n        return ValidationResult(\n            status=\"invalid\",\n            errors=errors,\n            warnings=warnings,\n            app_count=0,\n            recipe_path=str(recipe_path),\n        )\n\n    logger.verbose(\"VALIDATION\", \"YAML syntax is valid\")\n\n    # Validate recipe is a dict\n    if not isinstance(recipe, dict):\n        errors.append(\"Recipe must be a YAML dictionary/mapping\")\n        return ValidationResult(\n            status=\"invalid\",\n            errors=errors,\n            warnings=warnings,\n            app_count=0,\n            recipe_path=str(recipe_path),\n        )\n\n    # Check apiVersion\n    if \"apiVersion\" not in recipe:\n        errors.append(\"Missing required field: apiVersion\")\n    else:\n        api_version = recipe[\"apiVersion\"]\n        if not isinstance(api_version, str):\n            errors.append(\"apiVersion must be a string\")\n        elif api_version != \"napt/v1\":\n            warnings.append(\n                f\"apiVersion '{api_version}' may not be supported (expected: napt/v1)\"\n            )\n        if not errors:\n            logger.verbose(\"VALIDATION\", f\"apiVersion: {api_version}\")\n\n    # Check app field\n    app = recipe.get(\"app\")\n    if not app:\n        errors.append(\"Field 'app' is required\")\n        return ValidationResult(\n            status=\"invalid\",\n            errors=errors,\n            warnings=warnings,\n            app_count=0,\n            recipe_path=str(recipe_path),\n        )\n\n    if not isinstance(app, dict):\n        errors.append(\"Field 'app' must be a dictionary\")\n        return ValidationResult(\n            status=\"invalid\",\n            errors=errors,\n            warnings=warnings,\n            app_count=0,\n            recipe_path=str(recipe_path),\n        )\n\n    app_prefix = \"app\"\n\n    logger.verbose(\"VALIDATION\", f\"Found app: {app.get('name', 'unnamed')}\")\n\n    # Check required fields\n    for field in [\"name\", \"id\", \"source\"]:\n        if field not in app:\n            errors.append(f\"{app_prefix}: Missing required field: {field}\")\n\n    # Validate name\n    if \"name\" in app and not isinstance(app[\"name\"], str):\n        errors.append(f\"{app_prefix}: Field 'name' must be a string\")\n\n    # Validate id\n    if \"id\" in app:\n        if not isinstance(app[\"id\"], str):\n            errors.append(f\"{app_prefix}: Field 'id' must be a string\")\n        elif not app[\"id\"]:\n            errors.append(f\"{app_prefix}: Field 'id' cannot be empty\")\n\n    # Validate source\n    if \"source\" not in app:\n        # Already reported missing field, but continue to check other things\n        pass\n    else:\n        source = app[\"source\"]\n        if not isinstance(source, dict):\n            errors.append(f\"{app_prefix}.source: Must be a dictionary\")\n        else:\n            # Check strategy field\n            if \"strategy\" not in source:\n                errors.append(f\"{app_prefix}.source: Missing required field: strategy\")\n            else:\n                strategy_name = source[\"strategy\"]\n                if not isinstance(strategy_name, str):\n                    errors.append(f\"{app_prefix}.source.strategy: Must be a string\")\n                else:\n                    logger.verbose(\n                        \"VALIDATION\",\n                        f\"App '{app.get('name', 'unnamed')}' uses strategy: {strategy_name}\",\n                    )\n\n                    # Check if strategy exists\n                    try:\n                        strategy = get_strategy(strategy_name)\n                    except ConfigError as err:\n                        errors.append(f\"{app_prefix}.source.strategy: {err}\")\n                    else:\n                        # Validate strategy-specific configuration\n                        if hasattr(strategy, \"validate_config\"):\n                            try:\n                                config_errors = strategy.validate_config(app)\n                                for error in config_errors:\n                                    errors.append(f\"{app_prefix}: {error}\")\n                            except Exception as err:\n                                errors.append(\n                                    f\"{app_prefix}: Strategy validation failed: {err}\"\n                                )\n\n    # Determine final status\n    status = \"valid\" if len(errors) == 0 else \"invalid\"\n    app_count = 1 if status == \"valid\" else 0\n\n    if status == \"valid\":\n        logger.verbose(\"VALIDATION\", \"Recipe is valid!\")\n    else:\n        logger.verbose(\"VALIDATION\", f\"Recipe has {len(errors)} error(s)\")\n\n    return ValidationResult(\n        status=status,\n        errors=errors,\n        warnings=warnings,\n        app_count=app_count,\n        recipe_path=str(recipe_path),\n    )\n</code></pre>"},{"location":"api/versioning/","title":"versioning","text":""},{"location":"api/versioning/#notapkgtool.versioning.keys","title":"notapkgtool.versioning.keys","text":"<p>Core version comparison utilities for NAPT.</p> <p>This module is format-agnostic: it does NOT download or read files. It only parses and compares version strings consistently across sources (MSI, EXE, generic strings).</p>"},{"location":"api/versioning/#notapkgtool.versioning.keys.DiscoveredVersion","title":"DiscoveredVersion  <code>dataclass</code>","text":"<p>Container for a discovered version string.</p> <p>Attributes:</p> Name Type Description <code>version</code> <code>str</code> <p>Raw version string (e.g., \"140.0.7339.128\").</p> <code>source</code> <code>str</code> <p>Where it came from (e.g., \"regex_in_url\", \"msi\").</p> Source code in <code>notapkgtool/versioning/keys.py</code> <pre><code>@dataclass(frozen=True)\nclass DiscoveredVersion:\n    \"\"\"Container for a discovered version string.\n\n    Attributes:\n        version: Raw version string (e.g., \"140.0.7339.128\").\n        source: Where it came from (e.g., \"regex_in_url\", \"msi\").\n\n    \"\"\"\n\n    version: str\n    source: str\n</code></pre>"},{"location":"api/versioning/#notapkgtool.versioning.keys.VersionInfo","title":"VersionInfo  <code>dataclass</code>","text":"<p>Container for version information discovered without downloading.</p> <p>Used by version-first strategies (web_scrape, api_github, api_json) that can determine version and download URL without fetching the installer.</p> <p>Attributes:</p> Name Type Description <code>version</code> <code>str</code> <p>Raw version string (e.g., \"140.0.7339.128\").</p> <code>download_url</code> <code>str</code> <p>URL to download the installer.</p> <code>source</code> <code>str</code> <p>Strategy name for logging (e.g., \"web_scrape\", \"api_github\").</p> Source code in <code>notapkgtool/versioning/keys.py</code> <pre><code>@dataclass(frozen=True)\nclass VersionInfo:\n    \"\"\"Container for version information discovered without downloading.\n\n    Used by version-first strategies (web_scrape, api_github, api_json)\n    that can determine version and download URL without fetching the installer.\n\n    Attributes:\n        version: Raw version string (e.g., \"140.0.7339.128\").\n        download_url: URL to download the installer.\n        source: Strategy name for logging (e.g., \"web_scrape\", \"api_github\").\n\n    \"\"\"\n\n    version: str\n    download_url: str\n    source: str\n</code></pre>"},{"location":"api/versioning/#notapkgtool.versioning.keys.version_key_any","title":"version_key_any","text":"<pre><code>version_key_any(s: str, *, source: SourceHint = 'string') -&gt; tuple\n</code></pre> <p>Compute a comparable key for any version string.</p> <ul> <li>MSI/EXE: purely numeric (truncated to 3/4 parts).</li> <li>Generic string: semver-like robust key; if no numeric prefix,     fallback to (\"text\", raw).</li> </ul> Source code in <code>notapkgtool/versioning/keys.py</code> <pre><code>def version_key_any(s: str, *, source: SourceHint = \"string\") -&gt; tuple:\n    \"\"\"Compute a comparable key for any version string.\n\n    - MSI/EXE: purely numeric (truncated to 3/4 parts).\n    - Generic string: semver-like robust key; if no numeric prefix,\n        fallback to (\"text\", raw).\n    \"\"\"\n    if source in (\"msi\", \"exe\"):\n        nums = _clip_for_source(_ints_from_text(s), source)\n        return (\"num\", nums)\n\n    key = _semver_like_key_robust(s)\n    release = key[0]\n    if release != (0,):\n        # IMPORTANT: We do NOT include the raw string as a tiebreaker.\n        # This makes \"v1.2.3\" == \"1.2.3\" when the parsed keys are equal.\n        return (\"semverish\", key)\n\n    return (\"text\", s)\n</code></pre>"},{"location":"api/versioning/#notapkgtool.versioning.keys.compare_any","title":"compare_any","text":"<pre><code>compare_any(a: str, b: str, *, source: SourceHint = 'string') -&gt; int\n</code></pre> <p>Compare two versions with a source hint. Returns -1 if a &lt; b, 0 if equal, 1 if a &gt; b.</p> Source code in <code>notapkgtool/versioning/keys.py</code> <pre><code>def compare_any(\n    a: str,\n    b: str,\n    *,\n    source: SourceHint = \"string\",\n) -&gt; int:\n    \"\"\"Compare two versions with a source hint.\n    Returns -1 if a &lt; b, 0 if equal, 1 if a &gt; b.\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n\n    if source in (\"msi\", \"exe\"):\n        try:\n            aa = _clip_for_source(_ints_from_text(a), source)\n            bb = _clip_for_source(_ints_from_text(b), source)\n            aa, bb = _pad_equal(aa, bb)\n            result = (aa &gt; bb) - (aa &lt; bb)\n        except ValueError:\n            # If vendor sneaks letters into numeric fields, fallback to generic parsing.\n            ka = version_key_any(a, source=\"string\")\n            kb = version_key_any(b, source=\"string\")\n            result = (ka &gt; kb) - (ka &lt; kb)\n    else:\n        ka = version_key_any(a, source=\"string\")\n        kb = version_key_any(b, source=\"string\")\n        result = (ka &gt; kb) - (ka &lt; kb)\n\n    # Log comparison result if verbose mode is enabled\n    if result &lt; 0:\n        logger.verbose(\"VERSION\", f\"{a!r} is older than {b!r} (source={source})\")\n    elif result &gt; 0:\n        logger.verbose(\"VERSION\", f\"{a!r} is newer than {b!r} (source={source})\")\n    else:\n        logger.verbose(\"VERSION\", f\"{a!r} is the same as {b!r} (source={source})\")\n    return result\n</code></pre>"},{"location":"api/versioning/#notapkgtool.versioning.keys.is_newer_any","title":"is_newer_any","text":"<pre><code>is_newer_any(remote: str, current: str | None, *, source: SourceHint = 'string') -&gt; bool\n</code></pre> <p>Decide if 'remote' should be considered newer than 'current'. Returns True iff remote &gt; current under the given source semantics.</p> Source code in <code>notapkgtool/versioning/keys.py</code> <pre><code>def is_newer_any(\n    remote: str,\n    current: str | None,\n    *,\n    source: SourceHint = \"string\",\n) -&gt; bool:\n    \"\"\"Decide if 'remote' should be considered newer than 'current'.\n    Returns True iff remote &gt; current under the given source semantics.\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n\n    if current is None:\n        logger.verbose(\n            \"VERSION\",\n            f\"No current version. Treat {remote!r} as newer (source={source})\",\n        )\n        return True\n\n    cmpv = compare_any(remote, current, source=source)\n    # Note: compare_any() already logs the comparison result, so we don't need to log again here\n    return cmpv &gt; 0\n</code></pre>"},{"location":"api/versioning/#notapkgtool.versioning.msi","title":"notapkgtool.versioning.msi","text":"<p>MSI ProductVersion extraction for NAPT.</p> <p>This module extracts the ProductVersion property from Windows Installer (MSI) database files. It tries multiple backends in order of preference to maximize cross-platform compatibility.</p> <p>Backend Priority:</p> <p>On Windows:</p> <ol> <li>msilib (Python standard library, Python 3.10 and earlier only - removed in 3.13)</li> <li>_msi (CPython extension module, Windows-specific)</li> <li>PowerShell COM (Windows Installer COM API, always available)</li> </ol> <p>On Linux/macOS:</p> <ol> <li> <p>msiinfo (from msitools package, must be installed separately)</p> <p>The PowerShell fallback makes this truly universal on Windows systems, even when Python MSI libraries aren't available.</p> </li> </ol> <p>Installation Requirements:</p> <p>Windows:</p> <ul> <li>No additional packages required (PowerShell fallback always works)</li> <li>Optional: Ensure msilib is available for better performance</li> </ul> <p>Linux/macOS:</p> <ul> <li>Install msitools package:<ul> <li>Debian/Ubuntu: <code>sudo apt-get install msitools</code></li> <li>RHEL/Fedora: <code>sudo dnf install msitools</code></li> <li>macOS: <code>brew install msitools</code></li> </ul> </li> </ul> Example <p>Extract version from MSI:     <pre><code>from pathlib import Path\nfrom notapkgtool.versioning.msi import version_from_msi_product_version\ndiscovered = version_from_msi_product_version(\"chrome.msi\")\nprint(f\"{discovered.version} from {discovered.source}\")\n# 141.0.7390.123 from msi\n</code></pre></p> <p>Error handling:     <pre><code>try:\n    discovered = version_from_msi_product_version(\"missing.msi\")\nexcept PackagingError as e:\n    print(f\"Extraction failed: {e}\")\n</code></pre></p> Note <p>This is pure file introspection; no network calls are made. All backends query the MSI Property table for ProductVersion. The PowerShell approach uses COM (WindowsInstaller.Installer). Errors are chained for debugging (check 'from err' clause).</p>"},{"location":"api/versioning/#notapkgtool.versioning.msi.MSIMetadata","title":"MSIMetadata  <code>dataclass</code>","text":"<p>MSI Property table metadata.</p> <p>Attributes:</p> Name Type Description <code>product_name</code> <code>str</code> <p>ProductName from MSI (display name).</p> <code>product_version</code> <code>str</code> <p>ProductVersion from MSI.</p> Source code in <code>notapkgtool/versioning/msi.py</code> <pre><code>@dataclass(frozen=True)\nclass MSIMetadata:\n    \"\"\"MSI Property table metadata.\n\n    Attributes:\n        product_name: ProductName from MSI (display name).\n        product_version: ProductVersion from MSI.\n\n    \"\"\"\n\n    product_name: str\n    product_version: str\n</code></pre>"},{"location":"api/versioning/#notapkgtool.versioning.msi.version_from_msi_product_version","title":"version_from_msi_product_version","text":"<pre><code>version_from_msi_product_version(file_path: str | Path) -&gt; DiscoveredVersion\n</code></pre> <p>Extract ProductVersion from an MSI file.</p> <p>Uses cross-platform backends to read the MSI Property table. On Windows, tries msilib (Python 3.10 and earlier - removed in 3.13), _msi extension, then PowerShell COM API as universal fallback. On Linux/macOS, requires msitools package.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | Path</code> <p>Path to the MSI file.</p> required <p>Returns:</p> Type Description <code>DiscoveredVersion</code> <p>Discovered version with source information.</p> <p>Raises:</p> Type Description <code>PackagingError</code> <p>If the MSI file doesn't exist or version extraction fails.</p> <code>NotImplementedError</code> <p>If no extraction backend is available on this system.</p> Source code in <code>notapkgtool/versioning/msi.py</code> <pre><code>def version_from_msi_product_version(\n    file_path: str | Path,\n) -&gt; DiscoveredVersion:\n    \"\"\"Extract ProductVersion from an MSI file.\n\n    Uses cross-platform backends to read the MSI Property table. On Windows,\n    tries msilib (Python 3.10 and earlier - removed in 3.13), _msi extension,\n    then PowerShell COM API as universal fallback. On Linux/macOS, requires\n    msitools package.\n\n    Args:\n        file_path: Path to the MSI file.\n\n    Returns:\n        Discovered version with source information.\n\n    Raises:\n        PackagingError: If the MSI file doesn't exist or version extraction fails.\n        NotImplementedError: If no extraction backend is available on this system.\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    p = Path(file_path)\n    if not p.exists():\n        raise PackagingError(f\"MSI not found: {p}\")\n\n    logger.verbose(\"VERSION\", \"Strategy: msi\")\n    logger.verbose(\"VERSION\", f\"Extracting version from: {p.name}\")\n\n    # Try msilib first (standard library on Windows)\n    if sys.platform.startswith(\"win\") and msilib is not None:\n        logger.debug(\"VERSION\", \"Trying backend: msilib...\")\n        try:\n            db = msilib.OpenDatabase(str(p), msilib.MSIDBOPEN_READONLY)\n            view = db.OpenView(\n                \"SELECT `Value` FROM `Property` WHERE `Property`='ProductVersion'\"\n            )\n            view.Execute(None)\n            rec = view.Fetch()\n            if rec is None:\n                db.Close()\n                raise PackagingError(\"ProductVersion not found in MSI Property table.\")\n            version = rec.GetString(1)\n            db.Close()\n            if not version:\n                raise PackagingError(\"Empty ProductVersion in MSI Property table.\")\n            logger.verbose(\"VERSION\", f\"Success! Extracted: {version} (via msilib)\")\n            return DiscoveredVersion(version=version, source=\"msi\")\n        except Exception as err:\n            logger.debug(\"VERSION\", \"msilib failed, trying next backend...\")\n            raise PackagingError(\n                f\"failed to read MSI ProductVersion via msilib: {err}\"\n            ) from err\n\n    # Try _msi module (alternative Windows approach)\n    if sys.platform.startswith(\"win\"):\n        logger.debug(\"VERSION\", \"Trying backend: _msi...\")\n        try:\n            import _msi  # type: ignore\n        except ImportError:\n            # _msi not available, fall through to msiinfo\n            logger.debug(\"VERSION\", \"_msi not available, trying next backend...\")\n            pass\n        else:\n            try:\n                db = _msi.OpenDatabase(str(p), 0)  # 0: read-only\n                view = db.OpenView(\n                    \"SELECT `Value` FROM `Property` WHERE `Property`='ProductVersion'\"\n                )\n                view.Execute(None)\n                rec = view.Fetch()\n                if rec is None:\n                    raise PackagingError(\n                        \"ProductVersion not found in MSI Property table.\"\n                    )\n                version = rec.GetString(1)\n                if not version:\n                    raise PackagingError(\"Empty ProductVersion in MSI Property table.\")\n                view.Close()\n                db.Close()\n                logger.verbose(\"VERSION\", f\"Success! Extracted: {version} (via _msi)\")\n                return DiscoveredVersion(version=version, source=\"msi\")\n            except Exception as err:\n                logger.debug(\"VERSION\", \"_msi failed, trying next backend...\")\n                raise PackagingError(\n                    f\"failed to read MSI ProductVersion via _msi: {err}\"\n                ) from err\n\n    # Try PowerShell with Windows Installer COM on Windows\n    if sys.platform.startswith(\"win\"):\n        logger.debug(\"VERSION\", \"Trying backend: PowerShell COM...\")\n        try:\n            ps_script = f\"\"\"\n$installer = New-Object -ComObject WindowsInstaller.Installer\n$db = $installer.OpenDatabase('{p}', 0)\n$view = $db.OpenView(\"SELECT Value FROM Property WHERE Property='ProductVersion'\")\n$view.Execute()\n$record = $view.Fetch()\nif ($record) {{\n    $record.StringData(1)\n}} else {{\n    Write-Error \"ProductVersion not found\"\n    exit 1\n}}\n\"\"\"\n            result = subprocess.run(\n                [\"powershell\", \"-NoProfile\", \"-NonInteractive\", \"-Command\", ps_script],\n                check=True,\n                capture_output=True,\n                text=True,\n                timeout=10,\n            )\n            version = result.stdout.strip()\n            if version:\n                logger.verbose(\n                    \"VERSION\", f\"Success! Extracted: {version} (via PowerShell COM)\"\n                )\n                return DiscoveredVersion(version=version, source=\"msi\")\n        except subprocess.CalledProcessError as err:\n            logger.debug(\"VERSION\", \"PowerShell COM failed, trying next backend...\")\n            raise PackagingError(f\"PowerShell MSI query failed: {err}\") from err\n        except subprocess.TimeoutExpired:\n            logger.debug(\"VERSION\", \"PowerShell COM timed out, trying next backend...\")\n            raise PackagingError(\"PowerShell MSI query timed out\") from None\n\n    # Try msiinfo on Linux/macOS\n    msiinfo = shutil.which(\"msiinfo\")\n    if msiinfo:\n        logger.debug(\"VERSION\", \"Trying backend: msiinfo (msitools)...\")\n        try:\n            # msiinfo export &lt;package&gt; Property -&gt; stdout (tab-separated)\n            result = subprocess.run(\n                [msiinfo, \"export\", str(p), \"Property\"],\n                check=True,\n                capture_output=True,\n                text=True,\n            )\n            version_str: str | None = None\n            for line in result.stdout.splitlines():\n                parts = line.strip().split(\"\\t\", 1)  # \"Property&lt;TAB&gt;Value\"\n                if len(parts) == 2 and parts[0] == \"ProductVersion\":\n                    version_str = parts[1]\n                    break\n            if not version_str:\n                raise PackagingError(\"ProductVersion not found in MSI Property output.\")\n            logger.verbose(\n                \"VERSION\", f\"Success! Extracted: {version_str} (via msiinfo)\"\n            )\n            return DiscoveredVersion(version=version_str, source=\"msi\")\n        except subprocess.CalledProcessError as err:\n            logger.debug(\"VERSION\", \"msiinfo failed\")\n            raise PackagingError(f\"msiinfo failed: {err}\") from err\n\n    logger.debug(\"VERSION\", \"No MSI extraction backend available on this system\")\n    raise NotImplementedError(\n        \"MSI version extraction is not available on this host. \"\n        \"On Windows, ensure PowerShell is available. \"\n        \"On Linux/macOS, install 'msitools'.\"\n    )\n</code></pre>"},{"location":"api/versioning/#notapkgtool.versioning.msi.extract_msi_metadata","title":"extract_msi_metadata","text":"<pre><code>extract_msi_metadata(file_path: str | Path) -&gt; MSIMetadata\n</code></pre> <p>Extract ProductName and ProductVersion from MSI file.</p> <p>Uses cross-platform backends to read the MSI Property table. On Windows, tries msilib (Python 3.10 and earlier - removed in 3.13), _msi extension, then PowerShell COM API as universal fallback. On Linux/macOS, requires msitools package.</p> <p>This function extracts multiple properties in one pass for efficiency.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | Path</code> <p>Path to the MSI file.</p> required <p>Returns:</p> Type Description <code>MSIMetadata</code> <p>MSIMetadata with product information.</p> <p>Raises:</p> Type Description <code>PackagingError</code> <p>If the MSI file doesn't exist or metadata extraction fails.</p> <code>NotImplementedError</code> <p>If no extraction backend is available on this system.</p> Example <p>Extract MSI metadata:     <pre><code>from pathlib import Path\nfrom notapkgtool.versioning.msi import extract_msi_metadata\n\nmetadata = extract_msi_metadata(Path(\"chrome.msi\"))\nprint(f\"{metadata.product_name} {metadata.product_version}\")\n# Google Chrome 131.0.6778.86\n</code></pre></p> Note <p>ProductName may be empty string if not found in MSI. This is handled gracefully - build phase will fallback to recipe AppName if ProductName is empty.</p> Source code in <code>notapkgtool/versioning/msi.py</code> <pre><code>def extract_msi_metadata(file_path: str | Path) -&gt; MSIMetadata:\n    \"\"\"Extract ProductName and ProductVersion from MSI file.\n\n    Uses cross-platform backends to read the MSI Property table. On Windows,\n    tries msilib (Python 3.10 and earlier - removed in 3.13), _msi extension,\n    then PowerShell COM API as universal fallback. On Linux/macOS, requires\n    msitools package.\n\n    This function extracts multiple properties in one pass for efficiency.\n\n    Args:\n        file_path: Path to the MSI file.\n\n    Returns:\n        MSIMetadata with product information.\n\n    Raises:\n        PackagingError: If the MSI file doesn't exist or metadata extraction\n            fails.\n        NotImplementedError: If no extraction backend is available on this\n            system.\n\n    Example:\n        Extract MSI metadata:\n            ```python\n            from pathlib import Path\n            from notapkgtool.versioning.msi import extract_msi_metadata\n\n            metadata = extract_msi_metadata(Path(\"chrome.msi\"))\n            print(f\"{metadata.product_name} {metadata.product_version}\")\n            # Google Chrome 131.0.6778.86\n            ```\n\n    Note:\n        ProductName may be empty string if not found in MSI. This is handled\n        gracefully - build phase will fallback to recipe AppName if ProductName\n        is empty.\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    p = Path(file_path)\n    if not p.exists():\n        raise PackagingError(f\"MSI not found: {p}\")\n\n    logger.verbose(\"MSI\", f\"Extracting metadata from: {p.name}\")\n\n    # Try msilib first (standard library on Windows)\n    if sys.platform.startswith(\"win\") and msilib is not None:\n        logger.debug(\"MSI\", \"Trying backend: msilib...\")\n        try:\n            db = msilib.OpenDatabase(str(p), msilib.MSIDBOPEN_READONLY)\n            # Query for ProductName and ProductVersion\n            view = db.OpenView(\n                \"SELECT `Property`,`Value` FROM `Property` \"\n                \"WHERE `Property` IN ('ProductName','ProductVersion')\"\n            )\n            view.Execute(None)\n\n            metadata = {\"ProductName\": \"\", \"ProductVersion\": \"\"}\n            while True:\n                rec = view.Fetch()\n                if rec is None:\n                    break\n                prop_name = rec.GetString(1)\n                prop_value = rec.GetString(2)\n                if prop_name in metadata:\n                    metadata[prop_name] = prop_value\n\n            view.Close()\n            db.Close()\n\n            if not metadata[\"ProductVersion\"]:\n                raise PackagingError(\"ProductVersion not found in MSI Property table.\")\n\n            logger.verbose(\n                \"MSI\",\n                f\"Success! Extracted: {metadata['ProductName']} \"\n                f\"{metadata['ProductVersion']} (via msilib)\",\n            )\n            return MSIMetadata(\n                product_name=metadata[\"ProductName\"] or \"\",\n                product_version=metadata[\"ProductVersion\"],\n            )\n        except Exception as err:\n            logger.debug(\"MSI\", f\"msilib failed: {err}, trying next backend...\")\n\n    # Try _msi module (alternative Windows approach)\n    if sys.platform.startswith(\"win\"):\n        logger.debug(\"MSI\", \"Trying backend: _msi...\")\n        try:\n            import _msi  # type: ignore\n        except ImportError:\n            logger.debug(\"MSI\", \"_msi not available, trying next backend...\")\n        else:\n            try:\n                db = _msi.OpenDatabase(str(p), 0)  # 0: read-only\n                view = db.OpenView(\n                    \"SELECT `Property`,`Value` FROM `Property` \"\n                    \"WHERE `Property` IN ('ProductName','ProductVersion')\"\n                )\n                view.Execute(None)\n\n                metadata = {\n                    \"ProductName\": \"\",\n                    \"ProductVersion\": \"\",\n                }\n                while True:\n                    rec = view.Fetch()\n                    if rec is None:\n                        break\n                    prop_name = rec.GetString(1)\n                    prop_value = rec.GetString(2)\n                    if prop_name in metadata:\n                        metadata[prop_name] = prop_value\n\n                view.Close()\n                db.Close()\n\n                if not metadata[\"ProductVersion\"]:\n                    raise PackagingError(\n                        \"ProductVersion not found in MSI Property table.\"\n                    )\n\n                logger.verbose(\n                    \"MSI\",\n                    f\"Success! Extracted: {metadata['ProductName']} \"\n                    f\"{metadata['ProductVersion']} (via _msi)\",\n                )\n                return MSIMetadata(\n                    product_name=metadata[\"ProductName\"] or \"\",\n                    product_version=metadata[\"ProductVersion\"],\n                )\n            except Exception as err:\n                logger.debug(\"MSI\", f\"_msi failed: {err}, trying next backend...\")\n\n    # Try PowerShell with Windows Installer COM on Windows\n    if sys.platform.startswith(\"win\"):\n        logger.debug(\"MSI\", \"Trying backend: PowerShell COM...\")\n        try:\n            # Escape single quotes in path by doubling them (PowerShell escaping)\n            escaped_path = str(p).replace(\"'\", \"''\")\n            # Use double quotes for SQL string (PowerShell), single quotes for string literals (MSI SQL)\n            # No backticks needed - Property and Value aren't reserved words\n            ps_script = f\"\"\"\n$installer = New-Object -ComObject WindowsInstaller.Installer\n$db = $installer.OpenDatabase('{escaped_path}', 0)\nif ($null -eq $db) {{\n    Write-Error \"Failed to open database: '{escaped_path}'\"\n    exit 1\n}}\n$sqlQuery = \"SELECT Property, Value FROM Property WHERE Property = 'ProductName' OR Property = 'ProductVersion'\"\n$view = $db.OpenView($sqlQuery)\nif ($null -eq $view) {{\n    Write-Error \"OpenView returned null for SQL: $sqlQuery\"\n    exit 1\n}}\n$view.Execute()\n$metadata = @{{}}\nwhile ($record = $view.Fetch()) {{\n    $prop = $record.StringData(1)\n    $value = $record.StringData(2)\n    if ($prop -in @('ProductName','ProductVersion')) {{\n        $metadata[$prop] = $value\n    }}\n}}\n$view.Close()\n$db.Close()\nif (-not $metadata['ProductVersion']) {{\n    Write-Error \"ProductVersion not found\"\n    exit 1\n}}\n@($metadata['ProductName'], $metadata['ProductVersion']) -join \"`n\"\n\"\"\"\n            result = subprocess.run(\n                [\"powershell\", \"-NoProfile\", \"-NonInteractive\", \"-Command\", ps_script],\n                check=True,\n                capture_output=True,\n                text=True,\n                timeout=10,\n            )\n            lines = result.stdout.strip().split(\"\\n\")\n            product_name = lines[0] if len(lines) &gt; 0 else \"\"\n            product_version = lines[1] if len(lines) &gt; 1 else \"\"\n\n            if not product_version:\n                raise PackagingError(\"ProductVersion not found in MSI Property table.\")\n\n            logger.verbose(\n                \"MSI\",\n                f\"Success! Extracted: {product_name} {product_version} \"\n                \"(via PowerShell COM)\",\n            )\n            return MSIMetadata(\n                product_name=product_name or \"\",\n                product_version=product_version,\n            )\n        except subprocess.CalledProcessError as err:\n            # Capture stderr to see what PowerShell actually reported\n            stderr_output = err.stderr if err.stderr else \"No stderr captured\"\n            stdout_output = err.stdout if err.stdout else \"No stdout captured\"\n            logger.debug(\n                \"MSI\",\n                f\"PowerShell COM failed: {err}. stdout: {stdout_output}, stderr: {stderr_output}. Trying next backend...\",\n            )\n        except subprocess.TimeoutExpired:\n            logger.debug(\"MSI\", \"PowerShell COM timed out, trying next backend...\")\n        except Exception as err:\n            logger.debug(\"MSI\", f\"PowerShell COM failed: {err}, trying next backend...\")\n\n    # Try msiinfo on Linux/macOS (or as last resort on Windows)\n    msiinfo = shutil.which(\"msiinfo\")\n    if msiinfo:\n        logger.debug(\"MSI\", \"Trying backend: msiinfo (msitools)...\")\n        try:\n            # msiinfo export &lt;package&gt; Property -&gt; stdout (tab-separated)\n            result = subprocess.run(\n                [msiinfo, \"export\", str(p), \"Property\"],\n                check=True,\n                capture_output=True,\n                text=True,\n            )\n            metadata = {\"ProductName\": \"\", \"ProductVersion\": \"\"}\n            for line in result.stdout.splitlines():\n                parts = line.strip().split(\"\\t\", 1)  # \"Property&lt;TAB&gt;Value\"\n                if len(parts) == 2:\n                    prop_name = parts[0]\n                    prop_value = parts[1]\n                    if prop_name in metadata:\n                        metadata[prop_name] = prop_value\n\n            if not metadata[\"ProductVersion\"]:\n                raise PackagingError(\"ProductVersion not found in MSI Property output.\")\n\n            logger.verbose(\n                \"MSI\",\n                f\"Success! Extracted: {metadata['ProductName']} \"\n                f\"{metadata['ProductVersion']} (via msiinfo)\",\n            )\n            return MSIMetadata(\n                product_name=metadata[\"ProductName\"] or \"\",\n                product_version=metadata[\"ProductVersion\"],\n            )\n        except Exception as err:\n            logger.debug(\"MSI\", f\"msiinfo failed: {err}\")\n\n    # All backends failed\n    logger.debug(\"MSI\", \"No MSI extraction backend available on this system\")\n    raise NotImplementedError(\n        \"MSI metadata extraction is not available on this host. \"\n        \"On Windows, ensure PowerShell is available. \"\n        \"On Linux/macOS, install 'msitools'.\"\n    )\n</code></pre>"}]}