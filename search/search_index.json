{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"NAPT - Not a Pkg Tool","text":"<p>Automated Windows application packaging and deployment to Microsoft Intune using PSAppDeployToolkit</p> <p> </p>"},{"location":"#overview","title":"Overview","text":"<p>NAPT is a Python-based CLI tool that automates the entire workflow for packaging Windows applications and deploying them to Microsoft Intune. It runs on Windows, Linux, and macOS, though packaging (.intunewin creation) requires Windows.</p>"},{"location":"#why-napt","title":"Why NAPT?","text":"<p>Packaging applications for Microsoft Intune with PSAppDeployToolkit (PSADT) typically involves a manual, time-consuming process:</p> <ol> <li> <p>Manually check for new versions - Check vendor sites/APIs for updates. Easy to miss versions or waste time when nothing changed.</p> </li> <li> <p>Create PSADT deployment - Copy template, manually edit <code>Invoke-AppDeployToolkit.ps1</code> with variables, configure install/uninstall logic. Error-prone and repetitive.</p> </li> <li> <p>Create detection script - Write PowerShell detection logic, test thoroughly, maintain version checks. Must update for each new version.</p> </li> <li> <p>Package as .intunewin - Run IntuneWinAppUtil.exe manually, manage paths, handle errors. Tedious and error-prone.</p> </li> <li> <p>Upload to Intune - Upload package via portal, fill metadata, configure app info and requirements manually.</p> </li> <li> <p>Configure deployment - Set up rollout assignments manually for each version.</p> </li> </ol> <p>This manual workflow is repetitive, difficult to automate in CI/CD pipelines, lacks version tracking, and requires re-doing most of the work for every update. NAPT automates this entire workflow with YAML-based recipes and intelligent version tracking.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\u2705 Intelligent version tracking - Automatic discovery from MSI, EXE, URLs, or APIs with smart caching to skip unnecessary downloads</li> <li>\u2705 YAML-based recipes - Define app packaging once with layered configuration (Organization \u2192 Vendor \u2192 Recipe)</li> <li>\u2705 Automated PSADT packaging - Generate Intune-ready packages with detection scripts, no manual template editing</li> <li>\u2705 Cross-platform workflow - Run on Windows, Linux, and macOS (packaging requires Windows)</li> <li>\ud83d\udea7 Direct Intune upload - Automatic deployment (planned)</li> </ul>"},{"location":"#cross-platform-support","title":"Cross-Platform Support","text":"Feature Windows Linux/macOS Discovery &amp; Download \u2705 \u2705 PSADT Package Building \u2705 \u2705 Intune Packaging \u2705 \u26ab Windows Only <p>See the Cross-Platform Support section for detailed workflows.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Check out the Quick Start Guide for installation instructions and your first steps with NAPT.</p>"},{"location":"#creating-recipes","title":"Creating Recipes","text":"<p>Recipes are YAML configuration files that define how to discover, download, and package applications.</p> <p>Example recipes:</p> <ul> <li>chrome.yaml - url_download strategy with MSI version extraction</li> <li>7zip.yaml - web_scrape strategy for vendor download pages</li> </ul> <p>NAPT supports multiple discovery strategies (url_download, web_scrape, api_github, api_json) - see the Discovery Strategies guide for detailed configuration and more examples.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! See Contributing for guidelines.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the Apache License 2.0 - see the LICENSE file for details.</p>"},{"location":"#author","title":"Author","text":"<p>Roger Cibrian</p>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<ul> <li>Built for automating Windows application deployment</li> <li>Uses PSAppDeployToolkit (PSADT) for packaging</li> <li>Targets Microsoft Intune for distribution</li> </ul>"},{"location":"branching/","title":"Branching Strategy","text":"<p>NAPT uses GitHub Flow - a simple, branch-based workflow that keeps <code>main</code> always deployable.</p>"},{"location":"branching/#core-principles","title":"Core Principles","text":"<ol> <li><code>main</code> branch is always stable - Production-ready code only</li> <li>Feature branches for all work - Every change starts from a branch</li> <li>Pull Requests for review - All changes reviewed before merging</li> <li>Merge frequently - Keep branches short-lived (&lt; 1 week ideal)</li> </ol>"},{"location":"branching/#branch-structure","title":"Branch Structure","text":"<pre><code>main (always deployable)\n\u251c\u2500\u2500 feature/add-rpm-support\n\u251c\u2500\u2500 bugfix/fix-version-parsing\n\u251c\u2500\u2500 docs/update-installation-guide\n\u2514\u2500\u2500 refactor/simplify-config-loader\n</code></pre>"},{"location":"branching/#branch-naming-convention","title":"Branch Naming Convention","text":"<p>Use descriptive names with type prefixes:</p> Prefix Purpose Example <code>feature/</code> New features or enhancements <code>feature/add-rpm-support</code> <code>bugfix/</code> Bug fixes <code>bugfix/fix-version-parsing</code> <code>docs/</code> Documentation updates <code>docs/update-installation-guide</code> <code>refactor/</code> Code improvements (no behavior change) <code>refactor/simplify-config-loader</code> <code>test/</code> Test additions/improvements <code>test/add-integration-tests</code> <code>chore/</code> Maintenance tasks <code>chore/update-dependencies</code> <code>hotfix/</code> Urgent production fixes <code>hotfix/security-patch</code>"},{"location":"branching/#naming-rules","title":"Naming Rules","text":"<ul> <li>Use lowercase with hyphens</li> <li>Be descriptive but concise (3-6 words)</li> <li>Avoid generic names like <code>fix-bug</code> or <code>updates</code></li> <li>No issue numbers in branch names (use commit messages instead)</li> </ul> <p>Good Examples: <pre><code>feature/add-exe-version-extraction\nbugfix/fix-download-resume-logic\ndocs/add-cross-platform-examples\nrefactor/simplify-config-loader\n</code></pre></p> <p>Bad Examples: <pre><code>my-branch              # No type prefix\nfeature/stuff          # Not descriptive\nFeature/My_Branch      # Wrong case\nfix-bug                # Too generic\n</code></pre></p>"},{"location":"branching/#workflow","title":"Workflow","text":""},{"location":"branching/#starting-new-work","title":"Starting New Work","text":"<pre><code># Always start from updated main\ngit checkout main\ngit pull origin main\n\n# Create your feature branch\ngit checkout -b feature/your-feature-name\n</code></pre>"},{"location":"branching/#during-development","title":"During Development","text":"<pre><code># Make changes, commit frequently\ngit add .\ngit commit -m \"feat: add your feature\"\n\n# Push your branch\ngit push origin feature/your-feature-name\n</code></pre>"},{"location":"branching/#creating-a-pull-request","title":"Creating a Pull Request","text":"<ol> <li>Push your branch to GitHub</li> <li>Create a Pull Request on GitHub</li> <li>Fill out the description with:</li> <li>What the PR does</li> <li>Why the change is needed</li> <li>How it was tested</li> <li>Request review from maintainers</li> <li>Address any feedback</li> </ol>"},{"location":"branching/#after-merge","title":"After Merge","text":"<pre><code># Update your local main\ngit checkout main\ngit pull origin main\n\n# Delete your local feature branch\ngit branch -d feature/your-feature-name\n\n# Remote branch is usually auto-deleted by GitHub\n</code></pre>"},{"location":"branching/#commit-message-format","title":"Commit Message Format","text":"<p>Use conventional commit format for clarity:</p> <pre><code>&lt;type&gt;: &lt;description&gt;\n\n[optional body]\n</code></pre>"},{"location":"branching/#commit-types","title":"Commit Types","text":"Type Purpose Example <code>feat</code> New feature <code>feat: add EXE version extraction</code> <code>fix</code> Bug fix <code>fix: correct version comparison logic</code> <code>docs</code> Documentation <code>docs: update installation instructions</code> <code>refactor</code> Code improvement <code>refactor: simplify config loading</code> <code>test</code> Tests <code>test: add tests for MSI extraction</code> <code>chore</code> Maintenance <code>chore: update Poetry dependencies</code> <code>perf</code> Performance <code>perf: optimize version comparison</code>"},{"location":"branching/#commit-guidelines","title":"Commit Guidelines","text":"<ul> <li>Use imperative mood: \"add\" not \"added\" or \"adds\"</li> <li>Keep subject line under 50 characters</li> <li>Capitalize subject line</li> <li>No period at end of subject</li> <li>Separate subject from body with blank line</li> </ul> <p>Good Examples: <pre><code>git commit -m \"feat: add RPM version extraction support\"\ngit commit -m \"fix: handle missing ETag headers gracefully\"\ngit commit -m \"docs: add examples for Linux MSI extraction\"\n</code></pre></p> <p>Bad Examples: <pre><code>git commit -m \"added stuff\"           # Not descriptive\ngit commit -m \"Fix bug\"               # No type prefix\ngit commit -m \"WIP\"                   # Too vague\n</code></pre></p>"},{"location":"branching/#best-practices","title":"Best Practices","text":""},{"location":"branching/#do","title":"DO \u2705","text":"<ul> <li>Create small, focused branches with single purpose</li> <li>Commit early and often with clear messages</li> <li>Keep branches short-lived (merge within 1 week)</li> <li>Run tests before pushing (<code>pytest tests/</code>)</li> <li>Format code before committing (<code>black notapkgtool/</code>)</li> <li>Update branch with <code>main</code> if it's behind</li> <li>Delete branches after merging</li> </ul>"},{"location":"branching/#dont","title":"DON'T \u274c","text":"<ul> <li>Never commit directly to <code>main</code></li> <li>Don't create long-lived feature branches</li> <li>Don't use generic branch/commit names</li> <li>Don't merge without tests passing</li> <li>Don't force push to shared branches</li> <li>Don't include unrelated changes in one PR</li> </ul>"},{"location":"branching/#quality-checks","title":"Quality Checks","text":"<p>Before creating a Pull Request, ensure:</p> <pre><code># Run tests\npytest tests/\n\n# Format code\nblack notapkgtool/\n\n# Check linting\nruff check notapkgtool/\n\n# Run all checks at once\npytest tests/ &amp;&amp; black notapkgtool/ &amp;&amp; ruff check notapkgtool/\n</code></pre>"},{"location":"branching/#handling-merge-conflicts","title":"Handling Merge Conflicts","text":"<p>If your branch conflicts with <code>main</code>:</p> <pre><code># Update main\ngit checkout main\ngit pull origin main\n\n# Switch back to your branch\ngit checkout feature/your-feature\n\n# Merge main into your branch\ngit merge main\n\n# Resolve conflicts in your editor\n# Look for &lt;&lt;&lt;&lt;&lt;&lt;&lt; markers\n\n# After resolving, stage the files\ngit add path/to/resolved/file.py\n\n# Complete the merge\ngit commit\n\n# Push the updated branch\ngit push origin feature/your-feature\n</code></pre>"},{"location":"branching/#merge-strategy","title":"Merge Strategy","text":"<p>Default: Squash and Merge</p> <p>NAPT uses squash and merge for most Pull Requests to maintain a clean, readable history in <code>main</code>.</p>"},{"location":"branching/#why-squash-and-merge","title":"Why Squash and Merge?","text":"<ul> <li>\u2705 Clean history: One commit per feature/fix in <code>main</code></li> <li>\u2705 Conventional commits: Each merge becomes a properly formatted commit</li> <li>\u2705 Easy rollback: Revert entire features with one command</li> <li>\u2705 Better changelogs: No noise from \"WIP\" or \"fix typo\" commits</li> <li>\u2705 Simple bisecting: Each commit represents a complete, working change</li> </ul>"},{"location":"branching/#when-to-use-each-strategy","title":"When to Use Each Strategy","text":"<p>Squash and Merge (Default - 95% of PRs)</p> <p>Use for: - Feature additions - Bug fixes - Documentation updates - Refactoring - Chores and maintenance</p> <p>When merging on GitHub: 1. Click \"Squash and merge\" 2. Edit the commit message to follow conventional commit format 3. Summarize all changes in the commit body 4. Reference any issues with <code>Closes #XX</code></p> <p>Example: <pre><code>feat: add RPM version extraction support\n\n- Implement RPM ProductVersion parser using rpm-py-installer\n- Add cross-platform support for RPM files (Linux/macOS)\n- Add comprehensive test coverage with mock RPM files\n- Update documentation with RPM examples\n\nCloses #42\n</code></pre></p> <p>Regular Merge (Exceptional Cases)</p> <p>Use only when: - Multiple authors need attribution for distinct contributions - Release PRs where version bump history should be preserved - Large features with logically separate commits worth keeping</p> <p>Example scenarios: - Version bump PRs (preserve \"bump version\" + \"update changelog\" as separate commits) - Community contributions with multiple meaningful commits - Complex refactors where commit-by-commit history aids debugging</p>"},{"location":"branching/#workflow_1","title":"Workflow","text":"<ol> <li>Before creating PR: Clean up your branch commits if needed</li> <li>During review: Add commits normally (don't squash yet)</li> <li>When merging: Use GitHub's \"Squash and merge\" button</li> <li>After merge: Branch is auto-deleted, pull latest <code>main</code></li> </ol>"},{"location":"branching/#tips","title":"Tips","text":"<ul> <li>Don't worry about messy commits in your branch - they'll be squashed</li> <li>Focus on clear PR descriptions - they become the squash commit message</li> <li>Use conventional commit prefixes in PR titles for easy squashing</li> <li>If you accidentally use wrong merge method, you can revert and redo</li> </ul>"},{"location":"branching/#versioning-and-releases","title":"Versioning and Releases","text":""},{"location":"branching/#version-numbering","title":"Version Numbering","text":"<p>NAPT follows Semantic Versioning:</p> <ul> <li>MAJOR (e.g., 1.0.0) - Incompatible API changes</li> <li>MINOR (e.g., 0.2.0) - New functionality (backward compatible)</li> <li>PATCH (e.g., 0.2.1) - Bug fixes (backward compatible)</li> </ul> <p>Note: No \"v\" prefix - use <code>0.2.0</code> NOT <code>v0.2.0</code></p>"},{"location":"branching/#pre-release-checklist","title":"Pre-Release Checklist","text":"<p>Before creating a release:</p> <ul> <li> All feature work merged to <code>main</code></li> <li> Version updated in <code>pyproject.toml</code></li> <li> Version updated in <code>notapkgtool/__init__.py</code></li> <li> <code>docs/changelog.md</code> updated with all changes following Keep a Changelog 1.1.0</li> <li> <code>docs/changelog.md</code> has <code>[Unreleased]</code> section ready for next version</li> <li> Documentation updated (README, DOCUMENTATION, etc.)</li> <li> All tests passing</li> <li> Sample recipes tested end-to-end</li> </ul>"},{"location":"branching/#release-process","title":"Release Process","text":""},{"location":"branching/#1-prepare-release-pr","title":"1. Prepare Release PR","text":"<p>Create a dedicated PR for the version bump:</p> <pre><code>git checkout main\ngit pull origin main\ngit checkout -b chore/prepare-release-0.x.0\n\n# Update versions\n# Edit pyproject.toml: version = \"0.x.0\"\n# Edit notapkgtool/__init__.py: __version__ = \"0.x.0\"\n\n# Update docs/changelog.md\n# - Change [Unreleased] to [0.x.0] - YYYY-MM-DD\n# - Add new [Unreleased] section at top\n# - Update version comparison links\n\ngit add pyproject.toml notapkgtool/__init__.py docs/changelog.md\ngit commit -m \"chore: prepare release 0.x.0\"\ngit push origin chore/prepare-release-0.x.0\n</code></pre> <p>PR Title: <code>chore: prepare release 0.x.0</code></p> <p>PR Description: Brief summary of release highlights and link to docs/changelog.md</p>"},{"location":"branching/#2-merge-release-pr","title":"2. Merge Release PR","text":"<p>After review and approval, merge the PR to <code>main</code> using squash and merge.</p>"},{"location":"branching/#3-create-and-push-git-tag","title":"3. Create and Push Git Tag","text":"<pre><code>git checkout main\ngit pull origin main\ngit tag -a 0.x.0 -m \"Release 0.x.0\"\ngit push origin 0.x.0\n</code></pre>"},{"location":"branching/#4-create-github-release","title":"4. Create GitHub Release","text":"<p>Go to https://github.com/RogerCibrian/notapkgtool/releases/new</p> <p>Tag: Select the tag you just pushed (e.g., <code>0.x.0</code>)</p> <p>Release Title: <code>NAPT {version}</code></p> <p>Example: <code>NAPT 0.2.0</code></p> <p>Release Description: Follow the template in <code>.cursor/rules/napt-releases.mdc</code></p>"},{"location":"branching/#creating-github-releases","title":"Creating GitHub Releases","text":""},{"location":"branching/#release-title-format","title":"Release Title Format","text":"<pre><code>NAPT {version}\n</code></pre> <p>Examples: - <code>NAPT 0.2.0</code> - <code>NAPT 0.3.0</code> - <code>NAPT 1.0.0</code></p>"},{"location":"branching/#release-description-template","title":"Release Description Template","text":"<p>Use this structure for consistency:</p> <pre><code># \ud83c\udf89 NAPT {version} - {Feature Summary}\n\n{One sentence hero statement describing the release}\n\n## \u2728 What's New\n\n### \ud83d\udd28 {Category Name}\n\n- **{Feature Name}** with `command` details\n  - Bullet point details\n  - More details\n\n### \ud83d\udd0d {Another Category}\n\n{Continue for all major features...}\n\n## \ud83d\ude80 Quick Start\n\n```bash\n# Show new commands or updated workflows\nnapt command args\n</code></pre>"},{"location":"branching/#what-you-can-do-now","title":"\ud83d\udce6 What You Can Do Now","text":"<p>Workflow checklist: 1. \u2705 {Step 1} 2. \u2705 {Step 2} 3. \ud83d\udea7 {Coming soon}</p>"},{"location":"branching/#breaking-changes","title":"\u26a0\ufe0f Breaking Changes","text":"<p>Note: {Context about breaking changes policy}</p> <ul> <li>{Change description} - {Migration instructions}</li> </ul>"},{"location":"branching/#bug-fixes","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>{Fix description}</li> <li>{Another fix}</li> </ul>"},{"location":"branching/#stats","title":"\ud83d\udcca Stats","text":"<ul> <li>X files changed: X insertions(+), X deletions(-)</li> <li>New modules: X</li> <li>Test coverage: {Coverage info}</li> </ul>"},{"location":"branching/#links","title":"\ud83d\udd17 Links","text":"<ul> <li>Full Changelog: {Link to docs/changelog.md}</li> <li>Documentation: {Link to https://rogercibrian.github.io/notapkgtool}</li> <li>Roadmap: {Link to docs/roadmap.md}</li> <li>Sample Recipes: {Link to recipes/}</li> </ul>"},{"location":"branching/#whats-next-next-version","title":"\ud83c\udfaf What's Next ({next version})","text":"<ul> <li>{Planned feature 1}</li> <li>{Planned feature 2}</li> </ul> <p>Requirements: Python 3.11+, Windows/Linux/macOS</p> <p>Tested with:  - {App 1 and version} - {App 2 and version}</p> <p>Install: <code>pip install pyyaml requests</code> <pre><code>#### Emoji Guide for Categories\n\nUse these emojis for consistent categorization:\n\n- \ud83d\udd28 Build &amp; Packaging\n- \ud83d\udd0d Discovery &amp; Detection\n- \ud83d\uddc4\ufe0f State Management\n- \ud83e\uddea Testing Infrastructure\n- \ud83d\udccb Recipes &amp; Configuration\n- \ud83d\udcda Documentation\n- \ud83d\ude80 Quick Start / Usage\n- \ud83d\udce6 Capabilities / Workflow\n- \u26a0\ufe0f Breaking Changes / Warnings\n- \ud83d\udc1b Bug Fixes\n- \ud83d\udcca Statistics / Metrics\n- \ud83d\udd17 External Links\n- \ud83c\udfaf Roadmap / Future Plans\n- \u2728 Highlights (header)\n- \ud83c\udf89 Release Hero (title)\n\n#### Content Guidelines\n\n**Do Include**:\n- All significant changes from docs/changelog.md\n- Code examples for new commands\n- Migration instructions for breaking changes\n- Quick start guide updates\n- Test coverage and quality metrics\n- Links to full documentation\n- \"What you can do now\" workflow\n- Preview of next version features\n\n**Don't Include**:\n- Internal refactorings (unless visible impact)\n- Trivial formatting changes\n- Work-in-progress features\n- Overly technical implementation details\n- Every single bug fix (only notable ones)\n\n#### Writing Style\n\n- **Active voice**: \"This release adds...\" not \"Added in this release...\"\n- **Present tense**: \"This command creates...\" not \"This command will create...\"\n- **User-focused**: Emphasize benefits, not just features\n- **Concise**: One sentence per bullet when possible\n- **Scannable**: Use headers, bullets, and code blocks\n- **Complete**: Include all info needed to understand changes\n\n### Example Release (0.2.0)\n\nSee the 0.2.0 release for a complete example:\nhttps://github.com/RogerCibrian/notapkgtool/releases/tag/0.2.0\n\nKey elements:\n- Clear feature categories with emojis\n- Code examples showing new capabilities  \n- Breaking changes highlighted with migration notes\n- Stats showing scope of changes\n- Links to detailed documentation\n- Preview of what's coming next\n\n### Post-Release\n\nAfter creating the GitHub release:\n\n1. **Announce** (if applicable):\n   - Internal communication channels\n   - Project discussion boards\n   - Social media (if public release)\n\n2. **Monitor**:\n   - GitHub issues for bug reports\n   - User feedback on new features\n   - Update docs/roadmap.md based on feedback\n\n3. **Prepare Next Version**:\n   - Create `[Unreleased]` section in docs/changelog.md (if not already done)\n   - Update docs/roadmap.md with next milestone\n   - Start planning next feature set\n\n### PyPI Publication (Future)\n\nWhen ready to publish to PyPI:\n\n```bash\npoetry build\npoetry publish\n</code></pre></p> <p>Ensure <code>pyproject.toml</code> metadata is complete before first publication.</p>"},{"location":"branching/#common-scenarios","title":"Common Scenarios","text":""},{"location":"branching/#multiple-related-changes","title":"Multiple Related Changes","text":"<p>If changes are closely related, keep in one branch: <pre><code>feature/add-exe-support\n  \u251c\u2500\u2500 Add EXE parsing module\n  \u251c\u2500\u2500 Add tests\n  \u2514\u2500\u2500 Update documentation\n</code></pre></p> <p>If changes are independent, use separate branches: <pre><code>feature/add-exe-support\nfeature/add-rpm-support\n</code></pre></p>"},{"location":"branching/#long-running-features","title":"Long-Running Features","text":"<p>For features taking multiple days/weeks: 1. Keep branch updated with <code>main</code> regularly 2. Break into smaller PRs if possible 3. Use draft PRs to show progress 4. Consider feature flags for incomplete features</p>"},{"location":"branching/#urgent-hotfixes","title":"Urgent Hotfixes","text":"<p>For critical production issues: <pre><code># Branch from main\ngit checkout main\ngit pull origin main\ngit checkout -b hotfix/fix-security-vulnerability\n\n# Fix, test, and push\ngit commit -am \"fix: patch security vulnerability\"\ngit push origin hotfix/fix-security-vulnerability\n\n# Create PR with high priority\n# Fast-track review and merge\n</code></pre></p>"},{"location":"branching/#questions","title":"Questions?","text":"<ul> <li>Check the Documentation Site for technical details</li> <li>Check the README for project overview</li> <li>Open an issue for questions or discussions</li> </ul> <p>Last Updated: 2025-11-07 Strategy: GitHub Flow with Squash and Merge</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to NAPT (Not a Pkg Tool) will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#added","title":"Added","text":""},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Discovery Performance Optimization - Version-first strategies (web_scrape, api_github, api_json) now check versions before downloading, enabling ~100-300ms update checks when unchanged instead of full downloads</li> <li>State file now saves actual download URLs for all strategies</li> <li>BREAKING: Uniform Strategy Naming - Discovery strategies renamed to follow consistent <code>&lt;source&gt;_&lt;method&gt;</code> pattern for better discoverability and scalability:<ul> <li><code>http_static</code> \u2192 <code>url_download</code> (fixed URL with file extraction)</li> <li><code>url_regex</code> \u2192 <code>web_scrape</code> (web scraping for vendor download pages)</li> <li><code>http_json</code> \u2192 <code>api_json</code> (generic JSON API queries)</li> <li><code>github_release</code> \u2192 <code>api_github</code> (GitHub releases API)</li> </ul> </li> <li>BREAKING: Simplified Version Types - Version type names shortened for clarity:<ul> <li><code>msi_product_version_from_file</code> \u2192 <code>msi</code></li> <li>Removed nested <code>version.type</code> for <code>web_scrape</code> (simplified to <code>source.link_selector</code> and <code>source.version_pattern</code>)</li> </ul> </li> <li>Documentation Rendering - Fixed module docstrings to follow Google-style format with proper indentation for mkdocstrings</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Fixed ETag preservation bug causing alternating download/cached behavior in url_download strategy</li> <li>Fixed docstring formatting issues across multiple modules (missing blank lines, incorrect Args sections)</li> </ul>"},{"location":"changelog/#020-2025-11-07","title":"0.2.0 - 2025-11-07","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>PSADT Package Generation with <code>napt build</code> command - Creates complete PSADT v4 deployment packages with custom branding support</li> <li>.intunewin Package Creation with <code>napt package</code> command - Generates Intune-ready packages using Microsoft's IntuneWinAppUtil.exe</li> <li>GitHub Release Strategy (<code>api_github</code>) - Discovers versions from GitHub releases with asset pattern filtering</li> <li>HTTP JSON Strategy (<code>api_json</code>) - Extracts versions and download URLs from JSON API endpoints using JSONPath</li> <li>URL Regex Strategy (<code>url_pattern</code>) - Extracts versions directly from URLs using regex patterns</li> <li>Roadmap Management (<code>docs/roadmap.md</code>) - Structured feature tracking with status categories and workspace automation</li> <li>MkDocs Documentation Site - User guide and auto-generated API reference</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>State File Schema v2 - Convention-based file paths, improved metadata tracking, per-app isolation (Breaking: old state files need regeneration)</li> <li>CLI Commands - Renamed <code>check</code> to <code>validate</code> for clarity</li> <li>Recipe Format - PSADT <code>install</code>/<code>uninstall</code> blocks now generate PSAppDeployToolkit v4 scripts</li> <li>Console Output - Replaced Unicode symbols with ASCII for Windows compatibility (<code>\u2713</code> \u2192 <code>[OK]</code>, etc.)</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>PSADT Template Handling - Correctly identifies and copies PSAppDeployToolkit_Template_v4.zip files</li> <li>ETag Preservation - Fixed bug causing alternating download/cached behavior in url_download strategy</li> <li>Branding Application - Fixed Assets/ directory path resolution for custom icons and banners</li> <li>Version Extraction - Corrected regex escape sequences causing SyntaxWarnings</li> </ul>"},{"location":"changelog/#010-2025-10-23","title":"0.1.0 - 2025-10-23","text":"<p>Initial internal release.</p>"},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Recipe Validation with <code>napt check</code> command - Validates recipe syntax and configuration without network calls</li> <li>HTTP Static Discovery - Downloads installers from static URLs with ETag caching for efficiency</li> <li>Three-Layer Configuration - Organization defaults, vendor overrides, and recipe-specific settings with deep merging</li> <li>Version Comparison - Supports semantic versioning, MSI/EXE numeric versions, and Chrome-style multi-part versions</li> <li>MSI Version Extraction - Cross-platform support (Windows via msilib/PowerShell, Linux/macOS via msitools)</li> <li>Robust Downloads - Retry logic, atomic writes, SHA-256 verification, and conditional requests</li> </ul>"},{"location":"contributing/","title":"Contributing to NAPT","text":"<p>Thank you for your interest in contributing to NAPT! This guide will help you get started.</p>"},{"location":"contributing/#getting-started","title":"Getting Started","text":""},{"location":"contributing/#feature-ideas","title":"Feature Ideas","text":"<p>Have an idea for NAPT? Check docs/roadmap.md to see what's planned and add your suggestions to the appropriate category!</p>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<pre><code># Clone and install with dev dependencies\ngit clone https://github.com/RogerCibrian/notapkgtool.git\ncd notapkgtool\npoetry install\npoetry shell\n\n# Verify installation\nnapt --version\n</code></pre>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npoetry run pytest tests/\n\n# Run only unit tests (fast)\npoetry run pytest tests/ -m \"not integration\"\n\n# Run with coverage\npoetry run pytest tests/ --cov=notapkgtool --cov-report=html\n</code></pre>"},{"location":"contributing/#code-quality","title":"Code Quality","text":"<pre><code># Format code\npoetry run black notapkgtool/ tests/\n\n# Fix linting issues\npoetry run ruff check --fix notapkgtool/ tests/\n\n# Check docstring formatting\npoetry run ruff check --select D notapkgtool/\n\n# Check types (if using mypy)\npoetry run mypy notapkgtool/\n</code></pre>"},{"location":"contributing/#branching-strategy","title":"Branching Strategy","text":"<p>NAPT uses GitHub Flow - a simple, branch-based workflow. See branching.md for complete workflow details.</p> <p>Quick Summary: - Create feature branches from <code>main</code> (use prefixes: <code>feature/</code>, <code>bugfix/</code>, <code>docs/</code>) - Make frequent, small commits with conventional commit messages - Open Pull Requests for code review - Merge to <code>main</code> when approved - Keep <code>main</code> always stable and deployable</p> <p>Branch naming: <code>feature/add-rpm-support</code>, <code>bugfix/fix-version-parsing</code>, <code>docs/update-guide</code></p> <p>Commit format: <code>&lt;type&gt;: &lt;description&gt;</code> where type is feat, fix, docs, refactor, test, chore, or perf</p>"},{"location":"contributing/#code-guidelines","title":"Code Guidelines","text":""},{"location":"contributing/#python-docstring-standards","title":"Python Docstring Standards","text":"<p>All Python code must follow Google-style docstrings:</p> <p>Module docstrings:</p> <ul> <li>Brief summary + optional detailed description</li> <li>Use \"Key Features\" or \"Key Advantages\" bullet lists (with blank line before)</li> <li>Include Example section if helpful</li> <li>Avoid: schema dumps, workflow steps, package structure listings, migration notes</li> </ul> <p>Function docstrings:</p> <ul> <li>One-line summary + optional details</li> <li>Standard sections: <code>Args:</code>, <code>Returns:</code>, <code>Raises:</code>, <code>Example:</code>, <code>Note:</code></li> <li>Use <code>Example:</code> (singular, NEVER <code>Examples:</code> or <code>Usage Example:</code>)</li> <li>Use <code>Note:</code> (singular, NEVER <code>Notes:</code>)</li> <li>NO <code>&gt;&gt;&gt;</code> doctest prompts - causes rendering issues</li> <li>ALL content after section headers MUST be indented 4 spaces</li> <li>Add blank line after section headers before content</li> </ul> <p>Type annotations:</p> <ul> <li>Full coverage for public APIs</li> <li>Modern Python 3.11+ syntax (<code>X | None</code>, not <code>Optional[X]</code>)</li> </ul>"},{"location":"contributing/#markdown-documentation","title":"Markdown Documentation","text":"<p>When updating documentation in <code>docs/*.md</code>, follow the 3-tier structure:</p> <p>1. docs/index.md (Landing Page)</p> <ul> <li>High-level overview only</li> <li>Simple diagrams (5-10 nodes, centered with <code>&lt;div align=\"center\"&gt;</code>)</li> <li>Link to deeper content, don't duplicate</li> </ul> <p>2. docs/quick-start.md (Quick Start)</p> <ul> <li>Installation steps (pip first, then Poetry)</li> <li>Basic command examples with expected outputs</li> <li>Platform-specific requirements</li> </ul> <p>3. docs/user-guide.md (Comprehensive Guide)</p> <ul> <li>Section order: Commands \u2192 Strategies \u2192 State \u2192 Configuration \u2192 Best Practices</li> <li>Technical depth appropriate here</li> <li>Detailed diagrams (can split complex ones)</li> <li>Performance comparisons and troubleshooting</li> </ul> <p>Key principle: No redundancy - each piece of information lives in ONE appropriate place.</p>"},{"location":"contributing/#code-style","title":"Code Style","text":"<ul> <li>Formatting: Use Black (line length 88)</li> <li>Linting: Pass Ruff checks (including docstring checks with <code>-select D</code>)</li> <li>Type hints: Modern Python 3.11+ syntax (<code>X | None</code>, not <code>Optional[X]</code>)</li> <li>Import order: Ruff automatically organizes imports:</li> <li><code>from __future__ import annotations</code> (if needed)</li> <li>Standard library</li> <li>Third-party packages</li> <li>First-party (NAPT) imports</li> </ul>"},{"location":"contributing/#testing-requirements","title":"Testing Requirements","text":"<p>When adding new code:</p> <ol> <li>Write tests - All new features must have tests</li> <li>Mock external dependencies - Use requests-mock for HTTP, mock filesystem operations</li> <li>Test error cases - Not just happy paths</li> <li>Use fixtures - Leverage existing fixtures in <code>conftest.py</code></li> <li>Keep tests fast - Unit tests should run in milliseconds</li> <li>Mark integration tests - Use <code>@pytest.mark.integration</code> for tests with real dependencies</li> </ol>"},{"location":"contributing/#design-principles","title":"Design Principles","text":"<p>When contributing code:</p> <ol> <li>Follow existing patterns - Use the same style and structure as existing code</li> <li>Chain exceptions - Use <code>raise ... from err</code> for better debugging</li> <li>Return structured data - Public API functions return frozen dataclasses for testing</li> <li>Single responsibility - Each function does one thing well</li> <li>Document design decisions - Explain \"why\" in docstrings</li> <li>Test cross-platform - Ensure Linux/Windows/macOS compatibility</li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":""},{"location":"contributing/#before-submitting","title":"Before Submitting","text":"<p>Before creating a pull request, ensure:</p> <ul> <li> Code follows existing patterns and conventions</li> <li> All functions have comprehensive docstrings</li> <li> Type annotations are included</li> <li> Tests are added for new features</li> <li> All tests pass (<code>poetry run pytest tests/</code>)</li> <li> Code is formatted (<code>poetry run black notapkgtool/</code>)</li> <li> Linting passes (<code>poetry run ruff check --fix notapkgtool/</code>)</li> <li> Documentation is updated (README.md, docs/ if needed)</li> </ul>"},{"location":"contributing/#pr-description-template","title":"PR Description Template","text":"<pre><code>## Description\nBrief description of what this PR does.\n\n## Motivation\nWhy is this change needed?\n\n## Changes\n- Bullet list of key changes\n- Include any breaking changes\n\n## Testing\nHow was this tested?\n- [ ] Unit tests added/updated\n- [ ] Integration tests added/updated\n- [ ] Manual testing performed\n\n## Checklist\n- [ ] Code follows project conventions\n- [ ] Documentation updated\n- [ ] Tests pass\n- [ ] No linting errors\n</code></pre>"},{"location":"contributing/#questions-or-issues","title":"Questions or Issues?","text":"<ul> <li>Questions: Open a GitHub Discussion</li> <li>Bug Reports: Open a GitHub Issue with:</li> <li>NAPT version (<code>napt --version</code>)</li> <li>Python version</li> <li>Platform (Windows/Linux/macOS)</li> <li>Recipe file (or minimal example)</li> <li>Error message and traceback</li> <li>Steps to reproduce</li> </ul>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the Apache License 2.0.</p>"},{"location":"quick-start/","title":"Quick Start Guide","text":"<p>Get up and running with NAPT in minutes!</p>"},{"location":"quick-start/#installation","title":"Installation","text":""},{"location":"quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Git</li> </ul>"},{"location":"quick-start/#choose-your-installation-method","title":"Choose Your Installation Method","text":""},{"location":"quick-start/#option-1-pip-recommended-for-end-users","title":"Option 1: pip (Recommended for End Users)","text":"<p>Best for users who just want to use the tool without extra tooling.</p> <pre><code># Clone repository\ngit clone https://github.com/RogerCibrian/notapkgtool.git\ncd notapkgtool\n\n# Create and activate virtual environment (recommended)\npython -m venv .venv\n.venv\\Scripts\\Activate.ps1  # On Linux/macOS: source .venv/bin/activate\n\n# Install\npip install -e .\n\n# Verify installation\nnapt --version\n</code></pre>"},{"location":"quick-start/#option-2-poetry-recommended-for-development","title":"Option 2: Poetry (Recommended for Development)","text":"<p>Best for contributors and developers who want reproducible builds and dependency management.</p> <p>Prerequisites: Poetry must be installed. See Poetry Installation Guide</p> <pre><code># Clone and install\ngit clone https://github.com/RogerCibrian/notapkgtool.git\ncd notapkgtool\npoetry install\n\n# Activate virtual environment\npoetry shell\n\n# Verify installation\nnapt --version\n</code></pre>"},{"location":"quick-start/#platform-specific-requirements","title":"Platform-Specific Requirements","text":"<p>Windows: No additional requirements - NAPT uses native PowerShell COM API for MSI extraction.</p> <p>Linux/macOS: Install msitools for MSI version extraction:</p> <pre><code># Debian/Ubuntu\nsudo apt-get install msitools\n\n# RHEL/Fedora\nsudo dnf install msitools\n\n# macOS\nbrew install msitools\n</code></pre>"},{"location":"quick-start/#platform-requirements","title":"Platform Requirements","text":"<p>Packaging requires Windows. NAPT uses Microsoft's IntuneWinAppUtil.exe for creating .intunewin packages, which is Windows-only.</p> <p>Discovery and building work on all platforms. Develop on your preferred OS and package on Windows when ready.</p> <p>See the Cross-Platform Support section for CI/CD workflows and detailed examples.</p>"},{"location":"quick-start/#basic-usage","title":"Basic Usage","text":""},{"location":"quick-start/#validate-a-recipe","title":"Validate a Recipe","text":"<p>Quick validation checks syntax and configuration without downloading anything:</p> <pre><code># Basic validation\nnapt validate recipes/Google/chrome.yaml\n\n# With verbose output\nnapt validate recipes/Google/chrome.yaml --verbose\n</code></pre>"},{"location":"quick-start/#discover-latest-version","title":"Discover Latest Version","text":"<p>Download the installer and extract version information:</p> <pre><code># Discover version and download installer\n# State tracking enabled by default for efficient re-runs\nnapt discover recipes/Google/chrome.yaml\n\n# Specify custom output directory\nnapt discover recipes/Google/chrome.yaml --output-dir ./cache\n\n# Show verbose output with progress details\nnapt discover recipes/Google/chrome.yaml --verbose\n\n# Disable state tracking (always download, no caching)\nnapt discover recipes/Google/chrome.yaml --stateless\n\n# Show debug output with full configuration dumps\nnapt discover recipes/Google/chrome.yaml --debug\n</code></pre>"},{"location":"quick-start/#build-psadt-package","title":"Build PSADT Package","text":"<p>Create a complete PSADT package ready for deployment:</p> <pre><code># Build PSADT package from recipe and downloaded installer\nnapt build recipes/Google/chrome.yaml\n\n# Specify custom downloads and output directories\nnapt build recipes/Google/chrome.yaml --downloads-dir ./downloads --output-dir ./builds\n\n# Show verbose output\nnapt build recipes/Google/chrome.yaml --verbose\n</code></pre>"},{"location":"quick-start/#create-intunewin-package","title":"Create .intunewin Package","text":"<p>Package the PSADT build for Microsoft Intune:</p> <pre><code># Create .intunewin from build directory\nnapt package builds/napt-chrome/141.0.7390.123/\n\n# Specify output directory and clean source after packaging\nnapt package builds/napt-chrome/141.0.7390.123/ --output-dir ./packages --clean-source\n</code></pre> <p>\ud83d\udca1 Tip: Use <code>--verbose</code> to see progress details or <code>--debug</code> for full diagnostics including configuration dumps and backend selection</p>"},{"location":"quick-start/#example-workflow","title":"Example Workflow","text":"<p>Here's a complete workflow from recipe validation to Intune package:</p> <pre><code># 1. Validate recipe\nnapt validate recipes/Google/chrome.yaml\n# \u2713 Recipe is valid\n\n# 2. Discover and download latest version\nnapt discover recipes/Google/chrome.yaml\n# \u2192 downloads/googlechromestandaloneenterprise64.msi\n# \u2192 state/versions.json (updated)\n\n# 3. Build PSADT package\nnapt build recipes/Google/chrome.yaml\n# \u2192 builds/napt-chrome/141.0.7390.123/\n\n# 4. Create .intunewin package\nnapt package builds/napt-chrome/141.0.7390.123/\n# \u2192 packages/napt-chrome/napt-chrome-141.0.7390.123.intunewin\n\n# Result: Ready-to-upload .intunewin file in packages/napt-chrome/\n</code></pre>"},{"location":"quick-start/#whats-next","title":"What's Next?","text":"<p>Now that you have NAPT installed and understand the basic commands, explore:</p> <ul> <li>User Guide - Learn about discovery strategies, configuration, and advanced features</li> <li>API Reference - Use NAPT as a Python library</li> <li>Creating Recipes - Write your own application recipes</li> <li>Examples - Browse example recipes for Chrome, Git, and more</li> </ul>"},{"location":"roadmap/","title":"NAPT Roadmap","text":""},{"location":"roadmap/#philosophy","title":"Philosophy","text":"<p>This roadmap is a living document showing potential future directions for NAPT. Features listed here are ideas and possibilities, not commitments. Priorities may shift based on:</p> <ul> <li>User feedback and real-world usage</li> <li>Discovered technical challenges or opportunities</li> <li>New insights from development experience</li> <li>Community contributions</li> </ul> <p>Status Legend:</p> <ul> <li>\ud83d\udca1 Idea: Unformed thought, needs refinement</li> <li>\ud83d\udd2c Investigating: Researching feasibility/approach</li> <li>\ud83d\udccb Ready: Well-defined, ready for implementation</li> <li>\ud83d\udea7 In Progress: Actively being developed</li> <li>\u2705 Completed: Implemented and released</li> </ul>"},{"location":"roadmap/#how-to-use-this-roadmap","title":"How to Use This Roadmap","text":""},{"location":"roadmap/#adding-new-ideas","title":"Adding New Ideas","text":"<ol> <li>Add to appropriate category section with status \ud83d\udca1</li> <li>Include complexity estimate and value assessment</li> <li>Describe the problem it solves</li> <li>No need to design the solution yet</li> </ol>"},{"location":"roadmap/#promoting-ideas","title":"Promoting Ideas","text":"<p>When an idea becomes clearer: 1. Move to \"Investigating\" \ud83d\udd2c if research needed 2. Move to \"Ready for Implementation\" \ud83d\udccb when well-defined 3. Assign to milestone when scheduling work 4. Move to \"Completed\" when released</p>"},{"location":"roadmap/#declining-ideas","title":"Declining Ideas","text":"<p>If we decide not to pursue something: 1. Move to \"Declined / Won't Implement\" 2. Add brief rationale 3. Keep for future reference (prevents re-discussion)</p>"},{"location":"roadmap/#current-status","title":"Current Status","text":""},{"location":"roadmap/#ready-for-implementation","title":"Ready for Implementation \ud83d\udccb","text":""},{"location":"roadmap/#update-policy-enforcement","title":"Update Policy Enforcement","text":"<p>Complexity: Low (few hours to 1 day) Value: Medium</p> <p>Description: Complete the <code>policy/updates.py</code> module with actual logic.</p> <p>Current State: Module exists with data structures, no implementation</p> <p>Requirements: - Implement version comparison logic - Implement hash comparison logic - Support all strategy types (version_only, hash_or_version, etc.) - Integration with state tracking</p> <p>Design: Already specified in <code>defaults/org.yaml</code> config</p>"},{"location":"roadmap/#investigating","title":"Investigating \ud83d\udd2c","text":""},{"location":"roadmap/#microsoft-intune-upload","title":"Microsoft Intune Upload","text":"<p>Complexity: High (3-5 days) Value: Very High</p> <p>Description: Direct upload of .intunewin packages to Microsoft Intune via Graph API.</p> <p>Research Needed: - Authentication strategy (OAuth, service principal, managed identity?) - Graph API endpoints and permissions required - Win32 app metadata requirements - Error handling and retry logic - Rate limiting considerations</p> <p>Blockers: - Need to decide on authentication approach - Requires Azure AD app registration - May need different auth for different deployment scenarios</p> <p>References: - Microsoft Graph API - Win32 Apps - Intune App Upload Process</p>"},{"location":"roadmap/#deployment-wave-management","title":"Deployment Wave Management","text":"<p>Complexity: Very High (5-10 days) Value: High</p> <p>Description: Phased deployment with rings (Pilot \u2192 Production) and gradual rollout.</p> <p>Features Under Consideration: - Ring definitions (Pilot, UAT, Production) - Assignment group management - Rollout scheduling (% of users per day) - Health monitoring integration - Rollback capabilities</p> <p>Dependencies: - Requires Intune upload implementation first - Requires Graph API for assignment groups - May need separate monitoring/alerting</p> <p>Blockers: - Complex domain requiring deep Intune knowledge - Needs real-world deployment patterns study</p>"},{"location":"roadmap/#future-ideas-by-category","title":"Future Ideas (By Category)","text":""},{"location":"roadmap/#user-facing-features","title":"User-Facing Features","text":""},{"location":"roadmap/#detection-script-generation","title":"Detection Script Generation","text":"<p>Status: \ud83d\udca1 Idea Complexity: Medium (1-3 days) Value: High</p> <p>Description: Automatically generate detection scripts for Intune that check if an application is already installed.</p> <p>Approach Options: - For MSI: Generate script that checks ProductCode in registry - For EXE: Generate script that checks file version or registry keys - Template-based generation with recipe hints - Support for custom detection logic in recipes</p> <p>Benefits: - Reduces manual work for Intune app creation - Ensures consistent detection logic - Leverages information we already have (ProductCode, version, paths)</p> <p>Use Cases: - Automatic detection for Win32 apps in Intune - Prevent re-installation of already-installed apps - Version-based detection for upgrades</p> <p>Technical Considerations: - Need to handle both MSI and EXE installers - PowerShell detection script format for Intune - Support for custom registry keys or file paths - Version comparison in detection script</p>"},{"location":"roadmap/#prepost-installuninstall-script-support","title":"Pre/Post Install/Uninstall Script Support","text":"<p>Status: \ud83d\udca1 Idea Complexity: Low (few hours to 1 day) Value: Medium</p> <p>Description: Add support for pre-install, post-install, pre-uninstall, and post-uninstall script blocks in recipes.</p> <p>Proposed Recipe Format: <pre><code>psadt:\n  pre_install: |\n    # Close running processes\n    # Backup user data\n  install: |\n    # Main installation\n  post_install: |\n    # Configure settings\n    # Create shortcuts\n  pre_uninstall: |\n    # Backup settings\n  uninstall: |\n    # Main uninstallation\n  post_uninstall: |\n    # Clean up user data\n</code></pre></p> <p>Benefits: - More granular control over deployment lifecycle - Separation of concerns (prep vs install vs cleanup) - Aligns with PSADT's deployment phase structure - Cleaner recipe organization</p> <p>Implementation: - Add new fields to recipe schema - Insert into appropriate sections of Invoke-AppDeployToolkit.ps1 - Map to PSADT's Pre-Installation, Installation, Post-Installation sections - Validate all script blocks</p> <p>Related: PSADT already has these phases in the template structure</p>"},{"location":"roadmap/#enhanced-cli-help-menu","title":"Enhanced CLI Help Menu","text":"<p>Status: \ud83d\udca1 Idea Complexity: Low (few hours to 1 day) Value: Medium</p> <p>Description: Improve the <code>napt -h</code> help output with more detailed information, examples, and better organization.</p> <p>Potential Enhancements: - Add examples for common workflows in help text - Group commands by category (Discovery, Building, Packaging) - Show performance characteristics of strategies - Add tips for troubleshooting (--verbose, --debug flags) - Include links to online documentation - Better formatting with colors/sections (via rich or similar)</p> <p>Benefits: - Better discoverability of features - Reduces need to consult docs for basic usage - Improves new user onboarding experience - Quick reference for command options</p> <p>Related: CLI help currently minimal, relies on online documentation</p>"},{"location":"roadmap/#recipe-creation-tutorial","title":"Recipe Creation Tutorial","text":"<p>Status: \ud83d\udca1 Idea Complexity: Low (few hours to 1 day) Value: High</p> <p>Description: Step-by-step tutorial for creating recipes from scratch.</p> <p>Potential Content: - Recipe structure and required fields - Choosing the right discovery strategy - Testing recipes with napt validate/discover - Common patterns and examples - Troubleshooting tips</p> <p>Benefits: - Lower barrier to entry for new users - Reduces trial-and-error in recipe development - Consolidates recipe knowledge in one place</p> <p>Waiting On: Recipe schema stabilization and user feedback on patterns</p>"},{"location":"roadmap/#code-quality-validation","title":"Code Quality &amp; Validation","text":""},{"location":"roadmap/#powershell-validation","title":"PowerShell Validation","text":"<p>Status: \ud83d\udca1 Idea Complexity: Medium (1-3 days) Value: High</p> <p>Description: Validate PowerShell syntax in recipe install/uninstall blocks to catch errors before deployment.</p> <p>Approach Options: - Basic structural checks (balanced braces, quotes) - PowerShell parser integration (PSParser tokenizer) - Hybrid: Basic checks + optional advanced validation</p> <p>Benefits: - Catch syntax errors at recipe validation time - Prevent broken deployments - Better developer experience</p> <p>Related: TODO in <code>notapkgtool/build/packager.py</code> - discovered during testing</p>"},{"location":"roadmap/#recipe-linting-best-practices","title":"Recipe Linting &amp; Best Practices","text":"<p>Status: \ud83d\udca1 Idea Complexity: High (3-5 days) Value: Medium</p> <p>Description: Advanced recipe validation beyond syntax checking.</p> <p>Features: - Validate PSADT function names exist in v4 - Warn on deprecated patterns or old v3 functions - Check for common anti-patterns - Suggest improvements (e.g., use Uninstall-ADTApplication) - Style guide enforcement</p> <p>Benefits: - Higher quality recipes - Consistent code style - Educational for new users</p>"},{"location":"roadmap/#technical-enhancements","title":"Technical Enhancements","text":""},{"location":"roadmap/#exe-version-extraction","title":"EXE Version Extraction","text":"<p>Status: \ud83d\udca1 Idea Complexity: Medium (1-3 days) Value: Medium</p> <p>Description: Extract version information from PE (Portable Executable) headers for .exe installers.</p> <p>Technical Details: - New version types: <code>exe_file_version</code>, <code>exe_product_version</code> - Use <code>pefile</code> library for cross-platform support - Fallback to PowerShell on Windows</p> <p>Use Cases: - Applications distributed as EXE (Git, VS Code, etc.) - Vendors who don't provide version in URL or API</p> <p>Related: Mentioned in <code>notapkgtool/discovery/url_download.py</code> docstring</p>"},{"location":"roadmap/#parallel-package-building","title":"Parallel Package Building","text":"<p>Status: \ud83d\udca1 Idea Complexity: Medium (1-3 days) Value: Medium</p> <p>Description: Build multiple PSADT packages in parallel for faster multi-app workflows.</p> <p>Technical Details: - Use Python multiprocessing or asyncio - Parallel PSADT downloads and builds - Maintain state consistency - Progress reporting for multiple builds</p> <p>Use Cases: - Organizations with 50+ apps - Monthly update cycles - CI/CD pipelines</p>"},{"location":"roadmap/#intunewinapputil-version-tracking","title":"IntuneWinAppUtil Version Tracking","text":"<p>Status: \ud83d\udca1 Idea Complexity: Low (few hours to 1 day) Value: Low</p> <p>Description: Track version of IntuneWinAppUtil.exe in cache metadata instead of always using latest from master.</p> <p>Current Behavior: Downloads from <code>master</code> branch (always latest)</p> <p>Proposed Enhancement: - Track tool version in cache metadata - Allow pinning to specific commit/release - Auto-detect when tool updates available - Optional config setting for tool version/source</p> <p>Benefits: - Reproducible builds (pin to known-good version) - Control over tool updates - Better for air-gapped environments</p> <p>Related: TODO in <code>notapkgtool/build/packager.py:47</code></p>"},{"location":"roadmap/#declined-wont-implement","title":"Declined / Won't Implement","text":""},{"location":"roadmap/#built-in-pr-creation","title":"Built-in PR Creation","text":"<p>Reason: NAPT should focus on discovery and packaging. Git operations and PR creation should remain in CI/CD workflows (GitHub Actions, etc.). This keeps NAPT platform-agnostic and focused on its core mission.</p>"},{"location":"roadmap/#recently-completed","title":"Recently Completed","text":"<p>v0.2.0 - PSADT building, packaging, and new discovery strategies v0.1.0 - Core validation, discovery, and configuration system</p> <p>See CHANGELOG.md for detailed release history.</p>"},{"location":"user-guide/","title":"User Guide","text":"<p>This guide covers NAPT's key features, configuration system, and advanced usage patterns.</p>"},{"location":"user-guide/#commands-reference","title":"Commands Reference","text":""},{"location":"user-guide/#napt-validate","title":"napt validate","text":"<p>Validates recipe syntax and configuration without making network calls.</p> <pre><code>napt validate recipes/Google/chrome.yaml [--verbose]\n</code></pre> <p>Purpose:</p> <ul> <li>Quick feedback during recipe development</li> <li>CI/CD pre-checks</li> <li>Syntax validation</li> </ul> <p>What it checks:</p> <ul> <li>YAML syntax is valid</li> <li>Required fields present (apiVersion, apps, source)</li> <li>Discovery strategy exists and is registered</li> <li>Strategy-specific configuration is valid</li> </ul> <p>What it doesn't check:</p> <ul> <li>URLs are accessible</li> <li>Files can be downloaded</li> <li>Version extraction will work</li> </ul>"},{"location":"user-guide/#napt-discover","title":"napt discover","text":"<p>Discovers the latest version by downloading the installer and extracting version information.</p> <pre><code>napt discover recipes/Google/chrome.yaml [OPTIONS]\n\nOptions:\n  --output-dir DIR      Download directory (default: ./downloads)\n  --state-file FILE     State file path (default: state/versions.json)\n  --stateless           Disable state tracking\n  -v, --verbose         Show progress and status updates\n  -d, --debug           Show detailed debugging output\n</code></pre> <p>Features:</p> <ul> <li>\u2705 Discovers version using configured strategy</li> <li>\u2705 Downloads installer (or HTTP 304 if cached)</li> <li>\u2705 Extracts version from downloaded file</li> <li>\u2705 Updates state file with ETag caching</li> <li>\u2705 SHA-256 hash verification</li> </ul>"},{"location":"user-guide/#napt-build","title":"napt build","text":"<p>Builds a complete PSADT package from a recipe and downloaded installer.</p> <pre><code>napt build recipes/Google/chrome.yaml [OPTIONS]\n\nOptions:\n  --downloads-dir DIR   Installer directory (default: ./downloads)\n  --output-dir DIR      Build output directory (default: ./builds)\n  -v, --verbose         Show progress\n  -d, --debug           Show detailed output\n</code></pre> <p>Features:</p> <ul> <li>\u2705 Downloads PSADT release from GitHub (or uses cached version)</li> <li>\u2705 Extracts version from installer file</li> <li>\u2705 Generates Invoke-AppDeployToolkit.ps1 from template</li> <li>\u2705 Merges organization defaults with recipe-specific values</li> <li>\u2705 Inserts recipe install/uninstall code</li> <li>\u2705 Applies custom branding (logo, banner)</li> <li>\u2705 Creates versioned build directories</li> </ul>"},{"location":"user-guide/#napt-package","title":"napt package","text":"<p>Creates a .intunewin package from a built PSADT directory.</p> <pre><code>napt package BUILD_DIR [OPTIONS]\n\nOptions:\n  --output-dir DIR      Output directory (default: packages/{app_id}/)\n  --clean-source        Remove build directory after packaging\n  -v, --verbose         Show progress\n  -d, --debug           Show detailed output\n</code></pre> <p>Features:</p> <ul> <li>\u2705 Downloads IntuneWinAppUtil.exe (or uses cached version)</li> <li>\u2705 Validates build structure before packaging</li> <li>\u2705 Creates .intunewin file for Intune deployment</li> <li>\u2705 Optional source cleanup</li> </ul>"},{"location":"user-guide/#output-modes","title":"Output Modes","text":"<p>All commands support verbosity flags to control output detail:</p> Flag What it shows (none) Clean output with step indicators <code>[1/4]</code> and progress <code>--verbose</code> or <code>-v</code> All of the above, plus HTTP requests/responses, file operations, SHA-256 hashes, and configuration loading <code>--debug</code> or <code>-d</code> All verbose output, plus full YAML config dumps (org/vendor/recipe/merged), backend selection details, and regex match groups <p>Debug mode includes all verbose output plus deep diagnostic information. Use <code>--verbose</code> for normal troubleshooting and <code>--debug</code> when you need to understand exactly what NAPT is doing internally.</p>"},{"location":"user-guide/#discovery-strategies","title":"Discovery Strategies","text":"<p>Discovery strategies are the core mechanism for obtaining application installers and extracting version information.</p>"},{"location":"user-guide/#available-strategies","title":"Available Strategies","text":"Strategy Version Source Use Case Unchanged Check api_github Git tags GitHub-hosted releases Fast (GitHub API ~100ms) api_json JSON API REST APIs with metadata Fast (API call ~100ms) url_download File metadata Fixed URLs, MSI installers Medium (HTTP conditional ~500ms) web_scrape Download page Vendors without APIs Fast (page scrape + regex)"},{"location":"user-guide/#api_github","title":"api_github","text":"<p>Best for:</p> <ul> <li>Open-source projects on GitHub (Git, VS Code, Node.js)</li> <li>Projects with GitHub releases and release assets</li> <li>Semantic versioned tags</li> </ul> <p>Configuration:</p> <pre><code>source:\n  strategy: api_github\n  repo: \"git-for-windows/git\"\n  asset_pattern: \"Git-.*-64-bit\\\\.exe$\"\n  version_pattern: \"v?([0-9.]+)\"\n</code></pre> <p>Pros: Official GitHub API, reliable, fast update checks (API only, ~100ms), supports authentication Cons: GitHub API rate limits (60/hour unauthenticated)</p>"},{"location":"user-guide/#api_json","title":"api_json","text":"<p>Best for:</p> <ul> <li>Vendors with JSON REST APIs (Microsoft, Mozilla)</li> <li>Cloud services with version endpoints</li> <li>APIs requiring authentication or custom headers</li> </ul> <p>Configuration:</p> <pre><code>source:\n  strategy: api_json\n  api_url: \"https://vendor.com/api/latest\"\n  version_path: \"version\"\n  download_url_path: \"download_url\"\n  headers:\n    Authorization: \"Bearer ${API_TOKEN}\"\n</code></pre> <p>Pros: Fast update checks (API only, ~100ms), flexible, supports complex APIs, no file parsing Cons: Requires vendor API availability</p>"},{"location":"user-guide/#url_download","title":"url_download","text":"<p>Best for:</p> <ul> <li>Vendors with stable download URLs (Chrome, Firefox enterprise)</li> <li>MSI installers with ProductVersion embedded</li> <li>When version isn't in URL or easily parseable</li> </ul> <p>Configuration:</p> <pre><code>source:\n  strategy: url_download\n  url: \"https://dl.google.com/chrome/install/googlechromestandaloneenterprise64.msi\"\n  version:\n    type: msi\n</code></pre> <p>Pros: Simple and reliable, version directly from installer (most accurate) Cons: Must download file to know version, slower update checks (HTTP conditional request)</p>"},{"location":"user-guide/#web_scrape","title":"web_scrape","text":"<p>Best for:</p> <ul> <li>Vendors with download pages listing installers (7-Zip, etc.)</li> <li>When no direct download URL or API is available</li> <li>Version-encoded URLs on vendor websites</li> <li>Small vendors with simple HTML download pages</li> </ul> <p>Configuration:</p> <pre><code>source:\n  strategy: web_scrape\n  page_url: \"https://www.7-zip.org/download.html\"\n  link_selector: 'a[href$=\"-x64.msi\"]'        # CSS selector (recommended)\n  version_pattern: \"7z(\\\\d{2})(\\\\d{2})-x64\"   # Extract from discovered URL\n  version_format: \"{0}.{1}\"                    # Transform to \"25.01\"\n</code></pre> <p>Pros: Fast version checks (~100-300ms page scrape), works without APIs, CSS selectors are robust Cons: Requires page structure knowledge, may break if vendor redesigns site</p>"},{"location":"user-guide/#decision-guide","title":"Decision Guide","text":"<p>Use this flowchart to choose the right strategy:</p> <pre><code>flowchart TD\n    Start{JSON API for&lt;br/&gt;version/download?}\n    Start --&gt;|Yes| JSON[api_json&lt;br/&gt;Fast version checks]\n    Start --&gt;|No| GitHub{App on&lt;br/&gt;GitHub?}\n    GitHub --&gt;|Yes| GHRelease[api_github&lt;br/&gt;Reliable API, fast checks]\n    GitHub --&gt;|No| DirectURL{Have direct&lt;br/&gt;download URL?}\n    DirectURL --&gt;|Yes| Static[url_download&lt;br/&gt;Must download to check]\n    DirectURL --&gt;|No| Scrape[web_scrape&lt;br/&gt;Scrape page for link]</code></pre> <p>Performance Note: Version-first strategies (everything except url_download) can skip downloads entirely when versions haven't changed, making them ideal for scheduled CI/CD checks.</p>"},{"location":"user-guide/#state-management-caching","title":"State Management &amp; Caching","text":"<p>NAPT automatically tracks discovered versions and optimizes subsequent runs by avoiding unnecessary downloads.</p>"},{"location":"user-guide/#how-it-works","title":"How It Works","text":"<p>NAPT uses different caching approaches based on the discovery strategy, enabling significant performance optimization:</p> <ul> <li>Version-First (web_scrape, api_github, api_json): Checks version via API or page scraping (~100-300ms) before downloading. If unchanged and file exists, skips download entirely.</li> <li>File-First (url_download): Uses HTTP conditional requests (ETags) to check if file changed. If server returns 304 Not Modified (~500ms), uses cached file without re-downloading.</li> </ul> <p>This intelligent caching is critical for CI/CD with frequent scheduled checks, providing fast feedback when applications haven't changed.</p>"},{"location":"user-guide/#detailed-workflow","title":"Detailed Workflow","text":""},{"location":"user-guide/#version-first-strategies-web_scrape-api_github-api_json","title":"Version-First Strategies (web_scrape, api_github, api_json)","text":"<p>These strategies discover the version before downloading, enabling fast cache checks:</p> <pre><code>flowchart TD\n    Start([napt discover]) --&gt; LoadRecipe[Load Recipe YAML]\n    LoadRecipe --&gt; CheckCache{Cached&lt;br/&gt;Version?}\n\n    CheckCache --&gt;|Yes| DiscoverAPI[Discover Version via API/Regex]\n    CheckCache --&gt;|No - First Run| DiscoverFirst[Discover Version via API/Regex]\n\n    DiscoverAPI --&gt; Compare{Version&lt;br/&gt;Changed?}\n    Compare --&gt;|No - Same Version| CheckFile{File&lt;br/&gt;Exists?}\n    CheckFile --&gt;|Yes| Done([\u2713 Already Current&lt;br/&gt;No download needed])\n    CheckFile --&gt;|No| DownloadMissing[Download Missing File]\n    DownloadMissing --&gt; UpdateState1[Update state.json]\n    UpdateState1 --&gt; Done\n\n    Compare --&gt;|Yes - New Version| DownloadNew[Download New Installer]\n    DownloadNew --&gt; UpdateState2[Update state.json]\n    UpdateState2 --&gt; Ready([\u2713 Ready for napt build])\n\n    DiscoverFirst --&gt; DownloadFirstRun[Download Installer]\n    DownloadFirstRun --&gt; CreateState[Create state.json]\n    CreateState --&gt; Ready</code></pre> <p>Key optimization: Version discovered via API or page scraping (~100-300ms) before downloading. If unchanged and file exists, skip download entirely.</p>"},{"location":"user-guide/#file-first-strategy-url_download","title":"File-First Strategy (url_download)","text":"<p>This strategy must download (or check) the file first to extract the version:</p> <pre><code>flowchart TD\n    Start([napt discover]) --&gt; LoadRecipe[Load Recipe YAML]\n    LoadRecipe --&gt; CheckCache{Cached&lt;br/&gt;ETag?}\n\n    CheckCache --&gt;|Yes| ConditionalRequest[HTTP Request with ETag]\n    CheckCache --&gt;|No - First Run| DownloadFirst[Download File]\n\n    ConditionalRequest --&gt; ServerResponse{Server&lt;br/&gt;Response?}\n    ServerResponse --&gt;|304 Not Modified| UpdateTimestamp[Update state.json timestamp]\n    UpdateTimestamp --&gt; Done([\u2713 Already Current&lt;br/&gt;Using cached file])\n\n    ServerResponse --&gt;|200 OK - Changed| DownloadNew[Download New File]\n    DownloadNew --&gt; ExtractVersion[Extract Version from File]\n    ExtractVersion --&gt; UpdateState[Update state.json]\n    UpdateState --&gt; Ready([\u2713 Ready for napt build])\n\n    DownloadFirst --&gt; ExtractFirst[Extract Version from File]\n    ExtractFirst --&gt; CreateState[Create state.json with ETag]\n    CreateState --&gt; Ready</code></pre> <p>Key optimization: HTTP conditional request with ETag (~500ms). Server returns 304 Not Modified if unchanged, avoiding re-download. Version extracted after download/check.</p>"},{"location":"user-guide/#performance-comparison","title":"Performance Comparison","text":"Scenario Version-First File-First First run API call + Download Download only Unchanged (most common) ~100-300ms version check ~500ms HTTP conditional request Changed API call + Download Full download <p>Recommendation: Use version-first strategies (web_scrape, api_github, api_json) when available for fastest cache checks.</p>"},{"location":"user-guide/#default-behavior-stateful","title":"Default Behavior (Stateful)","text":"<pre><code># State tracking enabled by default\nnapt discover recipes/Google/chrome.yaml\n\n# Creates/updates: state/versions.json\n</code></pre>"},{"location":"user-guide/#stateless-mode","title":"Stateless Mode","text":"<pre><code># Disable state tracking for one-off checks\nnapt discover recipes/Google/chrome.yaml --stateless\n\n# Always downloads, no caching\n# Useful for CI/CD clean builds\n</code></pre>"},{"location":"user-guide/#configuration-layers","title":"Configuration Layers","text":"<p>NAPT uses a sophisticated 3-layer configuration system that promotes DRY (Don't Repeat Yourself) principles:</p>"},{"location":"user-guide/#the-three-layers","title":"The Three Layers","text":"<ol> <li> <p>Organization defaults (<code>defaults/org.yaml</code>) - Base configuration for all apps. Required if a defaults directory is found. Contains PSADT settings, update policies, and deployment waves.</p> </li> <li> <p>Vendor defaults (<code>defaults/vendors/&lt;Vendor&gt;.yaml</code>) - Vendor-specific overrides. Optional; only loaded if vendor is detected (e.g., Google-specific settings).</p> </li> <li> <p>Recipe configuration (<code>recipes/&lt;Vendor&gt;/&lt;app&gt;.yaml</code>) - App-specific settings. Always required; defines the specific app with final overrides.</p> </li> </ol>"},{"location":"user-guide/#merge-behavior","title":"Merge Behavior","text":"<p>The loader performs deep merging with \"last wins\" semantics:</p> <ul> <li>Dicts: Recursively merged (keys from overlay override base)</li> <li>Lists: Completely replaced (NOT appended/extended)</li> <li>Scalars: Overwritten (strings, numbers, booleans)</li> </ul>"},{"location":"user-guide/#example","title":"Example","text":"<pre><code># defaults/org.yaml\ndefaults:\n  psadt:\n    release: \"latest\"\n    app_vars:\n      AppVendor: \"Unknown\"\n</code></pre> <pre><code># defaults/vendors/Google.yaml\ndefaults:\n  psadt:\n    app_vars:\n      AppVendor: \"Google LLC\"\n</code></pre> <pre><code># recipes/Google/chrome.yaml\napps:\n  - name: \"Google Chrome\"\n    # AppVendor will be \"Google LLC\" (from vendor defaults)\n    # release will be \"latest\" (from org defaults)\n</code></pre>"},{"location":"user-guide/#cross-platform-support","title":"Cross-Platform Support","text":"<p>NAPT is a Windows tool for Microsoft Intune packaging. Develop on any platform, package on Windows.</p>"},{"location":"user-guide/#platform-compatibility-matrix","title":"Platform Compatibility Matrix","text":"Platform Download Discovery Build Package MSI Extraction Windows \u2705 \u2705 \u2705 \u2705 \u2705 Native (PowerShell COM) Linux \u2705 \u2705 \u2705 \u26ab Windows Only \u2705 Via msitools macOS \u2705 \u2705 \u2705 \u26ab Windows Only \u2705 Via msitools"},{"location":"user-guide/#why-windows-for-packaging","title":"Why Windows for Packaging?","text":"<p>The <code>napt package</code> command uses Microsoft's IntuneWinAppUtil.exe, which is a Windows-only .NET application. This is the official tool for creating .intunewin packages.</p>"},{"location":"user-guide/#recommended-workflows","title":"Recommended Workflows","text":""},{"location":"user-guide/#workflow-1-all-windows-simplest","title":"Workflow 1: All-Windows (Simplest)","text":"<pre><code># Run everything on Windows\nnapt discover recipes/Google/chrome.yaml\nnapt build recipes/Google/chrome.yaml\nnapt package builds/napt-chrome/142.0.7444.163/\n</code></pre>"},{"location":"user-guide/#workflow-2-mixed-platform-development","title":"Workflow 2: Mixed Platform Development","text":"<pre><code># On Linux/macOS: Discovery and build\nnapt discover recipes/Google/chrome.yaml\nnapt build recipes/Google/chrome.yaml\n\n# Transfer build directory to Windows (or use shared drive)\n# On Windows: Package\nnapt package builds/napt-chrome/142.0.7444.163/\n</code></pre>"},{"location":"user-guide/#msi-extraction-backends","title":"MSI Extraction Backends","text":"<p>Windows (tried in order):</p> <ol> <li><code>msilib</code> (Python standard library)</li> <li><code>_msi</code> (CPython extension)</li> <li>PowerShell COM (always available, universal fallback)</li> </ol> <p>Linux/macOS:</p> <ol> <li><code>msiinfo</code> from msitools package</li> </ol> <p>The PowerShell fallback makes MSI extraction truly universal on Windows systems, even when Python MSI libraries aren't available.</p>"},{"location":"user-guide/#programmatic-api","title":"Programmatic API","text":"<p>NAPT can be used as a Python library for automation and integration.</p>"},{"location":"user-guide/#basic-usage","title":"Basic Usage","text":"<pre><code>from pathlib import Path\nfrom notapkgtool.core import discover_recipe\nfrom notapkgtool.validation import validate_recipe\nfrom notapkgtool.config import load_effective_config\n\n# Validate recipe syntax (no downloads)\nresult = validate_recipe(\n    recipe_path=Path(\"recipes/Google/chrome.yaml\"),\n    verbose=True\n)\nprint(f\"Status: {result.status}\")\n\n# Discover version and download installer\nresult = discover_recipe(\n    recipe_path=Path(\"recipes/Google/chrome.yaml\"),\n    output_dir=Path(\"./downloads\"),\n    verbose=True\n)\nprint(f\"Version: {result.version}\")\nprint(f\"SHA-256: {result.sha256}\")\n\n# Load configuration\nconfig = load_effective_config(Path(\"recipes/Google/chrome.yaml\"))\n</code></pre>"},{"location":"user-guide/#version-comparison","title":"Version Comparison","text":"<pre><code>from notapkgtool.versioning import compare_any, is_newer_any\n\n# Compare versions\nif is_newer_any(\"1.2.0\", \"1.1.9\"):\n    print(\"Update available!\")\n\n# Detailed comparison\nresult = compare_any(\"2.0.0\", \"1.9.9\")\n# Returns: 1 (newer), 0 (same), or -1 (older)\n</code></pre>"},{"location":"user-guide/#exception-handling","title":"Exception Handling","text":"<p>NAPT uses a custom exception hierarchy that allows you to distinguish between different types of errors:</p> <ul> <li><code>ConfigError</code>: Configuration-related errors (YAML parse errors, missing fields, invalid strategy configuration, missing recipe files, validation failures)</li> <li><code>NetworkError</code>: Network/download-related errors (HTTP errors, API failures, download timeouts, network-related version extraction errors)</li> <li><code>PackagingError</code>: Packaging/build-related errors (build failures, missing tools, MSI extraction errors, packaging operations)</li> </ul> <p>All exceptions inherit from <code>NAPTError</code>, allowing you to catch all NAPT errors with a single <code>except</code> clause if needed.</p> <p>Example: Catching specific error types</p> <pre><code>from pathlib import Path\nfrom notapkgtool.core import discover_recipe\nfrom notapkgtool.exceptions import ConfigError, NetworkError, PackagingError\n\ntry:\n    result = discover_recipe(\n        recipe_path=Path(\"recipes/Google/chrome.yaml\"),\n        output_dir=Path(\"./downloads\")\n    )\nexcept ConfigError as e:\n    print(f\"Configuration error: {e}\")\n    # Handle config issues (fix recipe, check paths)\nexcept NetworkError as e:\n    print(f\"Network error: {e}\")\n    # Handle network issues (retry, check connectivity)\nexcept PackagingError as e:\n    print(f\"Packaging error: {e}\")\n    # Handle packaging issues (check tools, permissions)\n</code></pre> <p>Example: Catching all NAPT errors</p> <pre><code>from notapkgtool.exceptions import NAPTError\n\ntry:\n    result = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\nexcept NAPTError as e:\n    print(f\"NAPT error: {e}\")\n    # Handle any NAPT error generically\n</code></pre> <p>Note: The CLI layer catches these exceptions and converts them to exit codes (<code>0</code> for success, <code>1</code> for errors). When using NAPT as a library, catch exceptions directly rather than relying on exit codes.</p> <p>See the Exceptions API Reference for complete exception documentation, or the Core API Reference for function documentation.</p>"},{"location":"user-guide/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/#recipe-organization","title":"Recipe Organization","text":"<pre><code>recipes/\n\u251c\u2500\u2500 &lt;Vendor&gt;/\n\u2502   \u251c\u2500\u2500 &lt;app1&gt;.yaml\n\u2502   \u251c\u2500\u2500 &lt;app2&gt;.yaml\n\u2502   \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"user-guide/#vendor-detection","title":"Vendor Detection","text":"<p>NAPT automatically detects vendor from directory structure:</p> <ul> <li><code>recipes/Google/chrome.yaml</code> \u2192 Vendor: \"Google\"</li> <li>Loads <code>defaults/vendors/Google.yaml</code> if it exists</li> </ul>"},{"location":"user-guide/#state-management","title":"State Management","text":"<p>For production use:</p> <ul> <li>\u2705 Keep state tracking enabled (default)</li> <li>\u2705 Use version control for state files</li> <li>\u2705 Run on schedule to detect updates</li> <li>\u2705 Use <code>--verbose</code> in CI/CD for debugging</li> </ul> <p>For development:</p> <ul> <li>Use <code>--stateless</code> for testing</li> <li>Use <code>--debug</code> for troubleshooting</li> <li>Delete state file to force re-discovery</li> </ul>"},{"location":"user-guide/#error-handling","title":"Error Handling","text":""},{"location":"user-guide/#cli-exit-codes","title":"CLI Exit Codes","text":"<p>All commands return proper exit codes:</p> <ul> <li><code>0</code> = Success</li> <li><code>1</code> = Error (configuration, download, validation failure)</li> </ul> <p>Use in scripts:</p> <pre><code>if napt discover recipes/Google/chrome.yaml; then\n    napt build recipes/Google/chrome.yaml\nelse\n    echo \"Discovery failed\"\n    exit 1\nfi\n</code></pre>"},{"location":"user-guide/#library-exception-handling","title":"Library Exception Handling","text":"<p>When using NAPT as a Python library, catch exceptions directly rather than relying on exit codes. See the Programmatic API section for details on exception handling.</p>"},{"location":"user-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/#common-issues","title":"Common Issues","text":"<p>Problem: \"Command not found: napt\"</p> <pre><code># Solution 1: Activate Poetry shell\npoetry shell\n\n# Solution 2: Use poetry run prefix\npoetry run napt --version\n</code></pre> <p>Problem: MSI extraction fails on Linux/macOS</p> <pre><code># Solution: Install msitools\nsudo apt-get install msitools  # Debian/Ubuntu\nbrew install msitools           # macOS\n</code></pre> <p>Problem: State file corrupted</p> <pre><code># NAPT automatically creates backup\n# Backup saved to: state/versions.json.backup\n\n# Force re-download\nnapt discover recipes/app.yaml --stateless\n</code></pre> <p>Problem: GitHub API rate limit</p> <pre><code># Solution: Use authentication token in recipe\nsource:\n  strategy: api_github\n  token: \"${GITHUB_TOKEN}\"\n</code></pre> <pre><code># Set environment variable (Windows)\n$env:GITHUB_TOKEN=\"your_token_here\"\n\n# On Linux/macOS: export GITHUB_TOKEN=\"your_token_here\"\n</code></pre>"},{"location":"user-guide/#debug-mode","title":"Debug Mode","text":"<p>Always use <code>--debug</code> for troubleshooting:</p> <pre><code>napt discover recipes/Google/chrome.yaml --debug\n</code></pre> <p>This shows:</p> <ul> <li>Full configuration dumps</li> <li>HTTP request/response details</li> <li>Backend selection (MSI extraction method)</li> <li>File operations with paths</li> <li>Complete error tracebacks</li> </ul>"},{"location":"api/build/","title":"build","text":""},{"location":"api/build/#notapkgtool.build.manager","title":"notapkgtool.build.manager","text":"<p>Build manager for PSADT package creation.</p> <p>This module orchestrates the complete build process for creating PSADT packages from recipes and downloaded installers.</p> Design Principles <ul> <li>Filesystem is source of truth for version information</li> <li>Entire PSADT Template_v4 structure copied pristine</li> <li>Invoke-AppDeployToolkit.ps1 is generated from template (not copied)</li> <li>Build directories are versioned: {app_id}/{version}/</li> <li>Branding applied by replacing files in root Assets/ directory (v4 structure)</li> </ul> Example <p>Basic usage:     <pre><code>from pathlib import Path\nfrom notapkgtool.build import build_package\n\nresult = build_package(\n    recipe_path=Path(\"recipes/Google/chrome.yaml\"),\n    downloads_dir=Path(\"downloads\"),\n)\n\nprint(f\"Built: {result.build_dir}\")\n</code></pre></p>"},{"location":"api/build/#notapkgtool.build.manager.build_package","title":"build_package","text":"<pre><code>build_package(recipe_path: Path, downloads_dir: Path | None = None, output_dir: Path | None = None, verbose: bool = False, debug: bool = False) -&gt; BuildResult\n</code></pre> <p>Build a PSADT package from a recipe and downloaded installer.</p> <p>This is the main entry point for the build process. It:</p> <ol> <li>Loads the recipe configuration</li> <li>Finds the downloaded installer</li> <li>Extracts version from installer (filesystem is truth)</li> <li>Gets/downloads PSADT release</li> <li>Creates build directory structure</li> <li>Copies PSADT files (pristine)</li> <li>Generates Invoke-AppDeployToolkit.ps1 from template</li> <li>Copies installer to Files/</li> <li>Applies custom branding</li> </ol> <p>Parameters:</p> Name Type Description Default <code>recipe_path</code> <code>Path</code> <p>Path to the recipe YAML file.</p> required <code>downloads_dir</code> <code>Path | None</code> <p>Directory containing the downloaded installer. Default: Path(\"downloads\")</p> <code>None</code> <code>output_dir</code> <code>Path | None</code> <p>Base directory for build output. Default: From config or Path(\"builds\")</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Show verbose progress output. Default is False.</p> <code>False</code> <code>debug</code> <code>bool</code> <p>Show debug output. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>BuildResult</code> <p>BuildResult dataclass with the following fields:</p> <ul> <li>app_id (str): Unique application identifier from recipe configuration.</li> <li>app_name (str): Application display name from recipe configuration.</li> <li>version (str): Application version extracted from installer file (filesystem     is source of truth).</li> <li>build_dir (Path): Path to the created build directory, following the pattern     {output_dir}/{app_id}/{version}/.</li> <li>psadt_version (str): PSADT version used for the build (e.g., \"4.1.7\").</li> <li>status (str): Build status, typically \"success\" for completed builds.</li> </ul> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If recipe or installer doesn't exist.</p> <code>RuntimeError</code> <p>If build process fails.</p> Example <p>Basic build:     <pre><code>result = build_package(Path(\"recipes/Google/chrome.yaml\"))\nprint(result.build_dir)  # builds/napt-chrome/141.0.7390.123\n</code></pre></p> <p>Custom output directory:     <pre><code>result = build_package(\n    Path(\"recipes/Google/chrome.yaml\"),\n    output_dir=Path(\"custom/builds\")\n)\n</code></pre></p> Note <p>Requires installer to be downloaded first (run 'napt discover'). Version extracted from installer file, not state cache. Overwrites existing build directory if it exists. PSADT files are copied pristine from cache. Invoke-AppDeployToolkit.ps1 is generated (not copied).</p> Source code in <code>notapkgtool/build/manager.py</code> <pre><code>def build_package(\n    recipe_path: Path,\n    downloads_dir: Path | None = None,\n    output_dir: Path | None = None,\n    verbose: bool = False,\n    debug: bool = False,\n) -&gt; BuildResult:\n    \"\"\"Build a PSADT package from a recipe and downloaded installer.\n\n    This is the main entry point for the build process. It:\n\n    1. Loads the recipe configuration\n    2. Finds the downloaded installer\n    3. Extracts version from installer (filesystem is truth)\n    4. Gets/downloads PSADT release\n    5. Creates build directory structure\n    6. Copies PSADT files (pristine)\n    7. Generates Invoke-AppDeployToolkit.ps1 from template\n    8. Copies installer to Files/\n    9. Applies custom branding\n\n    Args:\n        recipe_path: Path to the recipe YAML file.\n        downloads_dir: Directory containing the downloaded\n            installer. Default: Path(\"downloads\")\n        output_dir: Base directory for build output.\n            Default: From config or Path(\"builds\")\n        verbose: Show verbose progress output. Default is False.\n        debug: Show debug output. Default is False.\n\n    Returns:\n        BuildResult dataclass with the following fields:\n\n            - app_id (str): Unique application identifier from recipe configuration.\n            - app_name (str): Application display name from recipe configuration.\n            - version (str): Application version extracted from installer file (filesystem\n                is source of truth).\n            - build_dir (Path): Path to the created build directory, following the pattern\n                {output_dir}/{app_id}/{version}/.\n            - psadt_version (str): PSADT version used for the build (e.g., \"4.1.7\").\n            - status (str): Build status, typically \"success\" for completed builds.\n\n    Raises:\n        FileNotFoundError: If recipe or installer doesn't exist.\n        RuntimeError: If build process fails.\n\n    Example:\n        Basic build:\n            ```python\n            result = build_package(Path(\"recipes/Google/chrome.yaml\"))\n            print(result.build_dir)  # builds/napt-chrome/141.0.7390.123\n            ```\n\n        Custom output directory:\n            ```python\n            result = build_package(\n                Path(\"recipes/Google/chrome.yaml\"),\n                output_dir=Path(\"custom/builds\")\n            )\n            ```\n\n    Note:\n        Requires installer to be downloaded first (run 'napt discover').\n        Version extracted from installer file, not state cache. Overwrites\n        existing build directory if it exists. PSADT files are copied pristine\n        from cache. Invoke-AppDeployToolkit.ps1 is generated (not copied).\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    # Load configuration\n    logger.step(1, 6, \"Loading configuration...\")\n    config = load_effective_config(recipe_path, verbose=verbose, debug=debug)\n\n    app = config[\"apps\"][0]\n    app_id = app.get(\"id\", \"unknown-app\")\n    app_name = app.get(\"name\", \"Unknown App\")\n\n    # Set defaults\n    if downloads_dir is None:\n        downloads_dir = Path(\"downloads\")\n\n    if output_dir is None:\n        output_dir = Path(\n            config.get(\"defaults\", {}).get(\"build\", {}).get(\"output_dir\", \"builds\")\n        )\n\n    # Find installer file\n    logger.step(2, 6, \"Finding installer...\")\n    installer_file = _find_installer_file(downloads_dir, config)\n\n    # Extract version from installer or state (filesystem + state are truth)\n    logger.step(3, 6, \"Extracting version from installer...\")\n    state_file = Path(\"state/versions.json\")  # Default state file location\n    version = _get_installer_version(installer_file, config, state_file)\n\n    logger.verbose(\"BUILD\", f\"Building {app_name} v{version}\")\n\n    # Get PSADT release\n    logger.step(4, 6, \"Getting PSADT release...\")\n    psadt_config = config.get(\"defaults\", {}).get(\"psadt\", {})\n    release_spec = psadt_config.get(\"release\", \"latest\")\n    cache_dir = Path(psadt_config.get(\"cache_dir\", \"cache/psadt\"))\n\n    psadt_cache_dir = get_psadt_release(\n        release_spec, cache_dir, verbose=verbose, debug=debug\n    )\n    psadt_version = psadt_cache_dir.name  # Directory name is the version\n\n    logger.verbose(\"BUILD\", f\"Using PSADT {psadt_version}\")\n\n    # Create build directory\n    logger.step(5, 6, \"Creating build structure...\")\n    build_dir = _create_build_directory(output_dir, app_id, version)\n\n    # Copy PSADT files (pristine)\n    _copy_psadt_pristine(psadt_cache_dir, build_dir)\n\n    # Generate Invoke-AppDeployToolkit.ps1\n    from .template import generate_invoke_script\n\n    template_path = psadt_cache_dir / \"Invoke-AppDeployToolkit.ps1\"\n    invoke_script = generate_invoke_script(\n        template_path, config, version, psadt_version, verbose=verbose, debug=debug\n    )\n\n    # Write generated script\n    script_dest = build_dir / \"Invoke-AppDeployToolkit.ps1\"\n    script_dest.write_text(invoke_script, encoding=\"utf-8\")\n    logger.verbose(\"BUILD\", \"[OK] Generated Invoke-AppDeployToolkit.ps1\")\n\n    # Copy installer\n    _copy_installer(installer_file, build_dir)\n\n    # Apply branding\n    logger.step(6, 6, \"Applying branding...\")\n    _apply_branding(config, build_dir)\n\n    logger.verbose(\"BUILD\", f\"[OK] Build complete: {build_dir}\")\n\n    return BuildResult(\n        app_id=app_id,\n        app_name=app_name,\n        version=version,\n        build_dir=build_dir,\n        psadt_version=psadt_version,\n        status=\"success\",\n    )\n</code></pre>"},{"location":"api/build/#notapkgtool.build.template","title":"notapkgtool.build.template","text":"<p>Invoke-AppDeployToolkit.ps1 template generation for NAPT.</p> <p>This module handles generating the Invoke-AppDeployToolkit.ps1 script by reading PSADT's template, substituting configuration values, and inserting recipe-specific install/uninstall code.</p> Design Principles <ul> <li>PSADT template remains pristine in cache</li> <li>Generate script by substitution, not modification</li> <li>Preserve PSADT's structure and comments</li> <li>Support dynamic values (AppScriptDate, discovered version)</li> <li>Merge org defaults with recipe overrides</li> </ul> Example <p>Basic usage:     <pre><code>from pathlib import Path\nfrom notapkgtool.build.template import generate_invoke_script\n\nscript = generate_invoke_script(\n    template_path=Path(\"cache/psadt/4.1.7/Invoke-AppDeployToolkit.ps1\"),\n    config=recipe_config,\n    version=\"141.0.7390.123\",\n    psadt_version=\"4.1.7\"\n)\n\nPath(\"builds/app/version/Invoke-AppDeployToolkit.ps1\").write_text(script)\n</code></pre></p>"},{"location":"api/build/#notapkgtool.build.template.generate_invoke_script","title":"generate_invoke_script","text":"<pre><code>generate_invoke_script(template_path: Path, config: dict[str, Any], version: str, psadt_version: str, verbose: bool = False, debug: bool = False) -&gt; str\n</code></pre> <p>Generate Invoke-AppDeployToolkit.ps1 from PSADT template and config.</p> <p>Reads the PSADT template, replaces the $adtSession hashtable with values from the configuration, and inserts recipe-specific install/ uninstall code.</p> <p>Parameters:</p> Name Type Description Default <code>template_path</code> <code>Path</code> <p>Path to PSADT's Invoke-AppDeployToolkit.ps1 template.</p> required <code>config</code> <code>dict[str, Any]</code> <p>Merged configuration (org + vendor + recipe).</p> required <code>version</code> <code>str</code> <p>Application version (from filesystem).</p> required <code>psadt_version</code> <code>str</code> <p>PSADT version being used.</p> required <code>verbose</code> <code>bool</code> <p>Show verbose output. Default is False.</p> <code>False</code> <code>debug</code> <code>bool</code> <p>Show debug output. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>Generated PowerShell script text.</p> <p>Raises:</p> Type Description <code>PackagingError</code> <p>If template doesn't exist or template parsing fails.</p> Example <p>Generate deployment script from template:     <pre><code>from pathlib import Path\n\nscript = generate_invoke_script(\n    Path(\"cache/psadt/4.1.7/Invoke-AppDeployToolkit.ps1\"),\n    config,\n    \"141.0.7390.123\",\n    \"4.1.7\"\n)\n</code></pre></p> Source code in <code>notapkgtool/build/template.py</code> <pre><code>def generate_invoke_script(\n    template_path: Path,\n    config: dict[str, Any],\n    version: str,\n    psadt_version: str,\n    verbose: bool = False,\n    debug: bool = False,\n) -&gt; str:\n    \"\"\"Generate Invoke-AppDeployToolkit.ps1 from PSADT template and config.\n\n    Reads the PSADT template, replaces the $adtSession hashtable with\n    values from the configuration, and inserts recipe-specific install/\n    uninstall code.\n\n    Args:\n        template_path: Path to PSADT's Invoke-AppDeployToolkit.ps1 template.\n        config: Merged configuration (org + vendor + recipe).\n        version: Application version (from filesystem).\n        psadt_version: PSADT version being used.\n        verbose: Show verbose output. Default is False.\n        debug: Show debug output. Default is False.\n\n    Returns:\n        Generated PowerShell script text.\n\n    Raises:\n        PackagingError: If template doesn't exist or template parsing fails.\n\n    Example:\n        Generate deployment script from template:\n            ```python\n            from pathlib import Path\n\n            script = generate_invoke_script(\n                Path(\"cache/psadt/4.1.7/Invoke-AppDeployToolkit.ps1\"),\n                config,\n                \"141.0.7390.123\",\n                \"4.1.7\"\n            )\n            ```\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    if not template_path.exists():\n        raise PackagingError(f\"PSADT template not found: {template_path}\")\n\n    logger.verbose(\"BUILD\", f\"Reading PSADT template: {template_path.name}\")\n\n    # Read template\n    template = template_path.read_text(encoding=\"utf-8\")\n\n    # Build $adtSession variables\n    logger.verbose(\"BUILD\", \"Building $adtSession variables...\")\n    session_vars = _build_adtsession_vars(config, version, psadt_version)\n\n    if debug:\n        logger.debug(\"BUILD\", \"--- $adtSession Variables ---\")\n        for key, value in session_vars.items():\n            logger.debug(\"BUILD\", f\"  {key} = {value}\")\n\n    # Replace $adtSession block\n    script = _replace_session_block(template, session_vars)\n    logger.verbose(\"BUILD\", \"[OK] Replaced $adtSession hashtable\")\n\n    # Insert recipe code\n    app = config[\"apps\"][0]\n    psadt_config = app.get(\"psadt\", {})\n    install_code = psadt_config.get(\"install\")\n    uninstall_code = psadt_config.get(\"uninstall\")\n\n    if install_code:\n        logger.verbose(\"BUILD\", \"Inserting install code from recipe\")\n    if uninstall_code:\n        logger.verbose(\"BUILD\", \"Inserting uninstall code from recipe\")\n\n    script = _insert_recipe_code(script, install_code, uninstall_code)\n\n    logger.verbose(\"BUILD\", \"[OK] Script generation complete\")\n\n    return script\n</code></pre>"},{"location":"api/build/#notapkgtool.build.packager","title":"notapkgtool.build.packager","text":"<p>.intunewin package generation for NAPT.</p> <p>This module handles creating .intunewin packages from built PSADT directories using Microsoft's IntuneWinAppUtil.exe tool.</p> Design Principles <ul> <li>IntuneWinAppUtil.exe is cached globally (not per-build)</li> <li>Package output follows convention: {app_id}-{version}.intunewin</li> <li>Build directory can optionally be cleaned after packaging</li> <li>Tool is downloaded from Microsoft's official GitHub repository</li> </ul> Example <p>Basic usage:     <pre><code>from pathlib import Path\nfrom notapkgtool.build.packager import create_intunewin\n\nresult = create_intunewin(\n    build_dir=Path(\"builds/napt-chrome/141.0.7390.123\"),\n    output_dir=Path(\"packages\")\n)\n\nprint(f\"Package: {result.package_path}\")\n</code></pre></p>"},{"location":"api/build/#notapkgtool.build.packager.create_intunewin","title":"create_intunewin","text":"<pre><code>create_intunewin(build_dir: Path, output_dir: Path | None = None, clean_source: bool = False, verbose: bool = False, debug: bool = False) -&gt; PackageResult\n</code></pre> <p>Create a .intunewin package from a PSADT build directory.</p> <p>Uses Microsoft's IntuneWinAppUtil.exe tool to package a PSADT build directory into a .intunewin file suitable for Intune deployment.</p> <p>Parameters:</p> Name Type Description Default <code>build_dir</code> <code>Path</code> <p>Path to the built PSADT package directory.</p> required <code>output_dir</code> <code>Path | None</code> <p>Directory for the .intunewin output. Default: packages/{app_id}/</p> <code>None</code> <code>clean_source</code> <code>bool</code> <p>If True, remove the build directory after packaging. Default is False.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>Show verbose output. Default is False.</p> <code>False</code> <code>debug</code> <code>bool</code> <p>Show debug output. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>PackageResult</code> <p>PackageResult dataclass with the following fields:</p> <ul> <li>build_dir (Path): Path to the PSADT build directory that was packaged.     This directory may have been removed if clean_source=True.</li> <li>package_path (Path): Path to the created .intunewin file, following the     pattern {output_dir}/{app_id}/{app_id}-{version}.intunewin.</li> <li>app_id (str): Unique application identifier extracted from build directory     structure.</li> <li>version (str): Application version extracted from build directory structure.</li> <li>status (str): Packaging status, typically \"success\" for completed packaging.</li> </ul> <p>Raises:</p> Type Description <code>ConfigError</code> <p>If build directory structure is invalid.</p> <code>PackagingError</code> <p>If packaging fails.</p> <code>NetworkError</code> <p>If IntuneWinAppUtil.exe download fails.</p> Example <p>Basic packaging:     <pre><code>result = create_intunewin(\n    build_dir=Path(\"builds/napt-chrome/141.0.7390.123\")\n)\nprint(result.package_path)\n# packages/napt-chrome/napt-chrome-141.0.7390.123.intunewin\n</code></pre></p> <p>With cleanup:     <pre><code>result = create_intunewin(\n    build_dir=Path(\"builds/napt-chrome/141.0.7390.123\"),\n    clean_source=True\n)\n# Build directory is removed after packaging\n</code></pre></p> Note <p>Requires build directory from 'napt build' command. IntuneWinAppUtil.exe is downloaded and cached on first use. Setup file is always \"Invoke-AppDeployToolkit.exe\". Output follows convention: packages/{app_id}/{app_id}-{version}.intunewin</p> Source code in <code>notapkgtool/build/packager.py</code> <pre><code>def create_intunewin(\n    build_dir: Path,\n    output_dir: Path | None = None,\n    clean_source: bool = False,\n    verbose: bool = False,\n    debug: bool = False,\n) -&gt; PackageResult:\n    \"\"\"Create a .intunewin package from a PSADT build directory.\n\n    Uses Microsoft's IntuneWinAppUtil.exe tool to package a PSADT build\n    directory into a .intunewin file suitable for Intune deployment.\n\n    Args:\n        build_dir: Path to the built PSADT package directory.\n        output_dir: Directory for the .intunewin output.\n            Default: packages/{app_id}/\n        clean_source: If True, remove the build directory\n            after packaging. Default is False.\n        verbose: Show verbose output. Default is False.\n        debug: Show debug output. Default is False.\n\n    Returns:\n        PackageResult dataclass with the following fields:\n\n            - build_dir (Path): Path to the PSADT build directory that was packaged.\n                This directory may have been removed if clean_source=True.\n            - package_path (Path): Path to the created .intunewin file, following the\n                pattern {output_dir}/{app_id}/{app_id}-{version}.intunewin.\n            - app_id (str): Unique application identifier extracted from build directory\n                structure.\n            - version (str): Application version extracted from build directory structure.\n            - status (str): Packaging status, typically \"success\" for completed packaging.\n\n    Raises:\n        ConfigError: If build directory structure is invalid.\n        PackagingError: If packaging fails.\n        NetworkError: If IntuneWinAppUtil.exe download fails.\n\n    Example:\n        Basic packaging:\n            ```python\n            result = create_intunewin(\n                build_dir=Path(\"builds/napt-chrome/141.0.7390.123\")\n            )\n            print(result.package_path)\n            # packages/napt-chrome/napt-chrome-141.0.7390.123.intunewin\n            ```\n\n        With cleanup:\n            ```python\n            result = create_intunewin(\n                build_dir=Path(\"builds/napt-chrome/141.0.7390.123\"),\n                clean_source=True\n            )\n            # Build directory is removed after packaging\n            ```\n\n    Note:\n        Requires build directory from 'napt build' command. IntuneWinAppUtil.exe\n        is downloaded and cached on first use. Setup file is always\n        \"Invoke-AppDeployToolkit.exe\". Output follows convention:\n        packages/{app_id}/{app_id}-{version}.intunewin\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n\n    build_dir = build_dir.resolve()\n\n    if not build_dir.exists():\n        raise PackagingError(f\"Build directory not found: {build_dir}\")\n\n    # Extract app_id and version from directory structure (app_id/version/)\n    version = build_dir.name\n    app_id = build_dir.parent.name\n\n    logger.verbose(\"PACKAGE\", f\"Packaging {app_id} v{version}\")\n\n    # Verify build structure\n    logger.step(1, 4, \"Verifying build structure...\")\n    _verify_build_structure(build_dir)\n\n    # Determine output directory\n    if output_dir is None:\n        output_dir = Path(\"packages\") / app_id\n\n    output_dir = output_dir.resolve()\n\n    # Get IntuneWinAppUtil tool\n    logger.step(2, 4, \"Getting IntuneWinAppUtil tool...\")\n    tool_cache = Path(\"cache/tools\")\n    tool_path = _get_intunewin_tool(tool_cache, verbose=verbose)\n\n    # Create .intunewin package\n    logger.step(3, 4, \"Creating .intunewin package...\")\n    package_path = _execute_packaging(\n        tool_path,\n        build_dir,\n        \"Invoke-AppDeployToolkit.exe\",\n        output_dir,\n        verbose=verbose,\n    )\n\n    # Optionally clean source\n    if clean_source:\n        logger.step(4, 4, \"Cleaning source build directory...\")\n        shutil.rmtree(build_dir)\n        logger.verbose(\"PACKAGE\", f\"[OK] Removed build directory: {build_dir}\")\n    else:\n        logger.step(4, 4, \"Package complete\")\n\n    logger.verbose(\"PACKAGE\", f\"[OK] Package created: {package_path}\")\n\n    return PackageResult(\n        build_dir=build_dir,\n        package_path=package_path,\n        app_id=app_id,\n        version=version,\n        status=\"success\",\n    )\n</code></pre>"},{"location":"api/cli/","title":"cli","text":""},{"location":"api/cli/#notapkgtool.cli","title":"notapkgtool.cli","text":"<p>Command-line interface for NAPT.</p> <p>This module provides the main CLI entry point for the napt tool, offering commands for recipe validation, package building, and deployment management.</p> <p>Commands:</p> <pre><code>validate: Validate recipe syntax and configuration\ndiscover: Discover latest version and download installer\nbuild: Build PSADT package from recipe\npackage: Create .intunewin package for Intune\n</code></pre> Example <p>Validate recipe syntax:     <pre><code>$ napt validate recipes/Google/chrome.yaml\n</code></pre></p> <p>Discover latest version:     <pre><code>$ napt discover recipes/Google/chrome.yaml\n</code></pre></p> <p>Build PSADT package:     <pre><code>$ napt build recipes/Google/chrome.yaml\n</code></pre></p> <p>Create .intunewin package:     <pre><code>$ napt package builds/napt-chrome/142.0.7444.60/\n</code></pre></p> <p>Enable verbose output:     <pre><code>$ napt discover recipes/Google/chrome.yaml --verbose\n</code></pre></p> <p>Enable debug output:     <pre><code>$ napt discover recipes/Google/chrome.yaml --debug\n</code></pre></p> <p>Exit Codes:</p> <ul> <li>0: Success</li> <li>1: Error (configuration, download, or validation failure)</li> </ul> Note <p>The CLI uses argparse for command parsing (stdlib, zero dependencies). Commands are registered with subparsers for clean organization. Each command has its own handler function (cmd_). Verbose mode shows full tracebacks on errors for debugging. Debug mode implies verbose mode and shows detailed configuration dumps."},{"location":"api/cli/#notapkgtool.cli.cmd_validate","title":"cmd_validate","text":"<pre><code>cmd_validate(args: Namespace) -&gt; int\n</code></pre> <p>Handler for 'napt validate' command.</p> <p>Validates recipe syntax and configuration without downloading files or making network calls. This is useful for quick feedback during recipe development and for CI/CD pre-checks.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Parsed command-line arguments containing recipe path and verbose flag.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Exit code (0 for valid recipe, 1 for invalid).</p> Note <p>Prints validation results, errors, and warnings to stdout.</p> Source code in <code>notapkgtool/cli.py</code> <pre><code>def cmd_validate(args: argparse.Namespace) -&gt; int:\n    \"\"\"Handler for 'napt validate' command.\n\n    Validates recipe syntax and configuration without downloading files or\n    making network calls. This is useful for quick feedback during recipe\n    development and for CI/CD pre-checks.\n\n    Args:\n        args: Parsed command-line arguments containing\n            recipe path and verbose flag.\n\n    Returns:\n        Exit code (0 for valid recipe, 1 for invalid).\n\n    Note:\n        Prints validation results, errors, and warnings to stdout.\n\n    \"\"\"\n    # Configure global logger\n    logger = get_logger(verbose=args.verbose, debug=False)\n    set_global_logger(logger)\n\n    recipe_path = Path(args.recipe).resolve()\n\n    print(f\"Validating recipe: {recipe_path}\")\n    print()\n\n    # Validate the recipe\n    result = validate_recipe(recipe_path, verbose=args.verbose)\n\n    # Display results\n    print(\"=\" * 70)\n    print(\"VALIDATION RESULTS\")\n    print(\"=\" * 70)\n    print(f\"Recipe:      {result.recipe_path}\")\n    print(f\"Status:      {result.status.upper()}\")\n    print(f\"App Count:   {result.app_count}\")\n    print()\n\n    # Show warnings if any\n    if result.warnings:\n        print(f\"Warnings ({len(result.warnings)}):\")\n        for warning in result.warnings:\n            print(f\"  [WARNING] {warning}\")\n        print()\n\n    # Show errors if any\n    if result.errors:\n        print(f\"Errors ({len(result.errors)}):\")\n        for error in result.errors:\n            print(f\"  [X] {error}\")\n        print()\n\n    print(\"=\" * 70)\n\n    if result.status == \"valid\":\n        print()\n        print(\"[SUCCESS] Recipe is valid!\")\n        return 0\n    else:\n        print()\n        print(f\"[FAILED] Recipe validation failed with {len(result.errors)} error(s).\")\n        return 1\n</code></pre>"},{"location":"api/cli/#notapkgtool.cli.cmd_discover","title":"cmd_discover","text":"<pre><code>cmd_discover(args: Namespace) -&gt; int\n</code></pre> <p>Handler for 'napt discover' command.</p> <p>Discovers the latest version of an application by querying the source and downloading the installer. This command validates the recipe YAML, uses the configured discovery strategy to find the latest version, downloads the installer (or uses cached version via ETag), extracts version information, and updates the state file with caching info.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Parsed command-line arguments containing recipe path, output directory, state file path, and flags.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Exit code (0 for success, 1 for failure).</p> Note <p>Downloads installer file to output_dir (or uses cached version). Updates state file with version and ETag information. Prints progress and results to stdout. Prints errors with optional traceback if verbose/debug.</p> Source code in <code>notapkgtool/cli.py</code> <pre><code>def cmd_discover(args: argparse.Namespace) -&gt; int:\n    \"\"\"Handler for 'napt discover' command.\n\n    Discovers the latest version of an application by querying the source\n    and downloading the installer. This command validates the recipe YAML,\n    uses the configured discovery strategy to find the latest version,\n    downloads the installer (or uses cached version via ETag), extracts\n    version information, and updates the state file with caching info.\n\n    Args:\n        args: Parsed command-line arguments containing\n            recipe path, output directory, state file path, and flags.\n\n    Returns:\n        Exit code (0 for success, 1 for failure).\n\n    Note:\n        Downloads installer file to output_dir (or uses cached version).\n        Updates state file with version and ETag information. Prints progress\n        and results to stdout. Prints errors with optional traceback if verbose/debug.\n\n    \"\"\"\n    # Configure global logger\n    logger = get_logger(verbose=args.verbose, debug=args.debug)\n    set_global_logger(logger)\n\n    recipe_path = Path(args.recipe).resolve()\n    output_dir = Path(args.output_dir).resolve()\n\n    if not recipe_path.exists():\n        print(f\"Error: Recipe file not found: {recipe_path}\")\n        return 1\n\n    print(f\"Discovering version for recipe: {recipe_path}\")\n    print(f\"Output directory: {output_dir}\")\n    print()\n\n    try:\n        result = discover_recipe(\n            recipe_path,\n            output_dir,\n            state_file=args.state_file if not args.stateless else None,\n            stateless=args.stateless,\n            verbose=args.verbose,\n            debug=args.debug,\n        )\n    except (ConfigError, NetworkError, PackagingError) as err:\n        print(f\"Error: {err}\")\n        if args.verbose or args.debug:\n            import traceback\n\n            traceback.print_exc()\n        return 1\n    except NAPTError as err:\n        # Catch any other NAPT errors we might have missed\n        print(f\"Error: {err}\")\n        if args.verbose or args.debug:\n            import traceback\n\n            traceback.print_exc()\n        return 1\n\n    # Display results\n    print(\"=\" * 70)\n    print(\"DISCOVERY RESULTS\")\n    print(\"=\" * 70)\n    print(f\"App Name:        {result.app_name}\")\n    print(f\"App ID:          {result.app_id}\")\n    print(f\"Strategy:        {result.strategy}\")\n    print(f\"Version:         {result.version}\")\n    print(f\"Version Source:  {result.version_source}\")\n    print(f\"File Path:       {result.file_path}\")\n    print(f\"SHA-256:         {result.sha256}\")\n    print(f\"Status:          {result.status}\")\n    print(\"=\" * 70)\n    print()\n    print(\"[SUCCESS] Version discovered successfully!\")\n\n    return 0\n</code></pre>"},{"location":"api/cli/#notapkgtool.cli.cmd_build","title":"cmd_build","text":"<pre><code>cmd_build(args: Namespace) -&gt; int\n</code></pre> <p>Handler for 'napt build' command.</p> <p>Builds a PSADT package from a recipe and downloaded installer. This command loads the recipe configuration, finds the downloaded installer, extracts version from the installer file (filesystem is truth), downloads/caches the specified PSADT release, creates build directory structure, copies PSADT files pristine from cache, generates Invoke-AppDeployToolkit.ps1 with recipe values, copies installer to Files/ directory, and applies custom branding.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Parsed command-line arguments containing recipe path, downloads directory, output directory, and flags.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Exit code (0 for success, 1 for failure).</p> Note <p>Creates build directory structure. Downloads PSADT release if not cached. Generates Invoke-AppDeployToolkit.ps1. Copies files to build directory. Prints progress and results to stdout.</p> Source code in <code>notapkgtool/cli.py</code> <pre><code>def cmd_build(args: argparse.Namespace) -&gt; int:\n    \"\"\"Handler for 'napt build' command.\n\n    Builds a PSADT package from a recipe and downloaded installer. This command\n    loads the recipe configuration, finds the downloaded installer, extracts\n    version from the installer file (filesystem is truth), downloads/caches\n    the specified PSADT release, creates build directory structure, copies\n    PSADT files pristine from cache, generates Invoke-AppDeployToolkit.ps1\n    with recipe values, copies installer to Files/ directory, and applies\n    custom branding.\n\n    Args:\n        args: Parsed command-line arguments containing\n            recipe path, downloads directory, output directory, and flags.\n\n    Returns:\n        Exit code (0 for success, 1 for failure).\n\n    Note:\n        Creates build directory structure. Downloads PSADT release if not cached.\n        Generates Invoke-AppDeployToolkit.ps1. Copies files to build directory.\n        Prints progress and results to stdout.\n\n    \"\"\"\n    # Configure global logger\n    logger = get_logger(verbose=args.verbose, debug=args.debug)\n    set_global_logger(logger)\n\n    recipe_path = Path(args.recipe).resolve()\n    downloads_dir = Path(args.downloads_dir).resolve()\n    output_dir = Path(args.output_dir) if args.output_dir else None\n\n    if not recipe_path.exists():\n        print(f\"Error: Recipe file not found: {recipe_path}\")\n        return 1\n\n    if not downloads_dir.exists():\n        print(f\"Error: Downloads directory not found: {downloads_dir}\")\n        print(\"Run 'napt discover' first to download the installer.\")\n        return 1\n\n    print(f\"Building PSADT package for recipe: {recipe_path}\")\n    print(f\"Downloads directory: {downloads_dir}\")\n    if output_dir:\n        print(f\"Output directory: {output_dir}\")\n    print()\n\n    try:\n        result = build_package(\n            recipe_path,\n            downloads_dir=downloads_dir,\n            output_dir=output_dir,\n            verbose=args.verbose,\n            debug=args.debug,\n        )\n    except (ConfigError, NetworkError, PackagingError) as err:\n        print(f\"Error: {err}\")\n        if args.verbose or args.debug:\n            import traceback\n\n            traceback.print_exc()\n        return 1\n    except NAPTError as err:\n        # Catch any other NAPT errors we might have missed\n        print(f\"Error: {err}\")\n        if args.verbose or args.debug:\n            import traceback\n\n            traceback.print_exc()\n        return 1\n\n    # Display results\n    print(\"=\" * 70)\n    print(\"BUILD RESULTS\")\n    print(\"=\" * 70)\n    print(f\"App Name:        {result.app_name}\")\n    print(f\"App ID:          {result.app_id}\")\n    print(f\"Version:         {result.version}\")\n    print(f\"PSADT Version:   {result.psadt_version}\")\n    print(f\"Build Directory: {result.build_dir}\")\n    print(f\"Status:          {result.status}\")\n    print(\"=\" * 70)\n    print()\n    print(\"[SUCCESS] PSADT package built successfully!\")\n\n    return 0\n</code></pre>"},{"location":"api/cli/#notapkgtool.cli.cmd_package","title":"cmd_package","text":"<pre><code>cmd_package(args: Namespace) -&gt; int\n</code></pre> <p>Handler for 'napt package' command.</p> <p>Creates a .intunewin package from a built PSADT directory. This command verifies the build directory has valid PSADT structure, downloads/caches IntuneWinAppUtil.exe if needed, runs IntuneWinAppUtil.exe to create .intunewin package, and optionally cleans the source build directory after packaging.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Parsed command-line arguments containing build directory path, output directory, clean flag, and debug flags.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Exit code (0 for success, 1 for failure).</p> Note <p>Creates .intunewin file in output directory. Downloads IntuneWinAppUtil.exe if not cached. Optionally removes build directory if --clean-source. Prints progress and results to stdout.</p> Source code in <code>notapkgtool/cli.py</code> <pre><code>def cmd_package(args: argparse.Namespace) -&gt; int:\n    \"\"\"Handler for 'napt package' command.\n\n    Creates a .intunewin package from a built PSADT directory. This command\n    verifies the build directory has valid PSADT structure, downloads/caches\n    IntuneWinAppUtil.exe if needed, runs IntuneWinAppUtil.exe to create\n    .intunewin package, and optionally cleans the source build directory\n    after packaging.\n\n    Args:\n        args: Parsed command-line arguments containing\n            build directory path, output directory, clean flag, and debug flags.\n\n    Returns:\n        Exit code (0 for success, 1 for failure).\n\n    Note:\n        Creates .intunewin file in output directory. Downloads IntuneWinAppUtil.exe\n        if not cached. Optionally removes build directory if --clean-source.\n        Prints progress and results to stdout.\n\n    \"\"\"\n    # Configure global logger\n    logger = get_logger(verbose=args.verbose, debug=args.debug)\n    set_global_logger(logger)\n\n    build_dir = Path(args.build_dir).resolve()\n    output_dir = Path(args.output_dir) if args.output_dir else None\n\n    if not build_dir.exists():\n        print(f\"Error: Build directory not found: {build_dir}\")\n        return 1\n\n    print(f\"Creating .intunewin package from: {build_dir}\")\n    if output_dir:\n        print(f\"Output directory: {output_dir}\")\n    print()\n\n    try:\n        result = create_intunewin(\n            build_dir,\n            output_dir=output_dir,\n            clean_source=args.clean_source,\n            verbose=args.verbose,\n            debug=args.debug,\n        )\n    except (ConfigError, NetworkError, PackagingError) as err:\n        print(f\"Error: {err}\")\n        if args.verbose or args.debug:\n            import traceback\n\n            traceback.print_exc()\n        return 1\n    except NAPTError as err:\n        # Catch any other NAPT errors we might have missed\n        print(f\"Error: {err}\")\n        if args.verbose or args.debug:\n            import traceback\n\n            traceback.print_exc()\n        return 1\n\n    # Display results\n    print(\"=\" * 70)\n    print(\"PACKAGE RESULTS\")\n    print(\"=\" * 70)\n    print(f\"App ID:          {result.app_id}\")\n    print(f\"Version:         {result.version}\")\n    print(f\"Package Path:    {result.package_path}\")\n    if args.clean_source:\n        print(f\"Build Directory: {result.build_dir} (removed)\")\n    else:\n        print(f\"Build Directory: {result.build_dir}\")\n    print(f\"Status:          {result.status}\")\n    print(\"=\" * 70)\n    print()\n    print(\"[SUCCESS] .intunewin package created successfully!\")\n\n    return 0\n</code></pre>"},{"location":"api/cli/#notapkgtool.cli.main","title":"main","text":"<pre><code>main() -&gt; None\n</code></pre> <p>Main entry point for the napt CLI.</p> <p>This function is registered as the 'napt' console script in pyproject.toml.</p> Source code in <code>notapkgtool/cli.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"Main entry point for the napt CLI.\n\n    This function is registered as the 'napt' console script in pyproject.toml.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        prog=\"napt\",\n        description=\"NAPT - Not a Pkg Tool for Windows/Intune packaging with PSADT\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n    )\n\n    parser.add_argument(\n        \"--version\",\n        action=\"version\",\n        version=f\"napt {version('notapkgtool')}\",\n    )\n\n    subparsers = parser.add_subparsers(\n        dest=\"command\",\n        help=\"Available commands\",\n        required=True,\n    )\n\n    # 'validate' command\n    parser_validate = subparsers.add_parser(\n        \"validate\",\n        help=\"Validate recipe syntax and configuration (no downloads)\",\n        description=(\n            \"Check recipe YAML for syntax errors and configuration issues \"\n            \"without making network calls.\"\n        ),\n    )\n    parser_validate.add_argument(\n        \"recipe\",\n        help=\"Path to the recipe YAML file\",\n    )\n    parser_validate.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"Show validation progress and details\",\n    )\n    parser_validate.set_defaults(func=cmd_validate)\n\n    # 'discover' command\n    parser_discover = subparsers.add_parser(\n        \"discover\",\n        help=\"Discover latest version and download installer\",\n        description=(\n            \"Find the latest version using the configured discovery strategy \"\n            \"and download the installer.\"\n        ),\n    )\n    parser_discover.add_argument(\n        \"recipe\",\n        help=\"Path to the recipe YAML file\",\n    )\n    parser_discover.add_argument(\n        \"--output-dir\",\n        default=\"./downloads\",\n        help=\"Directory to save downloaded files (default: ./downloads)\",\n    )\n    parser_discover.add_argument(\n        \"--state-file\",\n        type=Path,\n        default=Path(\"state/versions.json\"),\n        help=(\n            \"State file for version tracking and ETag caching \"\n            \"(default: state/versions.json)\"\n        ),\n    )\n    parser_discover.add_argument(\n        \"--stateless\",\n        action=\"store_true\",\n        help=\"Disable state tracking (no caching, always download full files)\",\n    )\n    parser_discover.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"Show progress and high-level status updates\",\n    )\n    parser_discover.add_argument(\n        \"-d\",\n        \"--debug\",\n        action=\"store_true\",\n        help=\"Show detailed debugging output (implies --verbose)\",\n    )\n    parser_discover.set_defaults(func=cmd_discover)\n\n    # 'build' command\n    parser_build = subparsers.add_parser(\n        \"build\",\n        help=\"Build PSADT package from recipe and installer\",\n        description=(\n            \"Create a PSADT deployment package from a recipe and \"\n            \"downloaded installer.\"\n        ),\n    )\n    parser_build.add_argument(\n        \"recipe\",\n        help=\"Path to the recipe YAML file\",\n    )\n    parser_build.add_argument(\n        \"--downloads-dir\",\n        default=\"./downloads\",\n        help=\"Directory containing the downloaded installer (default: ./downloads)\",\n    )\n    parser_build.add_argument(\n        \"--output-dir\",\n        default=None,\n        help=\"Base directory for build output (default: from config or ./builds)\",\n    )\n    parser_build.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"Show progress and high-level status updates\",\n    )\n    parser_build.add_argument(\n        \"-d\",\n        \"--debug\",\n        action=\"store_true\",\n        help=\"Show detailed debugging output (implies --verbose)\",\n    )\n    parser_build.set_defaults(func=cmd_build)\n\n    # 'package' command\n    parser_package = subparsers.add_parser(\n        \"package\",\n        help=\"Create .intunewin package from PSADT build directory\",\n        description=(\n            \"Package a built PSADT directory into a .intunewin file \"\n            \"for Intune deployment.\"\n        ),\n    )\n    parser_package.add_argument(\n        \"build_dir\",\n        help=\"Path to the built PSADT package directory\",\n    )\n    parser_package.add_argument(\n        \"--output-dir\",\n        default=None,\n        help=\"Directory for .intunewin output (default: packages/{app_id}/)\",\n    )\n    parser_package.add_argument(\n        \"--clean-source\",\n        action=\"store_true\",\n        help=\"Remove the build directory after packaging\",\n    )\n    parser_package.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"Show progress and high-level status updates\",\n    )\n    parser_package.add_argument(\n        \"-d\",\n        \"--debug\",\n        action=\"store_true\",\n        help=\"Show detailed debugging output (implies --verbose)\",\n    )\n    parser_package.set_defaults(func=cmd_package)\n\n    # Parse and dispatch\n    args = parser.parse_args()\n\n    # Call the appropriate command handler\n    exit_code = args.func(args)\n    sys.exit(exit_code)\n</code></pre>"},{"location":"api/config/","title":"config","text":""},{"location":"api/config/#notapkgtool.config","title":"notapkgtool.config","text":"<p>Configuration loading and management for NAPT.</p> <p>This module provides tools for loading, merging, and validating YAML-based configuration files with a layered approach:</p> <ul> <li>Organization-wide defaults (defaults/org.yaml)</li> <li>Vendor-specific defaults (defaults/vendors/.yaml) <li>Recipe-specific configuration (recipes//.yaml) <p>The loader performs deep merging where dicts are merged recursively and lists/scalars are replaced (last wins). Relative paths are resolved against the recipe file location for relocatability.</p> Example <p>Basic usage:     <pre><code>from pathlib import Path\nfrom notapkgtool.config import load_effective_config\n\nconfig = load_effective_config(Path(\"recipes/Google/chrome.yaml\"))\nfirst_app = config.get(\"apps\", [])[0]\nprint(first_app[\"name\"])  # \"Google Chrome\"\n</code></pre></p>"},{"location":"api/config/#notapkgtool.config.load_effective_config","title":"load_effective_config","text":"<pre><code>load_effective_config(recipe_path: Path, *, vendor: str | None = None, verbose: bool = False, debug: bool = False) -&gt; dict[str, Any]\n</code></pre> <p>Load and merge the effective configuration for a recipe.</p> Steps <ol> <li>Read recipe YAML</li> <li>Find defaults root by scanning upwards for 'defaults/org.yaml'</li> <li>Load org defaults (required if defaults root exists)</li> <li>Determine vendor (param 'vendor' &gt; folder name &gt; recipe contents)</li> <li>Load vendor defaults if present</li> <li>Merge: org -&gt; vendor -&gt; recipe (dicts deep-merge, lists replace)</li> <li>Resolve known relative paths (relative to the recipe directory)</li> <li>Inject dynamic fields (AppScriptDate = today if absent)</li> </ol> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>A merged configuration dict ready for downstream processors.</p> <code>dict[str, Any]</code> <p>If no defaults were found in the tree, the recipe is returned</p> <code>dict[str, Any]</code> <p>as-is (with path resolution + injection).</p> <p>Raises:</p> Type Description <code>ConfigError</code> <p>On YAML parse errors, empty files, invalid structure, or if the recipe file is missing.</p> Source code in <code>notapkgtool/config/loader.py</code> <pre><code>def load_effective_config(\n    recipe_path: Path,\n    *,\n    vendor: str | None = None,\n    verbose: bool = False,\n    debug: bool = False,\n) -&gt; dict[str, Any]:\n    \"\"\"Load and merge the effective configuration for a recipe.\n\n    Steps:\n        1. Read recipe YAML\n        2. Find defaults root by scanning upwards for 'defaults/org.yaml'\n        3. Load org defaults (required if defaults root exists)\n        4. Determine vendor (param 'vendor' &gt; folder name &gt; recipe contents)\n        5. Load vendor defaults if present\n        6. Merge: org -&gt; vendor -&gt; recipe (dicts deep-merge, lists replace)\n        7. Resolve known relative paths (relative to the recipe directory)\n        8. Inject dynamic fields (AppScriptDate = today if absent)\n\n    Returns:\n        A merged configuration dict ready for downstream processors.\n        If no defaults were found in the tree, the recipe is returned\n        as-is (with path resolution + injection).\n\n    Raises:\n        ConfigError: On YAML parse errors, empty files, invalid structure,\n            or if the recipe file is missing.\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    recipe_path = recipe_path.resolve()\n    recipe_dir = recipe_path.parent\n\n    logger.verbose(\"CONFIG\", f\"Loading recipe: {recipe_path}\")\n\n    # 1) Read recipe\n    recipe_obj = _load_yaml_file(recipe_path)\n    if not isinstance(recipe_obj, dict):\n        raise ConfigError(f\"top-level YAML must be a mapping (dict): {recipe_path}\")\n\n    # 2) Find defaults root\n    defaults_root = _find_defaults_root(recipe_dir)\n    if defaults_root and verbose:\n        logger.verbose(\"CONFIG\", f\"Found defaults root: {defaults_root}\")\n\n    merged: dict[str, Any] = {}\n    layers_merged = 0\n\n    org_defaults_path: Path | None = None\n    vendor_name: str | None = vendor\n\n    if defaults_root:\n        # 3) Load org defaults\n        org_defaults_path = defaults_root / \"org.yaml\"\n        if org_defaults_path.exists():\n            logger.verbose(\n                \"CONFIG\",\n                f\"Loading: {org_defaults_path.relative_to(defaults_root.parent)}\",\n            )\n            org_defaults = _load_yaml_file(org_defaults_path)\n            if isinstance(org_defaults, dict):\n                if debug:\n                    logger.debug(\"CONFIG\", \"--- Content from org.yaml ---\")\n                    _print_yaml_content(org_defaults, debug)\n                merged = _deep_merge_dicts(merged, org_defaults)\n                layers_merged += 1\n\n        # 4) Determine vendor\n        if vendor_name is None:\n            vendor_name = _detect_vendor(recipe_path, recipe_obj)\n\n        if vendor_name and verbose:\n            logger.verbose(\"CONFIG\", f\"Detected vendor: {vendor_name}\")\n\n        # 5) Load vendor defaults if present\n        if vendor_name:\n            candidate = defaults_root / \"vendors\" / f\"{vendor_name}.yaml\"\n            if candidate.exists():\n                logger.verbose(\n                    \"CONFIG\", f\"Loading: {candidate.relative_to(defaults_root.parent)}\"\n                )\n                vendor_defaults = _load_yaml_file(candidate)\n                if isinstance(vendor_defaults, dict):\n                    if debug:\n                        logger.debug(\n                            \"CONFIG\", f\"--- Content from {vendor_name}.yaml ---\"\n                        )\n                        _print_yaml_content(vendor_defaults, debug)\n                    merged = _deep_merge_dicts(merged, vendor_defaults)\n                    layers_merged += 1\n\n    # Show recipe content if verbose\n    if verbose:\n        logger.verbose(\"CONFIG\", f\"Loading: {recipe_path.name}\")\n    if debug:\n        logger.debug(\"CONFIG\", f\"--- Content from {recipe_path.name} ---\")\n        _print_yaml_content(recipe_obj, debug)\n\n    # 6) Merge recipe on top\n    merged = _deep_merge_dicts(merged, recipe_obj)\n    layers_merged += 1\n\n    if verbose:\n        logger.verbose(\"CONFIG\", f\"Deep merging {layers_merged} layer(s)\")\n        # Show final config structure\n        top_level_keys = list(merged.keys())\n        logger.verbose(\n            \"CONFIG\",\n            (\n                f\"Final config has {len(top_level_keys)} top-level keys: \"\n                f\"{', '.join(top_level_keys)}\"\n            ),\n        )\n    # Show the complete merged configuration in debug mode\n    if debug:\n        logger.debug(\"CONFIG\", \"--- Final Merged Configuration ---\")\n        _print_yaml_content(merged, debug)\n\n    # 7) Resolve relative paths (branding paths relative to defaults_root)\n    _resolve_known_paths(merged, recipe_dir, defaults_root)\n\n    # 8) Inject dynamic values (e.g., AppScriptDate)\n    _inject_dynamic_values(merged)\n\n    # Optionally attach context for debugging (commented out by default)\n    # merged[\"_load_context\"] = LoadContext(\n    #     recipe_path=recipe_path,\n    #     defaults_root=defaults_root,\n    #     vendor_name=vendor_name,\n    #     org_defaults_path=org_defaults_path,\n    #     vendor_defaults_path=vendor_defaults_path,\n    # ).__dict__\n\n    return merged\n</code></pre>"},{"location":"api/core/","title":"core","text":""},{"location":"api/core/#notapkgtool.core","title":"notapkgtool.core","text":"<p>Core orchestration for NAPT.</p> <p>This module provides high-level orchestration functions that coordinate the complete workflow for recipe validation, package building, and deployment.</p> <p>Two-Path Architecture:</p> <p>The orchestration automatically selects the optimal path based on what each discovery strategy can do:</p> <ul> <li> <p>Version-First Path (web_scrape, api_github, api_json): These strategies     can check the version without downloading the file. NAPT compares the     discovered version to the cached version. If they match and the file     already exists, the download is skipped entirely. This makes update checks     very fast (~100-300ms) since no large installer files are downloaded.</p> </li> <li> <p>File-First Path (url_download): This strategy requires downloading the     file to extract the version. NAPT uses HTTP ETag headers to check if the     file has changed. If the server responds with HTTP 304 (Not Modified),     the existing cached file is reused, avoiding unnecessary re-downloads.</p> </li> </ul> <p>Design Principles:</p> <ul> <li>Each function has a single, clear responsibility</li> <li>Functions return structured data (dataclasses) for easy testing and extension</li> <li>Error handling uses exceptions; CLI layer formats for user display</li> <li>Discovery strategies are dynamically loaded via registry pattern</li> <li>Configuration is immutable once loaded</li> </ul> Example <p>Programmatic usage:     <pre><code>from pathlib import Path\nfrom notapkgtool.core import discover_recipe\n\nresult = discover_recipe(\n    recipe_path=Path(\"recipes/Google/chrome.yaml\"),\n    output_dir=Path(\"./downloads\"),\n)\n\nprint(f\"App: {result.app_name}\")\nprint(f\"Version: {result.version}\")\nprint(f\"SHA-256: {result.sha256}\")\n\n# Version-first strategies: may have skipped download if unchanged!\n</code></pre></p>"},{"location":"api/core/#notapkgtool.core.derive_file_path_from_url","title":"derive_file_path_from_url","text":"<pre><code>derive_file_path_from_url(url: str, output_dir: Path) -&gt; Path\n</code></pre> <p>Derive file path from URL using same logic as download_file.</p> <p>This function ensures version-first strategies can locate cached files without downloading by following the same naming convention as the download module.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Download URL.</p> required <code>output_dir</code> <code>Path</code> <p>Directory where file would be downloaded.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Expected path to the file.</p> Example <p>Get expected file path for a download URL:     <pre><code>from pathlib import Path\n\npath = derive_file_path_from_url(\n    \"https://example.com/app.msi\",\n    Path(\"./downloads\")\n)\n# Returns: Path('./downloads/app.msi')\n</code></pre></p> Source code in <code>notapkgtool/core.py</code> <pre><code>def derive_file_path_from_url(url: str, output_dir: Path) -&gt; Path:\n    \"\"\"Derive file path from URL using same logic as download_file.\n\n    This function ensures version-first strategies can locate cached files\n    without downloading by following the same naming convention as the\n    download module.\n\n    Args:\n        url: Download URL.\n        output_dir: Directory where file would be downloaded.\n\n    Returns:\n        Expected path to the file.\n\n    Example:\n        Get expected file path for a download URL:\n            ```python\n            from pathlib import Path\n\n            path = derive_file_path_from_url(\n                \"https://example.com/app.msi\",\n                Path(\"./downloads\")\n            )\n            # Returns: Path('./downloads/app.msi')\n            ```\n\n    \"\"\"\n    from urllib.parse import urlparse\n\n    filename = Path(urlparse(url).path).name\n    return output_dir / filename\n</code></pre>"},{"location":"api/core/#notapkgtool.core.discover_recipe","title":"discover_recipe","text":"<pre><code>discover_recipe(recipe_path: Path, output_dir: Path, state_file: Path | None = Path('state/versions.json'), stateless: bool = False, verbose: bool = False, debug: bool = False) -&gt; DiscoverResult\n</code></pre> <p>Discover the latest version by loading config and downloading installer.</p> <p>This is the main entry point for the 'napt discover' command. It orchestrates the entire discovery workflow using a two-path architecture optimized for version-first strategies.</p> <p>The function uses duck typing to detect strategy capabilities:</p> <p>VERSION-FIRST PATH (if strategy has get_version_info method):</p> <ol> <li>Load effective configuration (org + vendor + recipe merged)</li> <li>Call strategy.get_version_info() to discover version (no download)</li> <li>Compare discovered version to cached known_version</li> <li>If match and file exists -&gt; skip download entirely (fast path!)</li> <li>If changed or missing -&gt; download installer via download_file()</li> <li>Update state and return results</li> </ol> <p>FILE-FIRST PATH (if strategy has only discover_version method):</p> <ol> <li>Load effective configuration (org + vendor + recipe merged)</li> <li>Call strategy.discover_version() with cached ETag</li> <li>Strategy handles conditional request (HTTP 304 vs 200)</li> <li>Extract version from downloaded file</li> <li>Update state and return results</li> </ol> <p>Parameters:</p> Name Type Description Default <code>recipe_path</code> <code>Path</code> <p>Path to the recipe YAML file. Must exist and be readable. The path is resolved to absolute form.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to download the installer to. Created if it doesn't exist. The downloaded file will be named based on Content-Disposition header or URL path.</p> required <code>state_file</code> <code>Path | None</code> <p>Path to state file for version tracking and ETag caching. Default is \"state/versions.json\". Set to None to disable.</p> <code>Path('state/versions.json')</code> <code>stateless</code> <code>bool</code> <p>If True, disable state tracking (no caching, always download). Default is False.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>If True, print verbose progress output. Default is False.</p> <code>False</code> <code>debug</code> <code>bool</code> <p>If True, print debug output. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>DiscoverResult</code> <p>DiscoverResult dataclass with the following fields:</p> <ul> <li>app_name (str): Application display name from recipe configuration.</li> <li>app_id (str): Unique application identifier from recipe configuration.</li> <li>strategy (str): Discovery strategy used (e.g., \"web_scrape\", \"api_github\",     \"api_json\", \"url_download\").</li> <li>version (str): Extracted version string (e.g., \"141.0.7390.123\").</li> <li>version_source (str): How version was determined (e.g., \"regex_in_url\",     \"msi\", \"api_tag\", \"api_json\").</li> <li>file_path (Path): Path to the downloaded installer file in output_dir.</li> <li>sha256 (str): SHA-256 hash of the downloaded file for integrity     verification.</li> <li>status (str): Always \"success\" for successful discovery operations.</li> </ul> <p>Raises:</p> Type Description <code>ConfigError</code> <p>On missing or invalid configuration fields (no apps defined, missing 'source.strategy' field, unknown discovery strategy name), YAML parse errors (from config loader), or if recipe file doesn't exist.</p> <code>NetworkError</code> <p>On download failures or version extraction errors.</p> Example <p>Basic version discovery:     <pre><code>from pathlib import Path\nresult = discover_recipe(\n    Path(\"recipes/Google/chrome.yaml\"),\n    Path(\"./downloads\")\n)\nprint(result.version)  # 141.0.7390.123\n</code></pre></p> <p>Handling errors:     <pre><code>try:\n    result = discover_recipe(Path(\"invalid.yaml\"), Path(\".\"))\nexcept ConfigError as e:\n    print(f\"Config error: {e}\")\nexcept NetworkError as e:\n    print(f\"Network error: {e}\")\n</code></pre></p> Note <p>Only the first app in a recipe is currently processed. The discovery strategy must be registered before calling this function. Version-first strategies (web_scrape, api_github, api_json) can skip downloads entirely when version unchanged (fast path optimization). File-first strategy (url_download) uses ETag conditional requests. Downloaded files are written atomically (.part then renamed). Progress output goes to stdout via the download module. Strategy type detected via duck typing (hasattr for get_version_info).</p> Source code in <code>notapkgtool/core.py</code> <pre><code>def discover_recipe(\n    recipe_path: Path,\n    output_dir: Path,\n    state_file: Path | None = Path(\"state/versions.json\"),\n    stateless: bool = False,\n    verbose: bool = False,\n    debug: bool = False,\n) -&gt; DiscoverResult:\n    \"\"\"Discover the latest version by loading config and downloading installer.\n\n    This is the main entry point for the 'napt discover' command. It orchestrates\n    the entire discovery workflow using a two-path architecture optimized for\n    version-first strategies.\n\n    The function uses duck typing to detect strategy capabilities:\n\n    VERSION-FIRST PATH (if strategy has get_version_info method):\n\n    1. Load effective configuration (org + vendor + recipe merged)\n    2. Call strategy.get_version_info() to discover version (no download)\n    3. Compare discovered version to cached known_version\n    4. If match and file exists -&gt; skip download entirely (fast path!)\n    5. If changed or missing -&gt; download installer via download_file()\n    6. Update state and return results\n\n    FILE-FIRST PATH (if strategy has only discover_version method):\n\n    1. Load effective configuration (org + vendor + recipe merged)\n    2. Call strategy.discover_version() with cached ETag\n    3. Strategy handles conditional request (HTTP 304 vs 200)\n    4. Extract version from downloaded file\n    5. Update state and return results\n\n    Args:\n        recipe_path: Path to the recipe YAML file. Must exist and be\n            readable. The path is resolved to absolute form.\n        output_dir: Directory to download the installer to. Created if\n            it doesn't exist. The downloaded file will be named based on\n            Content-Disposition header or URL path.\n        state_file: Path to state file for version tracking\n            and ETag caching. Default is \"state/versions.json\". Set to None\n            to disable.\n        stateless: If True, disable state tracking (no caching,\n            always download). Default is False.\n        verbose: If True, print verbose progress output.\n            Default is False.\n        debug: If True, print debug output. Default is False.\n\n    Returns:\n        DiscoverResult dataclass with the following fields:\n\n            - app_name (str): Application display name from recipe configuration.\n            - app_id (str): Unique application identifier from recipe configuration.\n            - strategy (str): Discovery strategy used (e.g., \"web_scrape\", \"api_github\",\n                \"api_json\", \"url_download\").\n            - version (str): Extracted version string (e.g., \"141.0.7390.123\").\n            - version_source (str): How version was determined (e.g., \"regex_in_url\",\n                \"msi\", \"api_tag\", \"api_json\").\n            - file_path (Path): Path to the downloaded installer file in output_dir.\n            - sha256 (str): SHA-256 hash of the downloaded file for integrity\n                verification.\n            - status (str): Always \"success\" for successful discovery operations.\n\n    Raises:\n        ConfigError: On missing or invalid configuration fields (no apps defined,\n            missing 'source.strategy' field, unknown discovery strategy name),\n            YAML parse errors (from config loader), or if recipe file doesn't exist.\n        NetworkError: On download failures or version extraction errors.\n\n    Example:\n        Basic version discovery:\n            ```python\n            from pathlib import Path\n            result = discover_recipe(\n                Path(\"recipes/Google/chrome.yaml\"),\n                Path(\"./downloads\")\n            )\n            print(result.version)  # 141.0.7390.123\n            ```\n\n        Handling errors:\n            ```python\n            try:\n                result = discover_recipe(Path(\"invalid.yaml\"), Path(\".\"))\n            except ConfigError as e:\n                print(f\"Config error: {e}\")\n            except NetworkError as e:\n                print(f\"Network error: {e}\")\n            ```\n\n    Note:\n        Only the first app in a recipe is currently processed. The discovery\n        strategy must be registered before calling this function. Version-first\n        strategies (web_scrape, api_github, api_json) can skip downloads\n        entirely when version unchanged (fast path optimization). File-first\n        strategy (url_download) uses ETag conditional requests. Downloaded files\n        are written atomically (.part then renamed). Progress output goes to\n        stdout via the download module. Strategy type detected via duck typing\n        (hasattr for get_version_info).\n\n    \"\"\"\n    logger = get_global_logger()\n\n    # Load state file unless running in stateless mode\n    state = None\n    if not stateless and state_file:\n        try:\n            state = load_state(state_file)\n            logger.verbose(\"STATE\", f\"Loaded state from {state_file}\")\n        except FileNotFoundError:\n            logger.verbose(\"STATE\", f\"State file not found, will create: {state_file}\")\n            state = {\n                \"metadata\": {\"napt_version\": __version__, \"schema_version\": \"2\"},\n                \"apps\": {},\n            }\n        except Exception as err:\n            logger.verbose(\"STATE\", f\"Warning: Failed to load state: {err}\")\n            logger.verbose(\"STATE\", \"Continuing without state tracking\")\n            state = None\n\n    # 1. Load and merge configuration\n    logger.step(1, 4, \"Loading configuration...\")\n    config = load_effective_config(recipe_path, verbose=verbose, debug=debug)\n\n    # 2. Extract the first app (for now we only process one app per recipe)\n    logger.step(2, 4, \"Discovering version...\")\n    apps = config.get(\"apps\", [])\n    if not apps:\n        raise ConfigError(f\"No apps defined in recipe: {recipe_path}\")\n\n    app = apps[0]\n    app_name = app.get(\"name\", \"Unknown\")\n    app_id = app.get(\"id\", \"unknown-id\")\n\n    # 3. Get the discovery strategy name\n    source = app.get(\"source\", {})\n    strategy_name = source.get(\"strategy\")\n    if not strategy_name:\n        raise ConfigError(f\"No 'source.strategy' defined for app: {app_name}\")\n\n    # 4. Get the strategy implementation\n    # Import strategies to ensure they're registered\n    import notapkgtool.discovery.api_github  # noqa: F401\n    import notapkgtool.discovery.api_json  # noqa: F401\n    import notapkgtool.discovery.url_download  # noqa: F401\n    import notapkgtool.discovery.web_scrape  # noqa: F401\n\n    strategy = get_strategy(strategy_name)\n\n    # Get cache for this recipe from state\n    cache = None\n    if state and app_id:\n        cache = state.get(\"apps\", {}).get(app_id)\n        if cache:\n            logger.verbose(\"STATE\", f\"Using cache for {app_id}\")\n            if cache.get(\"known_version\"):\n                logger.verbose(\n                    \"STATE\", f\"  Cached version: {cache.get('known_version')}\"\n                )\n            if cache.get(\"etag\"):\n                logger.verbose(\"STATE\", f\"  Cached ETag: {cache.get('etag')}\")\n\n    # 5. Run discovery: version-first or file-first path\n    logger.step(3, 4, \"Discovering version...\")\n\n    # Check if strategy supports version-first (has get_version_info method)\n    download_url = None  # Track actual download URL for state file\n    if hasattr(strategy, \"get_version_info\"):\n        # VERSION-FIRST PATH (web_scrape, api_github, api_json)\n        # Get version without downloading\n        version_info = strategy.get_version_info(app, verbose=verbose, debug=debug)\n        download_url = version_info.download_url  # Save for state file\n\n        logger.verbose(\"DISCOVERY\", f\"Version discovered: {version_info.version}\")\n\n        # Check if we can use cached file (version match + file exists)\n        if cache and cache.get(\"known_version\") == version_info.version:\n            # Derive file path from URL using same logic as download_file\n            file_path = derive_file_path_from_url(version_info.download_url, output_dir)\n\n            if file_path.exists():\n                # Fast path: version unchanged, file exists, skip download!\n                logger.verbose(\n                    \"CACHE\",\n                    f\"Version {version_info.version} unchanged, using cached file\",\n                )\n                logger.step(4, 4, \"Using cached file...\")\n                sha256 = cache.get(\"sha256\")\n                discovered_version = DiscoveredVersion(\n                    version_info.version, version_info.source\n                )\n                headers = {}  # No download occurred, no headers\n            else:\n                # File was deleted, re-download\n                logger.verbose(\n                    \"WARNING\",\n                    f\"Cached file {file_path} not found, re-downloading\",\n                )\n                logger.step(4, 4, \"Downloading installer...\")\n                file_path, sha256, headers = download_file(\n                    version_info.download_url,\n                    output_dir,\n                    verbose=verbose,\n                    debug=debug,\n                )\n                discovered_version = DiscoveredVersion(\n                    version_info.version, version_info.source\n                )\n        else:\n            # Version changed or no cache, download new version\n            if cache:\n                logger.verbose(\n                    \"DISCOVERY\",\n                    (\n                        f\"Version changed: {cache.get('known_version')} -&gt; \"\n                        f\"{version_info.version}\"\n                    ),\n                )\n            logger.step(4, 4, \"Downloading installer...\")\n            file_path, sha256, headers = download_file(\n                version_info.download_url,\n                output_dir,\n                verbose=verbose,\n                debug=debug,\n            )\n            discovered_version = DiscoveredVersion(\n                version_info.version, version_info.source\n            )\n    else:\n        # FILE-FIRST PATH (url_download only)\n        # Must download to extract version\n        logger.step(4, 4, \"Downloading installer...\")\n        discovered_version, file_path, sha256, headers = strategy.discover_version(\n            app, output_dir, cache=cache, verbose=verbose, debug=debug\n        )\n        download_url = str(app.get(\"source\", {}).get(\"url\", \"\"))  # Use source.url\n\n    # Update state with discovered information\n    if state and app_id and state_file:\n        from datetime import UTC, datetime\n\n        if \"apps\" not in state:\n            state[\"apps\"] = {}\n\n        # Extract ETag and Last-Modified from headers for next run\n        etag = headers.get(\"ETag\")\n        last_modified = headers.get(\"Last-Modified\")\n\n        if etag:\n            logger.verbose(\"STATE\", f\"Saving ETag for next run: {etag}\")\n        if last_modified:\n            logger.verbose(\n                \"STATE\", f\"Saving Last-Modified for next run: {last_modified}\"\n            )\n\n        # Build cache entry with new schema v2\n        cache_entry = {\n            \"url\": download_url\n            or \"\",  # Actual download URL (from version_info or source.url)\n            \"etag\": etag if etag else None,  # Only useful for url_download\n            \"last_modified\": (\n                last_modified if last_modified else None\n            ),  # Only useful for url_download\n            \"sha256\": sha256,\n        }\n\n        # Optional fields\n        if discovered_version.version:\n            cache_entry[\"known_version\"] = discovered_version.version\n        if strategy_name:\n            cache_entry[\"strategy\"] = strategy_name\n\n        state[\"apps\"][app_id] = cache_entry\n\n        state[\"metadata\"] = {\n            \"napt_version\": __version__,\n            \"last_updated\": datetime.now(UTC).isoformat(),\n            \"schema_version\": \"2\",\n        }\n\n        try:\n            save_state(state, state_file)\n            logger.verbose(\"STATE\", f\"Updated state file: {state_file}\")\n        except Exception as err:\n            logger.verbose(\"STATE\", f\"Warning: Failed to save state: {err}\")\n\n    # 6. Return results\n    return DiscoverResult(\n        app_name=app_name,\n        app_id=app_id,\n        strategy=strategy_name,\n        version=discovered_version.version,\n        version_source=discovered_version.source,\n        file_path=file_path,\n        sha256=sha256,\n        status=\"success\",\n    )\n</code></pre>"},{"location":"api/discovery/","title":"discovery","text":""},{"location":"api/discovery/#notapkgtool.discovery.base","title":"notapkgtool.discovery.base","text":"<p>Discovery strategy base protocol and registry for NAPT.</p> <p>This module defines the foundational components for the discovery system:</p> <ul> <li>DiscoveryStrategy protocol: Interface that all strategies must implement</li> <li>Strategy registry: Global dict mapping strategy names to implementations</li> <li>Registration and lookup functions: register_strategy() and get_strategy()</li> </ul> <p>The discovery system uses a strategy pattern to support multiple ways of obtaining application installers and their versions:</p> <ul> <li>url_download: Direct download from a static URL (FILE-FIRST)</li> <li>web_scrape: Scrape vendor download pages to find links and extract versions     (VERSION-FIRST)</li> <li>api_github: Fetch from GitHub releases API (VERSION-FIRST)</li> <li>api_json: Query JSON API endpoints for version and download URL (VERSION-FIRST)</li> </ul> Design Philosophy <ul> <li>Strategies are Protocol classes (structural subtyping, not inheritance)</li> <li>Registration happens at module import time (strategies self-register)</li> <li>Registry is a simple dict (no complex dependency injection needed)</li> <li>Each strategy is stateless and can be instantiated on-demand</li> </ul> <p>Protocol Benefits:</p> <p>Using typing.Protocol instead of ABC allows:</p> <ul> <li>Duck typing: Classes don't need explicit inheritance</li> <li>Better IDE support: Type checkers verify interface compliance</li> <li>Flexibility: Third-party code can add strategies without touching base</li> </ul> Example <p>Implementing a custom strategy:     <pre><code>from notapkgtool.discovery.base import register_strategy, DiscoveryStrategy\nfrom pathlib import Path\nfrom typing import Any\nfrom notapkgtool.versioning.keys import DiscoveredVersion\n\nclass MyCustomStrategy:\n    def discover_version(\n        self, app_config: dict[str, Any], output_dir: Path\n    ) -&gt; tuple[DiscoveredVersion, Path, str]:\n        # Implement your discovery logic here\n        ...\n\n# Register it (typically at module import)\nregister_strategy(\"my_custom\", MyCustomStrategy)\n\n# Now it can be used in recipes:\n# source:\n#   strategy: my_custom\n#   ...\n</code></pre></p>"},{"location":"api/discovery/#notapkgtool.discovery.base.DiscoveryStrategy","title":"DiscoveryStrategy","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for version discovery strategies.</p> <p>Each strategy must implement discover_version() which downloads and extracts version information based on the app config.</p> <p>Strategies may optionally implement validate_config() to provide strategy-specific configuration validation without network calls.</p> Source code in <code>notapkgtool/discovery/base.py</code> <pre><code>class DiscoveryStrategy(Protocol):\n    \"\"\"Protocol for version discovery strategies.\n\n    Each strategy must implement discover_version() which downloads\n    and extracts version information based on the app config.\n\n    Strategies may optionally implement validate_config() to provide\n    strategy-specific configuration validation without network calls.\n    \"\"\"\n\n    def discover_version(\n        self, app_config: dict[str, Any], output_dir: Path\n    ) -&gt; tuple[DiscoveredVersion, Path, str, dict]:\n        \"\"\"Discover and download an application version.\n\n        Args:\n            app_config: The app configuration from the recipe\n                (`config[\"apps\"][0]`).\n            output_dir: Directory to download the installer to.\n\n        Returns:\n            A tuple (discovered_version, file_path, sha256, headers), where\n                discovered_version is the version information, file_path is\n                the path to the downloaded file, sha256 is the SHA-256 hash,\n                and headers contains HTTP response headers for caching.\n\n        Raises:\n            ValueError: On discovery or download failures.\n            RuntimeError: On discovery or download failures.\n\n        \"\"\"\n        ...\n\n    def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n        \"\"\"Validate strategy-specific configuration (optional).\n\n        This method validates the app configuration for strategy-specific\n        requirements without making network calls or downloading files.\n        Useful for quick feedback during recipe development.\n\n        Args:\n            app_config: The app configuration from the recipe\n                (`config[\"apps\"][0]`).\n\n        Returns:\n            List of error messages. Empty list if configuration is valid.\n            Each error should be a human-readable description of the issue.\n\n        Example:\n            Check required fields:\n                ```python\n                def validate_config(self, app_config):\n                    errors = []\n                    source = app_config.get(\"source\", {})\n                    if \"url\" not in source:\n                        errors.append(\"Missing required field: source.url\")\n                    return errors\n                ```\n\n        Note:\n            This method is optional; strategies without it will skip validation.\n            Should NOT make network calls or download files. Should check field\n            presence, types, and format only. Used by 'napt validate' command\n            for fast recipe checking.\n\n        \"\"\"\n        ...\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.base.DiscoveryStrategy.discover_version","title":"discover_version","text":"<pre><code>discover_version(app_config: dict[str, Any], output_dir: Path) -&gt; tuple[DiscoveredVersion, Path, str, dict]\n</code></pre> <p>Discover and download an application version.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>The app configuration from the recipe (<code>config[\"apps\"][0]</code>).</p> required <code>output_dir</code> <code>Path</code> <p>Directory to download the installer to.</p> required <p>Returns:</p> Type Description <code>tuple[DiscoveredVersion, Path, str, dict]</code> <p>A tuple (discovered_version, file_path, sha256, headers), where discovered_version is the version information, file_path is the path to the downloaded file, sha256 is the SHA-256 hash, and headers contains HTTP response headers for caching.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>On discovery or download failures.</p> <code>RuntimeError</code> <p>On discovery or download failures.</p> Source code in <code>notapkgtool/discovery/base.py</code> <pre><code>def discover_version(\n    self, app_config: dict[str, Any], output_dir: Path\n) -&gt; tuple[DiscoveredVersion, Path, str, dict]:\n    \"\"\"Discover and download an application version.\n\n    Args:\n        app_config: The app configuration from the recipe\n            (`config[\"apps\"][0]`).\n        output_dir: Directory to download the installer to.\n\n    Returns:\n        A tuple (discovered_version, file_path, sha256, headers), where\n            discovered_version is the version information, file_path is\n            the path to the downloaded file, sha256 is the SHA-256 hash,\n            and headers contains HTTP response headers for caching.\n\n    Raises:\n        ValueError: On discovery or download failures.\n        RuntimeError: On discovery or download failures.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.base.DiscoveryStrategy.validate_config","title":"validate_config","text":"<pre><code>validate_config(app_config: dict[str, Any]) -&gt; list[str]\n</code></pre> <p>Validate strategy-specific configuration (optional).</p> <p>This method validates the app configuration for strategy-specific requirements without making network calls or downloading files. Useful for quick feedback during recipe development.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>The app configuration from the recipe (<code>config[\"apps\"][0]</code>).</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of error messages. Empty list if configuration is valid.</p> <code>list[str]</code> <p>Each error should be a human-readable description of the issue.</p> Example <p>Check required fields:     <pre><code>def validate_config(self, app_config):\n    errors = []\n    source = app_config.get(\"source\", {})\n    if \"url\" not in source:\n        errors.append(\"Missing required field: source.url\")\n    return errors\n</code></pre></p> Note <p>This method is optional; strategies without it will skip validation. Should NOT make network calls or download files. Should check field presence, types, and format only. Used by 'napt validate' command for fast recipe checking.</p> Source code in <code>notapkgtool/discovery/base.py</code> <pre><code>def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n    \"\"\"Validate strategy-specific configuration (optional).\n\n    This method validates the app configuration for strategy-specific\n    requirements without making network calls or downloading files.\n    Useful for quick feedback during recipe development.\n\n    Args:\n        app_config: The app configuration from the recipe\n            (`config[\"apps\"][0]`).\n\n    Returns:\n        List of error messages. Empty list if configuration is valid.\n        Each error should be a human-readable description of the issue.\n\n    Example:\n        Check required fields:\n            ```python\n            def validate_config(self, app_config):\n                errors = []\n                source = app_config.get(\"source\", {})\n                if \"url\" not in source:\n                    errors.append(\"Missing required field: source.url\")\n                return errors\n            ```\n\n    Note:\n        This method is optional; strategies without it will skip validation.\n        Should NOT make network calls or download files. Should check field\n        presence, types, and format only. Used by 'napt validate' command\n        for fast recipe checking.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.base.register_strategy","title":"register_strategy","text":"<pre><code>register_strategy(name: str, strategy_class: type[DiscoveryStrategy]) -&gt; None\n</code></pre> <p>Register a discovery strategy by name in the global registry.</p> <p>This function should be called when a strategy module is imported, typically at module level. Registering the same name twice will overwrite the previous registration (allows monkey-patching for tests).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Strategy name (e.g., \"url_download\"). This is the value used in recipe YAML files under source.strategy. Names should be lowercase with underscores for readability.</p> required <code>strategy_class</code> <code>type[DiscoveryStrategy]</code> <p>The strategy class to register. Must implement the DiscoveryStrategy protocol (have a discover_version method with the correct signature).</p> required Example <p>Register at module import time:     <pre><code># In discovery/my_strategy.py\nfrom .base import register_strategy\n\nclass MyStrategy:\n    def discover_version(self, app_config, output_dir):\n        ...\n\nregister_strategy(\"my_strategy\", MyStrategy)\n</code></pre></p> Note <p>No validation is performed at registration time. Type checkers will verify protocol compliance at static analysis time. Runtime errors occur at strategy instantiation or invocation.</p> Source code in <code>notapkgtool/discovery/base.py</code> <pre><code>def register_strategy(name: str, strategy_class: type[DiscoveryStrategy]) -&gt; None:\n    \"\"\"Register a discovery strategy by name in the global registry.\n\n    This function should be called when a strategy module is imported,\n    typically at module level. Registering the same name twice will\n    overwrite the previous registration (allows monkey-patching for tests).\n\n    Args:\n        name: Strategy name (e.g., \"url_download\"). This is the value\n            used in recipe YAML files under source.strategy. Names should be\n            lowercase with underscores for readability.\n        strategy_class: The strategy class to\n            register. Must implement the DiscoveryStrategy protocol (have a\n            discover_version method with the correct signature).\n\n    Example:\n        Register at module import time:\n            ```python\n            # In discovery/my_strategy.py\n            from .base import register_strategy\n\n            class MyStrategy:\n                def discover_version(self, app_config, output_dir):\n                    ...\n\n            register_strategy(\"my_strategy\", MyStrategy)\n            ```\n\n    Note:\n        No validation is performed at registration time. Type checkers will\n        verify protocol compliance at static analysis time. Runtime errors\n        occur at strategy instantiation or invocation.\n\n    \"\"\"\n    _STRATEGY_REGISTRY[name] = strategy_class\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.base.get_strategy","title":"get_strategy","text":"<pre><code>get_strategy(name: str) -&gt; DiscoveryStrategy\n</code></pre> <p>Get a discovery strategy instance by name from the global registry.</p> <p>The strategy is instantiated on-demand (strategies are stateless, so a new instance is created for each call). The strategy module must have been imported first for registration to occur.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Strategy name (e.g., \"url_download\"). Must exactly match a name registered via register_strategy(). Case-sensitive.</p> required <p>Returns:</p> Type Description <code>DiscoveryStrategy</code> <p>A new instance of the requested strategy, ready to use.</p> <p>Raises:</p> Type Description <code>ConfigError</code> <p>If the strategy name is not registered. The error message includes a list of available strategies for troubleshooting.</p> Example <p>Get and use a strategy:     <pre><code>from notapkgtool.discovery import get_strategy\nstrategy = get_strategy(\"url_download\")\n# Use strategy.discover_version(...)\n</code></pre></p> <p>Handle unknown strategy:     <pre><code>try:\n    strategy = get_strategy(\"nonexistent\")\nexcept ConfigError as e:\n    print(f\"Strategy not found: {e}\")\n</code></pre></p> Note <p>Strategies must be registered before they can be retrieved. The url_download strategy is auto-registered when imported. New strategies can be added by creating a module and registering.</p> Source code in <code>notapkgtool/discovery/base.py</code> <pre><code>def get_strategy(name: str) -&gt; DiscoveryStrategy:\n    \"\"\"Get a discovery strategy instance by name from the global registry.\n\n    The strategy is instantiated on-demand (strategies are stateless, so\n    a new instance is created for each call). The strategy module must\n    have been imported first for registration to occur.\n\n    Args:\n        name: Strategy name (e.g., \"url_download\"). Must exactly match\n            a name registered via register_strategy(). Case-sensitive.\n\n    Returns:\n        A new instance of the requested strategy, ready\n            to use.\n\n    Raises:\n        ConfigError: If the strategy name is not registered. The error message\n            includes a list of available strategies for troubleshooting.\n\n    Example:\n        Get and use a strategy:\n            ```python\n            from notapkgtool.discovery import get_strategy\n            strategy = get_strategy(\"url_download\")\n            # Use strategy.discover_version(...)\n            ```\n\n        Handle unknown strategy:\n            ```python\n            try:\n                strategy = get_strategy(\"nonexistent\")\n            except ConfigError as e:\n                print(f\"Strategy not found: {e}\")\n            ```\n\n    Note:\n        Strategies must be registered before they can be retrieved. The\n        url_download strategy is auto-registered when imported. New strategies\n        can be added by creating a module and registering.\n\n    \"\"\"\n    if name not in _STRATEGY_REGISTRY:\n        available = \", \".join(_STRATEGY_REGISTRY.keys())\n        raise ConfigError(\n            f\"Unknown discovery strategy: {name!r}. Available: {available or '(none)'}\"\n        )\n    return _STRATEGY_REGISTRY[name]()\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.url_download","title":"notapkgtool.discovery.url_download","text":"<p>URL download discovery strategy for NAPT.</p> <p>This is a FILE-FIRST strategy that downloads an installer from a fixed HTTP(S) URL and extracts version information from the downloaded file. Uses HTTP ETag conditional requests to avoid re-downloading unchanged files.</p> <p>Key Advantages:</p> <ul> <li>Works with any fixed URL (version not required in URL)</li> <li>Extracts accurate version directly from installer metadata</li> <li>Uses ETag-based conditional requests for efficiency (~500ms vs full download)</li> <li>Simple and reliable for vendors with stable download URLs</li> <li>Fallback strategy when version not available via API/URL pattern</li> </ul> <p>Supported Version Extraction:</p> <ul> <li>msi: Extract ProductVersion property from MSI files</li> <li>(Future) exe: Extract FileVersion from PE headers</li> <li>(Future) manual: Use a version specified in the recipe</li> </ul> <p>Use Cases:</p> <ul> <li>Google Chrome: Fixed enterprise MSI URL, version embedded in MSI</li> <li>Mozilla Firefox: Fixed enterprise MSI URL, version embedded in MSI</li> <li>Vendors with stable download URLs and embedded version metadata</li> <li>When version not available via API, URL pattern, or GitHub tags</li> </ul> <p>Recipe Configuration:</p> <pre><code>source:\n  strategy: url_download\n  url: \"https://vendor.com/installer.msi\"          # Required: download URL\n  version:\n    type: msi                                      # Required: extraction method\n    file: \"installer.msi\"  # Optional: defaults to URL filename\n</code></pre> <p>Configuration Fields:</p> <ul> <li>url (str, required): HTTP(S) URL to download the installer from. The URL     should be stable and point to the latest version.</li> <li>version.type (str, required): Version extraction method. Currently     supported: msi.</li> <li>version.file (str, optional): Specific filename to extract version from.     Defaults to the downloaded filename derived from the URL or     Content-Disposition header.</li> </ul> <p>Error Handling:</p> <ul> <li>ConfigError: Missing or invalid configuration fields</li> <li>NetworkError: Download failures, version extraction errors</li> <li>Errors are chained with 'from err' for better debugging</li> </ul> Example <p>In a recipe YAML:     <pre><code>apps:\n  - name: \"My App\"\n    id: \"my-app\"\n    source:\n      strategy: url_download\n      url: \"https://example.com/myapp-setup.msi\"\n      version:\n        type: msi\n</code></pre></p> <p>From Python: <pre><code>from pathlib import Path\nfrom notapkgtool.discovery.url_download import UrlDownloadStrategy\n\nstrategy = UrlDownloadStrategy()\napp_config = {\n    \"source\": {\n        \"url\": \"https://example.com/app.msi\",\n        \"version\": {\"type\": \"msi\"},\n    }\n}\n\n# With cache for ETag optimization\ncache = {\"etag\": 'W/\"abc123\"', \"sha256\": \"...\"}\ndiscovered, file_path, sha256, headers = strategy.discover_version(\n    app_config, Path(\"./downloads\"), cache=cache\n)\nprint(f\"Version {discovered.version} at {file_path}\")\n</code></pre></p> <p>From Python (using core orchestration):     <pre><code>from pathlib import Path\nfrom notapkgtool.core import discover_recipe\n\n# Automatically uses ETag optimization\nresult = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\nprint(f\"Version {result.version} at {result.file_path}\")\n</code></pre></p> Note <ul> <li>Must download file to extract version (architectural constraint)</li> <li>ETag optimization reduces bandwidth but still requires network round-trip</li> <li>Core orchestration automatically provides cached ETag if available</li> <li>Server must support ETag or Last-Modified headers for optimization</li> <li>If server doesn't support conditional requests, full download occurs every time</li> <li>Consider version-first strategies (web_scrape, api_github, api_json) for   better performance when version available via web scraping or API</li> </ul>"},{"location":"api/discovery/#notapkgtool.discovery.url_download.UrlDownloadStrategy","title":"UrlDownloadStrategy","text":"<p>Discovery strategy for static HTTP(S) URLs.</p> Configuration example <p>source:   strategy: url_download   url: \"https://example.com/installer.msi\"   version:     type: msi     file: \"installer.msi\"</p> Source code in <code>notapkgtool/discovery/url_download.py</code> <pre><code>class UrlDownloadStrategy:\n    \"\"\"Discovery strategy for static HTTP(S) URLs.\n\n    Configuration example:\n        source:\n          strategy: url_download\n          url: \"https://example.com/installer.msi\"\n          version:\n            type: msi\n            file: \"installer.msi\"\n    \"\"\"\n\n    def discover_version(\n        self,\n        app_config: dict[str, Any],\n        output_dir: Path,\n        cache: dict[str, Any] | None = None,\n        verbose: bool = False,\n        debug: bool = False,\n    ) -&gt; tuple[DiscoveredVersion, Path, str, dict]:\n        \"\"\"Download from static URL and extract version from the file.\n\n        Args:\n            app_config: App configuration containing source.url and\n                source.version.\n            output_dir: Directory to save the downloaded file.\n            cache: Cached state with etag, last_modified,\n                file_path, and sha256 for conditional requests. If provided\n                and file is unchanged (HTTP 304), the cached file is returned.\n            verbose: If True, print verbose logging messages.\n                Default is False.\n            debug: If True, print debug logging messages.\n                Default is False.\n\n        Returns:\n            A tuple (version_info, file_path, sha256, headers), where\n                version_info contains the discovered version information,\n                file_path is the Path to the downloaded file, sha256 is the\n                SHA-256 hash, and headers contains HTTP response headers.\n\n        Raises:\n            ConfigError: If required config fields are missing or invalid.\n            NetworkError: If download or version extraction fails.\n\n        \"\"\"\n        from notapkgtool.logging import get_global_logger\n\n        logger = get_global_logger()\n        source = app_config.get(\"source\", {})\n        url = source.get(\"url\")\n        if not url:\n            raise ConfigError(\"url_download strategy requires 'source.url' in config\")\n\n        version_config = source.get(\"version\", {})\n        version_type = version_config.get(\"type\")\n        if not version_type:\n            raise ConfigError(\n                \"url_download strategy requires 'source.version.type' in config\"\n            )\n\n        logger.verbose(\"DISCOVERY\", \"Strategy: url_download (file-first)\")\n        logger.verbose(\"DISCOVERY\", f\"Source URL: {url}\")\n        logger.verbose(\"DISCOVERY\", f\"Version extraction: {version_type}\")\n\n        # Extract ETag/Last-Modified from cache if available\n        etag = cache.get(\"etag\") if cache else None\n        last_modified = cache.get(\"last_modified\") if cache else None\n\n        if etag:\n            logger.verbose(\"DISCOVERY\", f\"Using cached ETag: {etag}\")\n        if last_modified:\n            logger.verbose(\"DISCOVERY\", f\"Using cached Last-Modified: {last_modified}\")\n\n        # Download the file (with conditional request if cache available)\n        try:\n            file_path, sha256, headers = download_file(\n                url,\n                output_dir,\n                etag=etag,\n                last_modified=last_modified,\n                verbose=verbose,\n                debug=debug,\n            )\n        except NotModifiedError:\n            # File unchanged (HTTP 304), use cached version\n            # Use convention-based path: derive filename from URL\n            logger.verbose(\n                \"DISCOVERY\", \"File not modified (HTTP 304), using cached version\"\n            )\n\n            if not cache or \"sha256\" not in cache:\n                raise NetworkError(\n                    \"Cache indicates file not modified, but missing SHA-256. \"\n                    \"Try running with --stateless to force re-download.\"\n                ) from None\n\n            # Derive file path from URL (convention-based, schema v2)\n            from urllib.parse import urlparse\n\n            filename = Path(urlparse(url).path).name\n            cached_file = output_dir / filename\n\n            if not cached_file.exists():\n                raise NetworkError(\n                    f\"Cached file {cached_file} not found. \"\n                    f\"File may have been deleted. Try running with --stateless.\"\n                ) from None\n\n            # Extract version from cached file\n            if version_type == \"msi\":\n                try:\n                    discovered = version_from_msi_product_version(\n                        cached_file, verbose=verbose, debug=debug\n                    )\n                except Exception as err:\n                    raise NetworkError(\n                        f\"Failed to extract MSI ProductVersion from cached \"\n                        f\"file {cached_file}: {err}\"\n                    ) from err\n            else:\n                raise ConfigError(\n                    f\"Unsupported version type: {version_type!r}. \" f\"Supported: msi\"\n                ) from None\n\n            # Return cached info with preserved headers (prevents overwriting ETag)\n            # When 304, no new headers received, so return cached values to\n            # preserve them\n            preserved_headers = {}\n            if cache.get(\"etag\"):\n                preserved_headers[\"ETag\"] = cache[\"etag\"]\n            if cache.get(\"last_modified\"):\n                preserved_headers[\"Last-Modified\"] = cache[\"last_modified\"]\n\n            return discovered, cached_file, cache[\"sha256\"], preserved_headers\n        except Exception as err:\n            if isinstance(err, (NetworkError, ConfigError)):\n                raise\n            raise NetworkError(f\"Failed to download {url}: {err}\") from err\n\n        # File was downloaded (not cached), extract version from it\n        if version_type == \"msi\":\n            try:\n                discovered = version_from_msi_product_version(\n                    file_path, verbose=verbose, debug=debug\n                )\n            except Exception as err:\n                raise NetworkError(\n                    f\"Failed to extract MSI ProductVersion from {file_path}: {err}\"\n                ) from err\n        else:\n            raise ConfigError(\n                f\"Unsupported version type: {version_type!r}. \" f\"Supported: msi\"\n            )\n\n        return discovered, file_path, sha256, headers\n\n    def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n        \"\"\"Validate url_download strategy configuration.\n\n        Checks for required fields and correct types without making network calls.\n\n        Args:\n            app_config: The app configuration from the recipe.\n\n        Returns:\n            List of error messages (empty if valid).\n\n        \"\"\"\n        errors = []\n        source = app_config.get(\"source\", {})\n\n        # Check required fields\n        if \"url\" not in source:\n            errors.append(\"Missing required field: source.url\")\n        elif not isinstance(source[\"url\"], str):\n            errors.append(\"source.url must be a string\")\n        elif not source[\"url\"].strip():\n            errors.append(\"source.url cannot be empty\")\n\n        # Check version configuration\n        if \"version\" not in source:\n            errors.append(\"Missing required field: source.version\")\n        elif not isinstance(source[\"version\"], dict):\n            errors.append(\"source.version must be a dictionary\")\n        else:\n            version_config = source[\"version\"]\n\n            # Check version.type\n            if \"type\" not in version_config:\n                errors.append(\"Missing required field: source.version.type\")\n            elif not isinstance(version_config[\"type\"], str):\n                errors.append(\"source.version.type must be a string\")\n            else:\n                version_type = version_config[\"type\"]\n                supported_types = [\"msi\"]\n                if version_type not in supported_types:\n                    errors.append(\n                        f\"Unsupported source.version.type: {version_type!r}. \"\n                        f\"Supported: {', '.join(supported_types)}\"\n                    )\n\n        return errors\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.url_download.UrlDownloadStrategy.discover_version","title":"discover_version","text":"<pre><code>discover_version(app_config: dict[str, Any], output_dir: Path, cache: dict[str, Any] | None = None, verbose: bool = False, debug: bool = False) -&gt; tuple[DiscoveredVersion, Path, str, dict]\n</code></pre> <p>Download from static URL and extract version from the file.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>App configuration containing source.url and source.version.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the downloaded file.</p> required <code>cache</code> <code>dict[str, Any] | None</code> <p>Cached state with etag, last_modified, file_path, and sha256 for conditional requests. If provided and file is unchanged (HTTP 304), the cached file is returned.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, print verbose logging messages. Default is False.</p> <code>False</code> <code>debug</code> <code>bool</code> <p>If True, print debug logging messages. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[DiscoveredVersion, Path, str, dict]</code> <p>A tuple (version_info, file_path, sha256, headers), where version_info contains the discovered version information, file_path is the Path to the downloaded file, sha256 is the SHA-256 hash, and headers contains HTTP response headers.</p> <p>Raises:</p> Type Description <code>ConfigError</code> <p>If required config fields are missing or invalid.</p> <code>NetworkError</code> <p>If download or version extraction fails.</p> Source code in <code>notapkgtool/discovery/url_download.py</code> <pre><code>def discover_version(\n    self,\n    app_config: dict[str, Any],\n    output_dir: Path,\n    cache: dict[str, Any] | None = None,\n    verbose: bool = False,\n    debug: bool = False,\n) -&gt; tuple[DiscoveredVersion, Path, str, dict]:\n    \"\"\"Download from static URL and extract version from the file.\n\n    Args:\n        app_config: App configuration containing source.url and\n            source.version.\n        output_dir: Directory to save the downloaded file.\n        cache: Cached state with etag, last_modified,\n            file_path, and sha256 for conditional requests. If provided\n            and file is unchanged (HTTP 304), the cached file is returned.\n        verbose: If True, print verbose logging messages.\n            Default is False.\n        debug: If True, print debug logging messages.\n            Default is False.\n\n    Returns:\n        A tuple (version_info, file_path, sha256, headers), where\n            version_info contains the discovered version information,\n            file_path is the Path to the downloaded file, sha256 is the\n            SHA-256 hash, and headers contains HTTP response headers.\n\n    Raises:\n        ConfigError: If required config fields are missing or invalid.\n        NetworkError: If download or version extraction fails.\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    source = app_config.get(\"source\", {})\n    url = source.get(\"url\")\n    if not url:\n        raise ConfigError(\"url_download strategy requires 'source.url' in config\")\n\n    version_config = source.get(\"version\", {})\n    version_type = version_config.get(\"type\")\n    if not version_type:\n        raise ConfigError(\n            \"url_download strategy requires 'source.version.type' in config\"\n        )\n\n    logger.verbose(\"DISCOVERY\", \"Strategy: url_download (file-first)\")\n    logger.verbose(\"DISCOVERY\", f\"Source URL: {url}\")\n    logger.verbose(\"DISCOVERY\", f\"Version extraction: {version_type}\")\n\n    # Extract ETag/Last-Modified from cache if available\n    etag = cache.get(\"etag\") if cache else None\n    last_modified = cache.get(\"last_modified\") if cache else None\n\n    if etag:\n        logger.verbose(\"DISCOVERY\", f\"Using cached ETag: {etag}\")\n    if last_modified:\n        logger.verbose(\"DISCOVERY\", f\"Using cached Last-Modified: {last_modified}\")\n\n    # Download the file (with conditional request if cache available)\n    try:\n        file_path, sha256, headers = download_file(\n            url,\n            output_dir,\n            etag=etag,\n            last_modified=last_modified,\n            verbose=verbose,\n            debug=debug,\n        )\n    except NotModifiedError:\n        # File unchanged (HTTP 304), use cached version\n        # Use convention-based path: derive filename from URL\n        logger.verbose(\n            \"DISCOVERY\", \"File not modified (HTTP 304), using cached version\"\n        )\n\n        if not cache or \"sha256\" not in cache:\n            raise NetworkError(\n                \"Cache indicates file not modified, but missing SHA-256. \"\n                \"Try running with --stateless to force re-download.\"\n            ) from None\n\n        # Derive file path from URL (convention-based, schema v2)\n        from urllib.parse import urlparse\n\n        filename = Path(urlparse(url).path).name\n        cached_file = output_dir / filename\n\n        if not cached_file.exists():\n            raise NetworkError(\n                f\"Cached file {cached_file} not found. \"\n                f\"File may have been deleted. Try running with --stateless.\"\n            ) from None\n\n        # Extract version from cached file\n        if version_type == \"msi\":\n            try:\n                discovered = version_from_msi_product_version(\n                    cached_file, verbose=verbose, debug=debug\n                )\n            except Exception as err:\n                raise NetworkError(\n                    f\"Failed to extract MSI ProductVersion from cached \"\n                    f\"file {cached_file}: {err}\"\n                ) from err\n        else:\n            raise ConfigError(\n                f\"Unsupported version type: {version_type!r}. \" f\"Supported: msi\"\n            ) from None\n\n        # Return cached info with preserved headers (prevents overwriting ETag)\n        # When 304, no new headers received, so return cached values to\n        # preserve them\n        preserved_headers = {}\n        if cache.get(\"etag\"):\n            preserved_headers[\"ETag\"] = cache[\"etag\"]\n        if cache.get(\"last_modified\"):\n            preserved_headers[\"Last-Modified\"] = cache[\"last_modified\"]\n\n        return discovered, cached_file, cache[\"sha256\"], preserved_headers\n    except Exception as err:\n        if isinstance(err, (NetworkError, ConfigError)):\n            raise\n        raise NetworkError(f\"Failed to download {url}: {err}\") from err\n\n    # File was downloaded (not cached), extract version from it\n    if version_type == \"msi\":\n        try:\n            discovered = version_from_msi_product_version(\n                file_path, verbose=verbose, debug=debug\n            )\n        except Exception as err:\n            raise NetworkError(\n                f\"Failed to extract MSI ProductVersion from {file_path}: {err}\"\n            ) from err\n    else:\n        raise ConfigError(\n            f\"Unsupported version type: {version_type!r}. \" f\"Supported: msi\"\n        )\n\n    return discovered, file_path, sha256, headers\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.url_download.UrlDownloadStrategy.validate_config","title":"validate_config","text":"<pre><code>validate_config(app_config: dict[str, Any]) -&gt; list[str]\n</code></pre> <p>Validate url_download strategy configuration.</p> <p>Checks for required fields and correct types without making network calls.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>The app configuration from the recipe.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of error messages (empty if valid).</p> Source code in <code>notapkgtool/discovery/url_download.py</code> <pre><code>def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n    \"\"\"Validate url_download strategy configuration.\n\n    Checks for required fields and correct types without making network calls.\n\n    Args:\n        app_config: The app configuration from the recipe.\n\n    Returns:\n        List of error messages (empty if valid).\n\n    \"\"\"\n    errors = []\n    source = app_config.get(\"source\", {})\n\n    # Check required fields\n    if \"url\" not in source:\n        errors.append(\"Missing required field: source.url\")\n    elif not isinstance(source[\"url\"], str):\n        errors.append(\"source.url must be a string\")\n    elif not source[\"url\"].strip():\n        errors.append(\"source.url cannot be empty\")\n\n    # Check version configuration\n    if \"version\" not in source:\n        errors.append(\"Missing required field: source.version\")\n    elif not isinstance(source[\"version\"], dict):\n        errors.append(\"source.version must be a dictionary\")\n    else:\n        version_config = source[\"version\"]\n\n        # Check version.type\n        if \"type\" not in version_config:\n            errors.append(\"Missing required field: source.version.type\")\n        elif not isinstance(version_config[\"type\"], str):\n            errors.append(\"source.version.type must be a string\")\n        else:\n            version_type = version_config[\"type\"]\n            supported_types = [\"msi\"]\n            if version_type not in supported_types:\n                errors.append(\n                    f\"Unsupported source.version.type: {version_type!r}. \"\n                    f\"Supported: {', '.join(supported_types)}\"\n                )\n\n    return errors\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.web_scrape","title":"notapkgtool.discovery.web_scrape","text":"<p>Web scraping discovery strategy for NAPT.</p> <p>This is a VERSION-FIRST strategy that scrapes vendor download pages to find download links and extract version information from those links. This enables version discovery for vendors that don't provide APIs or static URLs.</p> <p>Key Advantages:</p> <ul> <li>Discovers versions from vendor download pages</li> <li>Works for vendors without APIs or GitHub releases</li> <li>Version-first caching (can skip downloads when version unchanged)</li> <li>Supports both CSS selectors (recommended) and regex (fallback)</li> <li>No dependency on HTML structure stability (with good selectors)</li> <li>Handles relative and absolute URLs automatically</li> </ul> <p>Supported Link Finding:</p> <ul> <li>CSS selectors: Modern, robust, recommended approach</li> <li>Regex patterns: Fallback for edge cases or when CSS won't work</li> </ul> <p>Version Extraction:</p> <ul> <li>Extract version from the discovered download URL using regex</li> <li>Support for captured groups with formatting</li> <li>Transform version numbers (e.g., \"2501\" -&gt; \"25.01\")</li> </ul> <p>Use Cases:</p> <ul> <li>Vendors with download pages listing multiple versions (7-Zip, etc.)</li> <li>Legacy software without modern APIs</li> <li>Small vendors with simple download pages</li> <li>When GitHub releases and JSON APIs aren't available</li> </ul> Recipe Configuration <pre><code>source:\n  strategy: web_scrape\n  page_url: \"https://www.7-zip.org/download.html\"\n  link_selector: 'a[href$=\"-x64.msi\"]'        # CSS (recommended)\n  version_pattern: \"7z(\\d{2})(\\d{2})-x64\"   # Extract from URL\n  version_format: \"{0}.{1}\"                    # Transform to \"25.01\"\n</code></pre> Alternative with regex <pre><code>source:\n  strategy: web_scrape\n  page_url: \"https://vendor.com/downloads\"\n  link_pattern: 'href=\"(/files/app-v[0-9.]+-x64\\.msi)\"'\n  version_pattern: \"app-v([0-9.]+)-x64\"\n</code></pre> <p>Configuration Fields:</p> <ul> <li>page_url (str, required): URL of the page to scrape for download links</li> <li>link_selector (str, optional): CSS selector to find download link.     Recommended approach. Example: 'a[href$=\".msi\"]' finds links ending with .msi</li> <li>link_pattern (str, optional): Regex pattern as fallback when CSS won't     work. Must have one capture group for the URL. Example: 'href=\"([^\"]*.msi)\"'</li> <li>version_pattern (str, required): Regex pattern to extract version from     the discovered URL. Use capture groups to extract version parts. Example:     \"app-(\\d+.\\d+)\" or \"7z(\\d{2})(\\d{2})\"</li> <li>version_format (str, optional): Python format string to combine captured     groups. Use {0}, {1}, etc. for groups. Example: \"{0}.{1}\" transforms     captures \"25\", \"01\" into \"25.01\". Defaults to \"{0}\" (first capture group     only).</li> </ul> <p>Error Handling:</p> <ul> <li>ValueError: Missing or invalid configuration fields</li> <li>RuntimeError: Page download failures, selector/pattern not found</li> <li>Errors are chained with 'from err' for better debugging</li> </ul> <p>Finding CSS Selectors:</p> <pre><code>Use browser DevTools:\n\n1. Open download page in Chrome/Edge/Firefox\n2. Right-click download link -&gt; Inspect\n3. Right-click highlighted element -&gt; Copy -&gt; Copy selector\n4. Simplify selector (e.g., 'a[href$=\".msi\"]' instead of complex nth-child)\n</code></pre> <p>Common CSS Patterns:</p> <ul> <li>'a[href$=\".msi\"]' - Links ending with .msi</li> <li>'a[href*=\"x64\"]' - Links containing \"x64\"</li> <li>'a.download' - Links with class=\"download\"</li> <li>'a[href$=\"-x64.msi\"]:first-of-type' - First matching link</li> </ul> Example <p>In a recipe YAML:     <pre><code>apps:\n  - name: \"7-Zip\"\n    id: \"napt-7zip\"\n    source:\n      strategy: web_scrape\n      page_url: \"https://www.7-zip.org/download.html\"\n      link_selector: 'a[href$=\"-x64.msi\"]'\n      version_pattern: \"7z(\\d{2})(\\d{2})-x64\"\n      version_format: \"{0}.{1}\"\n</code></pre></p> <p>From Python (version-first approach):     <pre><code>from notapkgtool.discovery.web_scrape import WebScrapeStrategy\nfrom notapkgtool.io import download_file\n\nstrategy = WebScrapeStrategy()\napp_config = {\n    \"source\": {\n        \"page_url\": \"https://www.7-zip.org/download.html\",\n        \"link_selector\": 'a[href$=\"-x64.msi\"]',\n        \"version_pattern\": \"7z(\\d{2})(\\d{2})-x64\",\n        \"version_format\": \"{0}.{1}\",\n    }\n}\n\n# Get version WITHOUT downloading installer\nversion_info = strategy.get_version_info(app_config)\nprint(f\"Latest version: {version_info.version}\")\n\n# Download only if needed\nif need_to_download:\n    file_path, sha256, headers = download_file(\n        version_info.download_url, Path(\"./downloads\")\n    )\n    print(f\"Downloaded to {file_path}\")\n</code></pre></p> <p>From Python (using core orchestration):     <pre><code>from pathlib import Path\nfrom notapkgtool.core import discover_recipe\n\n# Automatically uses version-first optimization\nresult = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\nprint(f\"Version {result.version} at {result.file_path}\")\n</code></pre></p> Note <ul> <li>Version discovery via web scraping (no installer download required)</li> <li>Core orchestration automatically skips download if version unchanged</li> <li>CSS selectors are recommended (more robust than regex)</li> <li>Use browser DevTools to find selectors easily</li> <li>Selector should match exactly one link (first match is used)</li> <li>BeautifulSoup4 required for CSS selectors</li> <li>Regex fallback works without BeautifulSoup</li> </ul>"},{"location":"api/discovery/#notapkgtool.discovery.web_scrape.WebScrapeStrategy","title":"WebScrapeStrategy","text":"<p>Discovery strategy for web scraping download pages.</p> Configuration example <pre><code>source:\n  strategy: web_scrape\n  page_url: \"https://vendor.com/download.html\"\n  link_selector: 'a[href$=\".msi\"]'\n  version_pattern: \"app-v([0-9.]+)\"\n</code></pre> Source code in <code>notapkgtool/discovery/web_scrape.py</code> <pre><code>class WebScrapeStrategy:\n    \"\"\"Discovery strategy for web scraping download pages.\n\n    Configuration example:\n        ```yaml\n        source:\n          strategy: web_scrape\n          page_url: \"https://vendor.com/download.html\"\n          link_selector: 'a[href$=\".msi\"]'\n          version_pattern: \"app-v([0-9.]+)\"\n        ```\n    \"\"\"\n\n    def get_version_info(\n        self,\n        app_config: dict[str, Any],\n        verbose: bool = False,\n        debug: bool = False,\n    ) -&gt; VersionInfo:\n        \"\"\"Scrape download page for version and URL without downloading\n        (version-first path).\n\n        This method scrapes an HTML page, finds a download link using CSS selector\n        or regex, extracts the version from that link, and returns version info.\n        If the version matches cached state, the download can be skipped entirely.\n\n        Args:\n            app_config: App configuration containing source.page_url,\n                source.link_selector or source.link_pattern, and\n                source.version_pattern.\n            verbose: If True, print verbose logging messages.\n                Defaults to False.\n            debug: If True, print debug logging messages.\n                Defaults to False.\n\n        Returns:\n            Version info with version string, download URL, and\n                source name.\n\n        Raises:\n            ValueError: If required config fields are missing, invalid, or if\n                selectors/patterns don't match anything.\n            RuntimeError: If page download fails (chained with 'from err').\n\n        Example:\n            Scrape 7-Zip download page:\n                ```python\n                strategy = WebScrapeStrategy()\n                config = {\n                    \"source\": {\n                        \"page_url\": \"https://www.7-zip.org/download.html\",\n                        \"link_selector\": 'a[href$=\"-x64.msi\"]',\n                        \"version_pattern\": \"7z(\\\\d{2})(\\\\d{2})-x64\",\n                        \"version_format\": \"{0}.{1}\"\n                    }\n                }\n                version_info = strategy.get_version_info(config)\n                # version_info.version returns: '25.01'\n                ```\n\n        \"\"\"\n        from notapkgtool.logging import get_global_logger\n\n        logger = get_global_logger()\n        # Validate configuration\n        source = app_config.get(\"source\", {})\n        page_url = source.get(\"page_url\")\n        if not page_url:\n            raise ConfigError(\n                \"web_scrape strategy requires 'source.page_url' in config\"\n            )\n\n        link_selector = source.get(\"link_selector\")\n        link_pattern = source.get(\"link_pattern\")\n\n        if not link_selector and not link_pattern:\n            raise ConfigError(\n                \"web_scrape strategy requires either 'source.link_selector' or \"\n                \"'source.link_pattern' in config\"\n            )\n\n        version_pattern = source.get(\"version_pattern\")\n        if not version_pattern:\n            raise ConfigError(\n                \"web_scrape strategy requires 'source.version_pattern' in config\"\n            )\n\n        version_format = source.get(\"version_format\", \"{0}\")\n\n        logger.verbose(\"DISCOVERY\", \"Strategy: web_scrape (version-first)\")\n        logger.verbose(\"DISCOVERY\", f\"Page URL: {page_url}\")\n        if link_selector:\n            logger.verbose(\"DISCOVERY\", f\"Link selector (CSS): {link_selector}\")\n        if link_pattern:\n            logger.verbose(\"DISCOVERY\", f\"Link pattern (regex): {link_pattern}\")\n        logger.verbose(\"DISCOVERY\", f\"Version pattern: {version_pattern}\")\n\n        # Download the HTML page\n        logger.verbose(\"DISCOVERY\", f\"Fetching page: {page_url}\")\n        try:\n            response = requests.get(page_url, timeout=30)\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as err:\n            raise NetworkError(\n                f\"Failed to fetch page: {response.status_code} {response.reason}\"\n            ) from err\n        except requests.exceptions.RequestException as err:\n            raise NetworkError(f\"Failed to fetch page: {err}\") from err\n\n        html_content = response.text\n        logger.verbose(\"DISCOVERY\", f\"Page fetched ({len(html_content)} bytes)\")\n\n        # Find download link using CSS selector or regex\n        download_url = None\n\n        if link_selector:\n            # Use CSS selector with BeautifulSoup4\n            soup = BeautifulSoup(html_content, \"html.parser\")\n            element = soup.select_one(link_selector)\n\n            if not element:\n                raise ConfigError(\n                    f\"CSS selector {link_selector!r} did not match any elements on page\"\n                )\n\n            # Get href attribute\n            href = element.get(\"href\")\n            if not href:\n                raise ConfigError(\n                    f\"Element matched by {link_selector!r} has no href attribute\"\n                )\n\n            logger.verbose(\"DISCOVERY\", f\"Found link via CSS: {href}\")\n\n            # Build absolute URL\n            download_url = urljoin(page_url, href)\n\n        elif link_pattern:\n            # Use regex fallback\n            try:\n                pattern = re.compile(link_pattern)\n                match = pattern.search(html_content)\n\n                if not match:\n                    raise ConfigError(\n                        f\"Regex pattern {link_pattern!r} did not match anything on page\"\n                    )\n\n                # Get first capture group or full match\n                if pattern.groups &gt; 0:\n                    href = match.group(1)\n                else:\n                    href = match.group(0)\n\n                logger.verbose(\"DISCOVERY\", f\"Found link via regex: {href}\")\n\n                # Build absolute URL\n                download_url = urljoin(page_url, href)\n\n            except re.error as err:\n                raise ConfigError(\n                    f\"Invalid link_pattern regex: {link_pattern!r}\"\n                ) from err\n\n        logger.verbose(\"DISCOVERY\", f\"Download URL: {download_url}\")\n\n        # Extract version from the download URL\n        try:\n            version_regex = re.compile(version_pattern)\n            match = version_regex.search(download_url)\n\n            if not match:\n                raise ConfigError(\n                    f\"Version pattern {version_pattern!r} did not match \"\n                    f\"URL {download_url!r}\"\n                )\n\n            # Get captured groups\n            groups = match.groups()\n\n            if not groups:\n                # No capture groups, use full match\n                version_str = match.group(0)\n            else:\n                # Format using captured groups\n                try:\n                    version_str = version_format.format(*groups)\n                except (IndexError, KeyError) as err:\n                    raise ConfigError(\n                        f\"version_format {version_format!r} failed with \"\n                        f\"groups {groups}: {err}\"\n                    ) from err\n\n        except re.error as err:\n            raise ConfigError(\n                f\"Invalid version_pattern regex: {version_pattern!r}\"\n            ) from err\n\n        logger.verbose(\"DISCOVERY\", f\"Extracted version: {version_str}\")\n\n        return VersionInfo(\n            version=version_str,\n            download_url=download_url,\n            source=\"web_scrape\",\n        )\n\n    def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n        \"\"\"Validate web_scrape strategy configuration.\n\n        Checks for required fields and correct types without making network calls.\n\n        Args:\n            app_config: The app configuration from the recipe.\n\n        Returns:\n            List of error messages (empty if valid).\n\n        \"\"\"\n        errors = []\n        source = app_config.get(\"source\", {})\n\n        # Check page_url\n        if \"page_url\" not in source:\n            errors.append(\"Missing required field: source.page_url\")\n        elif not isinstance(source[\"page_url\"], str):\n            errors.append(\"source.page_url must be a string\")\n        elif not source[\"page_url\"].strip():\n            errors.append(\"source.page_url cannot be empty\")\n\n        # Check that at least one link finding method is provided\n        link_selector = source.get(\"link_selector\")\n        link_pattern = source.get(\"link_pattern\")\n\n        if not link_selector and not link_pattern:\n            errors.append(\n                \"Missing required field: must provide either \"\n                \"source.link_selector or source.link_pattern\"\n            )\n\n        # Validate link_selector if provided\n        if link_selector:\n            if not isinstance(link_selector, str):\n                errors.append(\"source.link_selector must be a string\")\n            elif not link_selector.strip():\n                errors.append(\"source.link_selector cannot be empty\")\n            else:\n                # Try to validate CSS selector syntax\n                try:\n                    # Test if selector is parseable\n                    soup = BeautifulSoup(\"&lt;html&gt;&lt;/html&gt;\", \"html.parser\")\n                    soup.select_one(link_selector)  # Will raise if invalid\n                except Exception as err:\n                    errors.append(f\"Invalid CSS selector: {err}\")\n\n        # Validate link_pattern if provided\n        if link_pattern:\n            if not isinstance(link_pattern, str):\n                errors.append(\"source.link_pattern must be a string\")\n            elif not link_pattern.strip():\n                errors.append(\"source.link_pattern cannot be empty\")\n            else:\n                # Validate regex compiles\n                try:\n                    re.compile(link_pattern)\n                except re.error as err:\n                    errors.append(f\"Invalid link_pattern regex: {err}\")\n\n        # Check version_pattern\n        if \"version_pattern\" not in source:\n            errors.append(\"Missing required field: source.version_pattern\")\n        elif not isinstance(source[\"version_pattern\"], str):\n            errors.append(\"source.version_pattern must be a string\")\n        elif not source[\"version_pattern\"].strip():\n            errors.append(\"source.version_pattern cannot be empty\")\n        else:\n            # Validate regex compiles\n            try:\n                re.compile(source[\"version_pattern\"])\n            except re.error as err:\n                errors.append(f\"Invalid version_pattern regex: {err}\")\n\n        # Validate version_format if provided\n        if \"version_format\" in source:\n            if not isinstance(source[\"version_format\"], str):\n                errors.append(\"source.version_format must be a string\")\n            elif not source[\"version_format\"].strip():\n                errors.append(\"source.version_format cannot be empty\")\n\n        return errors\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.web_scrape.WebScrapeStrategy.get_version_info","title":"get_version_info","text":"<pre><code>get_version_info(app_config: dict[str, Any], verbose: bool = False, debug: bool = False) -&gt; VersionInfo\n</code></pre> <p>Scrape download page for version and URL without downloading (version-first path).</p> <p>This method scrapes an HTML page, finds a download link using CSS selector or regex, extracts the version from that link, and returns version info. If the version matches cached state, the download can be skipped entirely.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>App configuration containing source.page_url, source.link_selector or source.link_pattern, and source.version_pattern.</p> required <code>verbose</code> <code>bool</code> <p>If True, print verbose logging messages. Defaults to False.</p> <code>False</code> <code>debug</code> <code>bool</code> <p>If True, print debug logging messages. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>VersionInfo</code> <p>Version info with version string, download URL, and source name.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If required config fields are missing, invalid, or if selectors/patterns don't match anything.</p> <code>RuntimeError</code> <p>If page download fails (chained with 'from err').</p> Example <p>Scrape 7-Zip download page:     <pre><code>strategy = WebScrapeStrategy()\nconfig = {\n    \"source\": {\n        \"page_url\": \"https://www.7-zip.org/download.html\",\n        \"link_selector\": 'a[href$=\"-x64.msi\"]',\n        \"version_pattern\": \"7z(\\d{2})(\\d{2})-x64\",\n        \"version_format\": \"{0}.{1}\"\n    }\n}\nversion_info = strategy.get_version_info(config)\n# version_info.version returns: '25.01'\n</code></pre></p> Source code in <code>notapkgtool/discovery/web_scrape.py</code> <pre><code>def get_version_info(\n    self,\n    app_config: dict[str, Any],\n    verbose: bool = False,\n    debug: bool = False,\n) -&gt; VersionInfo:\n    \"\"\"Scrape download page for version and URL without downloading\n    (version-first path).\n\n    This method scrapes an HTML page, finds a download link using CSS selector\n    or regex, extracts the version from that link, and returns version info.\n    If the version matches cached state, the download can be skipped entirely.\n\n    Args:\n        app_config: App configuration containing source.page_url,\n            source.link_selector or source.link_pattern, and\n            source.version_pattern.\n        verbose: If True, print verbose logging messages.\n            Defaults to False.\n        debug: If True, print debug logging messages.\n            Defaults to False.\n\n    Returns:\n        Version info with version string, download URL, and\n            source name.\n\n    Raises:\n        ValueError: If required config fields are missing, invalid, or if\n            selectors/patterns don't match anything.\n        RuntimeError: If page download fails (chained with 'from err').\n\n    Example:\n        Scrape 7-Zip download page:\n            ```python\n            strategy = WebScrapeStrategy()\n            config = {\n                \"source\": {\n                    \"page_url\": \"https://www.7-zip.org/download.html\",\n                    \"link_selector\": 'a[href$=\"-x64.msi\"]',\n                    \"version_pattern\": \"7z(\\\\d{2})(\\\\d{2})-x64\",\n                    \"version_format\": \"{0}.{1}\"\n                }\n            }\n            version_info = strategy.get_version_info(config)\n            # version_info.version returns: '25.01'\n            ```\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    # Validate configuration\n    source = app_config.get(\"source\", {})\n    page_url = source.get(\"page_url\")\n    if not page_url:\n        raise ConfigError(\n            \"web_scrape strategy requires 'source.page_url' in config\"\n        )\n\n    link_selector = source.get(\"link_selector\")\n    link_pattern = source.get(\"link_pattern\")\n\n    if not link_selector and not link_pattern:\n        raise ConfigError(\n            \"web_scrape strategy requires either 'source.link_selector' or \"\n            \"'source.link_pattern' in config\"\n        )\n\n    version_pattern = source.get(\"version_pattern\")\n    if not version_pattern:\n        raise ConfigError(\n            \"web_scrape strategy requires 'source.version_pattern' in config\"\n        )\n\n    version_format = source.get(\"version_format\", \"{0}\")\n\n    logger.verbose(\"DISCOVERY\", \"Strategy: web_scrape (version-first)\")\n    logger.verbose(\"DISCOVERY\", f\"Page URL: {page_url}\")\n    if link_selector:\n        logger.verbose(\"DISCOVERY\", f\"Link selector (CSS): {link_selector}\")\n    if link_pattern:\n        logger.verbose(\"DISCOVERY\", f\"Link pattern (regex): {link_pattern}\")\n    logger.verbose(\"DISCOVERY\", f\"Version pattern: {version_pattern}\")\n\n    # Download the HTML page\n    logger.verbose(\"DISCOVERY\", f\"Fetching page: {page_url}\")\n    try:\n        response = requests.get(page_url, timeout=30)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as err:\n        raise NetworkError(\n            f\"Failed to fetch page: {response.status_code} {response.reason}\"\n        ) from err\n    except requests.exceptions.RequestException as err:\n        raise NetworkError(f\"Failed to fetch page: {err}\") from err\n\n    html_content = response.text\n    logger.verbose(\"DISCOVERY\", f\"Page fetched ({len(html_content)} bytes)\")\n\n    # Find download link using CSS selector or regex\n    download_url = None\n\n    if link_selector:\n        # Use CSS selector with BeautifulSoup4\n        soup = BeautifulSoup(html_content, \"html.parser\")\n        element = soup.select_one(link_selector)\n\n        if not element:\n            raise ConfigError(\n                f\"CSS selector {link_selector!r} did not match any elements on page\"\n            )\n\n        # Get href attribute\n        href = element.get(\"href\")\n        if not href:\n            raise ConfigError(\n                f\"Element matched by {link_selector!r} has no href attribute\"\n            )\n\n        logger.verbose(\"DISCOVERY\", f\"Found link via CSS: {href}\")\n\n        # Build absolute URL\n        download_url = urljoin(page_url, href)\n\n    elif link_pattern:\n        # Use regex fallback\n        try:\n            pattern = re.compile(link_pattern)\n            match = pattern.search(html_content)\n\n            if not match:\n                raise ConfigError(\n                    f\"Regex pattern {link_pattern!r} did not match anything on page\"\n                )\n\n            # Get first capture group or full match\n            if pattern.groups &gt; 0:\n                href = match.group(1)\n            else:\n                href = match.group(0)\n\n            logger.verbose(\"DISCOVERY\", f\"Found link via regex: {href}\")\n\n            # Build absolute URL\n            download_url = urljoin(page_url, href)\n\n        except re.error as err:\n            raise ConfigError(\n                f\"Invalid link_pattern regex: {link_pattern!r}\"\n            ) from err\n\n    logger.verbose(\"DISCOVERY\", f\"Download URL: {download_url}\")\n\n    # Extract version from the download URL\n    try:\n        version_regex = re.compile(version_pattern)\n        match = version_regex.search(download_url)\n\n        if not match:\n            raise ConfigError(\n                f\"Version pattern {version_pattern!r} did not match \"\n                f\"URL {download_url!r}\"\n            )\n\n        # Get captured groups\n        groups = match.groups()\n\n        if not groups:\n            # No capture groups, use full match\n            version_str = match.group(0)\n        else:\n            # Format using captured groups\n            try:\n                version_str = version_format.format(*groups)\n            except (IndexError, KeyError) as err:\n                raise ConfigError(\n                    f\"version_format {version_format!r} failed with \"\n                    f\"groups {groups}: {err}\"\n                ) from err\n\n    except re.error as err:\n        raise ConfigError(\n            f\"Invalid version_pattern regex: {version_pattern!r}\"\n        ) from err\n\n    logger.verbose(\"DISCOVERY\", f\"Extracted version: {version_str}\")\n\n    return VersionInfo(\n        version=version_str,\n        download_url=download_url,\n        source=\"web_scrape\",\n    )\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.web_scrape.WebScrapeStrategy.validate_config","title":"validate_config","text":"<pre><code>validate_config(app_config: dict[str, Any]) -&gt; list[str]\n</code></pre> <p>Validate web_scrape strategy configuration.</p> <p>Checks for required fields and correct types without making network calls.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>The app configuration from the recipe.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of error messages (empty if valid).</p> Source code in <code>notapkgtool/discovery/web_scrape.py</code> <pre><code>def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n    \"\"\"Validate web_scrape strategy configuration.\n\n    Checks for required fields and correct types without making network calls.\n\n    Args:\n        app_config: The app configuration from the recipe.\n\n    Returns:\n        List of error messages (empty if valid).\n\n    \"\"\"\n    errors = []\n    source = app_config.get(\"source\", {})\n\n    # Check page_url\n    if \"page_url\" not in source:\n        errors.append(\"Missing required field: source.page_url\")\n    elif not isinstance(source[\"page_url\"], str):\n        errors.append(\"source.page_url must be a string\")\n    elif not source[\"page_url\"].strip():\n        errors.append(\"source.page_url cannot be empty\")\n\n    # Check that at least one link finding method is provided\n    link_selector = source.get(\"link_selector\")\n    link_pattern = source.get(\"link_pattern\")\n\n    if not link_selector and not link_pattern:\n        errors.append(\n            \"Missing required field: must provide either \"\n            \"source.link_selector or source.link_pattern\"\n        )\n\n    # Validate link_selector if provided\n    if link_selector:\n        if not isinstance(link_selector, str):\n            errors.append(\"source.link_selector must be a string\")\n        elif not link_selector.strip():\n            errors.append(\"source.link_selector cannot be empty\")\n        else:\n            # Try to validate CSS selector syntax\n            try:\n                # Test if selector is parseable\n                soup = BeautifulSoup(\"&lt;html&gt;&lt;/html&gt;\", \"html.parser\")\n                soup.select_one(link_selector)  # Will raise if invalid\n            except Exception as err:\n                errors.append(f\"Invalid CSS selector: {err}\")\n\n    # Validate link_pattern if provided\n    if link_pattern:\n        if not isinstance(link_pattern, str):\n            errors.append(\"source.link_pattern must be a string\")\n        elif not link_pattern.strip():\n            errors.append(\"source.link_pattern cannot be empty\")\n        else:\n            # Validate regex compiles\n            try:\n                re.compile(link_pattern)\n            except re.error as err:\n                errors.append(f\"Invalid link_pattern regex: {err}\")\n\n    # Check version_pattern\n    if \"version_pattern\" not in source:\n        errors.append(\"Missing required field: source.version_pattern\")\n    elif not isinstance(source[\"version_pattern\"], str):\n        errors.append(\"source.version_pattern must be a string\")\n    elif not source[\"version_pattern\"].strip():\n        errors.append(\"source.version_pattern cannot be empty\")\n    else:\n        # Validate regex compiles\n        try:\n            re.compile(source[\"version_pattern\"])\n        except re.error as err:\n            errors.append(f\"Invalid version_pattern regex: {err}\")\n\n    # Validate version_format if provided\n    if \"version_format\" in source:\n        if not isinstance(source[\"version_format\"], str):\n            errors.append(\"source.version_format must be a string\")\n        elif not source[\"version_format\"].strip():\n            errors.append(\"source.version_format cannot be empty\")\n\n    return errors\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.api_github","title":"notapkgtool.discovery.api_github","text":"<p>GitHub API discovery strategy for NAPT.</p> <p>This is a VERSION-FIRST strategy that queries the GitHub API to get version and download URL WITHOUT downloading the installer. This enables fast version checks and efficient caching.</p> <p>Key Advantages:</p> <ul> <li>Fast version discovery (GitHub API call ~100ms)</li> <li>Can skip downloads entirely when version unchanged</li> <li>Direct access to latest releases via stable GitHub API</li> <li>Version extraction from Git tags (semantic versioning friendly)</li> <li>Asset pattern matching for multi-platform releases</li> <li>Optional authentication for higher rate limits</li> <li>No web scraping required</li> <li>Ideal for CI/CD with scheduled checks</li> </ul> <p>Supported Version Extraction:</p> <ul> <li>Tag-based: Extract version from release tag names<ul> <li>Supports named capture groups: (?P...) <li>Default pattern strips \"v\" prefix: v1.2.3 -&gt; 1.2.3</li> <li>Falls back to full tag if no pattern match</li> <p>Use Cases:</p> <ul> <li>Open-source projects (Git, VS Code, Node.js, etc.)</li> <li>Projects with GitHub releases (Firefox, Chrome alternatives)</li> <li>Vendors who publish installers as release assets</li> <li>Projects with semantic versioned tags</li> <li>CI/CD pipelines with frequent version checks</li> </ul> Recipe Configuration <pre><code>source:\n    strategy: api_github\n    repo: \"git-for-windows/git\"                    # Required: owner/repo\n    asset_pattern: \"Git-.*-64-bit\\.exe$\"          # Required: regex for asset\n    version_pattern: \"v?([0-9.]+)\"                 # Optional: version extraction\n    prerelease: false                              # Optional: include prereleases\n    token: \"${GITHUB_TOKEN}\"                       # Optional: auth token\n</code></pre> <p>Configuration Fields:</p> <ul> <li>repo (str, required): GitHub repository in \"owner/name\" format     (e.g., \"git-for-windows/git\")</li> <li>asset_pattern (str, required): Regular expression to match asset     filename. If multiple assets match, the first match is used. Example:     \".*-x64.msi$\" matches assets ending with \"-x64.msi\"</li> <li>version_pattern (str, optional): Regular expression to extract version     from the release tag name. Use a named capture group (?P...) or     the entire match. Default: \"v?([0-9.]+)\" strips optional \"v\" prefix.     Example: \"release-([0-9.]+)\" for tags like \"release-1.2.3\".<ul> <li>prerelease (bool, optional): If True, include pre-release versions. If False   (default), only stable releases are considered. Uses GitHub's prerelease flag.</li> <li>token (str, optional): GitHub personal access token for authentication.   Increases rate limit from 60 to 5000 requests per hour. Can use environment   variable substitution: \"${GITHUB_TOKEN}\". No special permissions needed for   public repositories.</li> </ul> <p>Error Handling:</p> <ul> <li>ValueError: Missing or invalid configuration fields</li> <li>RuntimeError: API failures, no releases, no matching assets</li> <li>Errors are chained with 'from err' for better debugging</li> </ul> <p>Rate Limits:</p> <ul> <li>Unauthenticated: 60 requests/hour per IP</li> <li>Authenticated: 5000 requests/hour per token</li> <li>Tip: Use a token for production use or frequent checks</li> </ul> Example <p>In a recipe YAML:     <pre><code>apps:\n  - name: \"Git for Windows\"\n    id: \"git\"\n    source:\n      strategy: api_github\n      repo: \"git-for-windows/git\"\n      asset_pattern: \"Git-.*-64-bit\\.exe$\"\n</code></pre></p> <p>From Python (version-first approach):     <pre><code>from notapkgtool.discovery.api_github import ApiGithubStrategy\nfrom notapkgtool.io import download_file\n\nstrategy = ApiGithubStrategy()\napp_config = {\n    \"source\": {\n        \"repo\": \"git-for-windows/git\",\n        \"asset_pattern\": \".*-64-bit\\.exe$\",\n    }\n}\n\n# Get version WITHOUT downloading\nversion_info = strategy.get_version_info(app_config)\nprint(f\"Latest version: {version_info.version}\")\n\n# Download only if needed\nif need_to_download:\n    file_path, sha256, headers = download_file(\n        version_info.download_url, Path(\"./downloads\")\n    )\n    print(f\"Downloaded to {file_path}\")\n</code></pre></p> <p>From Python (using core orchestration):     <pre><code>from pathlib import Path\nfrom notapkgtool.core import discover_recipe\n\n# Automatically uses version-first optimization\nresult = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\nprint(f\"Version {result.version} at {result.file_path}\")\n</code></pre></p> Note <p>Version discovery via API only (no download required). Core orchestration automatically skips download if version unchanged. The GitHub API is stable and well-documented. Releases are fetched in order (latest first). Asset matching is case-sensitive by default (use (?i) for case-insensitive). Consider url_download if you need a direct download URL instead.</p>"},{"location":"api/discovery/#notapkgtool.discovery.api_github.ApiGithubStrategy","title":"ApiGithubStrategy","text":"<p>Discovery strategy for GitHub releases.</p> Configuration example <p>source:   strategy: api_github   repo: \"owner/repository\"   asset_pattern: \".*.msi$\"   version_pattern: \"v?([0-9.]+)\"   prerelease: false   token: \"${GITHUB_TOKEN}\"</p> Source code in <code>notapkgtool/discovery/api_github.py</code> <pre><code>class ApiGithubStrategy:\n    \"\"\"Discovery strategy for GitHub releases.\n\n    Configuration example:\n        source:\n          strategy: api_github\n          repo: \"owner/repository\"\n          asset_pattern: \".*\\\\.msi$\"\n          version_pattern: \"v?([0-9.]+)\"\n          prerelease: false\n          token: \"${GITHUB_TOKEN}\"\n    \"\"\"\n\n    def get_version_info(\n        self,\n        app_config: dict[str, Any],\n        verbose: bool = False,\n        debug: bool = False,\n    ) -&gt; VersionInfo:\n        \"\"\"Fetch latest release from GitHub API without downloading\n        (version-first path).\n\n        This method queries the GitHub API for the latest release and extracts\n        the version from the tag name and the download URL from matching assets.\n        If the version matches cached state, the download can be skipped entirely.\n\n        Args:\n            app_config: App configuration containing source.repo and\n                optional fields.\n            verbose: If True, print verbose logging messages.\n                Default is False.\n            debug: If True, print debug logging messages.\n                Default is False.\n\n        Returns:\n            Version info with version string, download URL, and\n                source name.\n\n        Raises:\n            ValueError: If required config fields are missing, invalid, or if\n                no matching assets are found.\n            RuntimeError: If API call fails or release has no assets.\n\n        Example:\n            Get version from GitHub releases:\n                ```python\n                strategy = ApiGithubStrategy()\n                config = {\n                    \"source\": {\n                        \"repo\": \"owner/repo\",\n                        \"asset_pattern\": \".*\\\\.msi$\"\n                    }\n                }\n                version_info = strategy.get_version_info(config)\n                # version_info.version returns: '1.0.0'\n                ```\n\n        \"\"\"\n        from notapkgtool.logging import get_global_logger\n\n        logger = get_global_logger()\n        # Validate configuration\n        source = app_config.get(\"source\", {})\n        repo = source.get(\"repo\")\n        if not repo:\n            raise ConfigError(\"api_github strategy requires 'source.repo' in config\")\n\n        # Validate repo format\n        if \"/\" not in repo or repo.count(\"/\") != 1:\n            raise ConfigError(\n                f\"Invalid repo format: {repo!r}. Expected 'owner/repository'\"\n            )\n\n        # Optional configuration\n        asset_pattern = source.get(\"asset_pattern\")\n        if not asset_pattern:\n            raise ConfigError(\n                \"api_github strategy requires 'source.asset_pattern' in config\"\n            )\n\n        version_pattern = source.get(\"version_pattern\", r\"v?([0-9.]+)\")\n        prerelease = source.get(\"prerelease\", False)\n        token = source.get(\"token\")\n\n        # Expand environment variables in token (e.g., ${GITHUB_TOKEN})\n        if token:\n            if token.startswith(\"${\") and token.endswith(\"}\"):\n                env_var = token[2:-1]\n                token = os.environ.get(env_var)\n                if not token:\n                    logger.verbose(\n                        \"DISCOVERY\",\n                        f\"Warning: Environment variable {env_var} not set\",\n                    )\n\n        logger.verbose(\"DISCOVERY\", \"Strategy: api_github (version-first)\")\n        logger.verbose(\"DISCOVERY\", f\"Repository: {repo}\")\n        logger.verbose(\"DISCOVERY\", f\"Version pattern: {version_pattern}\")\n        if asset_pattern:\n            logger.verbose(\"DISCOVERY\", f\"Asset pattern: {asset_pattern}\")\n        if prerelease:\n            logger.verbose(\"DISCOVERY\", \"Including pre-releases\")\n\n        # Fetch latest release from GitHub API\n        api_url = f\"https://api.github.com/repos/{repo}/releases/latest\"\n        headers = {\n            \"Accept\": \"application/vnd.github+json\",\n            \"X-GitHub-Api-Version\": \"2022-11-28\",\n        }\n\n        # Add authentication if token provided\n        if token:\n            headers[\"Authorization\"] = f\"token {token}\"\n            logger.verbose(\"DISCOVERY\", \"Using authenticated API request\")\n\n        logger.verbose(\"DISCOVERY\", f\"Fetching release from: {api_url}\")\n\n        try:\n            response = requests.get(api_url, headers=headers, timeout=30)\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as err:\n            if response.status_code == 404:\n                raise NetworkError(\n                    f\"Repository {repo!r} not found or has no releases\"\n                ) from err\n            elif response.status_code == 403:\n                raise NetworkError(\n                    f\"GitHub API rate limit exceeded. Consider using a token. \"\n                    f\"Status: {response.status_code}\"\n                ) from err\n            else:\n                raise NetworkError(\n                    f\"GitHub API request failed: {response.status_code} \"\n                    f\"{response.reason}\"\n                ) from err\n        except requests.exceptions.RequestException as err:\n            raise NetworkError(f\"Failed to fetch GitHub release: {err}\") from err\n\n        release_data = response.json()\n\n        # Check if this is a prerelease and we don't want those\n        if release_data.get(\"prerelease\", False) and not prerelease:\n            raise NetworkError(\n                f\"Latest release is a pre-release and prerelease=false. \"\n                f\"Tag: {release_data.get('tag_name')}\"\n            )\n\n        # Extract version from tag name\n        tag_name = release_data.get(\"tag_name\", \"\")\n        if not tag_name:\n            raise NetworkError(\"Release has no tag_name field\")\n\n        logger.verbose(\"DISCOVERY\", f\"Release tag: {tag_name}\")\n\n        try:\n            pattern = re.compile(version_pattern)\n            match = pattern.search(tag_name)\n            if not match:\n                raise ConfigError(\n                    f\"Version pattern {version_pattern!r} did not match \"\n                    f\"tag {tag_name!r}\"\n                )\n\n            # Try to get named capture group 'version' first, else use group 1,\n            # else full match\n            if \"version\" in pattern.groupindex:\n                version_str = match.group(\"version\")\n            elif pattern.groups &gt; 0:\n                version_str = match.group(1)\n            else:\n                version_str = match.group(0)\n\n        except re.error as err:\n            raise ConfigError(\n                f\"Invalid version_pattern regex: {version_pattern!r}\"\n            ) from err\n        except (ValueError, IndexError) as err:\n            raise ConfigError(\n                f\"Failed to extract version from tag {tag_name!r} \"\n                f\"using pattern {version_pattern!r}: {err}\"\n            ) from err\n\n        logger.verbose(\"DISCOVERY\", f\"Extracted version: {version_str}\")\n\n        # Find matching asset\n        assets = release_data.get(\"assets\", [])\n        if not assets:\n            raise NetworkError(\n                f\"Release {tag_name} has no assets. \"\n                f\"Check if assets were uploaded to the release.\"\n            )\n\n        logger.verbose(\"DISCOVERY\", f\"Release has {len(assets)} asset(s)\")\n\n        # Match asset by pattern\n        matched_asset = None\n        try:\n            pattern = re.compile(asset_pattern)\n        except re.error as err:\n            raise ConfigError(\n                f\"Invalid asset_pattern regex: {asset_pattern!r}\"\n            ) from err\n\n        for asset in assets:\n            asset_name = asset.get(\"name\", \"\")\n            if pattern.search(asset_name):\n                matched_asset = asset\n                logger.verbose(\"DISCOVERY\", f\"Matched asset: {asset_name}\")\n                break\n\n        if not matched_asset:\n            available = [a.get(\"name\", \"(unnamed)\") for a in assets]\n            raise ConfigError(\n                f\"No assets matched pattern {asset_pattern!r}. \"\n                f\"Available assets: {', '.join(available)}\"\n            )\n\n        # Get download URL\n        download_url = matched_asset.get(\"browser_download_url\")\n        if not download_url:\n            raise NetworkError(f\"Asset {matched_asset.get('name')} has no download URL\")\n\n        logger.verbose(\"DISCOVERY\", f\"Download URL: {download_url}\")\n\n        return VersionInfo(\n            version=version_str,\n            download_url=download_url,\n            source=\"api_github\",\n        )\n\n    def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n        \"\"\"Validate api_github strategy configuration.\n\n        Checks for required fields and correct types without making network calls.\n\n        Args:\n            app_config: The app configuration from the recipe.\n\n        Returns:\n            List of error messages (empty if valid).\n\n        \"\"\"\n        errors = []\n        source = app_config.get(\"source\", {})\n\n        # Check required fields\n        if \"repo\" not in source:\n            errors.append(\"Missing required field: source.repo\")\n        elif not isinstance(source[\"repo\"], str):\n            errors.append(\"source.repo must be a string\")\n        elif not source[\"repo\"].strip():\n            errors.append(\"source.repo cannot be empty\")\n        else:\n            # Validate repo format\n            repo = source[\"repo\"]\n            if repo.count(\"/\") != 1:\n                errors.append(\n                    \"source.repo must be in format 'owner/repo' (e.g., 'git/git')\"\n                )\n\n        if \"asset_pattern\" not in source:\n            errors.append(\"Missing required field: source.asset_pattern\")\n        elif not isinstance(source[\"asset_pattern\"], str):\n            errors.append(\"source.asset_pattern must be a string\")\n        elif not source[\"asset_pattern\"].strip():\n            errors.append(\"source.asset_pattern cannot be empty\")\n        else:\n            # Validate regex pattern syntax\n            pattern = source[\"asset_pattern\"]\n            import re\n\n            try:\n                re.compile(pattern)\n            except re.error as err:\n                errors.append(f\"Invalid asset_pattern regex: {err}\")\n\n        # Optional fields validation\n        if \"version_pattern\" in source:\n            if not isinstance(source[\"version_pattern\"], str):\n                errors.append(\"source.version_pattern must be a string\")\n            else:\n                pattern = source[\"version_pattern\"]\n                import re\n\n                try:\n                    re.compile(pattern)\n                except re.error as err:\n                    errors.append(f\"Invalid version_pattern regex: {err}\")\n\n        return errors\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.api_github.ApiGithubStrategy.get_version_info","title":"get_version_info","text":"<pre><code>get_version_info(app_config: dict[str, Any], verbose: bool = False, debug: bool = False) -&gt; VersionInfo\n</code></pre> <p>Fetch latest release from GitHub API without downloading (version-first path).</p> <p>This method queries the GitHub API for the latest release and extracts the version from the tag name and the download URL from matching assets. If the version matches cached state, the download can be skipped entirely.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>App configuration containing source.repo and optional fields.</p> required <code>verbose</code> <code>bool</code> <p>If True, print verbose logging messages. Default is False.</p> <code>False</code> <code>debug</code> <code>bool</code> <p>If True, print debug logging messages. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>VersionInfo</code> <p>Version info with version string, download URL, and source name.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If required config fields are missing, invalid, or if no matching assets are found.</p> <code>RuntimeError</code> <p>If API call fails or release has no assets.</p> Example <p>Get version from GitHub releases:     <pre><code>strategy = ApiGithubStrategy()\nconfig = {\n    \"source\": {\n        \"repo\": \"owner/repo\",\n        \"asset_pattern\": \".*\\.msi$\"\n    }\n}\nversion_info = strategy.get_version_info(config)\n# version_info.version returns: '1.0.0'\n</code></pre></p> Source code in <code>notapkgtool/discovery/api_github.py</code> <pre><code>def get_version_info(\n    self,\n    app_config: dict[str, Any],\n    verbose: bool = False,\n    debug: bool = False,\n) -&gt; VersionInfo:\n    \"\"\"Fetch latest release from GitHub API without downloading\n    (version-first path).\n\n    This method queries the GitHub API for the latest release and extracts\n    the version from the tag name and the download URL from matching assets.\n    If the version matches cached state, the download can be skipped entirely.\n\n    Args:\n        app_config: App configuration containing source.repo and\n            optional fields.\n        verbose: If True, print verbose logging messages.\n            Default is False.\n        debug: If True, print debug logging messages.\n            Default is False.\n\n    Returns:\n        Version info with version string, download URL, and\n            source name.\n\n    Raises:\n        ValueError: If required config fields are missing, invalid, or if\n            no matching assets are found.\n        RuntimeError: If API call fails or release has no assets.\n\n    Example:\n        Get version from GitHub releases:\n            ```python\n            strategy = ApiGithubStrategy()\n            config = {\n                \"source\": {\n                    \"repo\": \"owner/repo\",\n                    \"asset_pattern\": \".*\\\\.msi$\"\n                }\n            }\n            version_info = strategy.get_version_info(config)\n            # version_info.version returns: '1.0.0'\n            ```\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    # Validate configuration\n    source = app_config.get(\"source\", {})\n    repo = source.get(\"repo\")\n    if not repo:\n        raise ConfigError(\"api_github strategy requires 'source.repo' in config\")\n\n    # Validate repo format\n    if \"/\" not in repo or repo.count(\"/\") != 1:\n        raise ConfigError(\n            f\"Invalid repo format: {repo!r}. Expected 'owner/repository'\"\n        )\n\n    # Optional configuration\n    asset_pattern = source.get(\"asset_pattern\")\n    if not asset_pattern:\n        raise ConfigError(\n            \"api_github strategy requires 'source.asset_pattern' in config\"\n        )\n\n    version_pattern = source.get(\"version_pattern\", r\"v?([0-9.]+)\")\n    prerelease = source.get(\"prerelease\", False)\n    token = source.get(\"token\")\n\n    # Expand environment variables in token (e.g., ${GITHUB_TOKEN})\n    if token:\n        if token.startswith(\"${\") and token.endswith(\"}\"):\n            env_var = token[2:-1]\n            token = os.environ.get(env_var)\n            if not token:\n                logger.verbose(\n                    \"DISCOVERY\",\n                    f\"Warning: Environment variable {env_var} not set\",\n                )\n\n    logger.verbose(\"DISCOVERY\", \"Strategy: api_github (version-first)\")\n    logger.verbose(\"DISCOVERY\", f\"Repository: {repo}\")\n    logger.verbose(\"DISCOVERY\", f\"Version pattern: {version_pattern}\")\n    if asset_pattern:\n        logger.verbose(\"DISCOVERY\", f\"Asset pattern: {asset_pattern}\")\n    if prerelease:\n        logger.verbose(\"DISCOVERY\", \"Including pre-releases\")\n\n    # Fetch latest release from GitHub API\n    api_url = f\"https://api.github.com/repos/{repo}/releases/latest\"\n    headers = {\n        \"Accept\": \"application/vnd.github+json\",\n        \"X-GitHub-Api-Version\": \"2022-11-28\",\n    }\n\n    # Add authentication if token provided\n    if token:\n        headers[\"Authorization\"] = f\"token {token}\"\n        logger.verbose(\"DISCOVERY\", \"Using authenticated API request\")\n\n    logger.verbose(\"DISCOVERY\", f\"Fetching release from: {api_url}\")\n\n    try:\n        response = requests.get(api_url, headers=headers, timeout=30)\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as err:\n        if response.status_code == 404:\n            raise NetworkError(\n                f\"Repository {repo!r} not found or has no releases\"\n            ) from err\n        elif response.status_code == 403:\n            raise NetworkError(\n                f\"GitHub API rate limit exceeded. Consider using a token. \"\n                f\"Status: {response.status_code}\"\n            ) from err\n        else:\n            raise NetworkError(\n                f\"GitHub API request failed: {response.status_code} \"\n                f\"{response.reason}\"\n            ) from err\n    except requests.exceptions.RequestException as err:\n        raise NetworkError(f\"Failed to fetch GitHub release: {err}\") from err\n\n    release_data = response.json()\n\n    # Check if this is a prerelease and we don't want those\n    if release_data.get(\"prerelease\", False) and not prerelease:\n        raise NetworkError(\n            f\"Latest release is a pre-release and prerelease=false. \"\n            f\"Tag: {release_data.get('tag_name')}\"\n        )\n\n    # Extract version from tag name\n    tag_name = release_data.get(\"tag_name\", \"\")\n    if not tag_name:\n        raise NetworkError(\"Release has no tag_name field\")\n\n    logger.verbose(\"DISCOVERY\", f\"Release tag: {tag_name}\")\n\n    try:\n        pattern = re.compile(version_pattern)\n        match = pattern.search(tag_name)\n        if not match:\n            raise ConfigError(\n                f\"Version pattern {version_pattern!r} did not match \"\n                f\"tag {tag_name!r}\"\n            )\n\n        # Try to get named capture group 'version' first, else use group 1,\n        # else full match\n        if \"version\" in pattern.groupindex:\n            version_str = match.group(\"version\")\n        elif pattern.groups &gt; 0:\n            version_str = match.group(1)\n        else:\n            version_str = match.group(0)\n\n    except re.error as err:\n        raise ConfigError(\n            f\"Invalid version_pattern regex: {version_pattern!r}\"\n        ) from err\n    except (ValueError, IndexError) as err:\n        raise ConfigError(\n            f\"Failed to extract version from tag {tag_name!r} \"\n            f\"using pattern {version_pattern!r}: {err}\"\n        ) from err\n\n    logger.verbose(\"DISCOVERY\", f\"Extracted version: {version_str}\")\n\n    # Find matching asset\n    assets = release_data.get(\"assets\", [])\n    if not assets:\n        raise NetworkError(\n            f\"Release {tag_name} has no assets. \"\n            f\"Check if assets were uploaded to the release.\"\n        )\n\n    logger.verbose(\"DISCOVERY\", f\"Release has {len(assets)} asset(s)\")\n\n    # Match asset by pattern\n    matched_asset = None\n    try:\n        pattern = re.compile(asset_pattern)\n    except re.error as err:\n        raise ConfigError(\n            f\"Invalid asset_pattern regex: {asset_pattern!r}\"\n        ) from err\n\n    for asset in assets:\n        asset_name = asset.get(\"name\", \"\")\n        if pattern.search(asset_name):\n            matched_asset = asset\n            logger.verbose(\"DISCOVERY\", f\"Matched asset: {asset_name}\")\n            break\n\n    if not matched_asset:\n        available = [a.get(\"name\", \"(unnamed)\") for a in assets]\n        raise ConfigError(\n            f\"No assets matched pattern {asset_pattern!r}. \"\n            f\"Available assets: {', '.join(available)}\"\n        )\n\n    # Get download URL\n    download_url = matched_asset.get(\"browser_download_url\")\n    if not download_url:\n        raise NetworkError(f\"Asset {matched_asset.get('name')} has no download URL\")\n\n    logger.verbose(\"DISCOVERY\", f\"Download URL: {download_url}\")\n\n    return VersionInfo(\n        version=version_str,\n        download_url=download_url,\n        source=\"api_github\",\n    )\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.api_github.ApiGithubStrategy.validate_config","title":"validate_config","text":"<pre><code>validate_config(app_config: dict[str, Any]) -&gt; list[str]\n</code></pre> <p>Validate api_github strategy configuration.</p> <p>Checks for required fields and correct types without making network calls.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>The app configuration from the recipe.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of error messages (empty if valid).</p> Source code in <code>notapkgtool/discovery/api_github.py</code> <pre><code>def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n    \"\"\"Validate api_github strategy configuration.\n\n    Checks for required fields and correct types without making network calls.\n\n    Args:\n        app_config: The app configuration from the recipe.\n\n    Returns:\n        List of error messages (empty if valid).\n\n    \"\"\"\n    errors = []\n    source = app_config.get(\"source\", {})\n\n    # Check required fields\n    if \"repo\" not in source:\n        errors.append(\"Missing required field: source.repo\")\n    elif not isinstance(source[\"repo\"], str):\n        errors.append(\"source.repo must be a string\")\n    elif not source[\"repo\"].strip():\n        errors.append(\"source.repo cannot be empty\")\n    else:\n        # Validate repo format\n        repo = source[\"repo\"]\n        if repo.count(\"/\") != 1:\n            errors.append(\n                \"source.repo must be in format 'owner/repo' (e.g., 'git/git')\"\n            )\n\n    if \"asset_pattern\" not in source:\n        errors.append(\"Missing required field: source.asset_pattern\")\n    elif not isinstance(source[\"asset_pattern\"], str):\n        errors.append(\"source.asset_pattern must be a string\")\n    elif not source[\"asset_pattern\"].strip():\n        errors.append(\"source.asset_pattern cannot be empty\")\n    else:\n        # Validate regex pattern syntax\n        pattern = source[\"asset_pattern\"]\n        import re\n\n        try:\n            re.compile(pattern)\n        except re.error as err:\n            errors.append(f\"Invalid asset_pattern regex: {err}\")\n\n    # Optional fields validation\n    if \"version_pattern\" in source:\n        if not isinstance(source[\"version_pattern\"], str):\n            errors.append(\"source.version_pattern must be a string\")\n        else:\n            pattern = source[\"version_pattern\"]\n            import re\n\n            try:\n                re.compile(pattern)\n            except re.error as err:\n                errors.append(f\"Invalid version_pattern regex: {err}\")\n\n    return errors\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.api_json","title":"notapkgtool.discovery.api_json","text":"<p>JSON API discovery strategy for NAPT.</p> <p>This is a VERSION-FIRST strategy that queries JSON API endpoints to get version and download URL WITHOUT downloading the installer. This enables fast version checks and efficient caching.</p> <p>Key Advantages:</p> <ul> <li>Fast version discovery (API call ~100ms)</li> <li>Can skip downloads entirely when version unchanged</li> <li>Direct API access for version and download URL</li> <li>Support for complex JSON structures with JSONPath</li> <li>Custom headers for authentication</li> <li>Support for GET and POST requests</li> <li>No file parsing required</li> <li>Ideal for CI/CD with scheduled checks</li> </ul> <p>Supported Features:</p> <ul> <li>JSONPath navigation for nested structures</li> <li>Array indexing and filtering</li> <li>Custom HTTP headers (Authorization, etc.)</li> <li>POST requests with JSON body</li> <li>Environment variable expansion in values</li> </ul> <p>Use Cases:</p> <ul> <li>Vendors with JSON APIs (Microsoft, Mozilla, etc.)</li> <li>Cloud services with version endpoints</li> <li>CDNs that provide metadata APIs</li> <li>Applications with update check APIs</li> <li>APIs requiring authentication or custom headers</li> <li>CI/CD pipelines with frequent version checks</li> </ul> Recipe Configuration <pre><code>source:\n    strategy: api_json\n    api_url: \"https://vendor.com/api/latest\"\n    version_path: \"version\"                      # JSONPath to version\n    download_url_path: \"download_url\"            # JSONPath to URL\n    method: \"GET\"                                # Optional: GET or POST\n    headers:                                     # Optional: custom headers\n    Authorization: \"Bearer ${API_TOKEN}\"\n    Accept: \"application/json\"\n    body:                                        # Optional: POST body\n    platform: \"windows\"\n    arch: \"x64\"\n    timeout: 30                                  # Optional: timeout in seconds\n</code></pre> <p>Configuration Fields:</p> <ul> <li>api_url (str, required): API endpoint URL that returns JSON with version     and download information</li> <li>version_path (str, required): JSONPath expression to extract version from     the API response. Examples: \"version\", \"release.version\", \"data.version\"</li> <li>download_url_path (str, required): JSONPath expression to extract     download URL from the API response. Examples: \"download_url\", \"assets.url\",     \"platforms.windows.x64\"</li> <li>method (str, optional): HTTP method to use. Either \"GET\" or \"POST\".     Default is \"GET\"</li> <li>headers (dict, optional): Custom HTTP headers to send with the request.     Useful for authentication or setting Accept headers. Values support     environment variable expansion. Example: {\"Authorization\": \"Bearer ${API_TOKEN}\"}</li> <li>body (dict, optional): Request body for POST requests. Sent as JSON.     Only used when method=\"POST\". Example: {\"platform\": \"windows\", \"arch\": \"x64\"}<ul> <li>timeout (int, optional): Request timeout in seconds. Default is 30.</li> </ul> </li> </ul> <p>JSONPath Syntax:</p> <ul> <li>Simple paths: \"version\", \"release.version\"</li> <li>Array indexing: \"data.version\", \"releases.version\"</li> <li>Nested paths: \"data.latest.download.url\", \"response.assets.browser_download_url\"</li> </ul> <p>Error Handling:</p> <ul> <li>ValueError: Missing or invalid configuration, invalid JSONPath, path not found</li> <li>RuntimeError: API failures, invalid JSON response</li> <li>Errors are chained with 'from err' for better debugging</li> </ul> Example <p>In a recipe YAML (simple API):     <pre><code>apps:\n  - name: \"My App\"\n    id: \"my-app\"\n    source:\n      strategy: api_json\n      api_url: \"https://api.vendor.com/latest\"\n      version_path: \"version\"\n      download_url_path: \"download_url\"\n</code></pre></p> <p>In a recipe YAML (nested structure):     <pre><code>apps:\n  - name: \"My App\"\n    id: \"my-app\"\n    source:\n      strategy: api_json\n      api_url: \"https://api.vendor.com/releases\"\n      version_path: \"stable.version\"\n      download_url_path: \"stable.platforms.windows.x64\"\n      headers:\n        Authorization: \"Bearer ${API_TOKEN}\"\n</code></pre></p> <p>From Python (version-first approach):     <pre><code>from notapkgtool.discovery.api_json import ApiJsonStrategy\nfrom notapkgtool.io import download_file\n\nstrategy = ApiJsonStrategy()\napp_config = {\n    \"source\": {\n        \"api_url\": \"https://api.vendor.com/latest\",\n        \"version_path\": \"version\",\n        \"download_url_path\": \"download_url\",\n    }\n}\n\n# Get version WITHOUT downloading\nversion_info = strategy.get_version_info(app_config)\nprint(f\"Latest version: {version_info.version}\")\n\n# Download only if needed\nif need_to_download:\n    file_path, sha256, headers = download_file(\n        version_info.download_url, Path(\"./downloads\")\n    )\n    print(f\"Downloaded to {file_path}\")\n</code></pre></p> <p>From Python (using core orchestration):     <pre><code>from pathlib import Path\nfrom notapkgtool.core import discover_recipe\n\n# Automatically uses version-first optimization\nresult = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\nprint(f\"Version {result.version} at {result.file_path}\")\n</code></pre></p> Note <ul> <li>Version discovery via API only (no download required)</li> <li>Core orchestration automatically skips download if version unchanged</li> <li>JSONPath uses jsonpath-ng library for robust parsing</li> <li>Environment variable expansion works in headers and other string values</li> <li>POST body is sent as JSON (Content-Type: application/json)</li> <li>Timeout defaults to 30 seconds to prevent hanging on slow APIs</li> </ul>"},{"location":"api/discovery/#notapkgtool.discovery.api_json.ApiJsonStrategy","title":"ApiJsonStrategy","text":"<p>Discovery strategy for JSON API endpoints.</p> Configuration example <p>source:   strategy: api_json   api_url: \"https://api.vendor.com/latest\"   version_path: \"version\"   download_url_path: \"download_url\"   method: \"GET\"   headers:     Authorization: \"Bearer ${API_TOKEN}\"</p> Source code in <code>notapkgtool/discovery/api_json.py</code> <pre><code>class ApiJsonStrategy:\n    \"\"\"Discovery strategy for JSON API endpoints.\n\n    Configuration example:\n        source:\n          strategy: api_json\n          api_url: \"https://api.vendor.com/latest\"\n          version_path: \"version\"\n          download_url_path: \"download_url\"\n          method: \"GET\"\n          headers:\n            Authorization: \"Bearer ${API_TOKEN}\"\n    \"\"\"\n\n    def get_version_info(\n        self,\n        app_config: dict[str, Any],\n        verbose: bool = False,\n        debug: bool = False,\n    ) -&gt; VersionInfo:\n        \"\"\"Query JSON API for version and download URL without downloading\n        (version-first path).\n\n        This method calls a JSON API, extracts version and download URL using\n        JSONPath expressions. If the version matches cached state, the download\n        can be skipped entirely.\n\n        Args:\n            app_config: App configuration containing source.api_url,\n                source.version_path, and source.download_url_path.\n            verbose: If True, print verbose logging messages.\n                Default is False.\n            debug: If True, print debug logging messages.\n                Default is False.\n\n        Returns:\n            Version info with version string, download URL, and\n                source name.\n\n        Raises:\n            ValueError: If required config fields are missing, invalid, or if\n                JSONPath expressions don't match anything in the response.\n            RuntimeError: If API call fails (chained with 'from err').\n\n        Example:\n            Get version info from JSON API:\n                ```python\n                strategy = ApiJsonStrategy()\n                config = {\n                    \"source\": {\n                        \"api_url\": \"https://api.vendor.com/latest\",\n                        \"version_path\": \"version\",\n                        \"download_url_path\": \"download_url\"\n                    }\n                }\n                version_info = strategy.get_version_info(config)\n                # version_info.version returns: '1.0.0'\n                ```\n\n        \"\"\"\n        from notapkgtool.logging import get_global_logger\n\n        logger = get_global_logger()\n        # Validate configuration\n        source = app_config.get(\"source\", {})\n        api_url = source.get(\"api_url\")\n        if not api_url:\n            raise ConfigError(\"api_json strategy requires 'source.api_url' in config\")\n\n        version_path = source.get(\"version_path\")\n        if not version_path:\n            raise ConfigError(\n                \"api_json strategy requires 'source.version_path' in config\"\n            )\n\n        download_url_path = source.get(\"download_url_path\")\n        if not download_url_path:\n            raise ConfigError(\n                \"api_json strategy requires 'source.download_url_path' in config\"\n            )\n\n        # Optional configuration\n        method = source.get(\"method\", \"GET\").upper()\n        if method not in (\"GET\", \"POST\"):\n            raise ConfigError(f\"Invalid method: {method!r}. Must be 'GET' or 'POST'\")\n\n        headers = source.get(\"headers\", {})\n        body = source.get(\"body\", {})\n        timeout = source.get(\"timeout\", 30)\n\n        logger.verbose(\"DISCOVERY\", \"Strategy: api_json (version-first)\")\n        logger.verbose(\"DISCOVERY\", f\"API URL: {api_url}\")\n        logger.verbose(\"DISCOVERY\", f\"Method: {method}\")\n        logger.verbose(\"DISCOVERY\", f\"Version path: {version_path}\")\n        logger.verbose(\"DISCOVERY\", f\"Download URL path: {download_url_path}\")\n\n        # Expand environment variables in headers\n        expanded_headers = {}\n        for key, value in headers.items():\n            if (\n                isinstance(value, str)\n                and value.startswith(\"${\")\n                and value.endswith(\"}\")\n            ):\n                env_var = value[2:-1]\n                env_value = os.environ.get(env_var)\n                if not env_value:\n                    logger.verbose(\n                        \"DISCOVERY\",\n                        f\"Warning: Environment variable {env_var} not set\",\n                    )\n                else:\n                    expanded_headers[key] = env_value\n            else:\n                expanded_headers[key] = value\n\n        # Make API request\n        logger.verbose(\"DISCOVERY\", f\"Calling API: {method} {api_url}\")\n        try:\n            if method == \"GET\":\n                response = requests.get(\n                    api_url, headers=expanded_headers, timeout=timeout\n                )\n            else:  # POST\n                response = requests.post(\n                    api_url,\n                    headers=expanded_headers,\n                    json=body,\n                    timeout=timeout,\n                )\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as err:\n            raise NetworkError(\n                f\"API request failed: {response.status_code} {response.reason}\"\n            ) from err\n        except requests.exceptions.RequestException as err:\n            raise NetworkError(f\"Failed to call API: {err}\") from err\n\n        logger.verbose(\"DISCOVERY\", f\"API response: {response.status_code} OK\")\n\n        # Parse JSON response\n        try:\n            json_data = response.json()\n        except json.JSONDecodeError as err:\n            raise NetworkError(\n                f\"Invalid JSON response from API. Response: {response.text[:200]}\"\n            ) from err\n\n        if debug:\n            logger.verbose(\n                \"DISCOVERY\", f\"JSON response: {json.dumps(json_data, indent=2)}\"\n            )\n\n        # Extract version using JSONPath\n        logger.verbose(\"DISCOVERY\", f\"Extracting version from path: {version_path}\")\n        try:\n            version_expr = jsonpath_parse(version_path)\n            version_matches = version_expr.find(json_data)\n\n            if not version_matches:\n                raise ConfigError(\n                    f\"Version path {version_path!r} did not match anything \"\n                    f\"in API response\"\n                )\n\n            version_str = str(version_matches[0].value)\n        except Exception as err:\n            if isinstance(err, ConfigError):\n                raise\n            raise ConfigError(\n                f\"Failed to extract version using path {version_path!r}: {err}\"\n            ) from err\n\n        logger.verbose(\"DISCOVERY\", f\"Extracted version: {version_str}\")\n\n        # Extract download URL using JSONPath\n        logger.verbose(\n            \"DISCOVERY\", f\"Extracting download URL from path: {download_url_path}\"\n        )\n        try:\n            url_expr = jsonpath_parse(download_url_path)\n            url_matches = url_expr.find(json_data)\n\n            if not url_matches:\n                raise ConfigError(\n                    f\"Download URL path {download_url_path!r} did not match \"\n                    f\"anything in API response\"\n                )\n\n            download_url = str(url_matches[0].value)\n        except Exception as err:\n            if isinstance(err, ConfigError):\n                raise\n            raise ConfigError(\n                f\"Failed to extract download URL using path \"\n                f\"{download_url_path!r}: {err}\"\n            ) from err\n\n        logger.verbose(\"DISCOVERY\", f\"Download URL: {download_url}\")\n\n        return VersionInfo(\n            version=version_str,\n            download_url=download_url,\n            source=\"api_json\",\n        )\n\n    def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n        \"\"\"Validate api_json strategy configuration.\n\n        Checks for required fields and correct types without making network calls.\n\n        Args:\n            app_config: The app configuration from the recipe.\n\n        Returns:\n            List of error messages (empty if valid).\n\n        \"\"\"\n        errors = []\n        source = app_config.get(\"source\", {})\n\n        # Check required fields\n        if \"api_url\" not in source:\n            errors.append(\"Missing required field: source.api_url\")\n        elif not isinstance(source[\"api_url\"], str):\n            errors.append(\"source.api_url must be a string\")\n        elif not source[\"api_url\"].strip():\n            errors.append(\"source.api_url cannot be empty\")\n\n        if \"version_path\" not in source:\n            errors.append(\"Missing required field: source.version_path\")\n        elif not isinstance(source[\"version_path\"], str):\n            errors.append(\"source.version_path must be a string\")\n        elif not source[\"version_path\"].strip():\n            errors.append(\"source.version_path cannot be empty\")\n        else:\n            # Validate JSONPath syntax\n            from jsonpath_ng import parse as jsonpath_parse\n\n            try:\n                jsonpath_parse(source[\"version_path\"])\n            except Exception as err:\n                errors.append(f\"Invalid version_path JSONPath: {err}\")\n\n        if \"download_url_path\" not in source:\n            errors.append(\"Missing required field: source.download_url_path\")\n        elif not isinstance(source[\"download_url_path\"], str):\n            errors.append(\"source.download_url_path must be a string\")\n        elif not source[\"download_url_path\"].strip():\n            errors.append(\"source.download_url_path cannot be empty\")\n        else:\n            # Validate JSONPath syntax\n            from jsonpath_ng import parse as jsonpath_parse\n\n            try:\n                jsonpath_parse(source[\"download_url_path\"])\n            except Exception as err:\n                errors.append(f\"Invalid download_url_path JSONPath: {err}\")\n\n        # Optional fields validation\n        if \"method\" in source:\n            method = source[\"method\"]\n            if not isinstance(method, str):\n                errors.append(\"source.method must be a string\")\n            elif method.upper() not in [\"GET\", \"POST\"]:\n                errors.append(\"source.method must be 'GET' or 'POST'\")\n\n        if \"headers\" in source and not isinstance(source[\"headers\"], dict):\n            errors.append(\"source.headers must be a dictionary\")\n\n        if \"body\" in source and not isinstance(source[\"body\"], dict):\n            errors.append(\"source.body must be a dictionary\")\n\n        return errors\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.api_json.ApiJsonStrategy.get_version_info","title":"get_version_info","text":"<pre><code>get_version_info(app_config: dict[str, Any], verbose: bool = False, debug: bool = False) -&gt; VersionInfo\n</code></pre> <p>Query JSON API for version and download URL without downloading (version-first path).</p> <p>This method calls a JSON API, extracts version and download URL using JSONPath expressions. If the version matches cached state, the download can be skipped entirely.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>App configuration containing source.api_url, source.version_path, and source.download_url_path.</p> required <code>verbose</code> <code>bool</code> <p>If True, print verbose logging messages. Default is False.</p> <code>False</code> <code>debug</code> <code>bool</code> <p>If True, print debug logging messages. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>VersionInfo</code> <p>Version info with version string, download URL, and source name.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If required config fields are missing, invalid, or if JSONPath expressions don't match anything in the response.</p> <code>RuntimeError</code> <p>If API call fails (chained with 'from err').</p> Example <p>Get version info from JSON API:     <pre><code>strategy = ApiJsonStrategy()\nconfig = {\n    \"source\": {\n        \"api_url\": \"https://api.vendor.com/latest\",\n        \"version_path\": \"version\",\n        \"download_url_path\": \"download_url\"\n    }\n}\nversion_info = strategy.get_version_info(config)\n# version_info.version returns: '1.0.0'\n</code></pre></p> Source code in <code>notapkgtool/discovery/api_json.py</code> <pre><code>def get_version_info(\n    self,\n    app_config: dict[str, Any],\n    verbose: bool = False,\n    debug: bool = False,\n) -&gt; VersionInfo:\n    \"\"\"Query JSON API for version and download URL without downloading\n    (version-first path).\n\n    This method calls a JSON API, extracts version and download URL using\n    JSONPath expressions. If the version matches cached state, the download\n    can be skipped entirely.\n\n    Args:\n        app_config: App configuration containing source.api_url,\n            source.version_path, and source.download_url_path.\n        verbose: If True, print verbose logging messages.\n            Default is False.\n        debug: If True, print debug logging messages.\n            Default is False.\n\n    Returns:\n        Version info with version string, download URL, and\n            source name.\n\n    Raises:\n        ValueError: If required config fields are missing, invalid, or if\n            JSONPath expressions don't match anything in the response.\n        RuntimeError: If API call fails (chained with 'from err').\n\n    Example:\n        Get version info from JSON API:\n            ```python\n            strategy = ApiJsonStrategy()\n            config = {\n                \"source\": {\n                    \"api_url\": \"https://api.vendor.com/latest\",\n                    \"version_path\": \"version\",\n                    \"download_url_path\": \"download_url\"\n                }\n            }\n            version_info = strategy.get_version_info(config)\n            # version_info.version returns: '1.0.0'\n            ```\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    # Validate configuration\n    source = app_config.get(\"source\", {})\n    api_url = source.get(\"api_url\")\n    if not api_url:\n        raise ConfigError(\"api_json strategy requires 'source.api_url' in config\")\n\n    version_path = source.get(\"version_path\")\n    if not version_path:\n        raise ConfigError(\n            \"api_json strategy requires 'source.version_path' in config\"\n        )\n\n    download_url_path = source.get(\"download_url_path\")\n    if not download_url_path:\n        raise ConfigError(\n            \"api_json strategy requires 'source.download_url_path' in config\"\n        )\n\n    # Optional configuration\n    method = source.get(\"method\", \"GET\").upper()\n    if method not in (\"GET\", \"POST\"):\n        raise ConfigError(f\"Invalid method: {method!r}. Must be 'GET' or 'POST'\")\n\n    headers = source.get(\"headers\", {})\n    body = source.get(\"body\", {})\n    timeout = source.get(\"timeout\", 30)\n\n    logger.verbose(\"DISCOVERY\", \"Strategy: api_json (version-first)\")\n    logger.verbose(\"DISCOVERY\", f\"API URL: {api_url}\")\n    logger.verbose(\"DISCOVERY\", f\"Method: {method}\")\n    logger.verbose(\"DISCOVERY\", f\"Version path: {version_path}\")\n    logger.verbose(\"DISCOVERY\", f\"Download URL path: {download_url_path}\")\n\n    # Expand environment variables in headers\n    expanded_headers = {}\n    for key, value in headers.items():\n        if (\n            isinstance(value, str)\n            and value.startswith(\"${\")\n            and value.endswith(\"}\")\n        ):\n            env_var = value[2:-1]\n            env_value = os.environ.get(env_var)\n            if not env_value:\n                logger.verbose(\n                    \"DISCOVERY\",\n                    f\"Warning: Environment variable {env_var} not set\",\n                )\n            else:\n                expanded_headers[key] = env_value\n        else:\n            expanded_headers[key] = value\n\n    # Make API request\n    logger.verbose(\"DISCOVERY\", f\"Calling API: {method} {api_url}\")\n    try:\n        if method == \"GET\":\n            response = requests.get(\n                api_url, headers=expanded_headers, timeout=timeout\n            )\n        else:  # POST\n            response = requests.post(\n                api_url,\n                headers=expanded_headers,\n                json=body,\n                timeout=timeout,\n            )\n        response.raise_for_status()\n    except requests.exceptions.HTTPError as err:\n        raise NetworkError(\n            f\"API request failed: {response.status_code} {response.reason}\"\n        ) from err\n    except requests.exceptions.RequestException as err:\n        raise NetworkError(f\"Failed to call API: {err}\") from err\n\n    logger.verbose(\"DISCOVERY\", f\"API response: {response.status_code} OK\")\n\n    # Parse JSON response\n    try:\n        json_data = response.json()\n    except json.JSONDecodeError as err:\n        raise NetworkError(\n            f\"Invalid JSON response from API. Response: {response.text[:200]}\"\n        ) from err\n\n    if debug:\n        logger.verbose(\n            \"DISCOVERY\", f\"JSON response: {json.dumps(json_data, indent=2)}\"\n        )\n\n    # Extract version using JSONPath\n    logger.verbose(\"DISCOVERY\", f\"Extracting version from path: {version_path}\")\n    try:\n        version_expr = jsonpath_parse(version_path)\n        version_matches = version_expr.find(json_data)\n\n        if not version_matches:\n            raise ConfigError(\n                f\"Version path {version_path!r} did not match anything \"\n                f\"in API response\"\n            )\n\n        version_str = str(version_matches[0].value)\n    except Exception as err:\n        if isinstance(err, ConfigError):\n            raise\n        raise ConfigError(\n            f\"Failed to extract version using path {version_path!r}: {err}\"\n        ) from err\n\n    logger.verbose(\"DISCOVERY\", f\"Extracted version: {version_str}\")\n\n    # Extract download URL using JSONPath\n    logger.verbose(\n        \"DISCOVERY\", f\"Extracting download URL from path: {download_url_path}\"\n    )\n    try:\n        url_expr = jsonpath_parse(download_url_path)\n        url_matches = url_expr.find(json_data)\n\n        if not url_matches:\n            raise ConfigError(\n                f\"Download URL path {download_url_path!r} did not match \"\n                f\"anything in API response\"\n            )\n\n        download_url = str(url_matches[0].value)\n    except Exception as err:\n        if isinstance(err, ConfigError):\n            raise\n        raise ConfigError(\n            f\"Failed to extract download URL using path \"\n            f\"{download_url_path!r}: {err}\"\n        ) from err\n\n    logger.verbose(\"DISCOVERY\", f\"Download URL: {download_url}\")\n\n    return VersionInfo(\n        version=version_str,\n        download_url=download_url,\n        source=\"api_json\",\n    )\n</code></pre>"},{"location":"api/discovery/#notapkgtool.discovery.api_json.ApiJsonStrategy.validate_config","title":"validate_config","text":"<pre><code>validate_config(app_config: dict[str, Any]) -&gt; list[str]\n</code></pre> <p>Validate api_json strategy configuration.</p> <p>Checks for required fields and correct types without making network calls.</p> <p>Parameters:</p> Name Type Description Default <code>app_config</code> <code>dict[str, Any]</code> <p>The app configuration from the recipe.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of error messages (empty if valid).</p> Source code in <code>notapkgtool/discovery/api_json.py</code> <pre><code>def validate_config(self, app_config: dict[str, Any]) -&gt; list[str]:\n    \"\"\"Validate api_json strategy configuration.\n\n    Checks for required fields and correct types without making network calls.\n\n    Args:\n        app_config: The app configuration from the recipe.\n\n    Returns:\n        List of error messages (empty if valid).\n\n    \"\"\"\n    errors = []\n    source = app_config.get(\"source\", {})\n\n    # Check required fields\n    if \"api_url\" not in source:\n        errors.append(\"Missing required field: source.api_url\")\n    elif not isinstance(source[\"api_url\"], str):\n        errors.append(\"source.api_url must be a string\")\n    elif not source[\"api_url\"].strip():\n        errors.append(\"source.api_url cannot be empty\")\n\n    if \"version_path\" not in source:\n        errors.append(\"Missing required field: source.version_path\")\n    elif not isinstance(source[\"version_path\"], str):\n        errors.append(\"source.version_path must be a string\")\n    elif not source[\"version_path\"].strip():\n        errors.append(\"source.version_path cannot be empty\")\n    else:\n        # Validate JSONPath syntax\n        from jsonpath_ng import parse as jsonpath_parse\n\n        try:\n            jsonpath_parse(source[\"version_path\"])\n        except Exception as err:\n            errors.append(f\"Invalid version_path JSONPath: {err}\")\n\n    if \"download_url_path\" not in source:\n        errors.append(\"Missing required field: source.download_url_path\")\n    elif not isinstance(source[\"download_url_path\"], str):\n        errors.append(\"source.download_url_path must be a string\")\n    elif not source[\"download_url_path\"].strip():\n        errors.append(\"source.download_url_path cannot be empty\")\n    else:\n        # Validate JSONPath syntax\n        from jsonpath_ng import parse as jsonpath_parse\n\n        try:\n            jsonpath_parse(source[\"download_url_path\"])\n        except Exception as err:\n            errors.append(f\"Invalid download_url_path JSONPath: {err}\")\n\n    # Optional fields validation\n    if \"method\" in source:\n        method = source[\"method\"]\n        if not isinstance(method, str):\n            errors.append(\"source.method must be a string\")\n        elif method.upper() not in [\"GET\", \"POST\"]:\n            errors.append(\"source.method must be 'GET' or 'POST'\")\n\n    if \"headers\" in source and not isinstance(source[\"headers\"], dict):\n        errors.append(\"source.headers must be a dictionary\")\n\n    if \"body\" in source and not isinstance(source[\"body\"], dict):\n        errors.append(\"source.body must be a dictionary\")\n\n    return errors\n</code></pre>"},{"location":"api/exceptions/","title":"exceptions","text":""},{"location":"api/exceptions/#notapkgtool.exceptions","title":"notapkgtool.exceptions","text":"<p>Exception hierarchy for NAPT.</p> <p>This module defines a custom exception hierarchy that allows library users to distinguish between different types of errors. All exceptions inherit from NAPTError, allowing users to catch all NAPT errors with a single except clause if needed.</p> Example <p>Catching specific error types:     <pre><code>from notapkgtool.core import discover_recipe\nfrom notapkgtool.exceptions import ConfigError, NetworkError\n\ntry:\n    result = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\nexcept ConfigError as e:\n    print(f\"Configuration error: {e}\")\nexcept NetworkError as e:\n    print(f\"Network error: {e}\")\n</code></pre></p> <p>Catching all NAPT errors:     <pre><code>from notapkgtool.exceptions import NAPTError\n\ntry:\n    result = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\nexcept NAPTError as e:\n    print(f\"NAPT error: {e}\")\n</code></pre></p>"},{"location":"api/exceptions/#notapkgtool.exceptions.NAPTError","title":"NAPTError","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for all NAPT errors.</p> <p>All NAPT-specific exceptions inherit from this class, allowing users to catch all NAPT errors with a single except clause if needed.</p> Source code in <code>notapkgtool/exceptions.py</code> <pre><code>class NAPTError(Exception):\n    \"\"\"Base exception for all NAPT errors.\n\n    All NAPT-specific exceptions inherit from this class, allowing users\n    to catch all NAPT errors with a single except clause if needed.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/exceptions/#notapkgtool.exceptions.ConfigError","title":"ConfigError","text":"<p>               Bases: <code>NAPTError</code></p> <p>Raised for configuration-related errors.</p> <p>This exception is raised when there are problems with:</p> <ul> <li>YAML parse errors (syntax errors, invalid structure)</li> <li>Missing required configuration fields (e.g., no apps defined, missing     'source.strategy' field)</li> <li>Invalid strategy configuration (unknown strategy name, invalid strategy     parameters)</li> <li>Missing recipe files (file not found)</li> <li>Recipe validation failures (invalid recipe structure, missing required     app fields)</li> </ul> Example <p>Catching configuration errors:     <pre><code>from notapkgtool.exceptions import ConfigError\n\ntry:\n    config = load_effective_config(Path(\"invalid.yaml\"))\nexcept ConfigError as e:\n    print(f\"Config error: {e}\")\n</code></pre></p> Source code in <code>notapkgtool/exceptions.py</code> <pre><code>class ConfigError(NAPTError):\n    \"\"\"Raised for configuration-related errors.\n\n    This exception is raised when there are problems with:\n\n    - YAML parse errors (syntax errors, invalid structure)\n    - Missing required configuration fields (e.g., no apps defined, missing\n        'source.strategy' field)\n    - Invalid strategy configuration (unknown strategy name, invalid strategy\n        parameters)\n    - Missing recipe files (file not found)\n    - Recipe validation failures (invalid recipe structure, missing required\n        app fields)\n\n    Example:\n        Catching configuration errors:\n            ```python\n            from notapkgtool.exceptions import ConfigError\n\n            try:\n                config = load_effective_config(Path(\"invalid.yaml\"))\n            except ConfigError as e:\n                print(f\"Config error: {e}\")\n            ```\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/exceptions/#notapkgtool.exceptions.NetworkError","title":"NetworkError","text":"<p>               Bases: <code>NAPTError</code></p> <p>Raised for network/download-related errors.</p> <p>This exception is raised when there are problems with:</p> <ul> <li>Download failures (HTTP errors, connection timeouts, network     unreachable)</li> <li>API call failures (GitHub API errors, JSON API endpoint failures,     authentication issues)</li> <li>Network-related version extraction errors (API response parsing     failures)</li> </ul> Example <p>Catching network errors:     <pre><code>from notapkgtool.exceptions import NetworkError\n\ntry:\n    result = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\nexcept NetworkError as e:\n    print(f\"Network error: {e}\")\n</code></pre></p> Source code in <code>notapkgtool/exceptions.py</code> <pre><code>class NetworkError(NAPTError):\n    \"\"\"Raised for network/download-related errors.\n\n    This exception is raised when there are problems with:\n\n    - Download failures (HTTP errors, connection timeouts, network\n        unreachable)\n    - API call failures (GitHub API errors, JSON API endpoint failures,\n        authentication issues)\n    - Network-related version extraction errors (API response parsing\n        failures)\n\n    Example:\n        Catching network errors:\n            ```python\n            from notapkgtool.exceptions import NetworkError\n\n            try:\n                result = discover_recipe(Path(\"recipe.yaml\"), Path(\"./downloads\"))\n            except NetworkError as e:\n                print(f\"Network error: {e}\")\n            ```\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/exceptions/#notapkgtool.exceptions.PackagingError","title":"PackagingError","text":"<p>               Bases: <code>NAPTError</code></p> <p>Raised for packaging/build-related errors.</p> <p>This exception is raised when there are problems with:</p> <ul> <li>Build failures (PSADT template processing errors, file operations,     directory creation failures)</li> <li>Missing build tools (IntuneWinAppUtil.exe not found, PSADT template     missing)</li> <li>MSI extraction errors (failed to read MSI ProductVersion, unsupported     MSI format)</li> <li>Packaging operations (IntuneWinAppUtil.exe execution failures, invalid     build directory structure)</li> </ul> Example <p>Catching packaging errors:     <pre><code>from notapkgtool.exceptions import PackagingError\n\ntry:\n    build_package(Path(\"recipe.yaml\"), Path(\"./builds\"))\nexcept PackagingError as e:\n    print(f\"Packaging error: {e}\")\n</code></pre></p> Source code in <code>notapkgtool/exceptions.py</code> <pre><code>class PackagingError(NAPTError):\n    \"\"\"Raised for packaging/build-related errors.\n\n    This exception is raised when there are problems with:\n\n    - Build failures (PSADT template processing errors, file operations,\n        directory creation failures)\n    - Missing build tools (IntuneWinAppUtil.exe not found, PSADT template\n        missing)\n    - MSI extraction errors (failed to read MSI ProductVersion, unsupported\n        MSI format)\n    - Packaging operations (IntuneWinAppUtil.exe execution failures, invalid\n        build directory structure)\n\n    Example:\n        Catching packaging errors:\n            ```python\n            from notapkgtool.exceptions import PackagingError\n\n            try:\n                build_package(Path(\"recipe.yaml\"), Path(\"./builds\"))\n            except PackagingError as e:\n                print(f\"Packaging error: {e}\")\n            ```\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/io/","title":"io","text":""},{"location":"api/io/#notapkgtool.io.download","title":"notapkgtool.io.download","text":"<p>Robust HTTP(S) file download for NAPT.</p> <p>This module provides production-grade file downloading with features designed for reliability, reproducibility, and efficiency in automated packaging workflows.</p> <p>Key Features:</p> <ul> <li>Retry Logic with Exponential Backoff - Automatically retries on     transient failures (429, 500, 502, 503, 504) with exponential backoff.     Configurable via urllib3.util.Retry.</li> <li>Conditional Requests (HTTP 304 Not Modified) - Supports ETag and     Last-Modified headers to avoid re-downloading unchanged files.</li> <li>Atomic Writes - Downloads to temporary .part files with atomic rename     on success to prevent partial files.</li> <li>Integrity Verification - SHA-256 hashing during download with     optional checksum validation. Corrupted files are automatically removed.</li> <li>Smart Filename Detection - Respects Content-Disposition headers,     falls back to URL path, handles edge cases.</li> <li>Stable ETags - Forces Accept-Encoding: identity to avoid     representation-specific ETags and prevent false cache misses.</li> </ul> <p>Exception Classes:</p> <ul> <li>NotModifiedError: Raised when conditional request returns HTTP 304     (not an error condition).</li> </ul> <p>Constants:</p> <ul> <li>DEFAULT_CHUNK (int): Stream chunk size (1 MiB). Balance memory vs.     progress granularity.</li> </ul> Example <p>Basic download:     <pre><code>from pathlib import Path\nfrom notapkgtool.io import download_file\n\npath, sha256, headers = download_file(\n    url=\"https://example.com/installer.msi\",\n    destination_folder=Path(\"./downloads\"),\n)\nprint(f\"Downloaded to {path}\")\nprint(f\"SHA-256: {sha256}\")\n</code></pre></p> <p>Conditional download (avoid re-downloading):     <pre><code>from notapkgtool.io import NotModifiedError\n\ntry:\n    path, sha256, headers = download_file(\n        url=\"https://example.com/installer.msi\",\n        destination_folder=Path(\"./downloads\"),\n        etag=previous_etag,\n    )\nexcept NotModifiedError:\n    print(\"File unchanged, using cached version\")\n</code></pre></p> <p>Checksum validation:     <pre><code>try:\n    path, sha256, headers = download_file(\n        url=\"https://example.com/installer.msi\",\n        destination_folder=Path(\"./downloads\"),\n        expected_sha256=\"abc123...\",\n    )\nexcept NetworkError as e:\n    print(f\"Checksum mismatch: {e}\")\n</code></pre></p> <p>Design Decisions:</p> <ul> <li>Why identity encoding? CDNs like Cloudflare compute     representation-specific ETags. Requesting gzip vs identity yields     different ETags for the same content, causing unnecessary re-downloads.     We pin to identity for stability.</li> <li>Why atomic writes? Prevents partial files from appearing in the     destination. Critical for automation where another process might start     using a file before download completes.</li> <li>Why stream hashing? Computing SHA-256 while streaming avoids a second     file read, improving I/O efficiency especially for large installers.</li> </ul> Note <ul> <li>Progress output goes to stdout (can be captured/redirected)</li> <li>User-Agent identifies NAPT to help with debugging/support</li> <li>All HTTP errors are chained for better debugging</li> <li>Timeouts are per-request, not total download time</li> </ul>"},{"location":"api/io/#notapkgtool.io.download.NotModifiedError","title":"NotModifiedError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a conditional request (If-None-Match / If-Modified-Since) returns HTTP 304 Not Modified. Caller can treat this as \"no work to do\".</p> Source code in <code>notapkgtool/io/download.py</code> <pre><code>class NotModifiedError(Exception):\n    \"\"\"Raised when a conditional request (If-None-Match / If-Modified-Since)\n    returns HTTP 304 Not Modified. Caller can treat this as \"no work to do\".\n    \"\"\"\n</code></pre>"},{"location":"api/io/#notapkgtool.io.download.make_session","title":"make_session","text":"<pre><code>make_session() -&gt; requests.Session\n</code></pre> <p>Create a requests.Session with sane retry/backoff defaults.</p> <ul> <li>Retries on common transient status codes.</li> <li>Applies exponential backoff.</li> <li>Sets a helpful User-Agent to avoid being blocked.</li> </ul> <p>Notes on Accept-Encoding:</p> <ul> <li>We force 'Accept-Encoding: identity' to request the raw (uncompressed) bytes.</li> <li>Many CDNs compute representation-specific ETags (e.g., gzip vs identity).   That can cause conditional requests (If-None-Match) to miss and trigger   unnecessary re-downloads. Pinning identity stabilizes ETags for binary   installers (MSI/EXE/MSIX/ZIP), which are already compressed.</li> </ul> Source code in <code>notapkgtool/io/download.py</code> <pre><code>def make_session() -&gt; requests.Session:\n    \"\"\"Create a requests.Session with sane retry/backoff defaults.\n\n    - Retries on common transient status codes.\n    - Applies exponential backoff.\n    - Sets a helpful User-Agent to avoid being blocked.\n\n    Notes on Accept-Encoding:\n\n    - We force 'Accept-Encoding: identity' to request the raw (uncompressed) bytes.\n    - Many CDNs compute representation-specific ETags (e.g., gzip vs identity).\n      That can cause conditional requests (If-None-Match) to miss and trigger\n      unnecessary re-downloads. Pinning identity stabilizes ETags for binary\n      installers (MSI/EXE/MSIX/ZIP), which are already compressed.\n    \"\"\"\n    s = requests.Session()\n    retries = Retry(\n        total=5,\n        backoff_factor=0.5,\n        status_forcelist=(429, 500, 502, 503, 504),\n        allowed_methods=(\"GET\", \"HEAD\"),\n        raise_on_status=False,\n    )\n    s.headers.update(\n        {\n            \"User-Agent\": \"napt/0.1 (+https://github.com/RogerCibrian/notapkgtool)\",\n            # Request the raw, uncompressed representation to keep ETags stable\n            # across runs and avoid spurious 200s when a CDN flips to gzip.\n            \"Accept-Encoding\": \"identity\",\n        }\n    )\n    s.mount(\"http://\", HTTPAdapter(max_retries=retries))\n    s.mount(\"https://\", HTTPAdapter(max_retries=retries))\n    return s\n</code></pre>"},{"location":"api/io/#notapkgtool.io.download.download_file","title":"download_file","text":"<pre><code>download_file(url: str, destination_folder: Path, *, expected_sha256: str | None = None, validate_content_type: bool = False, timeout: int = 60, etag: str | None = None, last_modified: str | None = None, verbose: bool = False, debug: bool = False) -&gt; tuple[Path, str, dict]\n</code></pre> <p>Download a URL to destination_folder with robustness and reproducibility.</p> <p>Follows redirects and retries transient failures. Writes to .part then renames to  on success (atomic). Sends conditional headers if etag/last_modified provided. Validates checksum if expected_sha256 is set. <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Source URL.</p> required <code>destination_folder</code> <code>Path</code> <p>Folder to save into (created if missing).</p> required <code>expected_sha256</code> <code>str | None</code> <p>Optional known SHA-256 (hex). If set and mismatched, raises ValueError.</p> <code>None</code> <code>validate_content_type</code> <code>bool</code> <p>If True, rejects responses with text/html content-type.</p> <code>False</code> <code>timeout</code> <code>int</code> <p>Per-request timeout (seconds).</p> <code>60</code> <code>etag</code> <code>str | None</code> <p>Previous ETag to use for If-None-Match (conditional GET).</p> <code>None</code> <code>last_modified</code> <code>str | None</code> <p>Previous Last-Modified to use for If-Modified-Since (conditional GET).</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Print verbose progress.</p> <code>False</code> <code>debug</code> <code>bool</code> <p>Print debug information.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[Path, str, dict]</code> <p>A tuple (file_path, sha256_hex, headers_dict), where file_path is the Path to the downloaded file, sha256_hex is the SHA-256 hash of the file, and headers_dict contains HTTP response headers.</p> <p>Raises:</p> Type Description <code>NotModifiedError</code> <p>On HTTP 304 (conditional request satisfied).</p> <code>NetworkError</code> <p>For non-2xx responses (after retries) or checksum mismatch.</p> <code>ConfigError</code> <p>For content-type mismatch.</p> Source code in <code>notapkgtool/io/download.py</code> <pre><code>def download_file(\n    url: str,\n    destination_folder: Path,\n    *,\n    expected_sha256: str | None = None,\n    validate_content_type: bool = False,\n    timeout: int = 60,\n    etag: str | None = None,\n    last_modified: str | None = None,\n    verbose: bool = False,\n    debug: bool = False,\n) -&gt; tuple[Path, str, dict]:\n    \"\"\"Download a URL to destination_folder with robustness and reproducibility.\n\n    Follows redirects and retries transient failures. Writes to &lt;filename&gt;.part\n    then renames to &lt;filename&gt; on success (atomic). Sends conditional headers\n    if etag/last_modified provided. Validates checksum if expected_sha256 is set.\n\n    Args:\n        url: Source URL.\n        destination_folder: Folder to save into (created if missing).\n        expected_sha256: Optional known SHA-256 (hex). If set and mismatched,\n            raises ValueError.\n        validate_content_type: If True, rejects responses with text/html content-type.\n        timeout: Per-request timeout (seconds).\n        etag: Previous ETag to use for If-None-Match (conditional GET).\n        last_modified: Previous Last-Modified to use for If-Modified-Since\n            (conditional GET).\n        verbose: Print verbose progress.\n        debug: Print debug information.\n\n    Returns:\n        A tuple (file_path, sha256_hex, headers_dict), where file_path is\n            the Path to the downloaded file, sha256_hex is the SHA-256 hash\n            of the file, and headers_dict contains HTTP response headers.\n\n    Raises:\n        NotModifiedError: On HTTP 304 (conditional request satisfied).\n        NetworkError: For non-2xx responses (after retries) or checksum mismatch.\n        ConfigError: For content-type mismatch.\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    destination_folder = Path(destination_folder)\n    destination_folder.mkdir(parents=True, exist_ok=True)\n\n    headers: dict[str, str] = {}\n    if etag:\n        headers[\"If-None-Match\"] = etag\n        logger.verbose(\"HTTP\", f\"Using conditional request with ETag: {etag}\")\n    elif last_modified:\n        headers[\"If-Modified-Since\"] = last_modified\n        logger.verbose(\n            \"HTTP\", f\"Using conditional request with Last-Modified: {last_modified}\"\n        )\n\n    logger.verbose(\"HTTP\", f\"GET {url}\")\n    if verbose:\n        logger.verbose(\n            \"HTTP\",\n            \"Request headers: Accept-Encoding: identity, User-Agent: napt/0.1.0\",\n        )\n\n    with make_session() as session:\n        # Stream response so we can hash while writing.\n        resp = session.get(\n            url, stream=True, allow_redirects=True, timeout=timeout, headers=headers\n        )\n\n        # Log redirects\n        if verbose and len(resp.history) &gt; 0:\n            for hist in resp.history:\n                logger.verbose(\n                    \"HTTP\",\n                    (\n                        f\"Redirect {hist.status_code} -&gt; \"\n                        f\"{hist.headers.get('Location', 'unknown')}\"\n                    ),\n                )\n\n        # Conditional request satisfied: nothing changed since last time.\n        if resp.status_code == 304:\n            logger.verbose(\"HTTP\", \"Response: 304 Not Modified\")\n            resp.close()\n            raise NotModifiedError(\"Remote content not modified (HTTP 304).\")\n\n        # Raise for other HTTP errors after retries.\n        try:\n            resp.raise_for_status()\n        except requests.HTTPError as err:\n            # Chain for better context.\n            raise NetworkError(f\"download failed for {url}: {err}\") from err\n\n        logger.verbose(\"HTTP\", f\"Response: {resp.status_code} {resp.reason}\")\n\n        # Content-Disposition beats URL when naming the file.\n        cd_name = _filename_from_cd(resp.headers.get(\"Content-Disposition\", \"\"))\n        filename = cd_name or _filename_from_url(resp.url)\n        target = destination_folder / filename\n\n        # Log response details\n        if verbose:\n            content_length = resp.headers.get(\"Content-Length\", \"unknown\")\n            if content_length != \"unknown\":\n                size_mb = int(content_length) / (1024 * 1024)\n                logger.verbose(\n                    \"HTTP\", f\"Content-Length: {content_length} ({size_mb:.1f} MB)\"\n                )\n            etag_value = resp.headers.get(\"ETag\", \"not provided\")\n            logger.verbose(\"HTTP\", f\"ETag: {etag_value}\")\n            cd_header = resp.headers.get(\"Content-Disposition\", \"not provided\")\n            logger.verbose(\"HTTP\", f\"Content-Disposition: {cd_header}\")\n\n        # Optional content-type sanity check.\n        if validate_content_type:\n            ctype = resp.headers.get(\"Content-Type\", \"\")\n            if \"text/html\" in ctype.lower():\n                resp.close()\n                raise ConfigError(f\"expected binary, got content-type={ctype}\")\n\n        total_size = int(resp.headers.get(\"Content-Length\", \"0\") or 0)\n\n        tmp = target.with_suffix(target.suffix + \".part\")\n        logger.verbose(\"FILE\", f\"Downloading to: {tmp}\")\n\n        sha = hashlib.sha256()\n        downloaded = 0\n        last_percent = -1\n        started_at = time.time()\n\n        with tmp.open(\"wb\") as f:\n            for chunk in resp.iter_content(chunk_size=DEFAULT_CHUNK):\n                if not chunk:\n                    continue\n                f.write(chunk)\n                sha.update(chunk)\n                downloaded += len(chunk)\n\n                # Optional lightweight progress indicator.\n                if total_size:\n                    pct = int(downloaded * 100 / total_size)\n                    if pct != last_percent:\n                        print(f\"download progress: {pct}%\", end=\"\\r\")\n                        last_percent = pct\n\n        # Cleanup response socket.\n        resp.close()\n\n        digest = sha.hexdigest()\n        logger.verbose(\"FILE\", f\"SHA-256: {digest} (computed during download)\")\n\n        # Atomically \"commit\" the file.\n        logger.verbose(\"FILE\", f\"Atomic rename: {tmp.name} -&gt; {target.name}\")\n        tmp.replace(target)\n\n        # Validate checksum if the caller expects a specific digest.\n        if expected_sha256 and digest.lower() != expected_sha256.lower():\n            logger.verbose(\n                \"FILE\", f\"Checksum mismatch! Expected: {expected_sha256}, Got: {digest}\"\n            )\n            try:\n                target.unlink()\n            except OSError:\n                pass\n            raise NetworkError(\n                f\"sha256 mismatch for {filename}: got {digest}, \"\n                f\"expected {expected_sha256}\"\n            )\n\n        elapsed = time.time() - started_at\n        if not verbose:\n            # For non-verbose mode, just show simple completion message\n            print(f\"\\ndownload complete: {target} ({digest}) in {elapsed:.1f}s\")\n        else:\n            # For verbose mode, show detailed file info\n            logger.verbose(\"FILE\", f\"Download complete: {target}\")\n            logger.verbose(\"FILE\", f\"Time elapsed: {elapsed:.1f}s\")\n\n        # Hand back headers the caller may want to persist (ETag, Last-Modified).\n        return target, digest, dict(resp.headers)\n</code></pre>"},{"location":"api/io/#notapkgtool.io.upload","title":"notapkgtool.io.upload","text":""},{"location":"api/policy/","title":"policy","text":""},{"location":"api/policy/#notapkgtool.policy.updates","title":"notapkgtool.policy.updates","text":"<p>Update decision policy for NAPT.</p> <p>Determines whether a newly discovered remote artifact should be staged, based on version, hash, and org policy.</p> Example <p>Check if a new version should be staged:</p> <pre><code>from notapkgtool.policy.updates import should_stage, UpdatePolicy\n\ndecision = should_stage(\n    remote_version=\"124.0.6367.91\",\n    remote_hash=\"abc...\",\n    current_version=\"124.0.6367.70\",\n    current_hash=\"def...\",\n    policy=UpdatePolicy(\n        strategy=\"version_then_hash\",\n        allow_same_version_hash_change=True,\n        comparator=\"semver\"\n    ),\n)\n</code></pre>"},{"location":"api/policy/#notapkgtool.policy.updates.should_stage","title":"should_stage","text":"<pre><code>should_stage(*, remote_version: str, remote_hash: str, current_version: str | None, current_hash: str | None, policy: UpdatePolicy) -&gt; bool\n</code></pre> <p>Decide whether to stage a newly discovered artifact.</p> <p>Compares remote version/hash against current state using the configured policy strategy to determine if the new artifact should be staged.</p> <p>Parameters:</p> Name Type Description Default <code>remote_version</code> <code>str</code> <p>Version found during discovery.</p> required <code>remote_hash</code> <code>str</code> <p>SHA-256 hash of the newly downloaded artifact.</p> required <code>current_version</code> <code>str | None</code> <p>Version we last staged/deployed (None if none).</p> required <code>current_hash</code> <code>str | None</code> <p>Hash we last staged/deployed (None if none).</p> required <code>policy</code> <code>UpdatePolicy</code> <p>UpdatePolicy controlling the decision algorithm.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the new artifact should be staged, False otherwise.</p> Source code in <code>notapkgtool/policy/updates.py</code> <pre><code>def should_stage(\n    *,\n    remote_version: str,\n    remote_hash: str,\n    current_version: str | None,\n    current_hash: str | None,\n    policy: UpdatePolicy,\n) -&gt; bool:\n    \"\"\"Decide whether to stage a newly discovered artifact.\n\n    Compares remote version/hash against current state using the configured\n    policy strategy to determine if the new artifact should be staged.\n\n    Args:\n        remote_version: Version found during discovery.\n        remote_hash: SHA-256 hash of the newly downloaded artifact.\n        current_version: Version we last staged/deployed (None if none).\n        current_hash: Hash we last staged/deployed (None if none).\n        policy: UpdatePolicy controlling the decision algorithm.\n\n    Returns:\n        True if the new artifact should be staged, False otherwise.\n\n    \"\"\"\n    # If we have no prior state, stage the first artifact.\n    if current_version is None and current_hash is None:\n        return True\n\n    # Normalized comparisons\n    version_changed = (\n        True\n        if current_version is None\n        else is_newer_any(remote_version, current_version, policy.comparator)\n        or remote_version != current_version\n        # Treat \"different version string\" as change even if comparator\n        # treats them equal\n    )\n\n    hash_changed = (current_hash or \"\").lower() != (remote_hash or \"\").lower()\n\n    if policy.strategy == \"version_only\":\n        return version_changed\n\n    if policy.strategy == \"version_then_hash\":\n        if version_changed:\n            return True\n        if not version_changed and policy.allow_same_version_hash_change:\n            # Same version string but bits changed (repack, resign, silent fix)\n            return hash_changed\n        return False\n\n    if policy.strategy == \"hash_or_version\":\n        return version_changed or hash_changed\n\n    if policy.strategy == \"hash_only\":\n        return hash_changed\n\n    # Safe default: do not stage on unknown strategy\n    return False\n</code></pre>"},{"location":"api/psadt/","title":"psadt","text":""},{"location":"api/psadt/#notapkgtool.psadt.release","title":"notapkgtool.psadt.release","text":"<p>PSADT release management for NAPT.</p> <p>This module handles fetching, downloading, and caching PSAppDeployToolkit releases from the official GitHub repository. It reuses NAPT's existing GitHub release discovery infrastructure for consistency.</p> <p>Key Features:</p> <ul> <li>Fetch latest PSADT version from GitHub API</li> <li>Download and cache specific PSADT versions</li> <li>Extract releases to cache directory</li> <li>Version resolution (\"latest\" keyword support)</li> </ul> Example <p>Get and cache PSADT releases:     <pre><code>from pathlib import Path\nfrom notapkgtool.psadt import get_psadt_release, is_psadt_cached\n\n# Get latest PSADT\npsadt_dir = get_psadt_release(\"latest\", Path(\"cache/psadt\"))\n\n# Get specific version\npsadt_dir = get_psadt_release(\"4.1.7\", Path(\"cache/psadt\"))\n\n# Check if cached\nif is_psadt_cached(\"4.1.7\", Path(\"cache/psadt\")):\n    print(\"Already cached!\")\n</code></pre></p> Note <ul> <li>Reuses notapkgtool.discovery.api_github for API calls</li> <li>Caches releases by version: cache/psadt/{version}/</li> <li>Downloads .zip releases and extracts to cache</li> <li>Validates extracted PSADT structure (PSAppDeployToolkit/ folder exists)</li> </ul>"},{"location":"api/psadt/#notapkgtool.psadt.release.fetch_latest_psadt_version","title":"fetch_latest_psadt_version","text":"<pre><code>fetch_latest_psadt_version(verbose: bool = False) -&gt; str\n</code></pre> <p>Fetch the latest PSADT release version from GitHub.</p> <p>Queries the GitHub API for the latest release and extracts the version number from the tag name (e.g., \"4.1.7\" from tag \"4.1.7\").</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>If True, print verbose output about the API request. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>Version number (e.g., \"4.1.7\").</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the GitHub API request fails or version cannot be extracted.</p> Example <p>Get latest PSADT version from GitHub:     <pre><code>version = fetch_latest_psadt_version()\nprint(version)  # Output: \"4.1.7\"\n</code></pre></p> Note <ul> <li>Uses GitHub's public API (60 requests/hour limit without auth)</li> <li>Version is extracted from release tag name</li> <li>For higher rate limits, set GITHUB_TOKEN environment variable</li> </ul> Source code in <code>notapkgtool/psadt/release.py</code> <pre><code>def fetch_latest_psadt_version(verbose: bool = False) -&gt; str:\n    \"\"\"Fetch the latest PSADT release version from GitHub.\n\n    Queries the GitHub API for the latest release and extracts the version\n    number from the tag name (e.g., \"4.1.7\" from tag \"4.1.7\").\n\n    Args:\n        verbose: If True, print verbose output about the API request.\n            Defaults to False.\n\n    Returns:\n        Version number (e.g., \"4.1.7\").\n\n    Raises:\n        RuntimeError: If the GitHub API request fails or version cannot be\n            extracted.\n\n    Example:\n        Get latest PSADT version from GitHub:\n            ```python\n            version = fetch_latest_psadt_version()\n            print(version)  # Output: \"4.1.7\"\n            ```\n\n    Note:\n        - Uses GitHub's public API (60 requests/hour limit without auth)\n        - Version is extracted from release tag name\n        - For higher rate limits, set GITHUB_TOKEN environment variable\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    logger.verbose(\"PSADT\", f\"Querying GitHub API: {PSADT_GITHUB_API}\")\n\n    try:\n        headers = {\n            \"Accept\": \"application/vnd.github+json\",\n            \"X-GitHub-Api-Version\": \"2022-11-28\",\n        }\n\n        response = requests.get(PSADT_GITHUB_API, headers=headers, timeout=30)\n        response.raise_for_status()\n    except requests.RequestException as err:\n        raise NetworkError(\n            f\"Failed to fetch latest PSADT release from GitHub: {err}\"\n        ) from err\n\n    data = response.json()\n    tag_name = data.get(\"tag_name\", \"\")\n\n    if not tag_name:\n        raise NetworkError(\"GitHub API response missing 'tag_name' field\")\n\n    # Extract version from tag (e.g., \"4.1.7\" or \"v4.1.7\")\n    # PSADT uses tags without 'v' prefix\n    version_match = re.match(r\"v?(\\d+\\.\\d+\\.\\d+)\", tag_name)\n    if not version_match:\n        raise NetworkError(f\"Could not extract version from tag: {tag_name!r}\")\n\n    version = version_match.group(1)\n    logger.verbose(\"PSADT\", f\"Latest PSADT version: {version}\")\n\n    return version\n</code></pre>"},{"location":"api/psadt/#notapkgtool.psadt.release.is_psadt_cached","title":"is_psadt_cached","text":"<pre><code>is_psadt_cached(version: str, cache_dir: Path) -&gt; bool\n</code></pre> <p>Check if a PSADT version is already cached.</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>str</code> <p>PSADT version to check (e.g., \"4.1.7\").</p> required <code>cache_dir</code> <code>Path</code> <p>Base cache directory (e.g., Path(\"cache/psadt\")).</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the version is cached and valid, False otherwise.</p> Example <p>Check if PSADT version is cached:     <pre><code>from pathlib import Path\n\nif is_psadt_cached(\"4.1.7\", Path(\"cache/psadt\")):\n    print(\"Already downloaded!\")\n</code></pre></p> Note <p>Validates that the cache contains the expected PSADT structure:</p> <ul> <li>PSAppDeployToolkit/ folder must exist</li> <li>PSAppDeployToolkit.psd1 manifest must exist</li> </ul> Source code in <code>notapkgtool/psadt/release.py</code> <pre><code>def is_psadt_cached(version: str, cache_dir: Path) -&gt; bool:\n    \"\"\"Check if a PSADT version is already cached.\n\n    Args:\n        version: PSADT version to check (e.g., \"4.1.7\").\n        cache_dir: Base cache directory (e.g., Path(\"cache/psadt\")).\n\n    Returns:\n        True if the version is cached and valid, False otherwise.\n\n    Example:\n        Check if PSADT version is cached:\n            ```python\n            from pathlib import Path\n\n            if is_psadt_cached(\"4.1.7\", Path(\"cache/psadt\")):\n                print(\"Already downloaded!\")\n            ```\n\n    Note:\n        Validates that the cache contains the expected PSADT structure:\n\n        - PSAppDeployToolkit/ folder must exist\n        - PSAppDeployToolkit.psd1 manifest must exist\n\n    \"\"\"\n    version_dir = cache_dir / version\n    psadt_dir = version_dir / \"PSAppDeployToolkit\"\n    manifest = psadt_dir / \"PSAppDeployToolkit.psd1\"\n\n    return psadt_dir.exists() and manifest.exists()\n</code></pre>"},{"location":"api/psadt/#notapkgtool.psadt.release.get_psadt_release","title":"get_psadt_release","text":"<pre><code>get_psadt_release(release_spec: str, cache_dir: Path, verbose: bool = False, debug: bool = False) -&gt; Path\n</code></pre> <p>Download and extract a PSADT release to the cache directory.</p> <p>Resolves \"latest\" to the current latest version from GitHub, then downloads the release .zip file and extracts it to the cache.</p> <p>Parameters:</p> Name Type Description Default <code>release_spec</code> <code>str</code> <p>Version specifier - either \"latest\" or specific version (e.g., \"4.1.7\").</p> required <code>cache_dir</code> <code>Path</code> <p>Base cache directory for PSADT releases.</p> required <code>verbose</code> <code>bool</code> <p>Show verbose progress output. Defaults to False.</p> <code>False</code> <code>debug</code> <code>bool</code> <p>Show debug output. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the cached PSADT directory (cache_dir/{version}).</p> <p>Raises:</p> Type Description <code>NetworkError</code> <p>If download fails.</p> <code>PackagingError</code> <p>If extraction fails.</p> <code>ConfigError</code> <p>If release_spec is invalid.</p> Example <p>Get latest version:     <pre><code>from pathlib import Path\n\npsadt = get_psadt_release(\"latest\", Path(\"cache/psadt\"))\nprint(psadt)  # Output: cache/psadt/4.1.7\n</code></pre></p> <p>Get specific version:     <pre><code>psadt = get_psadt_release(\"4.1.7\", Path(\"cache/psadt\"))\n</code></pre></p> Note <ul> <li>Caches by version: cache/psadt/{version}/PSAppDeployToolkit/</li> <li>If already cached, returns path immediately (no re-download)</li> <li>Downloads from GitHub releases as .zip files</li> <li>Extracts entire archive to version directory</li> </ul> Source code in <code>notapkgtool/psadt/release.py</code> <pre><code>def get_psadt_release(\n    release_spec: str, cache_dir: Path, verbose: bool = False, debug: bool = False\n) -&gt; Path:\n    \"\"\"Download and extract a PSADT release to the cache directory.\n\n    Resolves \"latest\" to the current latest version from GitHub, then\n    downloads the release .zip file and extracts it to the cache.\n\n    Args:\n        release_spec: Version specifier - either \"latest\" or specific version\n            (e.g., \"4.1.7\").\n        cache_dir: Base cache directory for PSADT releases.\n        verbose: Show verbose progress output. Defaults to False.\n        debug: Show debug output. Defaults to False.\n\n    Returns:\n        Path to the cached PSADT directory (cache_dir/{version}).\n\n    Raises:\n        NetworkError: If download fails.\n        PackagingError: If extraction fails.\n        ConfigError: If release_spec is invalid.\n\n    Example:\n        Get latest version:\n            ```python\n            from pathlib import Path\n\n            psadt = get_psadt_release(\"latest\", Path(\"cache/psadt\"))\n            print(psadt)  # Output: cache/psadt/4.1.7\n            ```\n\n        Get specific version:\n            ```python\n            psadt = get_psadt_release(\"4.1.7\", Path(\"cache/psadt\"))\n            ```\n\n    Note:\n        - Caches by version: cache/psadt/{version}/PSAppDeployToolkit/\n        - If already cached, returns path immediately (no re-download)\n        - Downloads from GitHub releases as .zip files\n        - Extracts entire archive to version directory\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    # Resolve \"latest\" to actual version\n    if release_spec == \"latest\":\n        logger.verbose(\"PSADT\", \"Resolving 'latest' to current version...\")\n        version = fetch_latest_psadt_version(verbose=verbose)\n    else:\n        version = release_spec\n\n    logger.verbose(\"PSADT\", f\"PSADT version: {version}\")\n\n    # Check if already cached\n    if is_psadt_cached(version, cache_dir):\n        version_dir = cache_dir / version\n        logger.verbose(\"PSADT\", f\"Using cached PSADT: {version_dir}\")\n        return version_dir\n\n    # Need to download\n    logger.verbose(\"PSADT\", f\"Downloading PSADT {version}...\")\n\n    # Get release info from GitHub\n    release_url = f\"https://api.github.com/repos/{PSADT_REPO}/releases/tags/{version}\"\n\n    try:\n        headers = {\n            \"Accept\": \"application/vnd.github+json\",\n            \"X-GitHub-Api-Version\": \"2022-11-28\",\n        }\n\n        response = requests.get(release_url, headers=headers, timeout=30)\n        response.raise_for_status()\n    except requests.RequestException as err:\n        raise NetworkError(\n            f\"Failed to fetch PSADT release {version} from GitHub: {err}\"\n        ) from err\n\n    release_data = response.json()\n\n    # Find the Template_v4 .zip asset (the full v4 template structure)\n    assets = release_data.get(\"assets\", [])\n    zip_asset = None\n\n    # Look for Template_v4 version specifically\n    for asset in assets:\n        name = asset.get(\"name\", \"\")\n        if name.endswith(\".zip\") and \"Template_v4\" in name:\n            zip_asset = asset\n            break\n\n    # Fallback to any PSADT zip if Template_v4 not found\n    if not zip_asset:\n        for asset in assets:\n            name = asset.get(\"name\", \"\")\n            if name.endswith(\".zip\") and \"PSAppDeployToolkit\" in name:\n                zip_asset = asset\n                break\n\n    if not zip_asset:\n        raise NetworkError(\n            f\"No .zip asset found in PSADT release {version}. \"\n            f\"Available assets: {[a.get('name') for a in assets]}\"\n        )\n\n    download_url = zip_asset.get(\"browser_download_url\")\n    if not download_url:\n        raise NetworkError(f\"Asset missing download URL: {zip_asset}\")\n\n    logger.verbose(\"PSADT\", f\"Downloading: {zip_asset['name']}\")\n\n    # Download the .zip file\n    try:\n        zip_response = requests.get(download_url, timeout=300)\n        zip_response.raise_for_status()\n    except requests.RequestException as err:\n        raise NetworkError(f\"Failed to download PSADT release: {err}\") from err\n\n    # Create cache directory\n    version_dir = cache_dir / version\n    version_dir.mkdir(parents=True, exist_ok=True)\n\n    # Save .zip temporarily\n    zip_path = version_dir / f\"psadt_{version}.zip\"\n    zip_path.write_bytes(zip_response.content)\n\n    logger.verbose(\"PSADT\", f\"Extracting to: {version_dir}\")\n\n    # Extract .zip\n    try:\n        with zipfile.ZipFile(zip_path, \"r\") as zf:\n            zf.extractall(version_dir)\n    except zipfile.BadZipFile as err:\n        raise PackagingError(f\"Failed to extract PSADT archive: {err}\") from err\n    finally:\n        # Clean up .zip file\n        if zip_path.exists():\n            zip_path.unlink()\n\n    # Verify extracted structure\n    if not is_psadt_cached(version, cache_dir):\n        raise PackagingError(\n            f\"PSADT extraction failed: PSAppDeployToolkit/ folder \"\n            f\"not found in {version_dir}\"\n        )\n\n    logger.verbose(\"PSADT\", f\"PSADT {version} cached successfully\")\n\n    return version_dir\n</code></pre>"},{"location":"api/results/","title":"Results","text":""},{"location":"api/results/#notapkgtool.results","title":"notapkgtool.results","text":"<p>Public API return types for NAPT.</p> <p>This module defines dataclasses for return values from public API functions. These types represent the results of operations like discovery, building, packaging, and validation.</p> <p>All dataclasses are frozen (immutable) to prevent accidental mutation of return values.</p> Example <p>Using result types:     <pre><code>from pathlib import Path\nfrom notapkgtool.core import discover_recipe\nfrom notapkgtool.results import DiscoverResult\n\nresult: DiscoverResult = discover_recipe(\n    Path(\"recipes/Google/chrome.yaml\"),\n    Path(\"./downloads\")\n)\nprint(result.version)  # Attribute access, not dict access\n</code></pre></p> Note <p>Only public API return types belong in this module. Domain types (like DiscoveredVersion) and internal types (like LoadContext) should remain co-located with their related logic.</p>"},{"location":"api/results/#notapkgtool.results.DiscoverResult","title":"DiscoverResult  <code>dataclass</code>","text":"<p>Result from discovering a version and downloading an installer.</p> <p>Attributes:</p> Name Type Description <code>app_name</code> <code>str</code> <p>Application display name.</p> <code>app_id</code> <code>str</code> <p>Unique application identifier.</p> <code>strategy</code> <code>str</code> <p>Discovery strategy used (e.g., \"web_scrape\", \"api_github\").</p> <code>version</code> <code>str</code> <p>Extracted version string.</p> <code>version_source</code> <code>str</code> <p>How version was determined (e.g., \"regex_in_url\", \"msi\").</p> <code>file_path</code> <code>Path</code> <p>Path to the downloaded installer file.</p> <code>sha256</code> <code>str</code> <p>SHA-256 hash of the downloaded file.</p> <code>status</code> <code>str</code> <p>Always \"success\" for successful discovery.</p> Source code in <code>notapkgtool/results.py</code> <pre><code>@dataclass(frozen=True)\nclass DiscoverResult:\n    \"\"\"Result from discovering a version and downloading an installer.\n\n    Attributes:\n        app_name: Application display name.\n        app_id: Unique application identifier.\n        strategy: Discovery strategy used (e.g., \"web_scrape\", \"api_github\").\n        version: Extracted version string.\n        version_source: How version was determined (e.g., \"regex_in_url\", \"msi\").\n        file_path: Path to the downloaded installer file.\n        sha256: SHA-256 hash of the downloaded file.\n        status: Always \"success\" for successful discovery.\n    \"\"\"\n\n    app_name: str\n    app_id: str\n    strategy: str\n    version: str\n    version_source: str\n    file_path: Path\n    sha256: str\n    status: str\n</code></pre>"},{"location":"api/results/#notapkgtool.results.BuildResult","title":"BuildResult  <code>dataclass</code>","text":"<p>Result from building a PSADT package.</p> <p>Attributes:</p> Name Type Description <code>app_id</code> <code>str</code> <p>Unique application identifier.</p> <code>app_name</code> <code>str</code> <p>Application display name.</p> <code>version</code> <code>str</code> <p>Application version.</p> <code>build_dir</code> <code>Path</code> <p>Path to the build directory.</p> <code>psadt_version</code> <code>str</code> <p>PSADT version used for the build.</p> <code>status</code> <code>str</code> <p>Build status (typically \"success\").</p> Source code in <code>notapkgtool/results.py</code> <pre><code>@dataclass(frozen=True)\nclass BuildResult:\n    \"\"\"Result from building a PSADT package.\n\n    Attributes:\n        app_id: Unique application identifier.\n        app_name: Application display name.\n        version: Application version.\n        build_dir: Path to the build directory.\n        psadt_version: PSADT version used for the build.\n        status: Build status (typically \"success\").\n    \"\"\"\n\n    app_id: str\n    app_name: str\n    version: str\n    build_dir: Path\n    psadt_version: str\n    status: str\n</code></pre>"},{"location":"api/results/#notapkgtool.results.PackageResult","title":"PackageResult  <code>dataclass</code>","text":"<p>Result from creating a .intunewin package.</p> <p>Attributes:</p> Name Type Description <code>build_dir</code> <code>Path</code> <p>Path to the build directory.</p> <code>package_path</code> <code>Path</code> <p>Path to the created .intunewin file.</p> <code>app_id</code> <code>str</code> <p>Unique application identifier.</p> <code>version</code> <code>str</code> <p>Application version.</p> <code>status</code> <code>str</code> <p>Packaging status (typically \"success\").</p> Source code in <code>notapkgtool/results.py</code> <pre><code>@dataclass(frozen=True)\nclass PackageResult:\n    \"\"\"Result from creating a .intunewin package.\n\n    Attributes:\n        build_dir: Path to the build directory.\n        package_path: Path to the created .intunewin file.\n        app_id: Unique application identifier.\n        version: Application version.\n        status: Packaging status (typically \"success\").\n    \"\"\"\n\n    build_dir: Path\n    package_path: Path\n    app_id: str\n    version: str\n    status: str\n</code></pre>"},{"location":"api/results/#notapkgtool.results.ValidationResult","title":"ValidationResult  <code>dataclass</code>","text":"<p>Result from validating a recipe.</p> <p>Attributes:</p> Name Type Description <code>status</code> <code>str</code> <p>Validation status (\"valid\" or \"invalid\").</p> <code>errors</code> <code>list[str]</code> <p>List of error messages (empty if valid).</p> <code>warnings</code> <code>list[str]</code> <p>List of warning messages.</p> <code>app_count</code> <code>int</code> <p>Number of apps in the recipe.</p> <code>recipe_path</code> <code>str</code> <p>String path to the validated recipe file.</p> Source code in <code>notapkgtool/results.py</code> <pre><code>@dataclass(frozen=True)\nclass ValidationResult:\n    \"\"\"Result from validating a recipe.\n\n    Attributes:\n        status: Validation status (\"valid\" or \"invalid\").\n        errors: List of error messages (empty if valid).\n        warnings: List of warning messages.\n        app_count: Number of apps in the recipe.\n        recipe_path: String path to the validated recipe file.\n    \"\"\"\n\n    status: str\n    errors: list[str]\n    warnings: list[str]\n    app_count: int\n    recipe_path: str\n</code></pre>"},{"location":"api/state/","title":"state","text":""},{"location":"api/state/#notapkgtool.state","title":"notapkgtool.state","text":"<p>State tracking and version management for NAPT.</p> <p>This module provides state persistence for tracking discovered application versions, ETags, and file metadata between runs. This enables:</p> <ul> <li>Efficient conditional downloads (HTTP 304 Not Modified)</li> <li>Version change detection</li> <li>Bandwidth optimization for scheduled workflows</li> </ul> <p>The state file is a JSON file that stores:</p> <ul> <li>Discovered versions from vendors</li> <li>HTTP ETags and Last-Modified headers for conditional requests</li> <li>File paths and SHA-256 hashes for cached installers</li> <li>Last checked timestamps for monitoring</li> </ul> <p>State tracking is enabled by default and can be disabled with --stateless flag.</p> Example <p>Basic usage:</p> <pre><code>from pathlib import Path\nfrom notapkgtool.state import load_state, save_state\n\nstate = load_state(Path(\"state/versions.json\"))\n\napp_id = \"napt-chrome\"\ncache = state.get(\"apps\", {}).get(app_id)\n\nstate[\"apps\"][app_id] = {\n    \"url\": \"https://dl.google.com/chrome.msi\",\n    \"etag\": 'W/\"abc123\"',\n    \"sha256\": \"abc123...\",\n    \"known_version\": \"130.0.0\"\n}\n\nsave_state(state, Path(\"state/versions.json\"))\n</code></pre>"},{"location":"api/state/#notapkgtool.state.StateTracker","title":"StateTracker","text":"<p>Manages application state tracking with automatic persistence.</p> <p>This class provides a high-level interface for loading, querying, and updating the state file. It handles file I/O, error recovery, and provides convenience methods for common operations.</p> <p>Attributes:</p> Name Type Description <code>state_file</code> <p>Path to the JSON state file.</p> <code>state</code> <code>dict[str, Any]</code> <p>In-memory state dictionary.</p> Example <p>Basic usage:     <pre><code>from pathlib import Path\n\ntracker = StateTracker(Path(\"state/versions.json\"))\ntracker.load()\ncache = tracker.get_cache(\"napt-chrome\")\ntracker.update_cache(\n    \"napt-chrome\",\n    url=\"https://...\",\n    sha256=\"...\",\n    known_version=\"130.0.0\"\n)\ntracker.save()\n</code></pre></p> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>class StateTracker:\n    \"\"\"Manages application state tracking with automatic persistence.\n\n    This class provides a high-level interface for loading, querying, and\n    updating the state file. It handles file I/O, error recovery, and\n    provides convenience methods for common operations.\n\n    Attributes:\n        state_file: Path to the JSON state file.\n        state: In-memory state dictionary.\n\n    Example:\n        Basic usage:\n            ```python\n            from pathlib import Path\n\n            tracker = StateTracker(Path(\"state/versions.json\"))\n            tracker.load()\n            cache = tracker.get_cache(\"napt-chrome\")\n            tracker.update_cache(\n                \"napt-chrome\",\n                url=\"https://...\",\n                sha256=\"...\",\n                known_version=\"130.0.0\"\n            )\n            tracker.save()\n            ```\n\n    \"\"\"\n\n    def __init__(self, state_file: Path):\n        \"\"\"Initialize state tracker.\n\n        Args:\n            state_file: Path to JSON state file. Created if doesn't exist.\n\n        \"\"\"\n        self.state_file = state_file\n        self.state: dict[str, Any] = {}\n\n    def load(self) -&gt; dict[str, Any]:\n        \"\"\"Load state from file.\n\n        Creates default state structure if file doesn't exist.\n        Handles corrupted files by creating backup and starting fresh.\n\n        Returns:\n            Loaded state dictionary.\n\n        Raises:\n            OSError: If file permissions prevent reading.\n\n        \"\"\"\n        try:\n            self.state = load_state(self.state_file)\n        except FileNotFoundError:\n            # First run, create default state\n            self.state = create_default_state()\n            self.state_file.parent.mkdir(parents=True, exist_ok=True)\n            self.save()\n        except json.JSONDecodeError as err:\n            # Corrupted file, backup and create new\n            backup = self.state_file.with_suffix(\".json.backup\")\n            self.state_file.rename(backup)\n            self.state = create_default_state()\n            self.save()\n            raise PackagingError(\n                f\"Corrupted state file backed up to {backup}. \"\n                f\"Created fresh state file.\"\n            ) from err\n\n        return self.state\n\n    def save(self) -&gt; None:\n        \"\"\"Save current state to file.\n\n        Updates metadata.last_updated timestamp automatically.\n        Creates parent directories if needed.\n\n        Raises:\n            OSError: If file permissions prevent writing.\n\n        \"\"\"\n        # Update metadata\n        self.state.setdefault(\"metadata\", {})\n        self.state[\"metadata\"][\"last_updated\"] = datetime.now(UTC).isoformat()\n\n        # Ensure parent directory exists\n        self.state_file.parent.mkdir(parents=True, exist_ok=True)\n\n        save_state(self.state, self.state_file)\n\n    def get_cache(self, recipe_id: str) -&gt; dict[str, Any] | None:\n        \"\"\"Get cached information for a recipe.\n\n        Args:\n            recipe_id: Recipe identifier (from recipe's 'id' field).\n\n        Returns:\n            Cached data if available, None otherwise.\n\n        Example:\n            Retrieve cached information:\n                ```python\n                cache = tracker.get_cache(\"napt-chrome\")\n                if cache:\n                    etag = cache.get('etag')\n                    known_version = cache.get('known_version')\n                ```\n\n        \"\"\"\n        return self.state.get(\"apps\", {}).get(recipe_id)\n\n    def update_cache(\n        self,\n        recipe_id: str,\n        url: str,\n        sha256: str,\n        etag: str | None = None,\n        last_modified: str | None = None,\n        known_version: str | None = None,\n        strategy: str | None = None,\n    ) -&gt; None:\n        \"\"\"Update cached information for a recipe.\n\n        Args:\n            recipe_id: Recipe identifier.\n            url: Download URL for provenance tracking. For version-first strategies\n                (url_pattern, api_github, api_json), this is the actual download URL\n                from version_info. For file-first (url_download), this is source.url.\n            sha256: SHA-256 hash of file (for integrity checks).\n            etag: ETag header from download response. Used by url_download for HTTP 304\n                conditional requests. Saved but unused by version-first strategies.\n            last_modified: Last-Modified header from download response.\n                Used by url_download as fallback for conditional requests.\n                Saved but unused by version-first.\n            known_version: Version string. PRIMARY cache key for\n                version-first strategies (compared to skip downloads).\n                Informational only for url_download.\n            strategy: Discovery strategy used (for debugging).\n\n        Example:\n            Update cache entry:\n                ```python\n                tracker.update_cache(\n                    \"napt-chrome\",\n                    url=\"https://dl.google.com/chrome.msi\",\n                    sha256=\"abc123...\",\n                    etag='W/\"def456\"',\n                    known_version=\"130.0.0\"\n                )\n                ```\n\n        Note:\n            Schema v2: Removed file_path, last_checked, and renamed\n            version -&gt; known_version.\n\n            Field usage differs by strategy type:\n\n            - Version-first: known_version is PRIMARY cache key,\n                etag/last_modified unused\n            - File-first: etag/last_modified are PRIMARY cache keys,\n                known_version informational\n\n            Filesystem is the source of truth; state is for optimization only.\n\n        \"\"\"\n        if \"apps\" not in self.state:\n            self.state[\"apps\"] = {}\n\n        cache_entry = {\n            \"url\": url,\n            \"etag\": etag,\n            \"last_modified\": last_modified,\n            \"sha256\": sha256,\n        }\n\n        # Optional fields (only add if provided)\n        if known_version is not None:\n            cache_entry[\"known_version\"] = known_version\n        if strategy is not None:\n            cache_entry[\"strategy\"] = strategy\n\n        self.state[\"apps\"][recipe_id] = cache_entry\n\n    def has_version_changed(self, recipe_id: str, new_version: str) -&gt; bool:\n        \"\"\"Check if discovered version differs from cached known_version.\n\n        Args:\n            recipe_id: Recipe identifier.\n            new_version: Newly discovered version.\n\n        Returns:\n            True if version changed or no cached version exists.\n\n        Example:\n            Check if version has changed:\n                ```python\n                if tracker.has_version_changed(\"napt-chrome\", \"130.0.0\"):\n                    print(\"New version available!\")\n                ```\n\n        Note:\n            Uses 'known_version' field which is informational only.\n            Real version should be extracted from filesystem during build.\n\n        \"\"\"\n        cache = self.get_cache(recipe_id)\n        if not cache:\n            return True  # No cache, treat as changed\n\n        return cache.get(\"known_version\") != new_version\n</code></pre>"},{"location":"api/state/#notapkgtool.state.StateTracker.__init__","title":"__init__","text":"<pre><code>__init__(state_file: Path)\n</code></pre> <p>Initialize state tracker.</p> <p>Parameters:</p> Name Type Description Default <code>state_file</code> <code>Path</code> <p>Path to JSON state file. Created if doesn't exist.</p> required Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def __init__(self, state_file: Path):\n    \"\"\"Initialize state tracker.\n\n    Args:\n        state_file: Path to JSON state file. Created if doesn't exist.\n\n    \"\"\"\n    self.state_file = state_file\n    self.state: dict[str, Any] = {}\n</code></pre>"},{"location":"api/state/#notapkgtool.state.StateTracker.load","title":"load","text":"<pre><code>load() -&gt; dict[str, Any]\n</code></pre> <p>Load state from file.</p> <p>Creates default state structure if file doesn't exist. Handles corrupted files by creating backup and starting fresh.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Loaded state dictionary.</p> <p>Raises:</p> Type Description <code>OSError</code> <p>If file permissions prevent reading.</p> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def load(self) -&gt; dict[str, Any]:\n    \"\"\"Load state from file.\n\n    Creates default state structure if file doesn't exist.\n    Handles corrupted files by creating backup and starting fresh.\n\n    Returns:\n        Loaded state dictionary.\n\n    Raises:\n        OSError: If file permissions prevent reading.\n\n    \"\"\"\n    try:\n        self.state = load_state(self.state_file)\n    except FileNotFoundError:\n        # First run, create default state\n        self.state = create_default_state()\n        self.state_file.parent.mkdir(parents=True, exist_ok=True)\n        self.save()\n    except json.JSONDecodeError as err:\n        # Corrupted file, backup and create new\n        backup = self.state_file.with_suffix(\".json.backup\")\n        self.state_file.rename(backup)\n        self.state = create_default_state()\n        self.save()\n        raise PackagingError(\n            f\"Corrupted state file backed up to {backup}. \"\n            f\"Created fresh state file.\"\n        ) from err\n\n    return self.state\n</code></pre>"},{"location":"api/state/#notapkgtool.state.StateTracker.save","title":"save","text":"<pre><code>save() -&gt; None\n</code></pre> <p>Save current state to file.</p> <p>Updates metadata.last_updated timestamp automatically. Creates parent directories if needed.</p> <p>Raises:</p> Type Description <code>OSError</code> <p>If file permissions prevent writing.</p> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def save(self) -&gt; None:\n    \"\"\"Save current state to file.\n\n    Updates metadata.last_updated timestamp automatically.\n    Creates parent directories if needed.\n\n    Raises:\n        OSError: If file permissions prevent writing.\n\n    \"\"\"\n    # Update metadata\n    self.state.setdefault(\"metadata\", {})\n    self.state[\"metadata\"][\"last_updated\"] = datetime.now(UTC).isoformat()\n\n    # Ensure parent directory exists\n    self.state_file.parent.mkdir(parents=True, exist_ok=True)\n\n    save_state(self.state, self.state_file)\n</code></pre>"},{"location":"api/state/#notapkgtool.state.StateTracker.get_cache","title":"get_cache","text":"<pre><code>get_cache(recipe_id: str) -&gt; dict[str, Any] | None\n</code></pre> <p>Get cached information for a recipe.</p> <p>Parameters:</p> Name Type Description Default <code>recipe_id</code> <code>str</code> <p>Recipe identifier (from recipe's 'id' field).</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>Cached data if available, None otherwise.</p> Example <p>Retrieve cached information:     <pre><code>cache = tracker.get_cache(\"napt-chrome\")\nif cache:\n    etag = cache.get('etag')\n    known_version = cache.get('known_version')\n</code></pre></p> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def get_cache(self, recipe_id: str) -&gt; dict[str, Any] | None:\n    \"\"\"Get cached information for a recipe.\n\n    Args:\n        recipe_id: Recipe identifier (from recipe's 'id' field).\n\n    Returns:\n        Cached data if available, None otherwise.\n\n    Example:\n        Retrieve cached information:\n            ```python\n            cache = tracker.get_cache(\"napt-chrome\")\n            if cache:\n                etag = cache.get('etag')\n                known_version = cache.get('known_version')\n            ```\n\n    \"\"\"\n    return self.state.get(\"apps\", {}).get(recipe_id)\n</code></pre>"},{"location":"api/state/#notapkgtool.state.StateTracker.update_cache","title":"update_cache","text":"<pre><code>update_cache(recipe_id: str, url: str, sha256: str, etag: str | None = None, last_modified: str | None = None, known_version: str | None = None, strategy: str | None = None) -&gt; None\n</code></pre> <p>Update cached information for a recipe.</p> <p>Parameters:</p> Name Type Description Default <code>recipe_id</code> <code>str</code> <p>Recipe identifier.</p> required <code>url</code> <code>str</code> <p>Download URL for provenance tracking. For version-first strategies (url_pattern, api_github, api_json), this is the actual download URL from version_info. For file-first (url_download), this is source.url.</p> required <code>sha256</code> <code>str</code> <p>SHA-256 hash of file (for integrity checks).</p> required <code>etag</code> <code>str | None</code> <p>ETag header from download response. Used by url_download for HTTP 304 conditional requests. Saved but unused by version-first strategies.</p> <code>None</code> <code>last_modified</code> <code>str | None</code> <p>Last-Modified header from download response. Used by url_download as fallback for conditional requests. Saved but unused by version-first.</p> <code>None</code> <code>known_version</code> <code>str | None</code> <p>Version string. PRIMARY cache key for version-first strategies (compared to skip downloads). Informational only for url_download.</p> <code>None</code> <code>strategy</code> <code>str | None</code> <p>Discovery strategy used (for debugging).</p> <code>None</code> Example <p>Update cache entry:     <pre><code>tracker.update_cache(\n    \"napt-chrome\",\n    url=\"https://dl.google.com/chrome.msi\",\n    sha256=\"abc123...\",\n    etag='W/\"def456\"',\n    known_version=\"130.0.0\"\n)\n</code></pre></p> Note <p>Schema v2: Removed file_path, last_checked, and renamed version -&gt; known_version.</p> <p>Field usage differs by strategy type:</p> <ul> <li>Version-first: known_version is PRIMARY cache key,     etag/last_modified unused</li> <li>File-first: etag/last_modified are PRIMARY cache keys,     known_version informational</li> </ul> <p>Filesystem is the source of truth; state is for optimization only.</p> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def update_cache(\n    self,\n    recipe_id: str,\n    url: str,\n    sha256: str,\n    etag: str | None = None,\n    last_modified: str | None = None,\n    known_version: str | None = None,\n    strategy: str | None = None,\n) -&gt; None:\n    \"\"\"Update cached information for a recipe.\n\n    Args:\n        recipe_id: Recipe identifier.\n        url: Download URL for provenance tracking. For version-first strategies\n            (url_pattern, api_github, api_json), this is the actual download URL\n            from version_info. For file-first (url_download), this is source.url.\n        sha256: SHA-256 hash of file (for integrity checks).\n        etag: ETag header from download response. Used by url_download for HTTP 304\n            conditional requests. Saved but unused by version-first strategies.\n        last_modified: Last-Modified header from download response.\n            Used by url_download as fallback for conditional requests.\n            Saved but unused by version-first.\n        known_version: Version string. PRIMARY cache key for\n            version-first strategies (compared to skip downloads).\n            Informational only for url_download.\n        strategy: Discovery strategy used (for debugging).\n\n    Example:\n        Update cache entry:\n            ```python\n            tracker.update_cache(\n                \"napt-chrome\",\n                url=\"https://dl.google.com/chrome.msi\",\n                sha256=\"abc123...\",\n                etag='W/\"def456\"',\n                known_version=\"130.0.0\"\n            )\n            ```\n\n    Note:\n        Schema v2: Removed file_path, last_checked, and renamed\n        version -&gt; known_version.\n\n        Field usage differs by strategy type:\n\n        - Version-first: known_version is PRIMARY cache key,\n            etag/last_modified unused\n        - File-first: etag/last_modified are PRIMARY cache keys,\n            known_version informational\n\n        Filesystem is the source of truth; state is for optimization only.\n\n    \"\"\"\n    if \"apps\" not in self.state:\n        self.state[\"apps\"] = {}\n\n    cache_entry = {\n        \"url\": url,\n        \"etag\": etag,\n        \"last_modified\": last_modified,\n        \"sha256\": sha256,\n    }\n\n    # Optional fields (only add if provided)\n    if known_version is not None:\n        cache_entry[\"known_version\"] = known_version\n    if strategy is not None:\n        cache_entry[\"strategy\"] = strategy\n\n    self.state[\"apps\"][recipe_id] = cache_entry\n</code></pre>"},{"location":"api/state/#notapkgtool.state.StateTracker.has_version_changed","title":"has_version_changed","text":"<pre><code>has_version_changed(recipe_id: str, new_version: str) -&gt; bool\n</code></pre> <p>Check if discovered version differs from cached known_version.</p> <p>Parameters:</p> Name Type Description Default <code>recipe_id</code> <code>str</code> <p>Recipe identifier.</p> required <code>new_version</code> <code>str</code> <p>Newly discovered version.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if version changed or no cached version exists.</p> Example <p>Check if version has changed:     <pre><code>if tracker.has_version_changed(\"napt-chrome\", \"130.0.0\"):\n    print(\"New version available!\")\n</code></pre></p> Note <p>Uses 'known_version' field which is informational only. Real version should be extracted from filesystem during build.</p> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def has_version_changed(self, recipe_id: str, new_version: str) -&gt; bool:\n    \"\"\"Check if discovered version differs from cached known_version.\n\n    Args:\n        recipe_id: Recipe identifier.\n        new_version: Newly discovered version.\n\n    Returns:\n        True if version changed or no cached version exists.\n\n    Example:\n        Check if version has changed:\n            ```python\n            if tracker.has_version_changed(\"napt-chrome\", \"130.0.0\"):\n                print(\"New version available!\")\n            ```\n\n    Note:\n        Uses 'known_version' field which is informational only.\n        Real version should be extracted from filesystem during build.\n\n    \"\"\"\n    cache = self.get_cache(recipe_id)\n    if not cache:\n        return True  # No cache, treat as changed\n\n    return cache.get(\"known_version\") != new_version\n</code></pre>"},{"location":"api/state/#notapkgtool.state.load_state","title":"load_state","text":"<pre><code>load_state(state_file: Path) -&gt; dict[str, Any]\n</code></pre> <p>Load state from JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>state_file</code> <code>Path</code> <p>Path to JSON state file.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Loaded state dictionary.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If state file doesn't exist.</p> <code>JSONDecodeError</code> <p>If file contains invalid JSON.</p> <code>OSError</code> <p>If file cannot be read due to permissions.</p> Example <p>Load state from file:     <pre><code>from pathlib import Path\n\nstate = load_state(Path(\"state/versions.json\"))\napps = state.get(\"apps\", {})\n</code></pre></p> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def load_state(state_file: Path) -&gt; dict[str, Any]:\n    \"\"\"Load state from JSON file.\n\n    Args:\n        state_file: Path to JSON state file.\n\n    Returns:\n        Loaded state dictionary.\n\n    Raises:\n        FileNotFoundError: If state file doesn't exist.\n        json.JSONDecodeError: If file contains invalid JSON.\n        OSError: If file cannot be read due to permissions.\n\n    Example:\n        Load state from file:\n            ```python\n            from pathlib import Path\n\n            state = load_state(Path(\"state/versions.json\"))\n            apps = state.get(\"apps\", {})\n            ```\n\n    \"\"\"\n    with open(state_file, encoding=\"utf-8\") as f:\n        return json.load(f)\n</code></pre>"},{"location":"api/state/#notapkgtool.state.save_state","title":"save_state","text":"<pre><code>save_state(state: dict[str, Any], state_file: Path) -&gt; None\n</code></pre> <p>Save state to JSON file with pretty-printing.</p> <p>Creates parent directories if needed. Uses 2-space indentation and sorted keys for consistent diffs in version control.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>dict[str, Any]</code> <p>State dictionary to save.</p> required <code>state_file</code> <code>Path</code> <p>Path to JSON state file.</p> required <p>Raises:</p> Type Description <code>OSError</code> <p>If file cannot be written due to permissions.</p> Example <p>Save state to file:     <pre><code>from pathlib import Path\n\nstate = {\"metadata\": {}, \"apps\": {}}\nsave_state(state, Path(\"state/versions.json\"))\n</code></pre></p> Note <ul> <li>Uses 2-space indentation for readability</li> <li>Sorts keys alphabetically for consistent diffs</li> <li>Adds trailing newline for git compatibility</li> </ul> Source code in <code>notapkgtool/state/tracker.py</code> <pre><code>def save_state(state: dict[str, Any], state_file: Path) -&gt; None:\n    \"\"\"Save state to JSON file with pretty-printing.\n\n    Creates parent directories if needed. Uses 2-space indentation\n    and sorted keys for consistent diffs in version control.\n\n    Args:\n        state: State dictionary to save.\n        state_file: Path to JSON state file.\n\n    Raises:\n        OSError: If file cannot be written due to permissions.\n\n    Example:\n        Save state to file:\n            ```python\n            from pathlib import Path\n\n            state = {\"metadata\": {}, \"apps\": {}}\n            save_state(state, Path(\"state/versions.json\"))\n            ```\n\n    Note:\n        - Uses 2-space indentation for readability\n        - Sorts keys alphabetically for consistent diffs\n        - Adds trailing newline for git compatibility\n\n    \"\"\"\n    state_file.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(state_file, \"w\", encoding=\"utf-8\") as f:\n        json.dump(state, f, indent=2, sort_keys=True)\n        f.write(\"\\n\")  # Trailing newline for git\n</code></pre>"},{"location":"api/validation/","title":"validation","text":""},{"location":"api/validation/#notapkgtool.validation","title":"notapkgtool.validation","text":"<p>Recipe validation module.</p> <p>This module provides validation functions for checking recipe syntax and configuration without making network calls or downloading files. This is useful for quick feedback during recipe development and in CI/CD pipelines.</p> <p>Validation Checks:</p> <ul> <li>YAML syntax is valid</li> <li>Required top-level fields present (apiVersion, apps)</li> <li>apiVersion is supported</li> <li>Each app has required fields (name, id, source)</li> <li>Discovery strategy exists and is registered</li> <li>Strategy-specific configuration is valid</li> </ul> Example <p>Validate a recipe and handle results:     <pre><code>from pathlib import Path\nfrom notapkgtool.validation import validate_recipe\n\nresult = validate_recipe(Path(\"recipes/Google/chrome.yaml\"))\nif result.status == \"valid\":\n    print(f\"Recipe is valid with {result.app_count} app(s)\")\nelse:\n    for error in result.errors:\n        print(f\"Error: {error}\")\n</code></pre></p>"},{"location":"api/validation/#notapkgtool.validation.validate_recipe","title":"validate_recipe","text":"<pre><code>validate_recipe(recipe_path: Path, verbose: bool = False) -&gt; ValidationResult\n</code></pre> <p>Validate a recipe file without downloading anything.</p> <p>This function checks:</p> <ol> <li>YAML file can be parsed</li> <li>Required top-level fields are present</li> <li>apiVersion is supported</li> <li>Each app has required fields</li> <li>Discovery strategies exist</li> <li>Strategy-specific configuration is valid</li> </ol> <p>Does NOT:</p> <ul> <li>Make network calls</li> <li>Download files</li> <li>Verify URLs are accessible</li> <li>Check if versions can be extracted</li> </ul> <p>Parameters:</p> Name Type Description Default <code>recipe_path</code> <code>Path</code> <p>Path to the recipe YAML file to validate.</p> required <code>verbose</code> <code>bool</code> <p>If True, print validation progress. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>ValidationResult</code> <p>ValidationResult dataclass with the following fields:</p> <ul> <li>status (str): Validation status, either \"valid\" (no errors) or \"invalid\"     (has errors). Warnings do not affect status.</li> <li>errors (list[str]): List of error messages found during validation. Empty     list if recipe is valid. Each error describes a specific validation     failure (e.g., missing required field, invalid strategy configuration).</li> <li>warnings (list[str]): List of warning messages found during validation.     Warnings indicate potential issues but do not prevent validation from     passing (e.g., unsupported apiVersion, deprecated configuration).</li> <li>app_count (int): Number of apps defined in the recipe. Zero if recipe     structure is invalid.</li> <li>recipe_path (str): String path to the validated recipe file, useful for     error reporting and logging.</li> </ul> Example <p>Validate a recipe and check results:     <pre><code>from pathlib import Path\n\nresult = validate_recipe(Path(\"recipes/app.yaml\"))\nif result.status == \"valid\":\n    print(\"Recipe is valid!\")\nelse:\n    for error in result.errors:\n        print(f\"Error: {error}\")\n</code></pre></p> Source code in <code>notapkgtool/validation.py</code> <pre><code>def validate_recipe(recipe_path: Path, verbose: bool = False) -&gt; ValidationResult:\n    \"\"\"Validate a recipe file without downloading anything.\n\n    This function checks:\n\n    1. YAML file can be parsed\n    2. Required top-level fields are present\n    3. apiVersion is supported\n    4. Each app has required fields\n    5. Discovery strategies exist\n    6. Strategy-specific configuration is valid\n\n    Does NOT:\n\n    - Make network calls\n    - Download files\n    - Verify URLs are accessible\n    - Check if versions can be extracted\n\n    Args:\n        recipe_path: Path to the recipe YAML file to validate.\n        verbose: If True, print validation progress.\n            Default is False.\n\n    Returns:\n        ValidationResult dataclass with the following fields:\n\n            - status (str): Validation status, either \"valid\" (no errors) or \"invalid\"\n                (has errors). Warnings do not affect status.\n            - errors (list[str]): List of error messages found during validation. Empty\n                list if recipe is valid. Each error describes a specific validation\n                failure (e.g., missing required field, invalid strategy configuration).\n            - warnings (list[str]): List of warning messages found during validation.\n                Warnings indicate potential issues but do not prevent validation from\n                passing (e.g., unsupported apiVersion, deprecated configuration).\n            - app_count (int): Number of apps defined in the recipe. Zero if recipe\n                structure is invalid.\n            - recipe_path (str): String path to the validated recipe file, useful for\n                error reporting and logging.\n\n    Example:\n        Validate a recipe and check results:\n            ```python\n            from pathlib import Path\n\n            result = validate_recipe(Path(\"recipes/app.yaml\"))\n            if result.status == \"valid\":\n                print(\"Recipe is valid!\")\n            else:\n                for error in result.errors:\n                    print(f\"Error: {error}\")\n            ```\n\n    \"\"\"\n    errors = []\n    warnings = []\n    app_count = 0\n\n    if verbose:\n        print(f\"Validating recipe: {recipe_path}\")\n\n    # Check file exists\n    if not recipe_path.exists():\n        errors.append(f\"Recipe file not found: {recipe_path}\")\n        return ValidationResult(\n            status=\"invalid\",\n            errors=errors,\n            warnings=warnings,\n            app_count=0,\n            recipe_path=str(recipe_path),\n        )\n\n    # Parse YAML\n    try:\n        with open(recipe_path, encoding=\"utf-8\") as f:\n            recipe = yaml.safe_load(f)\n    except yaml.YAMLError as err:\n        errors.append(f\"Invalid YAML syntax: {err}\")\n        return ValidationResult(\n            status=\"invalid\",\n            errors=errors,\n            warnings=warnings,\n            app_count=0,\n            recipe_path=str(recipe_path),\n        )\n    except Exception as err:\n        errors.append(f\"Failed to read recipe file: {err}\")\n        return ValidationResult(\n            status=\"invalid\",\n            errors=errors,\n            warnings=warnings,\n            app_count=0,\n            recipe_path=str(recipe_path),\n        )\n\n    if verbose:\n        print(\"  [OK] YAML syntax is valid\")\n\n    # Validate recipe is a dict\n    if not isinstance(recipe, dict):\n        errors.append(\"Recipe must be a YAML dictionary/mapping\")\n        return ValidationResult(\n            status=\"invalid\",\n            errors=errors,\n            warnings=warnings,\n            app_count=0,\n            recipe_path=str(recipe_path),\n        )\n\n    # Check apiVersion\n    if \"apiVersion\" not in recipe:\n        errors.append(\"Missing required field: apiVersion\")\n    else:\n        api_version = recipe[\"apiVersion\"]\n        if not isinstance(api_version, str):\n            errors.append(\"apiVersion must be a string\")\n        elif api_version != \"napt/v1\":\n            warnings.append(\n                f\"apiVersion '{api_version}' may not be supported (expected: napt/v1)\"\n            )\n        if verbose and not errors:\n            print(f\"  [OK] apiVersion: {api_version}\")\n\n    # Check apps list\n    if \"apps\" not in recipe:\n        errors.append(\"Missing required field: apps\")\n        return ValidationResult(\n            status=\"invalid\",\n            errors=errors,\n            warnings=warnings,\n            app_count=0,\n            recipe_path=str(recipe_path),\n        )\n\n    apps = recipe[\"apps\"]\n    if not isinstance(apps, list):\n        errors.append(\"Field 'apps' must be a list\")\n        return ValidationResult(\n            status=\"invalid\",\n            errors=errors,\n            warnings=warnings,\n            app_count=0,\n            recipe_path=str(recipe_path),\n        )\n\n    if len(apps) == 0:\n        errors.append(\"Field 'apps' must contain at least one app\")\n        return ValidationResult(\n            status=\"invalid\",\n            errors=errors,\n            warnings=warnings,\n            app_count=0,\n            recipe_path=str(recipe_path),\n        )\n\n    app_count = len(apps)\n    if verbose:\n        print(f\"  [OK] Found {app_count} app(s)\")\n\n    # Validate each app\n    for idx, app in enumerate(apps):\n        app_prefix = f\"apps[{idx}]\"\n\n        if not isinstance(app, dict):\n            errors.append(f\"{app_prefix}: App must be a dictionary\")\n            continue\n\n        # Check required fields\n        for field in [\"name\", \"id\", \"source\"]:\n            if field not in app:\n                errors.append(f\"{app_prefix}: Missing required field: {field}\")\n\n        # Validate name\n        if \"name\" in app and not isinstance(app[\"name\"], str):\n            errors.append(f\"{app_prefix}: Field 'name' must be a string\")\n\n        # Validate id\n        if \"id\" in app:\n            if not isinstance(app[\"id\"], str):\n                errors.append(f\"{app_prefix}: Field 'id' must be a string\")\n            elif not app[\"id\"]:\n                errors.append(f\"{app_prefix}: Field 'id' cannot be empty\")\n\n        # Validate source\n        if \"source\" not in app:\n            continue  # Already reported missing field\n\n        source = app[\"source\"]\n        if not isinstance(source, dict):\n            errors.append(f\"{app_prefix}.source: Must be a dictionary\")\n            continue\n\n        # Check strategy field\n        if \"strategy\" not in source:\n            errors.append(f\"{app_prefix}.source: Missing required field: strategy\")\n            continue\n\n        strategy_name = source[\"strategy\"]\n        if not isinstance(strategy_name, str):\n            errors.append(f\"{app_prefix}.source.strategy: Must be a string\")\n            continue\n\n        if verbose:\n            print(\n                f\"  [OK] App '{app.get('name', 'unnamed')}' \"\n                f\"uses strategy: {strategy_name}\"\n            )\n\n        # Check if strategy exists\n        try:\n            strategy = get_strategy(strategy_name)\n        except ConfigError as err:\n            errors.append(f\"{app_prefix}.source.strategy: {err}\")\n            continue\n\n        # Validate strategy-specific configuration\n        if hasattr(strategy, \"validate_config\"):\n            try:\n                config_errors = strategy.validate_config(app)\n                for error in config_errors:\n                    errors.append(f\"{app_prefix}: {error}\")\n            except Exception as err:\n                errors.append(f\"{app_prefix}: Strategy validation failed: {err}\")\n\n    # Determine final status\n    status = \"valid\" if len(errors) == 0 else \"invalid\"\n\n    if verbose:\n        if status == \"valid\":\n            print(\"  [OK] Recipe is valid!\")\n        else:\n            print(f\"  [ERROR] Recipe has {len(errors)} error(s)\")\n\n    return ValidationResult(\n        status=status,\n        errors=errors,\n        warnings=warnings,\n        app_count=app_count,\n        recipe_path=str(recipe_path),\n    )\n</code></pre>"},{"location":"api/versioning/","title":"versioning","text":""},{"location":"api/versioning/#notapkgtool.versioning.keys","title":"notapkgtool.versioning.keys","text":"<p>Core version comparison utilities for NAPT.</p> <p>This module is format-agnostic: it does NOT download or read files. It only parses and compares version strings consistently across sources (MSI, EXE, generic strings).</p>"},{"location":"api/versioning/#notapkgtool.versioning.keys.DiscoveredVersion","title":"DiscoveredVersion  <code>dataclass</code>","text":"<p>Container for a discovered version string.</p> <p>Attributes:</p> Name Type Description <code>version</code> <code>str</code> <p>Raw version string (e.g., \"140.0.7339.128\").</p> <code>source</code> <code>str</code> <p>Where it came from (e.g., \"regex_in_url\", \"msi\").</p> Source code in <code>notapkgtool/versioning/keys.py</code> <pre><code>@dataclass(frozen=True)\nclass DiscoveredVersion:\n    \"\"\"Container for a discovered version string.\n\n    Attributes:\n        version: Raw version string (e.g., \"140.0.7339.128\").\n        source: Where it came from (e.g., \"regex_in_url\", \"msi\").\n\n    \"\"\"\n\n    version: str\n    source: str\n</code></pre>"},{"location":"api/versioning/#notapkgtool.versioning.keys.VersionInfo","title":"VersionInfo  <code>dataclass</code>","text":"<p>Container for version information discovered without downloading.</p> <p>Used by version-first strategies (web_scrape, api_github, api_json) that can determine version and download URL without fetching the installer.</p> <p>Attributes:</p> Name Type Description <code>version</code> <code>str</code> <p>Raw version string (e.g., \"140.0.7339.128\").</p> <code>download_url</code> <code>str</code> <p>URL to download the installer.</p> <code>source</code> <code>str</code> <p>Strategy name for logging (e.g., \"web_scrape\", \"api_github\").</p> Source code in <code>notapkgtool/versioning/keys.py</code> <pre><code>@dataclass(frozen=True)\nclass VersionInfo:\n    \"\"\"Container for version information discovered without downloading.\n\n    Used by version-first strategies (web_scrape, api_github, api_json)\n    that can determine version and download URL without fetching the installer.\n\n    Attributes:\n        version: Raw version string (e.g., \"140.0.7339.128\").\n        download_url: URL to download the installer.\n        source: Strategy name for logging (e.g., \"web_scrape\", \"api_github\").\n\n    \"\"\"\n\n    version: str\n    download_url: str\n    source: str\n</code></pre>"},{"location":"api/versioning/#notapkgtool.versioning.keys.version_key_any","title":"version_key_any","text":"<pre><code>version_key_any(s: str, *, source: SourceHint = 'string') -&gt; tuple\n</code></pre> <p>Compute a comparable key for any version string.</p> <ul> <li>MSI/EXE: purely numeric (truncated to 3/4 parts).</li> <li>Generic string: semver-like robust key; if no numeric prefix,     fallback to (\"text\", raw).</li> </ul> Source code in <code>notapkgtool/versioning/keys.py</code> <pre><code>def version_key_any(s: str, *, source: SourceHint = \"string\") -&gt; tuple:\n    \"\"\"Compute a comparable key for any version string.\n\n    - MSI/EXE: purely numeric (truncated to 3/4 parts).\n    - Generic string: semver-like robust key; if no numeric prefix,\n        fallback to (\"text\", raw).\n    \"\"\"\n    if source in (\"msi\", \"exe\"):\n        nums = _clip_for_source(_ints_from_text(s), source)\n        return (\"num\", nums)\n\n    key = _semver_like_key_robust(s)\n    release = key[0]\n    if release != (0,):\n        # IMPORTANT: We do NOT include the raw string as a tiebreaker.\n        # This makes \"v1.2.3\" == \"1.2.3\" when the parsed keys are equal.\n        return (\"semverish\", key)\n\n    return (\"text\", s)\n</code></pre>"},{"location":"api/versioning/#notapkgtool.versioning.keys.compare_any","title":"compare_any","text":"<pre><code>compare_any(a: str, b: str, *, source: SourceHint = 'string', verbose: bool = False) -&gt; int\n</code></pre> <p>Compare two versions with a source hint. Returns -1 if a &lt; b, 0 if equal, 1 if a &gt; b.</p> Source code in <code>notapkgtool/versioning/keys.py</code> <pre><code>def compare_any(\n    a: str,\n    b: str,\n    *,\n    source: SourceHint = \"string\",\n    verbose: bool = False,\n) -&gt; int:\n    \"\"\"Compare two versions with a source hint.\n    Returns -1 if a &lt; b, 0 if equal, 1 if a &gt; b.\n    \"\"\"\n    if source in (\"msi\", \"exe\"):\n        try:\n            aa = _clip_for_source(_ints_from_text(a), source)\n            bb = _clip_for_source(_ints_from_text(b), source)\n            aa, bb = _pad_equal(aa, bb)\n            result = (aa &gt; bb) - (aa &lt; bb)\n        except ValueError:\n            # If vendor sneaks letters into numeric fields, fallback to generic parsing.\n            ka = version_key_any(a, source=\"string\")\n            kb = version_key_any(b, source=\"string\")\n            result = (ka &gt; kb) - (ka &lt; kb)\n    else:\n        ka = version_key_any(a, source=\"string\")\n        kb = version_key_any(b, source=\"string\")\n        result = (ka &gt; kb) - (ka &lt; kb)\n\n    if verbose:\n        if result &lt; 0:\n            print(f\"[compare_any] {a!r} is older than {b!r} (source={source})\")\n        elif result &gt; 0:\n            print(f\"[compare_any] {a!r} is newer than {b!r} (source={source})\")\n        else:\n            print(f\"[compare_any] {a!r} is the same as {b!r} (source={source})\")\n    return result\n</code></pre>"},{"location":"api/versioning/#notapkgtool.versioning.keys.is_newer_any","title":"is_newer_any","text":"<pre><code>is_newer_any(remote: str, current: str | None, *, source: SourceHint = 'string', verbose: bool = False) -&gt; bool\n</code></pre> <p>Decide if 'remote' should be considered newer than 'current'. Returns True iff remote &gt; current under the given source semantics.</p> Source code in <code>notapkgtool/versioning/keys.py</code> <pre><code>def is_newer_any(\n    remote: str,\n    current: str | None,\n    *,\n    source: SourceHint = \"string\",\n    verbose: bool = False,\n) -&gt; bool:\n    \"\"\"Decide if 'remote' should be considered newer than 'current'.\n    Returns True iff remote &gt; current under the given source semantics.\n    \"\"\"\n    if current is None:\n        if verbose:\n            print(\n                f\"[is_newer_any] No current version. Treat {remote!r} \"\n                f\"as newer (source={source})\"\n            )\n        return True\n\n    cmpv = compare_any(remote, current, source=source, verbose=verbose)\n    if verbose:\n        if cmpv &gt; 0:\n            print(\n                f\"[is_newer_any] Remote {remote!r} is newer than \"\n                f\"current {current!r} (source={source})\"\n            )\n        elif cmpv == 0:\n            print(\n                f\"[is_newer_any] Remote {remote!r} is the same as \"\n                f\"current {current!r} (source={source})\"\n            )\n        else:\n            print(\n                f\"[is_newer_any] Remote {remote!r} is older than \"\n                f\"current {current!r} (source={source})\"\n            )\n    return cmpv &gt; 0\n</code></pre>"},{"location":"api/versioning/#notapkgtool.versioning.msi","title":"notapkgtool.versioning.msi","text":"<p>MSI ProductVersion extraction for NAPT.</p> <p>This module extracts the ProductVersion property from Windows Installer (MSI) database files. It tries multiple backends in order of preference to maximize cross-platform compatibility.</p> <p>Backend Priority:</p> <p>On Windows:</p> <ol> <li>msilib (Python standard library, Python 3.11+)</li> <li>_msi (CPython extension module, Windows-specific)</li> <li>PowerShell COM (Windows Installer COM API, always available)</li> </ol> <p>On Linux/macOS:</p> <ol> <li> <p>msiinfo (from msitools package, must be installed separately)</p> <p>The PowerShell fallback makes this truly universal on Windows systems, even when Python MSI libraries aren't available.</p> </li> </ol> <p>Installation Requirements:</p> <p>Windows:</p> <ul> <li>No additional packages required (PowerShell fallback always works)</li> <li>Optional: Ensure msilib is available for better performance</li> </ul> <p>Linux/macOS:</p> <ul> <li>Install msitools package:<ul> <li>Debian/Ubuntu: <code>sudo apt-get install msitools</code></li> <li>RHEL/Fedora: <code>sudo dnf install msitools</code></li> <li>macOS: <code>brew install msitools</code></li> </ul> </li> </ul> Example <p>Extract version from MSI:     <pre><code>from pathlib import Path\nfrom notapkgtool.versioning.msi import version_from_msi_product_version\ndiscovered = version_from_msi_product_version(\"chrome.msi\")\nprint(f\"{discovered.version} from {discovered.source}\")\n# 141.0.7390.123 from msi\n</code></pre></p> <p>Error handling:     <pre><code>try:\n    discovered = version_from_msi_product_version(\"missing.msi\")\nexcept PackagingError as e:\n    print(f\"Extraction failed: {e}\")\n</code></pre></p> Note <p>This is pure file introspection; no network calls are made. All backends query the MSI Property table for ProductVersion. The PowerShell approach uses COM (WindowsInstaller.Installer). Errors are chained for debugging (check 'from err' clause).</p>"},{"location":"api/versioning/#notapkgtool.versioning.msi.version_from_msi_product_version","title":"version_from_msi_product_version","text":"<pre><code>version_from_msi_product_version(file_path: str | Path, verbose: bool = False, debug: bool = False) -&gt; DiscoveredVersion\n</code></pre> <p>Extract ProductVersion from an MSI file.</p> <p>Uses cross-platform backends to read the MSI Property table. On Windows, tries msilib (Python 3.11+), _msi extension, then PowerShell COM API as universal fallback. On Linux/macOS, requires msitools package.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | Path</code> <p>Path to the MSI file.</p> required <code>verbose</code> <code>bool</code> <p>If True, print verbose logging messages. Default is False.</p> <code>False</code> <code>debug</code> <code>bool</code> <p>If True, print debug logging messages. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>DiscoveredVersion</code> <p>Discovered version with source information.</p> <p>Raises:</p> Type Description <code>PackagingError</code> <p>If the MSI file doesn't exist or version extraction fails.</p> <code>NotImplementedError</code> <p>If no extraction backend is available on this system.</p> Source code in <code>notapkgtool/versioning/msi.py</code> <pre><code>def version_from_msi_product_version(\n    file_path: str | Path, verbose: bool = False, debug: bool = False\n) -&gt; DiscoveredVersion:\n    \"\"\"Extract ProductVersion from an MSI file.\n\n    Uses cross-platform backends to read the MSI Property table. On Windows,\n    tries msilib (Python 3.11+), _msi extension, then PowerShell COM API as\n    universal fallback. On Linux/macOS, requires msitools package.\n\n    Args:\n        file_path: Path to the MSI file.\n        verbose: If True, print verbose logging messages.\n            Default is False.\n        debug: If True, print debug logging messages.\n            Default is False.\n\n    Returns:\n        Discovered version with source information.\n\n    Raises:\n        PackagingError: If the MSI file doesn't exist or version extraction fails.\n        NotImplementedError: If no extraction backend is available on this system.\n\n    \"\"\"\n    from notapkgtool.logging import get_global_logger\n\n    logger = get_global_logger()\n    p = Path(file_path)\n    if not p.exists():\n        raise PackagingError(f\"MSI not found: {p}\")\n\n    logger.verbose(\"VERSION\", \"Strategy: msi\")\n    logger.verbose(\"VERSION\", f\"Extracting version from: {p.name}\")\n\n    # Try msilib first (standard library on Windows)\n    if sys.platform.startswith(\"win\") and msilib is not None:\n        logger.debug(\"VERSION\", \"Trying backend: msilib...\")\n        try:\n            db = msilib.OpenDatabase(str(p), msilib.MSIDBOPEN_READONLY)\n            view = db.OpenView(\n                \"SELECT `Value` FROM `Property` WHERE `Property`='ProductVersion'\"\n            )\n            view.Execute(None)\n            rec = view.Fetch()\n            if rec is None:\n                db.Close()\n                raise PackagingError(\"ProductVersion not found in MSI Property table.\")\n            version = rec.GetString(1)\n            db.Close()\n            if not version:\n                raise PackagingError(\"Empty ProductVersion in MSI Property table.\")\n            logger.verbose(\"VERSION\", f\"Success! Extracted: {version} (via msilib)\")\n            return DiscoveredVersion(version=version, source=\"msi\")\n        except Exception as err:\n            logger.debug(\"VERSION\", \"msilib failed, trying next backend...\")\n            raise PackagingError(\n                f\"failed to read MSI ProductVersion via msilib: {err}\"\n            ) from err\n\n    # Try _msi module (alternative Windows approach)\n    if sys.platform.startswith(\"win\"):\n        logger.debug(\"VERSION\", \"Trying backend: _msi...\")\n        try:\n            import _msi  # type: ignore\n        except ImportError:\n            # _msi not available, fall through to msiinfo\n            logger.debug(\"VERSION\", \"_msi not available, trying next backend...\")\n            pass\n        else:\n            try:\n                db = _msi.OpenDatabase(str(p), 0)  # 0: read-only\n                view = db.OpenView(\n                    \"SELECT `Value` FROM `Property` WHERE `Property`='ProductVersion'\"\n                )\n                view.Execute(None)\n                rec = view.Fetch()\n                if rec is None:\n                    raise PackagingError(\n                        \"ProductVersion not found in MSI Property table.\"\n                    )\n                version = rec.GetString(1)\n                if not version:\n                    raise PackagingError(\"Empty ProductVersion in MSI Property table.\")\n                view.Close()\n                db.Close()\n                logger.verbose(\"VERSION\", f\"Success! Extracted: {version} (via _msi)\")\n                return DiscoveredVersion(version=version, source=\"msi\")\n            except Exception as err:\n                logger.debug(\"VERSION\", \"_msi failed, trying next backend...\")\n                raise PackagingError(\n                    f\"failed to read MSI ProductVersion via _msi: {err}\"\n                ) from err\n\n    # Try PowerShell with Windows Installer COM on Windows\n    if sys.platform.startswith(\"win\"):\n        logger.debug(\"VERSION\", \"Trying backend: PowerShell COM...\")\n        try:\n            ps_script = f\"\"\"\n$installer = New-Object -ComObject WindowsInstaller.Installer\n$db = $installer.OpenDatabase('{p}', 0)\n$view = $db.OpenView(\"SELECT Value FROM Property WHERE Property='ProductVersion'\")\n$view.Execute()\n$record = $view.Fetch()\nif ($record) {{\n    $record.StringData(1)\n}} else {{\n    Write-Error \"ProductVersion not found\"\n    exit 1\n}}\n\"\"\"\n            result = subprocess.run(\n                [\"powershell\", \"-NoProfile\", \"-NonInteractive\", \"-Command\", ps_script],\n                check=True,\n                capture_output=True,\n                text=True,\n                timeout=10,\n            )\n            version = result.stdout.strip()\n            if version:\n                logger.verbose(\n                    \"VERSION\", f\"Success! Extracted: {version} (via PowerShell COM)\"\n                )\n                return DiscoveredVersion(version=version, source=\"msi\")\n        except subprocess.CalledProcessError as err:\n            logger.debug(\"VERSION\", \"PowerShell COM failed, trying next backend...\")\n            raise PackagingError(f\"PowerShell MSI query failed: {err}\") from err\n        except subprocess.TimeoutExpired:\n            logger.debug(\"VERSION\", \"PowerShell COM timed out, trying next backend...\")\n            raise PackagingError(\"PowerShell MSI query timed out\") from None\n\n    # Try msiinfo on Linux/macOS\n    msiinfo = shutil.which(\"msiinfo\")\n    if msiinfo:\n        logger.debug(\"VERSION\", \"Trying backend: msiinfo (msitools)...\")\n        try:\n            # msiinfo export &lt;package&gt; Property -&gt; stdout (tab-separated)\n            result = subprocess.run(\n                [msiinfo, \"export\", str(p), \"Property\"],\n                check=True,\n                capture_output=True,\n                text=True,\n            )\n            version_str: str | None = None\n            for line in result.stdout.splitlines():\n                parts = line.strip().split(\"\\t\", 1)  # \"Property&lt;TAB&gt;Value\"\n                if len(parts) == 2 and parts[0] == \"ProductVersion\":\n                    version_str = parts[1]\n                    break\n            if not version_str:\n                raise PackagingError(\"ProductVersion not found in MSI Property output.\")\n            logger.verbose(\n                \"VERSION\", f\"Success! Extracted: {version_str} (via msiinfo)\"\n            )\n            return DiscoveredVersion(version=version_str, source=\"msi\")\n        except subprocess.CalledProcessError as err:\n            logger.debug(\"VERSION\", \"msiinfo failed\")\n            raise PackagingError(f\"msiinfo failed: {err}\") from err\n\n    logger.debug(\"VERSION\", \"No MSI extraction backend available on this system\")\n    raise NotImplementedError(\n        \"MSI version extraction is not available on this host. \"\n        \"On Windows, ensure PowerShell is available. \"\n        \"On Linux/macOS, install 'msitools'.\"\n    )\n</code></pre>"}]}